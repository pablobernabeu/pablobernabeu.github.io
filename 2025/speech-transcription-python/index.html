<!DOCTYPE html>
<html lang="en-uk">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.7.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Pablo Bernabeu">

  
  
  
    
  
  <meta name="description" content="A production-ready local transcription workflow leveraging OpenAI&#39;s Whisper models that addresses the limitations of cloud-based solutions through complete data sovereignty, unlimited scale, reproducible processing and advanced quality control, while maintaining GDPR compliance.">

  
  
  <meta name="indexnow-key" content="ba7d2697a8f44966bd90543d188a8aac">
  <meta name="indexnow-host" content="pablobernabeu.github.io">
  <meta name="indexnow-key-location" content="https://pablobernabeu.github.io/ba7d2697a8f44966bd90543d188a8aac.txt">
  

  
  <link rel="alternate" hreflang="en-uk" href="https://pablobernabeu.github.io/2025/speech-transcription-python/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      
        
      

      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  <style>/*!* Source Themes Academic v4.7.0 (https://sourcethemes.com/academic/) */
</style>
  <link rel="stylesheet" href="/css/academic.css">

  




  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu125e1cde4fb125eb9c515e372e2310e0_537990_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu125e1cde4fb125eb9c515e372e2310e0_537990_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://pablobernabeu.github.io/2025/speech-transcription-python/">

  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Pablo Bernabeu">
  <meta property="og:url" content="https://pablobernabeu.github.io/2025/speech-transcription-python/">
  <meta property="og:title" content="Secure and scalable speech transcription for local and HPC | Pablo Bernabeu">
  <meta property="og:description" content="A production-ready local transcription workflow leveraging OpenAI&#39;s Whisper models that addresses the limitations of cloud-based solutions through complete data sovereignty, unlimited scale, reproducible processing and advanced quality control, while maintaining GDPR compliance."><meta property="og:image" content="https://pablobernabeu.github.io/2025/speech-transcription-python/featured.png">
  <meta property="twitter:image" content="https://pablobernabeu.github.io/2025/speech-transcription-python/featured.png"><meta property="og:locale" content="en-uk">
  
    
      <meta property="article:published_time" content="2025-11-12T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2025-11-12T00:00:00&#43;00:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://pablobernabeu.github.io/2025/speech-transcription-python/"
  },
  "headline": "Secure and scalable speech transcription for local and HPC",
  
  "image": [
    "https://pablobernabeu.github.io/2025/speech-transcription-python/featured.png"
  ],
  
  "datePublished": "2025-11-12T00:00:00Z",
  "dateModified": "2025-11-12T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Pablo Bernabeu"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Pablo Bernabeu",
    "logo": {
      "@type": "ImageObject",
      "url": "https://pablobernabeu.github.io/images/icon_hu125e1cde4fb125eb9c515e372e2310e0_537990_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "A production-ready local transcription workflow leveraging OpenAI's Whisper models that addresses the limitations of cloud-based solutions through complete data sovereignty, unlimited scale, reproducible processing and advanced quality control, while maintaining GDPR compliance."
}
</script>

  

  


  


   
<script>
  (function () {
    "use strict";

    function getThemeMode() {
      try {
        const storedMode = localStorage.getItem("dark_mode");
        console.log("Theme init: stored dark_mode =", storedMode);
        return parseInt(storedMode || 2);
      } catch (e) {
        console.error("localStorage access failed:", e);
        return 2; 
      }
    }

    function shouldUseDarkTheme() {
      let currentThemeMode = getThemeMode();
      console.log("Theme init: currentThemeMode =", currentThemeMode);
      switch (currentThemeMode) {
        case 0:
          return false; 
        case 1:
          return true; 
        default:
          try {
            if (localStorage.getItem("dark_mode") === null) {
              console.log("Theme init: No preference saved, defaulting to light");
              return false; 
            }
          } catch (e) {
            console.error("localStorage check failed:", e);
          }
          return (
            window.matchMedia &&
            window.matchMedia("(prefers-color-scheme: dark)").matches
          );
      }
    }

    
    if (shouldUseDarkTheme()) {
      console.log("Theme init: Applying dark theme");
      document.documentElement.setAttribute("data-theme", "dark");
      document.documentElement.style.backgroundColor = "#0f172a";
      document.documentElement.style.color = "#e2e8f0";
      
      document.addEventListener("DOMContentLoaded", function() {
        document.body.classList.add("dark");
        console.log("Theme init: Added dark class to body");
      });
    } else {
      console.log("Theme init: Applying light theme");
    }
  })();
</script>

<link rel="stylesheet" href="/css/publication-type-badges.css">
<link rel="stylesheet" href="/css/custom-nav.css">
<script src="/js/open-science-badges.js" defer></script>
<script src="/js/publication-type-badge-colors.js" defer></script>
<script src="/js/publication-type-badge-popup.js" defer></script>
<script src="/js/github-button-fix.js" defer></script>
<script src="/js/abstract-heading-style.js" defer></script>



<link rel="stylesheet" href="/css/search-modal.css" />


<link rel="stylesheet" href="/css/tag-cloud-height.css" />


<script src="/js/tag-cloud-network.js"></script>


<script src="/js/article-ancillary-tags.js"></script>


<meta name="format-detection" content="telephone=no" />


<script>
  document.addEventListener("DOMContentLoaded", function () {
    setTimeout(function () {
      const searchModal = document.getElementById("search");
      if (!searchModal) return;

      let savedQuery = localStorage.getItem("searchQuery") || "";
      let savedResults = localStorage.getItem("searchResults") || "";
      window.searchModalPreventClose = false;

      
      function hasSearchResults() {
        const searchHits = document.getElementById("search-hits");
        return (
          searchHits && searchHits.querySelectorAll(".search-hit").length > 0
        );
      }

      
      function saveSearchResults() {
        const searchHits = document.getElementById("search-hits");
        if (searchHits && hasSearchResults()) {
          savedResults = searchHits.innerHTML;
          localStorage.setItem("searchResults", savedResults);
          console.log("Saved search results");
        }
      }

      
      function restoreSearchResults() {
        if (savedResults) {
          const searchHits = document.getElementById("search-hits");
          if (searchHits) {
            searchHits.innerHTML = savedResults;
            console.log("Restored search results");
          }
        }
      }

      
      function isModalVisible() {
        return (
          getComputedStyle(searchModal).display !== "none" &&
          searchModal.offsetParent !== null
        );
      }

      
      function saveQuery() {
        const searchInput = document.getElementById("search-query");
        if (searchInput && searchInput.value.trim()) {
          savedQuery = searchInput.value;
          localStorage.setItem("searchQuery", savedQuery);
          console.log("Saved query:", savedQuery);
        }
      }

      
      function forceRestoreQuery() {
        if (savedQuery) {
          const searchInput = document.getElementById("search-query");
          if (searchInput) {
            
            searchInput.value = savedQuery;
            searchInput.setAttribute("value", savedQuery);
            searchInput.defaultValue = savedQuery;

            console.log("Force restored query:", savedQuery);

            
            searchInput.dispatchEvent(new Event("input", { bubbles: true }));
          }
        }
      }

      
      const searchInput = document.getElementById("search-query");
      if (searchInput) {
        
        const originalDescriptor = Object.getOwnPropertyDescriptor(
          HTMLInputElement.prototype,
          "value"
        );

        
        Object.defineProperty(searchInput, "value", {
          get: function () {
            const currentValue = originalDescriptor.get.call(this);
            
            if (!currentValue && savedQuery && isModalVisible()) {
              console.log(
                "Intercepted empty value read, returning saved query:",
                savedQuery
              );
              return savedQuery;
            }
            return currentValue;
          },
          set: function (newValue) {
            console.log("Value being set to:", newValue);

            
            if (!newValue && savedQuery && isModalVisible()) {
              console.log(
                "BLOCKED attempt to clear input while modal is visible"
              );
              return; 
            }

            
            originalDescriptor.set.call(this, newValue);

            
            if (newValue && newValue.trim()) {
              savedQuery = newValue;
              localStorage.setItem("searchQuery", newValue);
              console.log("Saved new query via setter:", newValue);
            }
          },
          configurable: true,
        });

        searchInput.addEventListener("input", function () {
          if (this.value && this.value.trim()) {
            savedQuery = this.value;
            localStorage.setItem("searchQuery", this.value);
          }

          
          const hasResults = hasSearchResults();
          const hasQuery = this.value.trim().length > 0;
          window.searchModalPreventClose = hasResults || hasQuery;

          
          if (hasResults) {
            setTimeout(saveSearchResults, 200); 
          }
        });

        
        if (savedQuery) {
          originalDescriptor.set.call(searchInput, savedQuery);
        }
      }

      
      new MutationObserver(function (mutations) {
        mutations.forEach(function (mutation) {
          if (
            mutation.type === "attributes" &&
            (mutation.attributeName === "style" ||
              mutation.attributeName === "class")
          ) {
            const isVisible = isModalVisible();

            if (isVisible && !this.wasVisible) {
              
              console.log("Modal opened");
              if (savedQuery && searchInput) {
                
                const originalDescriptor = Object.getOwnPropertyDescriptor(
                  HTMLInputElement.prototype,
                  "value"
                );
                originalDescriptor.set.call(searchInput, savedQuery);

                
                if (savedResults) {
                  restoreSearchResults();
                }

                searchInput.dispatchEvent(
                  new Event("input", { bubbles: true })
                );
                console.log(
                  "Restored query and results on modal open:",
                  savedQuery
                );
              }
            }

            this.wasVisible = isVisible;
          }
        });
      }).observe(searchModal, {
        attributes: true,
        attributeFilter: ["style", "class"],
      });

      
      searchModal.addEventListener("click", function (e) {
        if (e.target === searchModal) {
          const hasResults = hasSearchResults();
          const hasQuery = searchInput && searchInput.value.trim().length > 0;

          if (hasResults || hasQuery) {
            e.preventDefault();
            e.stopPropagation();
            e.stopImmediatePropagation();
            return false;
          }
        }
      });

      
      document.addEventListener("keydown", function (e) {
        if (e.key === "Escape" && isModalVisible()) {
          saveQuery();
          saveSearchResults();
        }
      });

      
      const searchHits = document.getElementById("search-hits");
      if (searchHits) {
        new MutationObserver(function (mutations) {
          mutations.forEach(function (mutation) {
            if (mutation.type === "childList" && hasSearchResults()) {
              
              setTimeout(saveSearchResults, 300);
            }
          });
        }).observe(searchHits, { childList: true, subtree: true });
      }
    }, 1000);
  });
</script>

 
<script>
  window.addEventListener("load", function () {
    if (typeof IndexNowSubmission !== "undefined") {
      setTimeout(function () {
        IndexNowSubmission.submitCurrentPage();
      }, 2000);
    }
  });
</script>



  <title>Secure and scalable speech transcription for local and HPC | Pablo Bernabeu</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="   Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>

  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Pablo Bernabeu</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Pablo Bernabeu</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publication"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#applications-and-dashboards"><span><span data-toggle="tooltip1" data-placement="bottom" title=" &nbsp; Web applications and data dashboards &nbsp; ">Web Apps</span></span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#workshops"><span><span data-toggle="tooltip1" data-placement="bottom" title=" &nbsp; Presentations and workshops &nbsp; ">Presentations</span></span></a>
        </li>

        
        

        

        
        
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#bio"><span><span data-toggle="tooltip1" data-placement="bottom" title=" &nbsp; Contact &nbsp; | &nbsp; CV &nbsp; | &nbsp; Work &nbsp; | &nbsp; Education &nbsp; | &nbsp; Teaching and supervision &nbsp; | &nbsp; Funding &nbsp; | &nbsp; Other work &nbsp; | &nbsp; Skills &nbsp; ">CV+</span></span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#multimedia"><span><span data-toggle="tooltip1" data-placement="bottom" title=" &nbsp; Videos and podcasts &nbsp; ">Multimedia</span></span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#blog"><span><span data-toggle="tooltip1" data-placement="bottom" title=" &nbsp; Short essays &nbsp; | &nbsp; Tutorials &nbsp; | &nbsp; Inquiries &nbsp; | &nbsp; Functions for the implementation of experiments, data analysis and other purposes &nbsp; ">Resources</span></span></a>
        </li>

        
        

        

        
        
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/#"><span><i class='fas fa-search js-search-trigger'></i> <span class='d-lg-none js-search-trigger'>Search</span></span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      

      <li class="nav-item dropdown">
        <button type="button" class="nav-link js-font-size-toggle"><i class="fas fa-text-height" aria-hidden="true"></i></button>
        <div class="dropdown-menu dropdown-menu-right font-size-menu">
          <a class="dropdown-item js-font-increase" href="javascript:void(0)"><i class="fas fa-plus"></i> Larger font</a>
          <a class="dropdown-item js-font-reset" href="javascript:void(0)"><i class="fas fa-undo"></i> Reset</a>
          <a class="dropdown-item js-font-decrease" href="javascript:void(0)"><i class="fas fa-minus"></i> Smaller font</a>
        </div>
      </li>

      
      <li class="nav-item dropdown theme-dropdown">
        <button type="button" class="nav-link js-theme-toggle"><i class="fas fa-adjust" aria-hidden="true"></i></button>
        <div class="dropdown-menu dropdown-menu-right theme-menu">
          <a class="dropdown-item js-set-theme-light" href="javascript:void(0)">
            <i class="fas fa-sun"></i> Light
          </a>
          <a class="dropdown-item js-set-theme-dark" href="javascript:void(0)">
            <i class="fas fa-moon"></i> Dark
          </a>
        </div>
      </li>
      

      

    </ul>

  </div>
</nav>


  <article class="article">

  



















<div class="article-container pt-3">
  <h1>Secure and scalable speech transcription for local and HPC</h1>

  

  



  


<div class="article-metadata">

  
  

  
    
    
      
    
    
    <span style='font-size:100%;'>
      2025
    <span >
    
  

  

  

  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/categories/software/">software</a></span>
  

</div>

  














</div>

<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 402px;">
  <div style="position: relative">
    <img src="/2025/speech-transcription-python/featured_hu86bda7ae30f0e79cd5c3621119e57107_5810058_720x0_resize_lanczos_2.png" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      
<script src="https://pablobernabeu.github.io/2025/speech-transcription-python/index.en_files/clipboard/clipboard.min.js"></script>
<link href="https://pablobernabeu.github.io/2025/speech-transcription-python/index.en_files/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
<script src="https://pablobernabeu.github.io/2025/speech-transcription-python/index.en_files/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
<script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>


<div id="the-evolution-of-transcription-technology" class="section level2">
<h2>The Evolution of Transcription Technology</h2>
<p>The landscape of speech-to-text transcription has undergone a remarkable transformation in recent years, driven by the proliferation of generative artificial intelligence (genAI) tools. From basic dictation software to sophisticated neural networks, transcription technology has evolved to handle diverse audio conditions, multiple languages and complex speech patterns with unprecedented accuracy.</p>
<p>At the forefront of this revolution stands <a href="https://github.com/openai/whisper">OpenAI’s Whisper model family</a>, released as open-source tools that have democratised access to state-of-the-art <a href="https://huggingface.co/models?pipeline_tag=automatic-speech-recognition">automatic speech recognition (ASR)</a> capabilities. True to the “Open” in OpenAI’s original mission, these models have become the gold standard for transcription tasks, offering researchers and developers robust, multilingual speech recognition that rivals proprietary commercial solutions. The Whisper architecture, trained on 680,000 hours of multilingual audio data, represents a paradigm shift toward generalisable, production-ready ASR systems that can handle real-world audio conditions without extensive fine-tuning.</p>
</div>
<div id="chatbots-and-limitations" class="section level2">
<h2>Chatbots and Limitations</h2>
<p>Large Language Model chatbots such as <a href="https://chat.openai.com/">ChatGPT</a> and <a href="https://gemini.google.com/">Google Gemini</a> allow uploading recordings and having them transcribed using advanced models such as Whisper. However, this route has several limitations that make it unsuitable for serious research and production workflows.</p>
<p>First, cloud-based chatbot interfaces impose strict file size limitations, typically restricting uploads to recordings of 25MB or less, which translates to roughly 20-30 minutes of audio content. This constraint renders them impractical for transcribing lengthy interviews, focus groups, or extended research sessions that often span multiple hours.</p>
<p>Second, chatbot-based transcription provides significantly less reproducibility than local workflows. The exact model versions, processing parameters and post-processing steps remain opaque to users, making it impossible to replicate results or maintain consistent transcription quality across different sessions. This lack of transparency is particularly problematic for academic research where methodological rigor and reproducibility are paramount.</p>
<p>Third, when working with confidential or sensitive recordings, cloud-based solutions introduce substantial privacy and compliance risks. While some platforms offer temporary chat modes that allegedly prevent model training using uploaded content, this approach still requires transmitting sensitive audio data to third-party servers, potentially violating institutional policies, research ethics requirements, or data protection regulations such as the <a href="https://gdpr.eu/">General Data Protection Regulation (GDPR)</a>.</p>
</div>
<div id="addressing-the-limitations-python-supported-local-workflow" class="section level2">
<h2>Addressing the Limitations: Python-Supported Local Workflow</h2>
<p>The constraints of cloud-based transcription can be comprehensively addressed by implementing a secure, self-contained, local workflow that leverages the same advanced models while maintaining complete control over data processing and storage. This <a href="https://github.com/pablobernabeu/secure_local_HPC_speech_transcription">production-grade transcription system</a> offers several compelling advantages over cloud alternatives:</p>
<div id="complete-data-sovereignty-and-gdpr-compliance" class="section level3">
<h3>Complete Data Sovereignty and GDPR Compliance</h3>
<p>By executing all processing on local or institutional infrastructure, the workflow ensures that sensitive audio content never leaves the controlled environment. This approach provides full GDPR compliance and satisfies the stringent data protection requirements common in academic research, healthcare and corporate environments. The system downloads pre-trained models once and runs them entirely offline, eliminating ongoing data transmission concerns.</p>
</div>
<div id="unlimited-scale-and-batch-processing-capabilities" class="section level3">
<h3>Unlimited Scale and Batch Processing Capabilities</h3>
<p>Unlike cloud services with arbitrary file size limitations, the local workflow can process audio files of any length and handle large-scale batch operations. The system supports parallel processing across multiple graphics processing unit (GPU) nodes in high-performance computing (HPC) environments, enabling researchers to transcribe hundreds of hours of audio content efficiently. The intelligent job scheduling system automatically detects available files and optimises resource allocation across computing clusters.</p>
</div>
<div id="reproducible-and-auditable-processing" class="section level3">
<h3>Reproducible and Auditable Processing</h3>
<p>Every aspect of the transcription pipeline is configurable and documented, from model selection and audio enhancement parameters to text processing rules and privacy protection settings. This transparency enables researchers to maintain detailed methodological records, reproduce results across different time periods and adjust processing parameters to optimise for specific audio conditions or research requirements.</p>
</div>
<div id="advanced-quality-control-and-post-processing" class="section level3">
<h3>Advanced Quality Control and Post-Processing</h3>
<p>The workflow incorporates sophisticated quality improvement algorithms that address common artefacts introduced by generative artificial intelligence models. These include automatic detection and removal of spurious repetitions, intelligent punctuation correction and context-aware personal name masking that prevents false positives whilst maintaining conversation flow and readability.</p>
</div>
<div id="flexible-audio-enhancement-pipeline" class="section level3">
<h3>Flexible Audio Enhancement Pipeline</h3>
<p>The system includes an optional audio enhancement stage that applies spectral noise reduction, dynamic range compression and signal amplification to improve transcription quality for challenging audio conditions. This preprocessing stage uses the first 0.5 seconds of each recording as a noise reference, enabling adaptive enhancement that adjusts to different recording environments.</p>
</div>
<div id="multi-model-support-and-future-proofing" class="section level3">
<h3>Multi-Model Support and Future-Proofing</h3>
<p>While optimised for OpenAI’s Whisper models, the architecture supports any <a href="https://huggingface.co/">HuggingFace</a>-compatible <a href="https://huggingface.co/models?pipeline_tag=automatic-speech-recognition">ASR model</a>, enabling researchers to experiment with specialised models for domain-specific applications or incorporate newer model releases as they become available. The modular design ensures long-term sustainability and adaptability to evolving transcription technologies.</p>
</div>
</div>
<div id="example-output" class="section level2">
<h2>Example Output</h2>
<p>The repository includes <a href="https://github.com/pablobernabeu/secure_local_HPC_speech_transcription/tree/main/example_output">example output files</a> demonstrating the system’s transcription quality and formatting. Below is an <a href="https://github.com/pablobernabeu/secure_local_HPC_speech_transcription/blob/main/example_output/transcripts/The%20modular%20mini-grammar_%20Building%20testable%20and%20reproducible%20artificial%20languages%20using%20FAIR%20principles_transcript.txt">example transcript</a>:</p>
<textarea readonly style='border-color: lightgrey; overflow: hidden; color: darkblue; font-size: 90%; min-width: 100%; height: 80vh; white-space: pre-wrap; overflow-wrap: normal; padding-right: 0.5em; padding-left: 1em;'></textarea>
<script>
fetch('https://raw.githubusercontent.com/pablobernabeu/secure_local_HPC_speech_transcription/refs/heads/main/example_output/transcripts/The%20modular%20mini-grammar_%20Building%20testable%20and%20reproducible%20artificial%20languages%20using%20FAIR%20principles_transcript.txt')
  .then(response => response.text())
  .then(data => {
    document.querySelector('textarea').textContent = data;
  });
</script>
</div>
<div id="technical-architecture" class="section level2">
<h2>Technical Architecture</h2>
<p>The system is implemented as a monolithic <a href="https://www.python.org/">Python</a> script, <a href="https://github.com/pablobernabeu/secure_local_HPC_speech_transcription/blob/main/transcription.py"><code>transcription.py</code></a>, which integrates all core components into a single, self-contained processing engine. This architectural choice prioritises simplicity, maintainability and ease of deployment without external module dependencies. The script orchestrates a multi-stage pipeline and resolves several critical technical challenges through a unified command-line interface.</p>
<script src='https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Fsecure_local_HPC_speech_transcription%2Fblob%2Fmain%2Ftranscription.py%23L1096-L1117&style=a11y-dark&type=code&showFullPath=on&showCopy=on&showLineNumbers=on&showFileMeta=on'></script>
<div id="core-technical-solutions" class="section level3">
<h3>Core Technical Solutions</h3>
<p><strong>Challenge 1: GenAI-Generated Repetitions</strong>
A significant hurdle with generative AI models like Whisper is their tendency to produce spurious repetitions—a form of hallucination where the model gets “stuck” and repeats phrases.</p>
<ul>
<li><strong>Solution</strong>: The <code>--fix-spurious-repetitions</code> flag activates a sophisticated repetition detection algorithm. It analyses text patterns to distinguish between intentional, natural emphasis and AI-generated artefacts by considering the frequency, context, and structure of repeated segments.</li>
</ul>
<p><strong>Challenge 2: GenAI-Generated Language Switching</strong>
Whisper models can erroneously switch languages when interpreting phonetically ambiguous sounds.</p>
<ul>
<li><strong>Solution</strong>: The <code>--language</code> argument constrains the model to the designated language, preventing unwanted language switches while maintaining transcription accuracy.</li>
</ul>
<p><strong>Challenge 3: Intelligent and Private Name Masking</strong>
A key challenge is reliably identifying personal names while avoiding the masking of common words or technical terms (false positives).</p>
<ul>
<li><strong>Solution</strong>: The system uses a sophisticated, multi-tiered approach. The default is a curated database of over 1,793 names across nine languages, refined to minimise false positives on common words. For broader coverage, optional databases from Facebook (over 1.7 million names) can be enabled, though this increases the risk of false positives. Users can also provide custom lists of names to exclude from masking, which is useful for preserving the names of public figures or research team members.</li>
</ul>
<p><strong>Challenge 4: Scalable High-Performance Computing (HPC) Integration</strong>
The workflow is designed for large-scale batch processing in HPC environments using a Simple Linux Utility for Resource Management (SLURM) scheduler.</p>
<ul>
<li><strong>Solution</strong>: A collection of submission scripts provides dynamic job array sizing, automatically matching the number of jobs to the number of input files. The system intelligently optimises resource use by prioritising GPU allocation with a graceful fallback to CPU, ensuring continuous operation. It also includes comprehensive error detection and recovery. Users can override default HPC resource allocations using the <code>--memory</code> and <code>--time-limit</code> arguments for exceptionally large or complex files.</li>
</ul>
<p><strong>Challenge 5: Reproducible and Stable Environments</strong>
Creating a consistent Python environment across different platforms can be difficult due to dependency conflicts.</p>
<ul>
<li><strong>Solution</strong>: The project includes platform-agnostic setup scripts that automatically detect and adapt to different HPC module systems. They manage complex dependencies, particularly for <a href="https://pytorch.org/">PyTorch</a> and <a href="https://developer.nvidia.com/cuda-toolkit">CUDA</a>, and use version pinning to ensure stability and reproducibility.</li>
</ul>
<p><strong>Challenge 6: Speaker Attribution (Diarisation)</strong>
Identifying who is speaking in a multi-speaker recording is a common requirement.</p>
<ul>
<li><strong>Solution</strong>: The system integrates <a href="https://github.com/pyannote/pyannote-audio"><code>pyannote.audio</code></a> for speaker diarisation, which can be enabled with the <code>--speaker-attribution</code> flag. This feature requires a <a href="https://huggingface.co/settings/tokens">HuggingFace user access token</a> for the <a href="https://huggingface.co/pyannote/speaker-diarization-3.1"><code>pyannote/speaker-diarization-3.1</code></a> model.</li>
</ul>
</div>
</div>
<div id="describing-the-method-in-publications" class="section level2">
<h2>Describing the Method in Publications</h2>
<p>For researchers incorporating this workflow into their methodology, the following description provides a comprehensive yet concise summary suitable for academic publications:</p>
<blockquote>
<p>Audio recordings were transcribed using <a href="https://huggingface.co/openai/whisper-large-v3">OpenAI’s Whisper large-v3 model</a>, a state-of-the-art automatic speech recognition system (Batista, 2024). The transcription workflow maintained full GDPR compliance through a local implementation where the pre-trained model was downloaded from the OpenAI repository on the <a href="https://huggingface.co/">Hugging Face platform</a> and executed entirely on institutional high-performance computing infrastructure, ensuring no audio data or transcription content was transmitted to or processed by third-party services.</p>
<p>The pipeline incorporated several processing stages: optional audio enhancement for improved signal quality using spectral noise reduction and dynamic range compression, configurable language specification to prevent unwanted language switching artefacts, automatic detection and removal of spurious text repetitions generated by the AI model, comprehensive spelling corrections and text formatting, and privacy protection through intelligent personal name masking that replaced detected names with anonymised placeholders whilst avoiding false positives on common conversational words.</p>
<p>Quality control measures included automatic repetition pattern detection to remove AI-generated artefacts, punctuation spacing corrections and context-aware text processing to maintain natural conversation flow. The system generated both plain text transcripts and formatted Microsoft Word documents with comprehensive processing metadata and timestamps for reproducibility and audit purposes.</p>
<p><strong>Reference</strong></p>
<p>Batista, J. R. (2024). <em>Learn OpenAI Whisper: Transform your understanding of GenAI through robust and accurate speech processing solutions</em>. Packt Publishing Ltd.</p>
</blockquote>
<div id="licence" class="section level3">
<h3>Licence</h3>
<p>This workflow is made available under the <a href="https://github.com/pablobernabeu/secure_local_HPC_speech_transcription/blob/main/Licence.md">Creative Commons 4.0 Attribution 4.0 International licence</a>.</p>
</div>
<div id="citation" class="section level3">
<h3>Citation</h3>
<div style="text-align: left;">
<p><a href="https://doi.org/10.5281/zenodo.17624830"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.17624830.svg" alt="DOI" style="display: inline-block; margin: 0;"></a></p>
</div>
<p>If you use this workflow in your research, please cite:</p>
<blockquote>
<p class="hanging-indent">
Bernabeu, P. (2025). <em>Secure and scalable speech transcription for local and HPC</em> (Version 1.0.0) [Computer software]. Zenodo. <a href="https://doi.org/10.5281/zenodo.17624830" class="uri">https://doi.org/10.5281/zenodo.17624830</a>
</p>
</blockquote>
<p>The recommended BibTeX entry is:</p>
<pre class="text"><code>@misc{secure_local_HPC_speech_transcription,
  author    = {Bernabeu, Pablo},
  title     = {Secure and scalable speech transcription for local and {HPC}},
  year      = {2025},
  publisher = {Zenodo},
  version   = {1.0.0},
  doi       = {10.5281/zenodo.17624830},
  url       = {https://doi.org/10.5281/zenodo.17624830}
}</code></pre>
</div>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>This comprehensive transcription workflow represents a mature, production-ready alternative to cloud-based transcription services, specifically designed to meet the demanding requirements of research and development environments. By combining state-of-the-art AI models with robust engineering practices within a monolithic, easily maintainable architecture, the system delivers high-quality transcription capabilities whilst maintaining complete control over data processing, privacy protection and quality assurance.</p>
<p>The workflow’s emphasis on reproducibility, scalability and simplicity makes it particularly valuable for research applications where methodological rigour and long-term sustainability are essential. As speech recognition technology continues to evolve, this straightforward architecture ensures that researchers can incorporate new developments whilst maintaining the stability and clarity required for research workflows.</p>
<p>For organisations seeking to leverage advanced transcription capabilities without compromising data sovereignty or processing control, this workflow provides a compelling foundation for building sophisticated speech processing pipelines that can grow and adapt with emerging technologies and evolving research requirements.</p>
<div style="text-align: center; margin: 2em 0;">
<p><a href="https://github.com/pablobernabeu/secure_local_HPC_speech_transcription" target="_blank" class="github-workflow-button">
<svg style="width: 1.2em; height: 1.2em; vertical-align: middle; margin-right: 0.5em; fill: currentColor;" viewBox="0 0 16 16">
<path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/>
</svg>
View Workflow on GitHub
</a></p>
</div>
</div>

    </div>

    



<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/s/">s</a>
  
  <a class="badge badge-light" href="/tags/software/">software</a>
  
  <a class="badge badge-light" href="/tags/speech-to-text/">speech-to-text</a>
  
  <a class="badge badge-light" href="/tags/speech-recognition/">speech recognition</a>
  
  <a class="badge badge-light" href="/tags/transcription/">transcription</a>
  
  <a class="badge badge-light" href="/tags/whisper/">Whisper</a>
  
  <a class="badge badge-light" href="/tags/machine-learning/">machine learning</a>
  
  <a class="badge badge-light" href="/tags/huggingface/">huggingface</a>
  
  <a class="badge badge-light" href="/tags/python/">Python</a>
  
  <a class="badge badge-light" href="/tags/openai/">OpenAI</a>
  
  <a class="badge badge-light" href="/tags/natural-language-processing/">natural language processing</a>
  
  <a class="badge badge-light" href="/tags/audio-processing/">audio processing</a>
  
  <a class="badge badge-light" href="/tags/gdpr/">GDPR</a>
  
  <a class="badge badge-light" href="/tags/data-protection/">data protection</a>
  
  <a class="badge badge-light" href="/tags/data-privacy/">data privacy</a>
  
  <a class="badge badge-light" href="/tags/high-performance-computing/">high-performance computing</a>
  
  <a class="badge badge-light" href="/tags/privacy/">privacy</a>
  
</div>










<section id="comments">
  
    
<div id="disqus_thread"></div>
<script>
  let disqus_config = function () {
    
    
    
  };
  (function() {
    if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
      document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
      return;
    }
    var d = document, s = d.createElement('script'); s.async = true;
    s.src = 'https://' + "pablobernabeu-github-io" + '.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  
</section>






  
  



  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/htmlbars.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/css.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/javascript.min.js"></script>
        
      

    

    
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":2,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"   Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'presentation' : "Presentations"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.86be304a660142ef2ec2399e381fe5b1.js"></script>

    
    
    <script src="/js/indexnow.js"></script>
    

    
<script>
document.addEventListener('DOMContentLoaded', function() {
  
  if (window.innerWidth <= 991) {
    const toggler = document.querySelector('.navbar-toggler');
    const navbarCollapse = document.querySelector('#navbar-content');
    
    if (toggler && navbarCollapse) {
      
      toggler.addEventListener('mouseenter', function() {
        if (!navbarCollapse.classList.contains('show')) {
          $(navbarCollapse).collapse('show');
        }
      });
      
      
      
    }
  }
  
  
  if (typeof $ !== 'undefined') {
    $('[data-toggle="tooltip"]').tooltip('disable');
    $('[data-toggle="popover"]').popover('disable');
  }
});
</script>


<script src="/js/article-ancillary-tags.js"></script>



  
  
  <div class="container">
    



<footer class="site-footer">
  
  <p class="powered-by">
    Pablo Bernabeu, 2015—2026. Licence: <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. Email: <a href="mailto:pcbernabeu@gmail.com">pcbernabeu@gmail.com</a>. Cookies only used by third-party systems such as <a href="https://help.disqus.com/en/articles/1717155-use-of-cookies">Disqus</a>. &middot; 

    Website powered by the <a href="https://themes.gohugo.io/themes/starter-hugo-academic" rel="noopener">Academic theme</a> for <a href="https://gohugo.io" rel="noopener">Hugo</a> and by <a href='https://github.com/rstudio/blogdown' rel="noopener">blogdown</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top" style="background-image:none;">
        <span class="button_icon" style="background-image:none;">
          <i class="fas fa-chevron-up fa-2x" style="background-image:none;"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Citation</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
