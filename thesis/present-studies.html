<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>The present studies | Language and sensorimotor simulation in conceptual processing: Multilevel analysis and statistical power</title>
  <meta name="description" content="Research has suggested that conceptual processing depends on both language-based and sensorimotor information. In this thesis, I investigate the nature of these systems and their interplay at three levels of the experimental structure—namely, individuals, words and tasks. In Study 1, I contributed to a multi-lab replication of the object orientation effect, which has been used to test sensorimotor simulation. The effect did not appear in any of the 18 languages examined, and it was not influenced by individual differences in mental rotation. Next, in Study 2, we drew on three existing data sets that implemented semantic priming, semantic decision and lexical decision. We extended these data sets with measures of language-based and vision-based information, and analysed their interactions with participants’ vocabulary size and gender, and with presentation speed. The analysis had a conservative structure of fixed and random effects. First, we found that language-based information was more important than vision-based information. Second, in the semantic priming study—whose task required distinguishing between words and nonwords—, both language-based and vision-based information were more influential when words were presented faster. Third, a ‘task-relevance advantage’ was identified in higher-vocabulary participants. Specifically, in lexical decision, higher-vocabulary participants were more sensitive to language-based information than lower-vocabulary participants, whereas in semantic decision, higher-vocabulary participants were more sensitive to word concreteness. Fourth, we demonstrated the influence of the analytical method on the results. Last, we estimated the sample size required to investigate various effects. We found that 300 participants were sufficient to examine the effect of language-based information in words, whereas more than 1,000 participants were necessary to examine the effect of vision-based information and the interactions of both former variables with vocabulary size, gender and presentation speed. This power analysis suggests that larger sample sizes are necessary to investigate perceptual simulation and individual differences in conceptual processing." />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="The present studies | Language and sensorimotor simulation in conceptual processing: Multilevel analysis and statistical power" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Research has suggested that conceptual processing depends on both language-based and sensorimotor information. In this thesis, I investigate the nature of these systems and their interplay at three levels of the experimental structure—namely, individuals, words and tasks. In Study 1, I contributed to a multi-lab replication of the object orientation effect, which has been used to test sensorimotor simulation. The effect did not appear in any of the 18 languages examined, and it was not influenced by individual differences in mental rotation. Next, in Study 2, we drew on three existing data sets that implemented semantic priming, semantic decision and lexical decision. We extended these data sets with measures of language-based and vision-based information, and analysed their interactions with participants’ vocabulary size and gender, and with presentation speed. The analysis had a conservative structure of fixed and random effects. First, we found that language-based information was more important than vision-based information. Second, in the semantic priming study—whose task required distinguishing between words and nonwords—, both language-based and vision-based information were more influential when words were presented faster. Third, a ‘task-relevance advantage’ was identified in higher-vocabulary participants. Specifically, in lexical decision, higher-vocabulary participants were more sensitive to language-based information than lower-vocabulary participants, whereas in semantic decision, higher-vocabulary participants were more sensitive to word concreteness. Fourth, we demonstrated the influence of the analytical method on the results. Last, we estimated the sample size required to investigate various effects. We found that 300 participants were sufficient to examine the effect of language-based information in words, whereas more than 1,000 participants were necessary to examine the effect of vision-based information and the interactions of both former variables with vocabulary size, gender and presentation speed. This power analysis suggests that larger sample sizes are necessary to investigate perceptual simulation and individual differences in conceptual processing." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="The present studies | Language and sensorimotor simulation in conceptual processing: Multilevel analysis and statistical power" />
  
  <meta name="twitter:description" content="Research has suggested that conceptual processing depends on both language-based and sensorimotor information. In this thesis, I investigate the nature of these systems and their interplay at three levels of the experimental structure—namely, individuals, words and tasks. In Study 1, I contributed to a multi-lab replication of the object orientation effect, which has been used to test sensorimotor simulation. The effect did not appear in any of the 18 languages examined, and it was not influenced by individual differences in mental rotation. Next, in Study 2, we drew on three existing data sets that implemented semantic priming, semantic decision and lexical decision. We extended these data sets with measures of language-based and vision-based information, and analysed their interactions with participants’ vocabulary size and gender, and with presentation speed. The analysis had a conservative structure of fixed and random effects. First, we found that language-based information was more important than vision-based information. Second, in the semantic priming study—whose task required distinguishing between words and nonwords—, both language-based and vision-based information were more influential when words were presented faster. Third, a ‘task-relevance advantage’ was identified in higher-vocabulary participants. Specifically, in lexical decision, higher-vocabulary participants were more sensitive to language-based information than lower-vocabulary participants, whereas in semantic decision, higher-vocabulary participants were more sensitive to word concreteness. Fourth, we demonstrated the influence of the analytical method on the results. Last, we estimated the sample size required to investigate various effects. We found that 300 participants were sufficient to examine the effect of language-based information in words, whereas more than 1,000 participants were necessary to examine the effect of vision-based information and the interactions of both former variables with vocabulary size, gender and presentation speed. This power analysis suggests that larger sample sizes are necessary to investigate perceptual simulation and individual differences in conceptual processing." />
  

<meta name="author" content="Pablo César de Juan Bernabéu" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="misc/favicon.png" type="image/x-icon" />
<link rel="prev" href="chapter-3-study-2.-language-and-vision-in-conceptual-processing-multilevel-analysis-and-statistical-power.html"/>
<link rel="next" href="general-methods.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/codefolding-lua-1.1/codefolding-lua.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="misc/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href='./'>Language and sensorimotor simulation<br>in conceptual processing: Multilevel<br>analysis and statistical power</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="" data-path="acknowledgements-and-declaration.html"><a href="acknowledgements-and-declaration.html"><i class="fa fa-check"></i>Acknowledgements and declaration</a>
<ul>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="declaration.html"><a href="declaration.html"><i class="fa fa-check"></i>Declaration</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="setup-code.html"><a href="setup-code.html"><i class="fa fa-check"></i>Setup code</a></li>
<li class="chapter" data-level="" data-path="chapter-1-introduction.html"><a href="chapter-1-introduction.html"><i class="fa fa-check"></i>Chapter 1: Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="language-and-embodiment.html"><a href="language-and-embodiment.html"><i class="fa fa-check"></i>Language and embodiment</a></li>
<li class="chapter" data-level="" data-path="the-present-thesis.html"><a href="the-present-thesis.html"><i class="fa fa-check"></i>The present thesis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="chapter-2-study-1-investigating-object-orientation-effects-across-18-languages.html"><a href="chapter-2-study-1-investigating-object-orientation-effects-across-18-languages.html"><i class="fa fa-check"></i>Chapter 2 (Study 1): Investigating object orientation effects across 18 languages</a>
<ul>
<li class="chapter" data-level="" data-path="study-and-methods.html"><a href="study-and-methods.html"><i class="fa fa-check"></i>Study and methods</a></li>
<li class="chapter" data-level="" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i>Results</a></li>
<li class="chapter" data-level="" data-path="discussion.html"><a href="discussion.html"><i class="fa fa-check"></i>Discussion</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="chapter-3-study-2.-language-and-vision-in-conceptual-processing-multilevel-analysis-and-statistical-power.html"><a href="chapter-3-study-2.-language-and-vision-in-conceptual-processing-multilevel-analysis-and-statistical-power.html"><i class="fa fa-check"></i>Chapter 3 (Study 2). Language and vision in conceptual processing: Multilevel analysis and statistical power</a>
<ul>
<li class="chapter" data-level="" data-path="present-studies.html"><a href="present-studies.html"><i class="fa fa-check"></i>The present studies</a>
<ul>
<li class="chapter" data-level="" data-path="present-studies.html"><a href="present-studies.html#language"><i class="fa fa-check"></i>Language</a></li>
<li class="chapter" data-level="" data-path="present-studies.html"><a href="present-studies.html#embodiment-represented-by-vision-based-information"><i class="fa fa-check"></i>Embodiment represented by vision-based information</a></li>
<li class="chapter" data-level="" data-path="present-studies.html"><a href="present-studies.html#levels-of-analysis"><i class="fa fa-check"></i>Levels of analysis</a></li>
<li class="chapter" data-level="" data-path="present-studies.html"><a href="present-studies.html#hypotheses"><i class="fa fa-check"></i>Hypotheses</a></li>
<li class="chapter" data-level="" data-path="present-studies.html"><a href="present-studies.html#statistical-power-analysis"><i class="fa fa-check"></i>Statistical power analysis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="general-methods.html"><a href="general-methods.html"><i class="fa fa-check"></i>General methods</a>
<ul>
<li class="chapter" data-level="" data-path="general-methods.html"><a href="general-methods.html#covariates"><i class="fa fa-check"></i>Covariates</a></li>
<li class="chapter" data-level="" data-path="general-methods.html"><a href="general-methods.html#data-preprocessing-and-statistical-analysis"><i class="fa fa-check"></i>Data preprocessing and statistical analysis</a></li>
<li class="chapter" data-level="" data-path="general-methods.html"><a href="general-methods.html#statistical-power-analysis-1"><i class="fa fa-check"></i>Statistical power analysis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming.html"><a href="study-2.1-semantic-priming.html"><i class="fa fa-check"></i>Study 2.1: Semantic priming</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming.html"><a href="study-2.1-semantic-priming.html#language-vision-and-soa"><i class="fa fa-check"></i>Language, vision and SOA</a></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming.html"><a href="study-2.1-semantic-priming.html#language-vision-and-vocabulary-size"><i class="fa fa-check"></i>Language, vision and vocabulary size</a></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming.html"><a href="study-2.1-semantic-priming.html#the-present-study"><i class="fa fa-check"></i>The present study</a></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming.html"><a href="study-2.1-semantic-priming.html#methods"><i class="fa fa-check"></i>Methods</a></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming.html"><a href="study-2.1-semantic-priming.html#semanticpriming-results"><i class="fa fa-check"></i>Results of Study 2.1</a></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming.html"><a href="study-2.1-semantic-priming.html#discussion-of-study-2.1"><i class="fa fa-check"></i>Discussion of Study 2.1</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision.html"><a href="study-2.2-semantic-decision.html"><i class="fa fa-check"></i>Study 2.2: Semantic decision</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision.html"><a href="study-2.2-semantic-decision.html#methods-1"><i class="fa fa-check"></i>Methods</a></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision.html"><a href="study-2.2-semantic-decision.html#results-of-study-2.2"><i class="fa fa-check"></i>Results of Study 2.2</a></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision.html"><a href="study-2.2-semantic-decision.html#discussion-of-study-2.2"><i class="fa fa-check"></i>Discussion of Study 2.2</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="lexicaldecision.html"><a href="lexicaldecision.html"><i class="fa fa-check"></i>Study 2.3: Lexical decision</a>
<ul>
<li class="chapter" data-level="" data-path="lexicaldecision.html"><a href="lexicaldecision.html#methods-2"><i class="fa fa-check"></i>Methods</a></li>
<li class="chapter" data-level="" data-path="lexicaldecision.html"><a href="lexicaldecision.html#results-of-study-2.3"><i class="fa fa-check"></i>Results of Study 2.3</a></li>
<li class="chapter" data-level="" data-path="lexicaldecision.html"><a href="lexicaldecision.html#discussion-of-study-2.3"><i class="fa fa-check"></i>Discussion of Study 2.3</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="general-discussion-of-study-2.html"><a href="general-discussion-of-study-2.html"><i class="fa fa-check"></i>General discussion of Study 2</a>
<ul>
<li class="chapter" data-level="" data-path="general-discussion-of-study-2.html"><a href="general-discussion-of-study-2.html#operationalisation-of-variables-and-other-analytical-choices"><i class="fa fa-check"></i>Operationalisation of variables and other analytical choices</a></li>
<li class="chapter" data-level="" data-path="general-discussion-of-study-2.html"><a href="general-discussion-of-study-2.html#statistical-power"><i class="fa fa-check"></i>Statistical power</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="chapter-4-general-discussion.html"><a href="chapter-4-general-discussion.html"><i class="fa fa-check"></i>Chapter 4: General discussion</a>
<ul>
<li class="chapter" data-level="" data-path="key-findings.html"><a href="key-findings.html"><i class="fa fa-check"></i>Key findings</a></li>
<li class="chapter" data-level="" data-path="limitations-and-future-directions.html"><a href="limitations-and-future-directions.html"><i class="fa fa-check"></i>Limitations and future directions</a></li>
</ul></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="" data-path="appendix-A-lexical-covariates.html"><a href="appendix-A-lexical-covariates.html"><i class="fa fa-check"></i>Appendix A: Selection of lexical covariates</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming-1.html"><a href="study-2.1-semantic-priming-1.html"><i class="fa fa-check"></i>Study 2.1: Semantic priming</a></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-1.html"><a href="study-2.2-semantic-decision-1.html"><i class="fa fa-check"></i>Study 2.2: Semantic decision</a></li>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision.html"><a href="study-2.3-lexical-decision.html"><i class="fa fa-check"></i>Study 2.3: Lexical decision</a></li>
<li class="chapter" data-level="" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i>Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-B-frequentist-analysis-diagnostics.html"><a href="appendix-B-frequentist-analysis-diagnostics.html"><i class="fa fa-check"></i>Appendix B: Diagnostics for the frequentist analyses</a>
<ul>
<li class="chapter" data-level="" data-path="convergence-1.html"><a href="convergence-1.html"><i class="fa fa-check"></i>Convergence</a>
<ul>
<li class="chapter" data-level="" data-path="convergence-1.html"><a href="convergence-1.html#the-multiple-optimisers-sanity-check-from-lme4allfit"><i class="fa fa-check"></i>The multiple-optimisers sanity check from <code>lme4::allFit()</code></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="residual-errors-not-normally-distributed.html"><a href="residual-errors-not-normally-distributed.html"><i class="fa fa-check"></i>Residual errors not normally distributed</a>
<ul>
<li class="chapter" data-level="" data-path="residual-errors-not-normally-distributed.html"><a href="residual-errors-not-normally-distributed.html#method-a-robustlmm-model"><i class="fa fa-check"></i>Method A: <em>robustlmm</em> model</a></li>
<li class="chapter" data-level="" data-path="residual-errors-not-normally-distributed.html"><a href="residual-errors-not-normally-distributed.html#method-b-inverse-gaussian-model-with-identity-link-function"><i class="fa fa-check"></i>Method B: Inverse Gaussian model with identity link function</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming-2.html"><a href="study-2.1-semantic-priming-2.html"><i class="fa fa-check"></i>Study 2.1: Semantic priming</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming-2.html"><a href="study-2.1-semantic-priming-2.html#convergence-2"><i class="fa fa-check"></i>Convergence</a></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming-2.html"><a href="study-2.1-semantic-priming-2.html#residual-errors-not-normally-distributed-1"><i class="fa fa-check"></i>Residual errors not normally distributed</a></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming-2.html"><a href="study-2.1-semantic-priming-2.html#semantic-priming-model-including-visual-similarity"><i class="fa fa-check"></i>Semantic priming model including visual similarity</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-2.html"><a href="study-2.2-semantic-decision-2.html"><i class="fa fa-check"></i>Study 2.2: Semantic decision</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-2.html"><a href="study-2.2-semantic-decision-2.html#convergence-4"><i class="fa fa-check"></i>Convergence</a></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-2.html"><a href="study-2.2-semantic-decision-2.html#residual-errors-not-normally-distributed-3"><i class="fa fa-check"></i>Residual errors not normally distributed</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision-1.html"><a href="study-2.3-lexical-decision-1.html"><i class="fa fa-check"></i>Study 2.3: Lexical decision</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision-1.html"><a href="study-2.3-lexical-decision-1.html#convergence-5"><i class="fa fa-check"></i>Convergence</a></li>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision-1.html"><a href="study-2.3-lexical-decision-1.html#residual-errors-not-normally-distributed-4"><i class="fa fa-check"></i>Residual errors not normally distributed</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-C-Bayesian-analysis-diagnostics.html"><a href="appendix-C-Bayesian-analysis-diagnostics.html"><i class="fa fa-check"></i>Appendix C: Diagnostics for the Bayesian analyses</a>
<ul>
<li class="chapter" data-level="" data-path="study1-bayesian-diagnostics.html"><a href="study1-bayesian-diagnostics.html"><i class="fa fa-check"></i>Study 2.1: Semantic priming</a>
<ul>
<li class="chapter" data-level="" data-path="study1-bayesian-diagnostics.html"><a href="study1-bayesian-diagnostics.html#prior-predictive-checks"><i class="fa fa-check"></i>Prior predictive checks</a></li>
<li class="chapter" data-level="" data-path="study1-bayesian-diagnostics.html"><a href="study1-bayesian-diagnostics.html#posterior-predictive-checks"><i class="fa fa-check"></i>Posterior predictive checks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-3.html"><a href="study-2.2-semantic-decision-3.html"><i class="fa fa-check"></i>Study 2.2: Semantic decision</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-3.html"><a href="study-2.2-semantic-decision-3.html#prior-predictive-checks-1"><i class="fa fa-check"></i>Prior predictive checks</a></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-3.html"><a href="study-2.2-semantic-decision-3.html#posterior-predictive-checks-1"><i class="fa fa-check"></i>Posterior predictive checks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision-2.html"><a href="study-2.3-lexical-decision-2.html"><i class="fa fa-check"></i>Study 2.3: Lexical decision</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision-2.html"><a href="study-2.3-lexical-decision-2.html#prior-predictive-checks-2"><i class="fa fa-check"></i>Prior predictive checks</a></li>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision-2.html"><a href="study-2.3-lexical-decision-2.html#posterior-predictive-checks-2"><i class="fa fa-check"></i>Posterior predictive checks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-D-interaction-plots.html"><a href="appendix-D-interaction-plots.html"><i class="fa fa-check"></i>Appendix D: Further interaction plots</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming-3.html"><a href="study-2.1-semantic-priming-3.html"><i class="fa fa-check"></i>Study 2.1: Semantic priming</a></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-4.html"><a href="study-2.2-semantic-decision-4.html"><i class="fa fa-check"></i>Study 2.2: Semantic decision</a></li>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision-3.html"><a href="study-2.3-lexical-decision-3.html"><i class="fa fa-check"></i>Study 2.3: Lexical decision</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-E-Bayesian-analysis-results.html"><a href="appendix-E-Bayesian-analysis-results.html"><i class="fa fa-check"></i>Appendix E: Results from the Bayesian analyses</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming-4.html"><a href="study-2.1-semantic-priming-4.html"><i class="fa fa-check"></i>Study 2.1: Semantic priming</a></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-5.html"><a href="study-2.2-semantic-decision-5.html"><i class="fa fa-check"></i>Study 2.2: Semantic decision</a></li>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision-4.html"><a href="study-2.3-lexical-decision-4.html"><i class="fa fa-check"></i>Study 2.3: Lexical decision</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href='https://github.com/rstudio/bookdown' target='blank'>Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Language and sensorimotor simulation in conceptual processing: Multilevel analysis and statistical power</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">

<!-- Display citation of thesis at top of every page -->

<div class='alert alert-warning' role='alert' style='padding-bottom:10px; margin-bottom:30px; font-size:85%;'>

  This online book is a reprint of:

  <div style = 'text-indent:-2em; margin-left:2em; color:black;'>
  Bernabeu, P. (2022). <i>Language and sensorimotor simulation in conceptual processing: Multilevel analysis and statistical power</i>. Lancaster University. <a href='https://doi.org/https://doi.org/10.17635/lancaster/thesis/1795'>https://doi.org/https://doi.org/10.17635/lancaster/thesis/1795</a>
  </div>

  Materials: <a href='https://osf.io/vyb8k'>https://osf.io/vyb8k</a>

</div>
<div id="present-studies" class="section level2 hasAnchor">
<h2>The present studies<a href="present-studies.html#present-studies" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We revisit three larger-than-average studies to investigate the interplay between language and embodiment in conceptual processing. We devote a study to each of the three original studies. Thus, Study 2.1 is centred on <span class="citation">Hutchison et al. (<a href="#ref-hutchison2013a" role="doc-biblioref">2013</a>)</span> and uses the semantic priming paradigm. Study 2.2 is centred on <span class="citation">Pexman et al. (<a href="#ref-pexman2017a" role="doc-biblioref">2017</a>)</span> and uses the semantic decision paradigm. Study 2.3 is centred on <span class="citation">Balota et al. (<a href="#ref-balota2007a" role="doc-biblioref">2007</a>)</span> and uses the lexical decision paradigm. Each of these central studies contained measures of participants’ vocabulary size and gender. Furthermore, the core data sets were expanded by adding variables that captured the language-based information in words <span class="citation">(<a href="#ref-mandera2017a" role="doc-biblioref">Mandera et al., 2017</a>; <a href="#ref-wingfieldUnderstandingRoleLinguistic2022" role="doc-biblioref">Wingfield &amp; Connell, 2022b</a>)</span> and the vision-based information in words <span class="citation">(<a href="#ref-lynott2020a" role="doc-biblioref">Lynott et al., 2020</a>; <a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>)</span>—the latter being used to represent the embodiment system. One of the key questions we investigated using this array of variables was whether individual differences in vocabulary and gender modulated participants’ sensivity to the language-based and vision-based information in words. Alongside the effects of interest, several covariates were included in the models to allow a rigorous analysis <span class="citation">(<a href="#ref-sassenhagenCommonMisapplicationStatistical2016" role="doc-biblioref">Sassenhagen &amp; Alday, 2016</a>)</span>. These covariates comprised measures of general cognition and lexical characteristics of the stimulus words. Last, in each study, we performed a statistical power analysis to help estimate the sample size needed to investigate a variety of effects in future studies.</p>
<p>Below, we delve into the language and the embodiment components of these studies.</p>
<div id="language" class="section level3 hasAnchor">
<h3>Language<a href="present-studies.html#language" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Studies have operationalised the language system at the word level using measures that capture the relationships among words without explicitly drawing on any sensory or affective modalities. Two main types of linguistic measures exist: those based on text corpora—dubbed <em>word co-occurrence</em> measures <span class="citation">(<a href="#ref-bullinariaExtractingSemanticRepresentations2007" role="doc-biblioref">Bullinaria &amp; Levy, 2007</a>; <a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>; <a href="#ref-wingfieldUnderstandingRoleLinguistic2022" role="doc-biblioref">Wingfield &amp; Connell, 2022b</a>)</span>—and those based on associations collected from human participants—dubbed <em>word association</em> measures <span class="citation">(<a href="#ref-de2016a" role="doc-biblioref">De Deyne et al., 2016</a>, <a href="#ref-de2019a" role="doc-biblioref">2019</a>)</span>. Notwithstanding the interrelation between word co-occurrence and word association <span class="citation">(<a href="#ref-planchueloNatureWordAssociations2022" role="doc-biblioref">Planchuelo et al., 2022</a>)</span>, co-occurrence is more purely linguistic, whereas association indirectly captures more of the sensory and affective meaning of words <span class="citation">(<a href="#ref-dedeyneVisualAffectiveMultimodal2021" role="doc-biblioref">De Deyne et al., 2021</a>)</span>.</p>
<div id="operationalisation-and-hypotheses" class="section level4 hasAnchor">
<h4>Operationalisation and hypotheses<a href="present-studies.html#operationalisation-and-hypotheses" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In Study 2.1 (semantic priming) and Study 2.2 (semantic decision), co-occurrence measures were used to represent the language system at the word level. Specifically, in Study 2.1, this measure was called <code>language-based similarity</code>, and it was based on the degree of text-based co-occurrence between the prime word and the target word in each trial <span class="citation">(<a href="#ref-mandera2017a" role="doc-biblioref">Mandera et al., 2017</a>)</span>. In Study 2.2, the measure was called <code>word co-occurrence</code>, and it was based on the degree of text-based co-occurrence between each stimulus word and the words ‘abstract’ and ‘concrete’ <span class="citation">(<a href="#ref-wingfieldUnderstandingRoleLinguistic2022" role="doc-biblioref">Wingfield &amp; Connell, 2022b</a>)</span>. In Study 2.3 (lexical decision), a co-occurrence measure could not be used, as the co-occurrence of words in consecutive trials could not be calculated due to the high frequency of nonword trials throughout the lexical decision task. Therefore, a single-word measure had to be used instead. Word frequency was used as it was the lexical variable, among five, that had the largest effect (see <a href="appendix-A-lexical-covariates.html#appendix-A-lexical-covariates">Appendix A</a>).</p>
<p>At the individual level, language was represented by participants’ vocabulary size in Studies 2.1 and 2.2, and by participants’ vocabulary age in Study 2.3. Vocabulary <em>size</em> and <em>age</em> did not differ in any consequential way. They both captured the amount of vocabulary knowledge of each participant, by testing their knowledge of a small sample of pre-normed words, and thereby inferring their overall knowledge.</p>
<p>We hypothesised that word co-occurrence, word frequency and vocabulary size would all have facilitatory effects on participants’ performance, with higher values leading to shorter RTs <span class="citation">(<a href="#ref-pexman2018a" role="doc-biblioref">Pexman &amp; Yap, 2018</a>; <a href="#ref-wingfieldUnderstandingRoleLinguistic2022" role="doc-biblioref">Wingfield &amp; Connell, 2022b</a>; <a href="#ref-yapIndividualDifferencesJoint2009" role="doc-biblioref">Yap et al., 2009</a>)</span>.</p>
</div>
</div>
<div id="embodiment-represented-by-vision-based-information" class="section level3 hasAnchor">
<h3>Embodiment represented by vision-based information<a href="present-studies.html#embodiment-represented-by-vision-based-information" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In previous studies, the embodiment system has been represented at the word level by perceptual, motor, affective or social variables <span class="citation">(<a href="#ref-fernandinoDecodingInformationStructure2022" role="doc-biblioref">Fernandino et al., 2022</a>; <a href="#ref-viglioccoTheorySemanticRepresentation2009" role="doc-biblioref">Vigliocco et al., 2009</a>; <a href="#ref-wangSocialEmotionDimensional2021" role="doc-biblioref">X. Wang et al., 2021</a>)</span>. For instance, the perceptual modalities have often corresponded to the five Aristotelian senses—vision, hearing, touch, taste and smell <span class="citation">(<a href="#ref-bernabeu2017a" role="doc-biblioref">Bernabeu et al., 2017</a>, <a href="#ref-bernabeu2021a" role="doc-biblioref">2021</a>; <a href="#ref-louwerseTasteWordsLinguistic2011" role="doc-biblioref">Louwerse &amp; Connell, 2011</a>)</span>—and, less often, to interoception <span class="citation">(<a href="#ref-connellInteroceptionForgottenModality2018" role="doc-biblioref">Connell et al., 2018</a>)</span>. Yet, out of all these domains, vision has been most frequently used in research <span class="citation">(e.g., <a href="#ref-bottiniConcretenessAdvantageLexical2021" role="doc-biblioref">Bottini et al., 2021</a>; <a href="#ref-dedeyneVisualAffectiveMultimodal2021" role="doc-biblioref">De Deyne et al., 2021</a>; <a href="#ref-pearsonHeterogeneityMentalRepresentation2015" role="doc-biblioref">Pearson &amp; Kosslyn, 2015</a>; <a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>; <a href="#ref-yeeColorlessGreenIdeas2012" role="doc-biblioref">Yee et al., 2012</a>)</span>. The hegemony of vision is likely due to the central position of vision in the human brain <span class="citation">(<a href="#ref-reillyEnglishLexiconMirrors2020" role="doc-biblioref">Reilly et al., 2020</a>)</span> as well as in several languages <span class="citation">(<a href="#ref-bernabeuDutchModalityExclusivity2018" role="doc-biblioref">Bernabeu, 2018</a>; <a href="#ref-chenMandarinChineseModality2019" role="doc-biblioref">I.-H. Chen et al., 2019</a>; <a href="#ref-lynott2020a" role="doc-biblioref">Lynott et al., 2020</a>; <a href="#ref-miceliPerceptualInteroceptiveStrength2021" role="doc-biblioref">Miceli et al., 2021</a>; <a href="#ref-morucciAugmentedModalityExclusivity2019" role="doc-biblioref">Morucci et al., 2019</a>; <a href="#ref-roqueVisionVerbsDominate2015" role="doc-biblioref">Roque et al., 2015</a>; <a href="#ref-speedDutchSensoryModality2021" role="doc-biblioref">Speed &amp; Brybaert, 2021</a>; <a href="#ref-speedGroundingLanguageNeglected2020" role="doc-biblioref">Speed &amp; Majid, 2020</a>; <a href="#ref-vergallitoPerceptualModalityNorms2020" role="doc-biblioref">Vergallito et al., 2020</a>; <a href="#ref-winterVisionDominatesPerceptual2018" role="doc-biblioref">Winter et al., 2018</a>; <a href="#ref-zhongSensorimotorNormsChinese2022" role="doc-biblioref">Zhong et al., 2022</a>)</span>. In the present study, we focussed on vision alone due to three reasons. First, we wanted to use a single variable to represent sensorimotor information, just as a single variable would be used to represent linguistic information. Using a single variable for each system facilitates the analysis of interactions with other variables. Second, vision is very prominent in cognition, as we just reviewed. Third, we had planned to use the present research to determine the sample size of a subsequent study that focusses on vision (indeed, the present study grew out of a statistical power analysis).</p>
<div id="operationalisation-and-hypotheses-1" class="section level4 hasAnchor">
<h4>Operationalisation and hypotheses<a href="present-studies.html#operationalisation-and-hypotheses-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>At the word level, we operationalised visual information using the visual strength variable from the Lancaster Sensorimotor Norms <span class="citation">(<a href="#ref-lynott2020a" role="doc-biblioref">Lynott et al., 2020</a>)</span>. This variable measures the degree of visual experience associated with concepts. In Study 2.1, we created the variable <code>visual-strength difference</code> by subtracting the visual strength of the prime word from that of the target word, in each trial. Thus, visual-strength difference measured—in each trial—how much the prime word and the target word differed in their degrees of vision-based information. Even though we could not find any previous studies that reported the effect of visual strength (or visual-strength difference) on RT, we hypothesised a priming effect underpinned by this variable, consistent with related research <span class="citation">(<a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>)</span>. Specifically, we hypothesised that visual-strength difference would have an inhibitory effect on participants’ performance, with higher values leading to longer RTs.</p>
<p>In Studies 2.2 and 2.3, we used the <code>visual strength</code> score per stimulus word. We hypothesised that this variable would have a facilitatory effect on participants’ performance—i.e., higher values leading to shorter RTs—, consistent with related research <span class="citation">(<a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>)</span>.</p>
<p>Unlike language, vision was not examined at the individual level because the available variables were based on one self-reported value per participant <span class="citation">(<a href="#ref-balota2007a" role="doc-biblioref">Balota et al., 2007</a>; <a href="#ref-hutchison2013a" role="doc-biblioref">Hutchison et al., 2013</a>)</span>, contrasting with the greater precision of the vocabulary measures, which consisted of multiple trials. Nonetheless, we recognise the need to investigate the role of perceptual experience <span class="citation">(<a href="#ref-murakiSimulatingSemanticsAre2021" role="doc-biblioref">Muraki &amp; Pexman, 2021</a>; <a href="#ref-plautIndividualDevelopmentalDifferences2000" role="doc-biblioref">Plaut &amp; Booth, 2000</a>)</span> alongside that of linguistic experience in the future.</p>
</div>
</div>
<div id="levels-of-analysis" class="section level3 hasAnchor">
<h3>Levels of analysis<a href="present-studies.html#levels-of-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Experimental data in psycholinguistics can be divided into various levels, such as individuals, words and tasks. The simultaneous examination of a theory across several levels is expected to enhance our understanding of the theory <span class="citation">(<a href="#ref-ostarekStrongInferenceResearch2021" role="doc-biblioref">Ostarek &amp; Bottini, 2021</a>)</span>—for instance, by revealing the distribution of explanatory power (that is, effect size) within and across these levels. Several studies have probed more than one level—for instance, word level and individual level <span class="citation">(<a href="#ref-aujlaLanguageExperiencePredicts2021" role="doc-biblioref">Aujla, 2021</a>; <a href="#ref-lim2020a" role="doc-biblioref">Lim et al., 2020</a>; <a href="#ref-pexman2018a" role="doc-biblioref">Pexman &amp; Yap, 2018</a>; <a href="#ref-yapIndividualDifferencesJoint2009" role="doc-biblioref">Yap et al., 2009</a>)</span>, or word level and task level <span class="citation">(<a href="#ref-al-azaryCanYouTouch2022" role="doc-biblioref">Al-Azary et al., 2022</a>; <a href="#ref-connell2013a" role="doc-biblioref">Connell &amp; Lynott, 2013</a>, <a href="#ref-connellSeeHearWhat2014" role="doc-biblioref">2014a</a>; <a href="#ref-ostarekSixChallengesEmbodiment2019" role="doc-biblioref">Ostarek &amp; Huettig, 2019</a>; <a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>)</span>. This multilevel approach is complementary to a different line of research that aims to test the causality of various sources of information in conceptual processing, such as language <span class="citation">(<a href="#ref-ponari2018a" role="doc-biblioref">Ponari, Norbury, Rotaru, et al., 2018</a>)</span>, perception <span class="citation">(<a href="#ref-stasenkoWhenConceptsLose2014" role="doc-biblioref">Stasenko et al., 2014</a>)</span> and action <span class="citation">(<a href="#ref-speedImpairedComprehensionSpeed2017" role="doc-biblioref">Speed et al., 2017</a>)</span>.</p>
<p>The three levels considered in this study—individual, word and task—are described below.</p>
<div id="individual-level" class="section level4 hasAnchor">
<h4>Individual level<a href="present-studies.html#individual-level" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The individual level is concerned with the role of individual differences in domains such as language, perception, mental imagery and physical experience <span class="citation">(e.g., <a href="#ref-daidoneVocabularySizeKey2021" role="doc-biblioref">Daidone &amp; Darcy, 2021</a>; <a href="#ref-davies2017a" role="doc-biblioref">Davies et al., 2017</a>; <a href="#ref-dils2010a" role="doc-biblioref">Dils &amp; Boroditsky, 2010</a>; <a href="#ref-fettermanFeelingWarmBeing2018" role="doc-biblioref">Fetterman et al., 2018</a>; <a href="#ref-holt2006a" role="doc-biblioref">Holt &amp; Beilock, 2006</a>; <a href="#ref-mak2019a" role="doc-biblioref">Mak &amp; Willems, 2019</a>; <a href="#ref-miceliDifferencesRelatedAging2022" role="doc-biblioref">Miceli et al., 2022</a>; <a href="#ref-pexman2018a" role="doc-biblioref">Pexman &amp; Yap, 2018</a>; <a href="#ref-vukovic2015a" role="doc-biblioref">Vukovic &amp; Williams, 2015</a>; <a href="#ref-yapIndividualDifferencesJoint2009" role="doc-biblioref">Yap et al., 2009</a>, <a href="#ref-yap2012a" role="doc-biblioref">2012</a>, <a href="#ref-yap2017a" role="doc-biblioref">2017</a>)</span>.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> Recent studies have revealed important roles of participant-specific variables in topics where these variables have not traditionally been considered <span class="citation">(<a href="#ref-delucaRedefiningBilingualismSpectrum2019" role="doc-biblioref">DeLuca et al., 2019</a>; <a href="#ref-kosIndividualVariationLate2012" role="doc-biblioref">Kos et al., 2012</a>; <a href="#ref-montero-melisConsistencyMotionEvent2021" role="doc-biblioref">Montero-Melis, 2021</a>)</span>.</p>
<p>Vocabulary size is used to represent the language system at the individual level. It measures the number of words a person can recognise out of a sample. Furthermore, covariates akin to general cognition—where available—were included the models (see <a href="general-methods.html#covariates">Covariates</a> section below).</p>
</div>
<div id="word-level" class="section level4 hasAnchor">
<h4>Word level<a href="present-studies.html#word-level" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The word level is concerned with the lexical and semantic information in words <span class="citation">(e.g., <a href="#ref-dedeyneVisualAffectiveMultimodal2021" role="doc-biblioref">De Deyne et al., 2021</a>; <a href="#ref-lam2015a" role="doc-biblioref">Lam et al., 2015</a>; <a href="#ref-lund1995a" role="doc-biblioref">Lund et al., 1995</a>; <a href="#ref-lund1996a" role="doc-biblioref">Lund &amp; Burgess, 1996</a>; <a href="#ref-lynott2020a" role="doc-biblioref">Lynott et al., 2020</a>; <a href="#ref-mandera2017a" role="doc-biblioref">Mandera et al., 2017</a>; <a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>; <a href="#ref-pexman2017a" role="doc-biblioref">Pexman et al., 2017</a>; <a href="#ref-santosPropertyGenerationReflects2011" role="doc-biblioref">Santos et al., 2011</a>; <a href="#ref-wingfieldUnderstandingRoleLinguistic2022" role="doc-biblioref">Wingfield &amp; Connell, 2022b</a>)</span>. The word-level variables of interest in this study are language-based and vision-based information (both described above). The covariates are lexical variables and word concreteness. The lexical covariates were selected in each study out of the same five variables (see <a href="general-methods.html#covariates">Covariates</a> section below).</p>
</div>
<div id="task-level" class="section level4 hasAnchor">
<h4>Task level<a href="present-studies.html#task-level" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The task level is concerned with experimental conditions affecting, for instance, processing speed. In Study 2.1 (semantic priming), there is one task-level factor, namely, stimulus onset asynchrony (SOA), which measures the temporal interval between the onset of the prime word and the onset of the target word.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> In Studies 2.2 and 2.3, there are no task-level variables.</p>
<p>Beyond task-level variables, there is an additional source of task-related information across the three studies—namely, the experimental paradigm used in each study (i.e., semantic priming, semantic decision and lexical decision). Indeed, it is possible to examine how the effects vary across these paradigms <span class="citation">(see <a href="#ref-wingfieldUnderstandingRoleLinguistic2022" role="doc-biblioref">Wingfield &amp; Connell, 2022b</a>)</span>. This comparison, however, must be considered cautiously due to the existence of other non-trivial differences across these studies, such as the numbers of observations. With this caveat noted, the tasks used across these studies likely elicit varying degrees of semantic depth, as ordered below <span class="citation">(see <a href="#ref-balotaDepthAutomaticSpreading1986" role="doc-biblioref">Balota &amp; Lorch, 1986</a>; <a href="#ref-barsalouLanguageSimulationConceptual2008" role="doc-biblioref">Barsalou et al., 2008</a>; <a href="#ref-beckerLongtermSemanticPriming1997" role="doc-biblioref">Becker et al., 1997</a>; <a href="#ref-dewitMaskedSemanticPriming2015" role="doc-biblioref">de Wit &amp; Kinoshita, 2015</a>; <a href="#ref-joordensLongShortSemantic1997" role="doc-biblioref">Joordens &amp; Becker, 1997</a>; <a href="#ref-lam2015a" role="doc-biblioref">Lam et al., 2015</a>; <a href="#ref-murakiSimulatingSemanticsAre2021" role="doc-biblioref">Muraki &amp; Pexman, 2021</a>; <a href="#ref-ostarekTaskdependentCausalRole2017" role="doc-biblioref">Ostarek &amp; Huettig, 2017</a>; <a href="#ref-versaceImpactEmbodiedSimulation2021" role="doc-biblioref">Versace et al., 2021</a>; <a href="#ref-wingfieldUnderstandingRoleLinguistic2022" role="doc-biblioref">Wingfield &amp; Connell, 2022b</a>)</span>.</p>
<ol style="list-style-type: decimal">
<li><p><em>Semantic decision</em> (Study 2.2) likely elicits the deepest semantic processing, as the instructions of this task ask for a concreteness judgement. In this task, participants are asked to classify words as abstract or concrete, which elicits deeper semantic processing than the task of identifying word forms—i.e., lexical decision <span class="citation">(<a href="#ref-dewitMaskedSemanticPriming2015" role="doc-biblioref">de Wit &amp; Kinoshita, 2015</a>)</span>.</p></li>
<li><p><em>Semantic priming</em> (Study 2.1). The task administered to participants in semantic priming studies is often lexical decision, as in Study 2.1 below. The fundamental characteristic of semantic priming is that, in each trial, a prime word is briefly presented before the target word. The prime word is not directly relevant to the task, as participants respond to the target word. Nonetheless, participants normally process both the prime word and the target word in each trial, and this combination allows researchers to analyse responses based on the prime–target relationship. In this regard, this paradigm could be considered more deeply semantic than lexical decision. Indeed, slower responses in semantic priming studies—reflecting difficult lexical decisions—have been linked to larger priming effects <span class="citation">(<a href="#ref-balotaMeanResponseLatency2008" role="doc-biblioref">Balota et al., 2008</a>; <a href="#ref-hoedemakerItTakesTime2014" role="doc-biblioref">Hoedemaker &amp; Gordon, 2014</a>; <a href="#ref-yapAdditiveInteractiveEffects2013" role="doc-biblioref">Yap et al., 2013</a>)</span>, revealing a degree of semantic association that has not been identified in the lexical decision task.</p></li>
<li><p><em>Lexical decision</em> (Study 2.3) is likely the semantically-shallowest task of these three, as it focusses solely on the identification of word forms.</p></li>
</ol>
</div>
</div>
<div id="hypotheses" class="section level3 hasAnchor">
<h3>Hypotheses<a href="present-studies.html#hypotheses" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The central objective of the present studies is the simultaneous investigation of language-based and vision-based information, along with the interactions between each of those and vocabulary size, gender and presentation speed (i.e., SOA). Previous studies have examined subsets of these effects using the same data sets we are using <span class="citation">(<a href="#ref-balota2007a" role="doc-biblioref">Balota et al., 2007</a>; <a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>; <a href="#ref-pexman2017a" role="doc-biblioref">Pexman et al., 2017</a>; <a href="#ref-pexman2018a" role="doc-biblioref">Pexman &amp; Yap, 2018</a>; <a href="#ref-wingfieldUnderstandingRoleLinguistic2022" role="doc-biblioref">Wingfield &amp; Connell, 2022b</a>; <a href="#ref-yap2012a" role="doc-biblioref">Yap et al., 2012</a>, <a href="#ref-yap2017a" role="doc-biblioref">2017</a>)</span>. Out of these studies, only <span class="citation">Petilli et al. (<a href="#ref-petilli2021a" role="doc-biblioref">2021</a>)</span> investigated <em>both</em> language and vision. However, in contrast to our present study, Petilli et al. did not examine the role of vocabulary size or any other individual differences, instead collapsing the data across participants.</p>
<p>In addition to main effects of the aforementioned variables, our three studies have four interactions in common: (1a) language-based information × vocabulary size, (1b) vision-based information × vocabulary size, (2a) language-based information × participants’ gender, and (2b) vision-based information × participants’ gender. In addition, Study 2.1 contained two further interactions: (3a) language-based information × SOA, (3b) vision-based information × SOA (note that the names of some predictors vary across studies, as detailed in the <a href="present-studies.html#language">present studies</a> section above). Each interaction and the corresponding hypotheses are addressed below.</p>
<div id="a.-language-based-information-vocabulary-size" class="section level4 hasAnchor">
<h4>1a. Language-based information × vocabulary size<a href="present-studies.html#a.-language-based-information-vocabulary-size" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We outline three hypotheses supported by literature regarding the interaction between language-based information and participants’ vocabulary size.</p>
<ul>
<li><p><em>Larger vocabulary, larger effects.</em> Higher-vocabulary participants might be more sensitive to linguistic features than lower-vocabulary participants, thanks to a larger number of semantic associations <span class="citation">(<a href="#ref-connell2019a" role="doc-biblioref">Connell, 2019</a>; <a href="#ref-landauerIntroductionLatentSemantic1998" role="doc-biblioref">Landauer et al., 1998</a>; <a href="#ref-louwerse2015a" role="doc-biblioref">Louwerse et al., 2015</a>; <a href="#ref-paivioMentalRepresentationsDual1990" role="doc-biblioref">Paivio, 1990</a>; <a href="#ref-pylyshynWhatMindEye1973" role="doc-biblioref">Pylyshyn, 1973</a>)</span>. For instance, <span class="citation">Yap et al. (<a href="#ref-yap2017a" role="doc-biblioref">2017</a>)</span> revisited the semantic priming study of <span class="citation">Hutchinson and Louwerse (<a href="#ref-hutchinson2013a" role="doc-biblioref">2013</a>)</span> and observed a larger semantic priming effect in higher-vocabulary participants.</p></li>
<li><p><em>Larger vocabulary, smaller effects.</em> Higher-vocabulary participants might be less sensitive to linguistic features, thanks to a more automated language processing <span class="citation">(<a href="#ref-perfettiLexicalQualityHypothesis2002" role="doc-biblioref">Perfetti &amp; Hart, 2002</a>)</span>. Some of the evidence aligned with this hypothesis was obtained by <span class="citation">Yap et al. (<a href="#ref-yapIndividualDifferencesJoint2009" role="doc-biblioref">2009</a>)</span>, who observed a smaller semantic priming effect in higher-vocabulary participants. Similarly, <span class="citation">Yap et al. (<a href="#ref-yap2012a" role="doc-biblioref">2012</a>)</span> found that higher-vocabulary participants in a lexical decision task <span class="citation">(<a href="#ref-balota2007a" role="doc-biblioref">Balota et al., 2007</a>)</span> were less sensitive to a cluster of lexical and semantic features (i.e., word frequency, semantic neighborhood density and number of senses).</p></li>
<li><p><em>Larger vocabulary, more task-relevant effects.</em> Higher-vocabulary participants might present a greater sensitivity to task-relevant variables, borne out of their greater linguistic experience, relative to lower vocabulary participants. This would be consistent with the findings of <span class="citation">Pexman and Yap (<a href="#ref-pexman2018a" role="doc-biblioref">2018</a>)</span>, who revisited the semantic decision study of <span class="citation">Pexman et al. (<a href="#ref-pexman2017a" role="doc-biblioref">2017</a>)</span>. The semantic decision task of the Pexman et al. consisted of classifying words as abstract or concrete. Pexman and Yap found that word concreteness—a very relevant source of information for this task—was more influential in higher-vocabulary participants than in lower-vocabulary ones. In contrast, word frequency and age of acquisition—-not as relevant to the task–were more influential in lower-vocabulary participants <span class="citation">(also see <a href="#ref-lim2020a" role="doc-biblioref">Lim et al., 2020</a>)</span>. In our present studies, we set our hypotheses regarding the ‘task-relevance advantage’ by working under the assumption that the language-based information in words—represented by one variable in each study—is important for the three tasks, given the large effects of language across tasks <span class="citation">(<a href="#ref-banksLinguisticDistributionalKnowledge2021" role="doc-biblioref">Banks et al., 2021</a>; <a href="#ref-kiela2014a" role="doc-biblioref">Kiela &amp; Bottou, 2014</a>; <a href="#ref-lam2015a" role="doc-biblioref">Lam et al., 2015</a>; <a href="#ref-louwerse2015a" role="doc-biblioref">Louwerse et al., 2015</a>; <a href="#ref-pecherDoesPizzaPrime1998" role="doc-biblioref">Pecher et al., 1998</a>; <a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>)</span>. Therefore, the relevance hypothesis predicts that higher-vocabulary participants—compared to lower-vocabulary ones—will be more sensitive to language-based information (as represented by <code>language-based similarity</code> in Study 2.1, <code>word co-occurrence</code> in Study 2.2, and <code>word frequency</code> in Study 2.3).</p></li>
</ul>
</div>
<div id="b.-vision-based-information-vocabulary-size" class="section level4 hasAnchor">
<h4>1b. Vision-based information × vocabulary size<a href="present-studies.html#b.-vision-based-information-vocabulary-size" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To our knowledge, no previous studies have investigated the interaction between vision-based information and participants’ vocabulary size. We entertained two hypotheses. First, lower-vocabulary participants might be more sensitive to visual strength than higher-vocabulary participants. In this way, lower-vocabulary participants might <em>compensate</em> for the disadvantage on the language side. Second, we considered the possibility that there were no interaction effect.</p>
</div>
<div id="a.-language-based-information-gender" class="section level4 hasAnchor">
<h4>2a. Language-based information × gender<a href="present-studies.html#a.-language-based-information-gender" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We entertained two hypotheses regarding the interaction between language-based information and participants’ gender: (a) that the language system would be more important in female participants than in males <span class="citation">(<a href="#ref-burman2008a" role="doc-biblioref">Burman et al., 2008</a>; <a href="#ref-hutchinson2013a" role="doc-biblioref">Hutchinson &amp; Louwerse, 2013</a>; <a href="#ref-jung2019a" role="doc-biblioref">Jung et al., 2019</a>; <a href="#ref-ullman2008a" role="doc-biblioref">Ullman et al., 2008</a>)</span>, and (b) that this interaction effect would be absent, as a recent review suggested that gender differences are negligible in the general population <span class="citation">(<a href="#ref-wallentinChapterGenderDifferences2020" role="doc-biblioref">Wallentin, 2020</a>)</span>.</p>
</div>
<div id="b.-vision-based-information-gender" class="section level4 hasAnchor">
<h4>2b. Vision-based information × gender<a href="present-studies.html#b.-vision-based-information-gender" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To our knowledge, no previous studies have investigated the interaction between vision-based information and participants’ gender. We entertained two hypotheses. Our first hypothesis was that this interaction would stand opposite to the interaction between language and gender. That is, if female participants were to present a greater role of language-based information, male participants would present a greater role of vision-based information, thereby compensating for the disadvantage on the language side. Our second hypothesis was the absence of this interaction effect <span class="citation">(see <a href="#ref-wallentinChapterGenderDifferences2020" role="doc-biblioref">Wallentin, 2020</a>)</span>.</p>
</div>
<div id="a.-language-based-information-soa" class="section level4 hasAnchor">
<h4>3a. Language-based information × SOA<a href="present-studies.html#a.-language-based-information-soa" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Previous research predicts that language-based information will have a larger effect with the short SOA than with the long one <span class="citation">(<a href="#ref-lam2015a" role="doc-biblioref">Lam et al., 2015</a>; <a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>)</span>), which also aligns with research demonstrating the fast activation of language-based information <span class="citation">(<a href="#ref-louwerseTasteWordsLinguistic2011" role="doc-biblioref">Louwerse &amp; Connell, 2011</a>; <a href="#ref-santosPropertyGenerationReflects2011" role="doc-biblioref">Santos et al., 2011</a>; <a href="#ref-simmonsFMRIEvidenceWord2008" role="doc-biblioref">Simmons et al., 2008</a>)</span>.</p>
</div>
<div id="b.-vision-based-information-soa" class="section level4 hasAnchor">
<h4>3b. Vision-based information × SOA<a href="present-studies.html#b.-vision-based-information-soa" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The interaction between vision-based information and SOA allows three hypotheses. First, some previous research predicts that the role of vision-based information will be more prevalent with the long SOA than with the short one <span class="citation">(<a href="#ref-louwerseTasteWordsLinguistic2011" role="doc-biblioref">Louwerse &amp; Connell, 2011</a>; <a href="#ref-santosPropertyGenerationReflects2011" role="doc-biblioref">Santos et al., 2011</a>; <a href="#ref-simmonsFMRIEvidenceWord2008" role="doc-biblioref">Simmons et al., 2008</a>; also see <a href="#ref-barsalouLanguageSimulationConceptual2008" role="doc-biblioref">Barsalou et al., 2008</a>)</span>. Second, in contrast, other research <span class="citation">(<a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>)</span> based on the same data that we are analysing <span class="citation">(<a href="#ref-hutchison2013a" role="doc-biblioref">Hutchison et al., 2013</a>)</span> predicts vision-based priming only with the short SOA (200 ms), and not with the long one (1,200 ms). Third, other research does not predict any vision-based priming effect <span class="citation">(<a href="#ref-hutchisonSemanticPrimingDue2003" role="doc-biblioref">Hutchison, 2003</a>; <a href="#ref-ostarekTaskdependentCausalRole2017" role="doc-biblioref">Ostarek &amp; Huettig, 2017</a>; <a href="#ref-pecherDoesPizzaPrime1998" role="doc-biblioref">Pecher et al., 1998</a>; <a href="#ref-yeeColorlessGreenIdeas2012" role="doc-biblioref">Yee et al., 2012</a>)</span>. In this regard, some studies have observed vision-based priming when the task was preceded by another task that required attention to visual features of concepts <span class="citation">(<a href="#ref-pecherDoesPizzaPrime1998" role="doc-biblioref">Pecher et al., 1998</a>; <a href="#ref-yeeColorlessGreenIdeas2012" role="doc-biblioref">Yee et al., 2012</a>)</span>, but the present data <span class="citation">(<a href="#ref-hutchison2013a" role="doc-biblioref">Hutchison et al., 2013</a>)</span> does not contain such a prior task.</p>
</div>
<div id="language-and-vision-across-studies" class="section level4 hasAnchor">
<h4>Language and vision across studies<a href="present-studies.html#language-and-vision-across-studies" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Next, we consider our hypotheses regarding the role of language and vision across studies. Yet, before addressing those, we reiterate that caution is required due to the existence of other differences across these studies, such as the number of observations. First, we hypothesise that language-based information will be relevant in the three studies due to the consistent importance of language observed in past studies <span class="citation">(<a href="#ref-banksLinguisticDistributionalKnowledge2021" role="doc-biblioref">Banks et al., 2021</a>; <a href="#ref-kiela2014a" role="doc-biblioref">Kiela &amp; Bottou, 2014</a>; <a href="#ref-lam2015a" role="doc-biblioref">Lam et al., 2015</a>; <a href="#ref-louwerse2015a" role="doc-biblioref">Louwerse et al., 2015</a>; <a href="#ref-pecherDoesPizzaPrime1998" role="doc-biblioref">Pecher et al., 1998</a>; <a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>)</span>. Second, the extant evidence regarding vision-based information is less conclusive. Some studies have observed effects of vision-based information <span class="citation">(<a href="#ref-connellSeeHearWhat2014" role="doc-biblioref">Connell &amp; Lynott, 2014a</a>; <a href="#ref-floresdarcaisSemanticActivationRecognition1985" role="doc-biblioref">Flores d’Arcais et al., 1985</a>; <a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>; <a href="#ref-schreuderEffectsPerceptualConceptual1984" role="doc-biblioref">Schreuder et al., 1984</a>)</span>, whereas others have not <span class="citation">(<a href="#ref-hutchisonSemanticPrimingDue2003" role="doc-biblioref">Hutchison, 2003</a>; <a href="#ref-ostarekTaskdependentCausalRole2017" role="doc-biblioref">Ostarek &amp; Huettig, 2017</a>)</span>, and a third set of studies have only observed them when the critical task was preceded by a task that required attention to visual features of concepts <span class="citation">(<a href="#ref-pecherDoesPizzaPrime1998" role="doc-biblioref">Pecher et al., 1998</a>; <a href="#ref-yeeColorlessGreenIdeas2012" role="doc-biblioref">Yee et al., 2012</a>)</span>. Based on these precedents, we hypothesise that vision-based information will be relevant in semantic decision, whereas it might or might not be relevant in semantic priming and in lexical decision.</p>
</div>
</div>
<div id="statistical-power-analysis" class="section level3 hasAnchor">
<h3>Statistical power analysis<a href="present-studies.html#statistical-power-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Statistical power depends on the following factors: (1) sample size—comprising the number of participants, items, trials, etc.—, (2) effect size, (3) measurement variability and (4) number of comparisons being performed. Out of these, sample size is the factor that can best be controlled by researchers <span class="citation">(<a href="#ref-kumleEstimatingPowerGeneralized2021" role="doc-biblioref">Kumle et al., 2021</a>)</span>. The three studies we present below, containing larger-than-average sample sizes, offer an opportunity to perform an a-priori power analysis to help determine the sample size of future studies <span class="citation">(<a href="#ref-albersWhenPowerAnalyses2018" role="doc-biblioref">Albers &amp; Lakens, 2018</a>)</span>.</p>
<div id="motivations" class="section level4 hasAnchor">
<h4>Motivations<a href="present-studies.html#motivations" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Insufficient statistical power lowers the reliability of effect sizes, and increases the likelihood of false positive results—i.e., Type I errors—as well as the likelihood of false negative results—i.e., Type II errors <span class="citation">(<a href="#ref-gelmanPowerCalculationsAssessing2014" role="doc-biblioref">Gelman &amp; Carlin, 2014</a>; <a href="#ref-lokenMeasurementErrorReplication2017" role="doc-biblioref">Loken &amp; Gelman, 2017</a>; <a href="#ref-tverskyBeliefLawSmall1971" role="doc-biblioref">Tversky &amp; Kahneman, 1971</a>; <a href="#ref-vondermalsburgFalsePositivesOther2017" role="doc-biblioref">von der Malsburg &amp; Angele, 2017</a>)</span>. For instance, <span class="citation">Vasishth and Gelman (<a href="#ref-vasishthHowEmbraceVariation2021" role="doc-biblioref">2021</a>)</span> illustrate how, in low-powered studies, effect sizes associated with significant results tend to be overestimated <span class="citation">(also see <a href="#ref-vasishthStatisticalSignificanceFilter2018" role="doc-biblioref">Vasishth, Mertzen, et al., 2018</a>)</span>.</p>
<p>Over the past decade, replication studies and power analyses have uncovered insufficient sample sizes in psychology <span class="citation">(<a href="#ref-brysbaertHowManyParticipants2019" role="doc-biblioref">Brysbaert, 2019</a>; <a href="#ref-heymanReliabilityItemlevelSemantic2018" role="doc-biblioref">Heyman et al., 2018</a>; <a href="#ref-lynottReplicationExperiencingPhysical2014" role="doc-biblioref">Lynott et al., 2014</a>; <a href="#ref-montero-melisSatelliteVsVerbframing2017" role="doc-biblioref">Montero-Melis et al., 2017</a>, <a href="#ref-montero-melisNoEvidenceEmbodiment2022" role="doc-biblioref">2022</a>; <a href="#ref-rodriguez-ferreiroSemanticPrimingSchizotypal2020" role="doc-biblioref">Rodríguez-Ferreiro et al., 2020</a>; <a href="#ref-vasishthStatisticalSignificanceFilter2018" role="doc-biblioref">Vasishth, Mertzen, et al., 2018</a>)</span>. In one of these studies, <span class="citation">Heyman et al. (<a href="#ref-heymanReliabilityItemlevelSemantic2018" role="doc-biblioref">2018</a>)</span> demonstrated that increasing the sample size resulted in an increase of the reliability of the estimates, which in turn lowered the Type I error rate and the Type II error rate—i.e., false negative and false positive results, respectively. Calls for larger sample sizes have also been voiced in the field of neuroscience. For instance, <span class="citation">Marek et al. (<a href="#ref-marekReproducibleBrainwideAssociation2022" role="doc-biblioref">2022</a>)</span> estimated the sample size that would be required to reliably study the mapping between individual differences—such as general cognition—and brain structures. The authors found that the current median of 25 participants in each of these studies contrasted with the thousands of participants—around 10,000—that would be needed for a well-powered study <span class="citation">(also see <a href="#ref-buttonPowerFailureWhy2013" role="doc-biblioref">Button et al., 2013</a>)</span>.</p>
<p>More topic-specific power analyses are necessary due to several reasons. First, power analyses provide greater certainty on the reasons behind non-replications <span class="citation">(e.g., <a href="#ref-opensciencecollaborationEstimatingReproducibilityPsychological2015" role="doc-biblioref">Open Science Collaboration, 2015</a>)</span>, and behind non-significant results at large. Non-replications are not solely explained by methodological differences across studies, questionable research practices and publication bias <span class="citation">(<a href="#ref-andersonResponseCommentEstimating2016" role="doc-biblioref">C. J. Anderson et al., 2016</a>; <a href="#ref-barsalouEstablishingGeneralizableMechanisms2019" role="doc-biblioref">Barsalou, 2019</a>; <a href="#ref-corkerHighQualityDirect2014" role="doc-biblioref">Corker et al., 2014</a>; <a href="#ref-gilbertCommentEstimatingReproducibility2016" role="doc-biblioref">Gilbert et al., 2016</a>; <a href="#ref-williamsImprovingPsychologicalScience2014" role="doc-biblioref">Williams, 2014</a>; <a href="#ref-zwaanReplicationsShouldBe2014" role="doc-biblioref">Zwaan, 2014</a>; also see <a href="#ref-tiokhinCompetitionPriorityHarms2021" role="doc-biblioref">Tiokhin et al., 2021</a>)</span>. In addition to these factors, a lack of statistical power can cause non-replications and non-significant results <span class="citation">(see <a href="#ref-lokenMeasurementErrorReplication2017" role="doc-biblioref">Loken &amp; Gelman, 2017</a>; <a href="#ref-vasishthHowEmbraceVariation2021" role="doc-biblioref">Vasishth &amp; Gelman, 2021</a>)</span>.</p>
<p>Regarding non-significant results, it is worthwhile to consider some examples from research on individual differences. In this literature, there is a body of non-significant results, both in behavioural studies <span class="citation">(<a href="#ref-daidoneVocabularySizeKey2021" role="doc-biblioref">Daidone &amp; Darcy, 2021</a>; <a href="#ref-hedge2018a" role="doc-biblioref">Hedge et al., 2018</a>; <a href="#ref-murakiSimulatingSemanticsAre2021" role="doc-biblioref">Muraki &amp; Pexman, 2021</a>; <a href="#ref-ponari2018a" role="doc-biblioref">Ponari, Norbury, Rotaru, et al., 2018</a>; <a href="#ref-rodriguez-ferreiroSemanticPrimingSchizotypal2020" role="doc-biblioref">Rodríguez-Ferreiro et al., 2020</a>; for a Bayes factor analysis, see <a href="#ref-rouderPsychometricsIndividualDifferences2019" role="doc-biblioref">Rouder &amp; Haaf, 2019</a>)</span> and in neuroscientific studies <span class="citation">(<a href="#ref-diazNeuralSensitivityPhonological2021" role="doc-biblioref">Diaz et al., 2021</a>)</span>. A greater availability of power analyses within this topic area and others will at least shed light on the influence of statistical power on the results. Furthermore, power analyses facilitate the identification of sensible sample sizes for future studies. Last, it should be noted that although increasing the statistical power comes at a cost in the short term, power analyses will help maximise the use of research funding in the long term by fostering more replicable research <span class="citation">(see <a href="#ref-vasishthHowEmbraceVariation2021" role="doc-biblioref">Vasishth &amp; Gelman, 2021</a>; remember <a href="#ref-opensciencecollaborationEstimatingReproducibilityPsychological2015" role="doc-biblioref">Open Science Collaboration, 2015</a>)</span>.</p>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-al-azaryCanYouTouch2022" class="csl-entry">
Al-Azary, H., Yu, T., &amp; McRae, K. (2022). Can you touch the <span>N400</span>? <span>The</span> interactive effects of body-object interaction and task demands on <span>N400</span> amplitudes and decision latencies. <em>Brain and Language</em>, <em>231</em>, 105147. <a href="https://doi.org/10.1016/j.bandl.2022.105147">https://doi.org/10.1016/j.bandl.2022.105147</a>
</div>
<div id="ref-albersWhenPowerAnalyses2018" class="csl-entry">
Albers, C., &amp; Lakens, D. (2018). When power analyses based on pilot data are biased: <span>Inaccurate</span> effect size estimators and follow-up bias. <em>Journal of Experimental Social Psychology</em>, <em>74</em>, 187–195. <a href="https://doi.org/10.1016/j.jesp.2017.09.004">https://doi.org/10.1016/j.jesp.2017.09.004</a>
</div>
<div id="ref-andersonResponseCommentEstimating2016" class="csl-entry">
Anderson, C. J., Bahník, Š., Barnett-Cowan, M., Bosco, F. A., Chandler, J., Chartier, C. R., Cheung, F., Christopherson, C. D., Cordes, A., Cremata, E. J., Della Penna, N., Estel, V., Fedor, A., Fitneva, S. A., Frank, M. C., Grange, J. A., Hartshorne, J. K., Hasselman, F., Henninger, F., … Zuni, K. (2016). Response to <span>Comment</span> on <span>“<span>Estimating</span> the reproducibility of psychological science.”</span> <em>Science</em>, <em>351</em>(6277), 1037–1037. <a href="https://doi.org/10.1126/science.aad9163">https://doi.org/10.1126/science.aad9163</a>
</div>
<div id="ref-aujlaLanguageExperiencePredicts2021" class="csl-entry">
Aujla, H. (2021). Language experience predicts semantic priming of lexical decision. <em>Canadian Journal of Experimental Psychology/Revue Canadienne de Psychologie Expérimentale</em>, <em>75</em>(3), 235. <a href="https://doi.org/10.1037/cep0000255">https://doi.org/10.1037/cep0000255</a>
</div>
<div id="ref-balotaDepthAutomaticSpreading1986" class="csl-entry">
Balota, D. A., &amp; Lorch, R. F. (1986). Depth of automatic spreading activation: <span>Mediated</span> priming effects in pronunciation but not in lexical decision. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, <em>12</em>(3), 336–345. <a href="https://doi.org/10.1037/0278-7393.12.3.336">https://doi.org/10.1037/0278-7393.12.3.336</a>
</div>
<div id="ref-balotaMeanResponseLatency2008" class="csl-entry">
Balota, D. A., Yap, M. J., Cortese, M. J., &amp; Watson, J. M. (2008). Beyond mean response latency: <span>Response</span> time distributional analyses of semantic priming. <em>Journal of Memory and Language</em>, <em>59</em>(4), 495–523. <a href="https://doi.org/10.1016/j.jml.2007.10.004">https://doi.org/10.1016/j.jml.2007.10.004</a>
</div>
<div id="ref-balota2007a" class="csl-entry">
Balota, D. A., Yap, M. J., Hutchison, K. A., Cortese, M. J., Kessler, B., Loftis, B., Neely, J. H., Nelson, D. L., Simpson, G. B., &amp; Treiman, R. (2007). The <span>English Lexicon Project</span>. <em>Behavior Research Methods</em>, <em>39</em>, 445–459. <a href="https://doi.org/10.3758/BF03193014">https://doi.org/10.3758/BF03193014</a>
</div>
<div id="ref-banksLinguisticDistributionalKnowledge2021" class="csl-entry">
Banks, B., Wingfield, C., &amp; Connell, L. (2021). Linguistic distributional knowledge and sensorimotor grounding both contribute to semantic category production. <em>Cognitive Science</em>, <em>45</em>(10), e13055. <a href="https://doi.org/10.1111/cogs.13055">https://doi.org/10.1111/cogs.13055</a>
</div>
<div id="ref-barsalouEstablishingGeneralizableMechanisms2019" class="csl-entry">
Barsalou, L. W. (2019). Establishing generalizable mechanisms. <em>Psychological Inquiry</em>, <em>30</em>(4), 220–230. <a href="https://doi.org/10.1080/1047840X.2019.1693857">https://doi.org/10.1080/1047840X.2019.1693857</a>
</div>
<div id="ref-barsalouLanguageSimulationConceptual2008" class="csl-entry">
Barsalou, L. W., Santos, A., Simmons, W. K., &amp; Wilson, C. D. (2008). Language and simulation in conceptual processing. In <em>Symbols and <span>Embodiment</span></em>. <span>Oxford University Press</span>. <a href="https://doi.org/10.1093/acprof:oso/9780199217274.003.0013">https://doi.org/10.1093/acprof:oso/9780199217274.003.0013</a>
</div>
<div id="ref-beckerLongtermSemanticPriming1997" class="csl-entry">
Becker, S., Moscovitch, M., Behrmann, M., &amp; Joordens, S. (1997). Long-term semantic priming: <span>A</span> computational account and empirical evidence. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, <em>23</em>(5), 1059–1082. <a href="https://doi.org/10.1037/0278-7393.23.5.1059">https://doi.org/10.1037/0278-7393.23.5.1059</a>
</div>
<div id="ref-bernabeuDutchModalityExclusivity2018" class="csl-entry">
Bernabeu, P. (2018). <em>Dutch modality exclusivity norms for 336 properties and 411 concepts</em>. <span>PsyArXiv</span>. <a href="https://doi.org/10.31234/osf.io/s2c5h">https://doi.org/10.31234/osf.io/s2c5h</a>
</div>
<div id="ref-bernabeu2021a" class="csl-entry">
Bernabeu, P., Lynott, D., &amp; Connell, L. (2021). <em>Preregistration: <span>The</span> interplay between linguistic and embodied systems in conceptual processing</em>. <span>OSF</span>. <a href="https://osf.io/ftydw">https://osf.io/ftydw</a>
</div>
<div id="ref-bernabeu2017a" class="csl-entry">
Bernabeu, P., Willems, R. M., &amp; Louwerse, M. M. (2017). Modality switch effects emerge early and increase throughout conceptual processing: <span>Evidence</span> from <span>ERPs</span>. In G. Gunzelmann, A. Howes, T. Tenbrink, &amp; E. J. Davelaar (Eds.), <em>Proceedings of the 39th <span>Annual Conference</span> of the <span>Cognitive Science Society</span></em> (pp. 1629–1634). <span>Cognitive Science Society</span>. <a href="https://doi.org/10.31234/osf.io/a5pcz">https://doi.org/10.31234/osf.io/a5pcz</a>
</div>
<div id="ref-bottiniConcretenessAdvantageLexical2021" class="csl-entry">
Bottini, R., Morucci, P., D’Urso, A., Collignon, O., &amp; Crepaldi, D. (2021). The concreteness advantage in lexical decision does not depend on perceptual simulations. <em>Journal of Experimental Psychology: General</em>. <a href="https://doi.org/10.1037/xge0001090">https://doi.org/10.1037/xge0001090</a>
</div>
<div id="ref-brauer2018a" class="csl-entry">
Brauer, M., &amp; Curtin, J. J. (2018). Linear mixed-effects models and the analysis of nonindependent data: <span>A</span> unified framework to analyze categorical and continuous independent variables that vary within-subjects and/or within-items. <em>Psychological Methods</em>, <em>23</em>(3), 389–411. <a href="https://doi.org/10.1037/met0000159">https://doi.org/10.1037/met0000159</a>
</div>
<div id="ref-brysbaertHowManyParticipants2019" class="csl-entry">
Brysbaert, M. (2019). How many participants do we have to include in properly powered experiments? <span>A</span> tutorial of power analysis with reference tables. <em>Journal of Cognition</em>, <em>2</em>(1, 1), 16. <a href="https://doi.org/10.5334/joc.72">https://doi.org/10.5334/joc.72</a>
</div>
<div id="ref-bullinariaExtractingSemanticRepresentations2007" class="csl-entry">
Bullinaria, J. A., &amp; Levy, J. P. (2007). Extracting semantic representations from word co-occurrence statistics: <span>A</span> computational study. <em>Behavior Research Methods</em>, <em>39</em>(3), 510–526. <a href="https://doi.org/10.3758/BF03193020">https://doi.org/10.3758/BF03193020</a>
</div>
<div id="ref-burman2008a" class="csl-entry">
Burman, D., Bitan, T., &amp; Both, J. (2008). Sex differences in neural processing of language among children. <em>Neuropsychologia</em>, <em>46, 5</em>, 1349–1362. <a href="https://doi.org/10.1016/j.neuropsychologia.2007.12.021">https://doi.org/10.1016/j.neuropsychologia.2007.12.021</a>
</div>
<div id="ref-buttonPowerFailureWhy2013" class="csl-entry">
Button, K. S., Ioannidis, J. P. A., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S. J., &amp; Munafò, M. R. (2013). Power failure: <span>Why</span> small sample size undermines the reliability of neuroscience. <em>Nature Reviews Neuroscience</em>, <em>14</em>(5, 5), 365–376. <a href="https://doi.org/10.1038/nrn3475">https://doi.org/10.1038/nrn3475</a>
</div>
<div id="ref-chenMandarinChineseModality2019" class="csl-entry">
Chen, I.-H., Zhao, Q., Long, Y., Lu, Q., &amp; Huang, C.-R. (2019). Mandarin <span>Chinese</span> modality exclusivity norms. <em>PLOS ONE</em>, <em>14</em>(2), e0211336. <a href="https://doi.org/10.1371/journal.pone.0211336">https://doi.org/10.1371/journal.pone.0211336</a>
</div>
<div id="ref-connell2019a" class="csl-entry">
Connell, L. (2019). What have labels ever done for us? <span>The</span> linguistic shortcut in conceptual processing. <em>Language, Cognition and Neuroscience</em>, <em>34</em>(10), 1308–1318. <a href="https://doi.org/10.1080/23273798.2018.1471512">https://doi.org/10.1080/23273798.2018.1471512</a>
</div>
<div id="ref-connell2013a" class="csl-entry">
Connell, L., &amp; Lynott, D. (2013). Flexible and fast: <span>Linguistic</span> shortcut affects both shallow and deep conceptual processing. <em>Psychonomic Bulletin &amp; Review</em>, <em>20, 3</em>, 542–550. <a href="https://doi.org/10.3758/s13423-012-0368-x">https://doi.org/10.3758/s13423-012-0368-x</a>
</div>
<div id="ref-connellSeeHearWhat2014" class="csl-entry">
Connell, L., &amp; Lynott, D. (2014a). I see/hear what you mean: <span>Semantic</span> activation in visual word recognition depends on perceptual attention. <em>Journal of Experimental Psychology: General</em>, <em>143</em>(2), 527–533. <a href="https://doi.org/10.1037/a0034626">https://doi.org/10.1037/a0034626</a>
</div>
<div id="ref-connellInteroceptionForgottenModality2018" class="csl-entry">
Connell, L., Lynott, D., &amp; Banks, B. (2018). Interoception: The forgotten modality in perceptual grounding of abstract and concrete concepts. <em>Philosophical Transactions of the Royal Society B: Biological Sciences</em>, <em>373</em>(1752), 20170143. <a href="https://doi.org/10.1098/rstb.2017.0143">https://doi.org/10.1098/rstb.2017.0143</a>
</div>
<div id="ref-corkerHighQualityDirect2014" class="csl-entry">
Corker, K. S., Lynott, D., Wortman, J., Connell, L., Donnellan, M. B., Lucas, R. E., &amp; O’Brien, K. (2014). High quality direct replications matter: <span>Response</span> to <span>Williams</span> (2014). <em>Social Psychology</em>, <em>45</em>(4), 324–326.
</div>
<div id="ref-daidoneVocabularySizeKey2021" class="csl-entry">
Daidone, D., &amp; Darcy, I. (2021). Vocabulary size is a key factor in predicting second language lexical encoding accuracy. <em>Frontiers in Psychology</em>, <em>12</em>, 688356. <a href="https://doi.org/10.3389/fpsyg.2021.688356">https://doi.org/10.3389/fpsyg.2021.688356</a>
</div>
<div id="ref-davies2017a" class="csl-entry">
Davies, R. A., Arnell, R., Birchenough, J. M., Grimmond, D., &amp; Houlson, S. (2017). Reading through the life span: <span>Individual</span> differences in psycholinguistic effects. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, <em>43</em>(8), 1298. <a href="https://doi.org/10.1037/xlm0000366">https://doi.org/10.1037/xlm0000366</a>
</div>
<div id="ref-dedeyneVisualAffectiveMultimodal2021" class="csl-entry">
De Deyne, S., Navarro, D. J., Collell, G., &amp; Perfors, A. (2021). Visual and affective multimodal models of word meaning in language and mind. <em>Cognitive Science</em>, <em>45</em>(1), e12922. <a href="https://doi.org/10.1111/cogs.12922">https://doi.org/10.1111/cogs.12922</a>
</div>
<div id="ref-de2019a" class="csl-entry">
De Deyne, S., Navarro, D. J., Perfors, A., Brysbaert, M., &amp; Storms, G. (2019). The <span>“<span>Small World</span> of <span>Words</span>”</span> <span>English</span> word association norms for over 12,000 cue words. <em>Behavior Research Methods</em>, <em>51</em>, 987–1006. <a href="https://doi.org/10.3758/s13428-018-1115-7">https://doi.org/10.3758/s13428-018-1115-7</a>
</div>
<div id="ref-de2016a" class="csl-entry">
De Deyne, S., Perfors, A., &amp; Navarro, D. (2016). Predicting human similarity judgments with distributional models: <span>The</span> value of word associations. <em>Proceedings of <span>COLING</span> 2016, the 26th International Conference on Computational Linguistics: <span>Technical</span> Papers</em>, 1861–1870.
</div>
<div id="ref-dewitMaskedSemanticPriming2015" class="csl-entry">
de Wit, B., &amp; Kinoshita, S. (2015). The masked semantic priming effect is task dependent: <span>Reconsidering</span> the automatic spreading activation process. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, <em>41</em>(4), 1062–1075. <a href="https://doi.org/10.1037/xlm0000074">https://doi.org/10.1037/xlm0000074</a>
</div>
<div id="ref-delucaRedefiningBilingualismSpectrum2019" class="csl-entry">
DeLuca, V., Rothman, J., Bialystok, E., &amp; Pliatsikas, C. (2019). Redefining bilingualism as a spectrum of experiences that differentially affects brain structure and function. <em>Proceedings of the National Academy of Sciences</em>, <em>116</em>(15), 7565–7574. <a href="https://doi.org/10.1073/pnas.1811513116">https://doi.org/10.1073/pnas.1811513116</a>
</div>
<div id="ref-diazNeuralSensitivityPhonological2021" class="csl-entry">
Diaz, M. T., Karimi, H., Troutman, S. B. W., Gertel, V. H., Cosgrove, A. L., &amp; Zhang, H. (2021). Neural sensitivity to phonological characteristics is stable across the lifespan. <em>NeuroImage</em>, <em>225</em>, 117511. <a href="https://doi.org/10.1016/j.neuroimage.2020.117511">https://doi.org/10.1016/j.neuroimage.2020.117511</a>
</div>
<div id="ref-dils2010a" class="csl-entry">
Dils, A. T., &amp; Boroditsky, L. (2010). Visual motion aftereffect from understanding motion language. <em>Proceedings of the National Academy of Sciences</em>, <em>107</em>(37), 16396–16400. <a href="https://doi.org/10.1073/pnas.1009438107">https://doi.org/10.1073/pnas.1009438107</a>
</div>
<div id="ref-fernandinoDecodingInformationStructure2022" class="csl-entry">
Fernandino, L., Tong, J.-Q., Conant, L. L., Humphries, C. J., &amp; Binder, J. R. (2022). Decoding the information structure underlying the neural representation of concepts. <em>Proceedings of the National Academy of Sciences</em>, <em>119</em>(6). <a href="https://doi.org/10.1073/pnas.2108091119">https://doi.org/10.1073/pnas.2108091119</a>
</div>
<div id="ref-fettermanFeelingWarmBeing2018" class="csl-entry">
Fetterman, A. K., Wilkowski, B. M., &amp; Robinson, M. D. (2018). On feeling warm and being warm: <span>Daily</span> perceptions of physical warmth fluctuate with interpersonal warmth. <em>Social Psychological and Personality Science</em>, <em>9</em>(5), 560–567. <a href="https://doi.org/10.1177/1948550617712032">https://doi.org/10.1177/1948550617712032</a>
</div>
<div id="ref-floresdarcaisSemanticActivationRecognition1985" class="csl-entry">
Flores d’Arcais, G. B., Schreuder, R., &amp; Glazenborg, G. (1985). Semantic activation during recognition of referential words. <em>Psychological Research</em>, <em>47</em>(1), 39–49. <a href="https://doi.org/10.1007/BF00309217">https://doi.org/10.1007/BF00309217</a>
</div>
<div id="ref-gelmanPowerCalculationsAssessing2014" class="csl-entry">
Gelman, A., &amp; Carlin, J. (2014). Beyond power calculations: Assessing type <span>S</span> (sign) and type <span>M</span> (magnitude) errors. <em>Perspectives on Psychological Science</em>, <em>9</em>(6), 641–651. <a href="https://doi.org/10.1177/1745691614551642">https://doi.org/10.1177/1745691614551642</a>
</div>
<div id="ref-gilbertCommentEstimatingReproducibility2016" class="csl-entry">
Gilbert, D. T., King, G., Pettigrew, S., &amp; Wilson, T. D. (2016). Comment on <span>“<span>Estimating</span> the reproducibility of psychological science.”</span> <em>Science</em>, <em>351</em>(6277), 1037–1037. <a href="https://doi.org/10.1126/science.aad7243">https://doi.org/10.1126/science.aad7243</a>
</div>
<div id="ref-hedge2018a" class="csl-entry">
Hedge, C., Powell, G., &amp; Sumner, P. (2018). The reliability paradox: <span>Why</span> robust cognitive tasks do not produce reliable individual differences. <em>Behavior Research Methods</em>, <em>50</em>(3), 1166–1186. <a href="https://doi.org/10.3758/s13428-017-0935-1">https://doi.org/10.3758/s13428-017-0935-1</a>
</div>
<div id="ref-heymanReliabilityItemlevelSemantic2018" class="csl-entry">
Heyman, T., Bruninx, A., Hutchison, K. A., &amp; Storms, G. (2018). The (un)reliability of item-level semantic priming effects. <em>Behavior Research Methods</em>, <em>50</em>(6), 2173–2183. <a href="https://doi.org/10.3758/s13428-018-1040-9">https://doi.org/10.3758/s13428-018-1040-9</a>
</div>
<div id="ref-hoedemakerItTakesTime2014" class="csl-entry">
Hoedemaker, R. S., &amp; Gordon, P. C. (2014). It takes time to prime: <span>Semantic</span> priming in the ocular lexical decision task. <em>Journal of Experimental Psychology: Human Perception and Performance</em>, <em>40</em>(6), 2179–2197. <a href="https://doi.org/10.1037/a0037677">https://doi.org/10.1037/a0037677</a>
</div>
<div id="ref-holt2006a" class="csl-entry">
Holt, L. E., &amp; Beilock, S. L. (2006). Expertise and its embodiment: <span>Examining</span> the impact of sensorimotor skill expertise on the representation of action-related text. <em>Psychonomic Bulletin &amp; Review</em>, <em>13</em>(4), 694–701. <a href="https://doi.org/10.3758/BF03193983">https://doi.org/10.3758/BF03193983</a>
</div>
<div id="ref-hutchinson2013a" class="csl-entry">
Hutchinson, S., &amp; Louwerse, M. M. (2013). Language statistics and individual differences in processing primary metaphors. <em>Cognitive Linguistics</em>, <em>24</em>(4), 667–687. <a href="https://doi.org/10.1515/cog-2013-0023">https://doi.org/10.1515/cog-2013-0023</a>
</div>
<div id="ref-hutchisonSemanticPrimingDue2003" class="csl-entry">
Hutchison, K. A. (2003). Is semantic priming due to association strength or feature overlap? <span>A</span> microanalytic review. <em>Psychonomic Bulletin &amp; Review</em>, <em>10</em>(4), 785–813. <a href="https://doi.org/10.3758/BF03196544">https://doi.org/10.3758/BF03196544</a>
</div>
<div id="ref-hutchison2013a" class="csl-entry">
Hutchison, K. A., Balota, D. A., Neely, J. H., Cortese, M. J., Cohen-Shikora, E. R., Tse, C.-S., Yap, M. J., Bengson, J. J., Niemeyer, D., &amp; Buchanan, E. (2013). The semantic priming project. <em>Behavior Research Methods</em>, <em>45</em>, 1099–1114. <a href="https://doi.org/10.3758/s13428-012-0304-z">https://doi.org/10.3758/s13428-012-0304-z</a>
</div>
<div id="ref-joordensLongShortSemantic1997" class="csl-entry">
Joordens, S., &amp; Becker, S. (1997). The long and short of semantic priming effects in lexical decision. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, <em>23</em>(5), 1083–1105. <a href="https://doi.org/10.1037/0278-7393.23.5.1083">https://doi.org/10.1037/0278-7393.23.5.1083</a>
</div>
<div id="ref-jung2019a" class="csl-entry">
Jung, M., Mody, M., Fujioka, T., Kimura, Y., Okazawa, H., &amp; Kosaka, H. (2019). Sex differences in white matter pathways related to language ability. <em>Frontiers in Human Neuroscience</em>, <em>13</em>, 898. <a href="https://doi.org/10.3389/fnins.2019.00898">https://doi.org/10.3389/fnins.2019.00898</a>
</div>
<div id="ref-kiela2014a" class="csl-entry">
Kiela, D., &amp; Bottou, L. (2014). Learning image embeddings using convolutional neural networks for improved multi-modal semantics. <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (<span>EMNLP</span></em>, 36–45. <a href="https://doi.org/10.3115/v1/D14-1005">https://doi.org/10.3115/v1/D14-1005</a>
</div>
<div id="ref-kosIndividualVariationLate2012" class="csl-entry">
Kos, M., Van den Brink, D., &amp; Hagoort, P. (2012). Individual variation in the late positive complex to semantic anomalies. <em>Frontiers in Psychology</em>, <em>3</em>(318). <a href="https://doi.org/10.3389/fpsyg.2012.00318">https://doi.org/10.3389/fpsyg.2012.00318</a>
</div>
<div id="ref-kumleEstimatingPowerGeneralized2021" class="csl-entry">
Kumle, L., Võ, M. L.-H., &amp; Draschkow, D. (2021). Estimating power in (generalized) linear mixed models: <span>An</span> open introduction and tutorial in <span>R</span>. <em>Behavior Research Methods</em>. <a href="https://doi.org/10.3758/s13428-021-01546-0">https://doi.org/10.3758/s13428-021-01546-0</a>
</div>
<div id="ref-lam2015a" class="csl-entry">
Lam, K. J., Dijkstra, T., &amp; Rueschemeyer, S. A. (2015). Feature activation during word recognition: Action, visual, and associative-semantic priming effects. <em>Frontiers in Psychology</em>, <em>6</em>, 659. <a href="https://doi.org/10.3389/fpsyg.2015.00659">https://doi.org/10.3389/fpsyg.2015.00659</a>
</div>
<div id="ref-lamiellStatisticalThinkingPsychology2019" class="csl-entry">
Lamiell, J. T. (2019). Statistical thinking in psychology: Some needed critical perspective on what <span>“everyone knows.”</span> In J. T. Lamiell (Ed.), <em>Psychology’s <span>Misuse</span> of <span>Statistics</span> and <span>Persistent Dismissal</span> of its <span>Critics</span></em> (pp. 99–121). <span>Springer International Publishing</span>. <a href="https://doi.org/10.1007/978-3-030-12131-0_5">https://doi.org/10.1007/978-3-030-12131-0_5</a>
</div>
<div id="ref-landauerIntroductionLatentSemantic1998" class="csl-entry">
Landauer, T. K., Foltz, P. W., &amp; Laham, D. (1998). An introduction to latent semantic analysis. <em>Discourse Processes</em>, <em>25</em>(2-3), 259–284. <a href="https://doi.org/10.1080/01638539809545028">https://doi.org/10.1080/01638539809545028</a>
</div>
<div id="ref-lim2020a" class="csl-entry">
Lim, R. Y., Yap, M. J., &amp; Tse, C.-S. (2020). Individual differences in <span>Cantonese Chinese</span> word recognition: <span>Insights</span> from the <span>Chinese Lexicon Project</span>. <em>Quarterly Journal of Experimental Psychology</em>, <em>73</em>(4), 504–518. <a href="https://doi.org/10.1177/1747021820906566">https://doi.org/10.1177/1747021820906566</a>
</div>
<div id="ref-lokenMeasurementErrorReplication2017" class="csl-entry">
Loken, E., &amp; Gelman, A. (2017). Measurement error and the replication crisis. <em>Science</em>, <em>355</em>(6325), 584–585. <a href="https://doi.org/10.1126/science.aal3618">https://doi.org/10.1126/science.aal3618</a>
</div>
<div id="ref-louwerseTasteWordsLinguistic2011" class="csl-entry">
Louwerse, M. M., &amp; Connell, L. (2011). A taste of words: Linguistic context and perceptual simulation predict the modality of words. <em>Cognitive Science</em>, <em>35</em>(2), 381–398. <a href="https://doi.org/10.1111/j.1551-6709.2010.01157.x">https://doi.org/10.1111/j.1551-6709.2010.01157.x</a>
</div>
<div id="ref-louwerse2015a" class="csl-entry">
Louwerse, M. M., Hutchinson, S., Tillman, R., &amp; Recchia, G. (2015). Effect size matters: <span>The</span> role of language statistics and perceptual simulation in conceptual processing. <em>Language, Cognition and Neuroscience</em>, <em>30</em>(4), 430–447. <a href="https://doi.org/10.1080/23273798.2014.981552">https://doi.org/10.1080/23273798.2014.981552</a>
</div>
<div id="ref-lund1996a" class="csl-entry">
Lund, K., &amp; Burgess, C. (1996). Producing high-dimensional semantic spaces from lexical co-occurrence. <em>Behavior Research Methods, Instruments, &amp; Computers</em>, <em>28</em>(2), 203–208. <a href="https://doi.org/10.3758/BF03204766">https://doi.org/10.3758/BF03204766</a>
</div>
<div id="ref-lund1995a" class="csl-entry">
Lund, K., Burgess, C., &amp; Atchley, R. A. (1995). Semantic and associative priming in high-dimensional semantic space. <em>Proceedings of the Cognitive Science Society</em>, 660–665.
</div>
<div id="ref-lynott2020a" class="csl-entry">
Lynott, D., Connell, L., Brysbaert, M., Brand, J., &amp; Carney, J. (2020). The <span>Lancaster Sensorimotor Norms</span>: <span>Multidimensional</span> measures of perceptual and action strength for 40,000 <span>English</span> words. <em>Behavior Research Methods</em>, <em>52</em>, 1271–1291. <a href="https://doi.org/10.3758/s13428-019-01316-z">https://doi.org/10.3758/s13428-019-01316-z</a>
</div>
<div id="ref-lynottReplicationExperiencingPhysical2014" class="csl-entry">
Lynott, D., Corker, K. S., Wortman, J., Connell, L., Donnellan, M. B., Lucas, R. E., &amp; O’Brien, K. (2014). Replication of <span>“<span>Experiencing</span> physical warmth promotes interpersonal warmth”</span> by <span>Williams</span> and <span>Bargh</span> (2008). <em>Social Psychology</em>, <em>45</em>(3), 216–222. <a href="https://doi.org/10.1027/1864-9335/a000187">https://doi.org/10.1027/1864-9335/a000187</a>
</div>
<div id="ref-mak2019a" class="csl-entry">
Mak, M., &amp; Willems, R. M. (2019). Mental simulation during literary reading: <span>Individual</span> differences revealed with eye-tracking. <em>Language, Cognition and Neuroscience</em>, <em>34</em>(4), 511–535. <a href="https://doi.org/10.1080/23273798.2018.1552007">https://doi.org/10.1080/23273798.2018.1552007</a>
</div>
<div id="ref-mandera2017a" class="csl-entry">
Mandera, P., Keuleers, E., &amp; Brysbaert, M. (2017). Explaining human performance in psycholinguistic tasks with models of semantic similarity based on prediction and counting: <span>A</span> review and empirical validation. <em>Journal of Memory and Language</em>, <em>92</em>, 57–78. <a href="https://doi.org/10.1016/j.jml.2016.04.001">https://doi.org/10.1016/j.jml.2016.04.001</a>
</div>
<div id="ref-marekReproducibleBrainwideAssociation2022" class="csl-entry">
Marek, S., Tervo-Clemmens, B., Calabro, F. J., Montez, D. F., Kay, B. P., Hatoum, A. S., Donohue, M. R., Foran, W., Miller, R. L., Hendrickson, T. J., Malone, S. M., Kandala, S., Feczko, E., Miranda-Dominguez, O., Graham, A. M., Earl, E. A., Perrone, A. J., Cordova, M., Doyle, O., … Dosenbach, N. U. F. (2022). Reproducible brain-wide association studies require thousands of individuals. <em>Nature</em>, 1–7. <a href="https://doi.org/10.1038/s41586-022-04492-9">https://doi.org/10.1038/s41586-022-04492-9</a>
</div>
<div id="ref-miceliPerceptualInteroceptiveStrength2021" class="csl-entry">
Miceli, A., Wauthia, E., Lefebvre, L., Ris, L., &amp; Simoes Loureiro, I. (2021). Perceptual and interoceptive strength norms for 270 french words. <em>Frontiers in Psychology</em>, <em>12</em>. <a href="https://www.frontiersin.org/article/10.3389/fpsyg.2021.667271">https://www.frontiersin.org/article/10.3389/fpsyg.2021.667271</a>
</div>
<div id="ref-miceliDifferencesRelatedAging2022" class="csl-entry">
Miceli, A., Wauthia, E., Lefebvre, L., Vallet, G. T., Ris, L., &amp; Loureiro, I. S. (2022). Differences related to aging in sensorimotor knowledge: <span>Investigation</span> of perceptual strength and body object interaction. <em>Archives of Gerontology and Geriatrics</em>, <em>102</em>, 104715. <a href="https://doi.org/10.1016/j.archger.2022.104715">https://doi.org/10.1016/j.archger.2022.104715</a>
</div>
<div id="ref-montero-melisConsistencyMotionEvent2021" class="csl-entry">
Montero-Melis, G. (2021). Consistency in motion event encoding across languages. <em>Frontiers in Psychology</em>, <em>12</em>(625153). <a href="https://doi.org/10.3389/fpsyg.2021.625153">https://doi.org/10.3389/fpsyg.2021.625153</a>
</div>
<div id="ref-montero-melisSatelliteVsVerbframing2017" class="csl-entry">
Montero-Melis, G., Eisenbeiss, S., Narasimhan, B., Ibarretxe-Antuñano, I., Kita, S., Kopecka, A., Lüpke, F., Nikitina, T., Tragel, I., Jaeger, T. F., &amp; Bohnemeyer, J. (2017). Satellite- vs. Verb-framing underpredicts nonverbal motion categorization: Insights from a large language sample and simulations. <em>Cognitive Semantics</em>, <em>3</em>(1), 36–61. <a href="https://doi.org/10.1163/23526416-00301002">https://doi.org/10.1163/23526416-00301002</a>
</div>
<div id="ref-montero-melisNoEvidenceEmbodiment2022" class="csl-entry">
Montero-Melis, G., van Paridon, J., Ostarek, M., &amp; Bylund, E. (2022). No evidence for embodiment: <span>The</span> motor system is not needed to keep action verbs in working memory. <em>Cortex</em>, <em>150</em>, 108–125. <a href="https://doi.org/10.1016/j.cortex.2022.02.006">https://doi.org/10.1016/j.cortex.2022.02.006</a>
</div>
<div id="ref-morucciAugmentedModalityExclusivity2019" class="csl-entry">
Morucci, P., Bottini, R., &amp; Crepaldi, D. (2019). Augmented modality exclusivity norms for concrete and abstract <span>Italian</span> property words. <em>Journal of Cognition</em>, <em>2</em>(1), 42. <a href="https://doi.org/10.5334/joc.88">https://doi.org/10.5334/joc.88</a>
</div>
<div id="ref-murakiSimulatingSemanticsAre2021" class="csl-entry">
Muraki, E. J., &amp; Pexman, P. M. (2021). Simulating semantics: <span>Are</span> individual differences in motor imagery related to sensorimotor effects in language processing? <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, <em>47</em>(12), 1939–1957. <a href="https://doi.org/10.1037/xlm0001039">https://doi.org/10.1037/xlm0001039</a>
</div>
<div id="ref-opensciencecollaborationEstimatingReproducibilityPsychological2015" class="csl-entry">
Open Science Collaboration. (2015). Estimating the reproducibility of psychological science. <em>Science</em>, <em>349</em>(6251), aac4716. <a href="https://doi.org/10.1126/science.aac4716">https://doi.org/10.1126/science.aac4716</a>
</div>
<div id="ref-ostarekStrongInferenceResearch2021" class="csl-entry">
Ostarek, M., &amp; Bottini, R. (2021). Towards strong inference in research on embodiment – <span>Possibilities</span> and limitations of causal paradigms. <em>Journal of Cognition</em>, <em>4</em>(1), 5. <a href="https://doi.org/10.5334/joc.139">https://doi.org/10.5334/joc.139</a>
</div>
<div id="ref-ostarekTaskdependentCausalRole2017" class="csl-entry">
Ostarek, M., &amp; Huettig, F. (2017). A task-dependent causal role for low-level visual processes in spoken word comprehension. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, <em>43</em>(8), 1215–1224. <a href="https://doi.org/10.1037/xlm0000375">https://doi.org/10.1037/xlm0000375</a>
</div>
<div id="ref-ostarekSixChallengesEmbodiment2019" class="csl-entry">
Ostarek, M., &amp; Huettig, F. (2019). Six challenges for embodiment research. <em>Current Directions in Psychological Science</em>, <em>28</em>(6), 593–599. <a href="https://doi.org/10.1177/0963721419866441">https://doi.org/10.1177/0963721419866441</a>
</div>
<div id="ref-paivioMentalRepresentationsDual1990" class="csl-entry">
Paivio, A. (1990). <em>Mental representations: A dual coding approach</em>. <span>Oxford University Press</span>. <a href="https://doi.org/10.1093/acprof:oso/9780195066661.001.0001">https://doi.org/10.1093/acprof:oso/9780195066661.001.0001</a>
</div>
<div id="ref-pearsonHeterogeneityMentalRepresentation2015" class="csl-entry">
Pearson, J., &amp; Kosslyn, S. M. (2015). The heterogeneity of mental representation: <span>Ending</span> the imagery debate. <em>Proceedings of the National Academy of Sciences</em>, <em>112</em>(33), 10089–10092. <a href="https://doi.org/10.1073/pnas.1504933112">https://doi.org/10.1073/pnas.1504933112</a>
</div>
<div id="ref-pecherDoesPizzaPrime1998" class="csl-entry">
Pecher, D., Zeelenberg, R., &amp; Raaijmakers, J. G. W. (1998). Does pizza prime coin? <span>Perceptual</span> priming in lexical decision and pronunciation. <em>Journal of Memory and Language</em>, <em>38</em>(4), 401–418. <a href="https://doi.org/10.1006/jmla.1997.2557">https://doi.org/10.1006/jmla.1997.2557</a>
</div>
<div id="ref-perfettiLexicalQualityHypothesis2002" class="csl-entry">
Perfetti, C. A., &amp; Hart, L. (2002). The lexical quality hypothesis. In L. Verhoeven, C. Elbro, &amp; P. Reitsma (Eds.), <em>Studies in <span>Written Language</span> and <span>Literacy</span></em> (Vol. 11, pp. 189–213). <span>John Benjamins Publishing Company</span>. <a href="https://doi.org/10.1075/swll.11.14per">https://doi.org/10.1075/swll.11.14per</a>
</div>
<div id="ref-petilli2021a" class="csl-entry">
Petilli, M. A., Günther, F., Vergallito, A., Ciapparelli, M., &amp; Marelli, M. (2021). Data-driven computational models reveal perceptual simulation in word processing. <em>Journal of Memory and Language</em>, <em>117</em>, 104194. <a href="https://doi.org/10.1016/j.jml.2020.104194">https://doi.org/10.1016/j.jml.2020.104194</a>
</div>
<div id="ref-pexman2017a" class="csl-entry">
Pexman, P. M., Heard, A., Lloyd, E., &amp; Yap, M. J. (2017). The <span>Calgary</span> semantic decision project: <span>Concrete</span>/abstract decision data for 10,000 <span>English</span> words. <em>Behavior Research Methods</em>, <em>49</em>(2), 407–417. <a href="https://doi.org/10.3758/s13428-016-0720-6">https://doi.org/10.3758/s13428-016-0720-6</a>
</div>
<div id="ref-pexman2018a" class="csl-entry">
Pexman, P. M., &amp; Yap, M. J. (2018). Individual differences in semantic processing: <span>Insights</span> from the <span>Calgary</span> semantic decision project. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, <em>44</em>(7), 1091–1112. <a href="https://doi.org/10.1037/xlm0000499">https://doi.org/10.1037/xlm0000499</a>
</div>
<div id="ref-planchueloNatureWordAssociations2022" class="csl-entry">
Planchuelo, C., Buades-Sitjar, F., Hinojosa, J. A., &amp; Duñabeitia, J. A. (2022). The <span>Nature</span> of <span>Word Associations</span> in <span>Sentence Contexts</span>. <em>Experimental Psychology</em>. <a href="https://doi.org/10.1027/1618-3169/a000547">https://doi.org/10.1027/1618-3169/a000547</a>
</div>
<div id="ref-plautIndividualDevelopmentalDifferences2000" class="csl-entry">
Plaut, D. C., &amp; Booth, J. R. (2000). Individual and developmental differences in semantic priming: <span>Empirical</span> and computational support for a single-mechanism account of lexical processing. <em>Psychological Review</em>, <em>107</em>(4), 786–823. <a href="https://doi.org/10.1037/0033-295X.107.4.786">https://doi.org/10.1037/0033-295X.107.4.786</a>
</div>
<div id="ref-ponari2018a" class="csl-entry">
Ponari, M., Norbury, C. F., Rotaru, A., Lenci, A., &amp; Vigliocco, G. (2018). Learning abstract words and concepts: <span>Insights</span> from developmental language disorder. <em>Philosophical Transactions of the Royal Society B: Biological Sciences</em>, <em>373</em>, 20170140. <a href="https://doi.org/10.1098/rstb.2017.0140">https://doi.org/10.1098/rstb.2017.0140</a>
</div>
<div id="ref-pylyshynWhatMindEye1973" class="csl-entry">
Pylyshyn, Z. W. (1973). What the mind’s eye tells the mind’s brain: <span>A</span> critique of mental imagery. <em>Psychological Bulletin</em>, <em>80</em>(1), 1–24. <a href="https://doi.org/10.1037/h0034650">https://doi.org/10.1037/h0034650</a>
</div>
<div id="ref-reillyEnglishLexiconMirrors2020" class="csl-entry">
Reilly, J., Flurie, M., &amp; Peelle, J. E. (2020). The <span>English</span> lexicon mirrors functional brain activation for a sensory hierarchy dominated by vision and audition: <span class="nocase">Point-counterpoint</span>. <em>Journal of Neurolinguistics</em>, <em>55</em>, 100895. <a href="https://doi.org/10.1016/j.jneuroling.2020.100895">https://doi.org/10.1016/j.jneuroling.2020.100895</a>
</div>
<div id="ref-rodriguez-ferreiroSemanticPrimingSchizotypal2020" class="csl-entry">
Rodríguez-Ferreiro, J., Aguilera, M., &amp; Davies, R. (2020). Semantic priming and schizotypal personality: Reassessing the link between thought disorder and enhanced spreading of semantic activation. <em>PeerJ</em>, <em>8</em>, e9511. <a href="https://doi.org/10.7717/peerj.9511">https://doi.org/10.7717/peerj.9511</a>
</div>
<div id="ref-roqueVisionVerbsDominate2015" class="csl-entry">
Roque, L. S., Kendrick, K. H., Norcliffe, E., Brown, P., Defina, R., Dingemanse, M., Dirksmeyer, T., Enfield, N. J., Floyd, S., Hammond, J., Rossi, G., Tufvesson, S., Putten, S. van, &amp; Majid, A. (2015). Vision verbs dominate in conversation across cultures, but the ranking of non-visual verbs varies. <em>Cognitive Linguistics</em>, <em>26</em>(1), 31–60. <a href="https://doi.org/10.1515/cog-2014-0089">https://doi.org/10.1515/cog-2014-0089</a>
</div>
<div id="ref-rouderPsychometricsIndividualDifferences2019" class="csl-entry">
Rouder, J. N., &amp; Haaf, J. M. (2019). A psychometrics of individual differences in experimental tasks. <em>Psychonomic Bulletin &amp; Review</em>, <em>26</em>(2), 452–467. <a href="https://doi.org/10.3758/s13423-018-1558-y">https://doi.org/10.3758/s13423-018-1558-y</a>
</div>
<div id="ref-santosPropertyGenerationReflects2011" class="csl-entry">
Santos, A., Chaigneau, S. E., Simmons, W. K., &amp; Barsalou, L. W. (2011). Property generation reflects word association and situated simulation. <em>Language and Cognition</em>, <em>3</em>(1), 83–119. <a href="https://doi.org/10.1515/langcog.2011.004">https://doi.org/10.1515/langcog.2011.004</a>
</div>
<div id="ref-sassenhagenCommonMisapplicationStatistical2016" class="csl-entry">
Sassenhagen, J., &amp; Alday, P. M. (2016). A common misapplication of statistical inference: <span>Nuisance</span> control with null-hypothesis significance tests. <em>Brain and Language</em>, <em>162</em>, 42–45. <a href="https://doi.org/10.1016/j.bandl.2016.08.001">https://doi.org/10.1016/j.bandl.2016.08.001</a>
</div>
<div id="ref-schreuderEffectsPerceptualConceptual1984" class="csl-entry">
Schreuder, R., Flores d’Arcais, G. B., &amp; Glazenborg, G. (1984). Effects of perceptual and conceptual similarity in semantic priming. <em>Psychological Research</em>, <em>45</em>(4), 339–354. <a href="https://doi.org/10.1007/BF00309710">https://doi.org/10.1007/BF00309710</a>
</div>
<div id="ref-simmonsFMRIEvidenceWord2008" class="csl-entry">
Simmons, W. K., Hamann, S. B., Harenski, C. L., Hu, X. P., &amp; Barsalou, L. W. (2008). <span class="nocase">fMRI</span> evidence for word association and situated simulation in conceptual processing. <em>Journal of Physiology-Paris</em>, <em>102</em>(1), 106–119. <a href="https://doi.org/10.1016/j.jphysparis.2008.03.014">https://doi.org/10.1016/j.jphysparis.2008.03.014</a>
</div>
<div id="ref-speedDutchSensoryModality2021" class="csl-entry">
Speed, L. J., &amp; Brybaert, M. (2021). Dutch sensory modality norms. <em>Behavior Research Methods</em>. <a href="https://doi.org/10.3758/s13428-021-01656-9">https://doi.org/10.3758/s13428-021-01656-9</a>
</div>
<div id="ref-speedGroundingLanguageNeglected2020" class="csl-entry">
Speed, L. J., &amp; Majid, A. (2020). Grounding language in the neglected senses of touch, taste, and smell. <em>Cognitive Neuropsychology</em>, <em>37</em>(5-6), 363–392. <a href="https://doi.org/10.1080/02643294.2019.1623188">https://doi.org/10.1080/02643294.2019.1623188</a>
</div>
<div id="ref-speedImpairedComprehensionSpeed2017" class="csl-entry">
Speed, L. J., van Dam, W. O., Hirath, P., Vigliocco, G., &amp; Desai, R. H. (2017). Impaired comprehension of speed verbs in parkinson’s disease. <em>Journal of the International Neuropsychological Society</em>, <em>23</em>(5), 412–420. <a href="https://doi.org/10.1017/S1355617717000248">https://doi.org/10.1017/S1355617717000248</a>
</div>
<div id="ref-stasenkoWhenConceptsLose2014" class="csl-entry">
Stasenko, A., Garcea, F. E., Dombovy, M., &amp; Mahon, B. Z. (2014). When concepts lose their color: <span>A</span> case of object-color knowledge impairment. <em>Cortex</em>, <em>58</em>, 217–238. <a href="https://doi.org/10.1016/j.cortex.2014.05.013">https://doi.org/10.1016/j.cortex.2014.05.013</a>
</div>
<div id="ref-tiokhinCompetitionPriorityHarms2021" class="csl-entry">
Tiokhin, L., Yan, M., &amp; Morgan, T. J. H. (2021). Competition for priority harms the reliability of science, but reforms can help. <em>Nature Human Behaviour</em>, <em>5</em>(7, 7), 857–867. <a href="https://doi.org/10.1038/s41562-020-01040-1">https://doi.org/10.1038/s41562-020-01040-1</a>
</div>
<div id="ref-tverskyBeliefLawSmall1971" class="csl-entry">
Tversky, A., &amp; Kahneman, D. (1971). Belief in the law of small numbers. <em>Psychological Bulletin</em>, <em>76</em>(2), 105–110. <a href="https://doi.org/10.1037/h0031322">https://doi.org/10.1037/h0031322</a>
</div>
<div id="ref-ullman2008a" class="csl-entry">
Ullman, M. T., Miranda, R. A., &amp; Travers, M. L. (2008). Sex differences in the neurocognition of language. In J. B. Becker, K. J. Berkley, N. Geary, E. Hampson, J. Herman, &amp; E. Young (Eds.), <em>Sex on the brain: <span>From</span> genes to behavior</em> (pp. 291–309). <span>Oxford University Press</span>.
</div>
<div id="ref-vasishthHowEmbraceVariation2021" class="csl-entry">
Vasishth, S., &amp; Gelman, A. (2021). How to embrace variation and accept uncertainty in linguistic and psycholinguistic data analysis. <em>Linguistics</em>, <em>59</em>(5), 1311–1342. <a href="https://doi.org/10.1515/ling-2019-0051">https://doi.org/10.1515/ling-2019-0051</a>
</div>
<div id="ref-vasishthStatisticalSignificanceFilter2018" class="csl-entry">
Vasishth, S., Mertzen, D., Jäger, L. A., &amp; Gelman, A. (2018). The statistical significance filter leads to overoptimistic expectations of replicability. <em>Journal of Memory and Language</em>, <em>103</em>, 151–175. <a href="https://doi.org/10.1016/j.jml.2018.07.004">https://doi.org/10.1016/j.jml.2018.07.004</a>
</div>
<div id="ref-vergallitoPerceptualModalityNorms2020" class="csl-entry">
Vergallito, A., Petilli, M. A., &amp; Marelli, M. (2020). Perceptual modality norms for 1,121 <span>Italian</span> words: <span>A</span> comparison with concreteness and imageability scores and an analysis of their impact in word processing tasks. <em>Behavior Research Methods</em>, <em>52</em>(4), 1599–1616. <a href="https://doi.org/10.3758/s13428-019-01337-8">https://doi.org/10.3758/s13428-019-01337-8</a>
</div>
<div id="ref-versaceImpactEmbodiedSimulation2021" class="csl-entry">
Versace, R., Bailloud, N., Magnan, A., &amp; Ecalle, J. (2021). The impact of embodied simulation in vocabulary learning. <em>The Mental Lexicon</em>, <em>16</em>(1), 2–22. <a href="https://doi.org/10.1075/ml.20011.ver">https://doi.org/10.1075/ml.20011.ver</a>
</div>
<div id="ref-viglioccoTheorySemanticRepresentation2009" class="csl-entry">
Vigliocco, G., Meteyard, L., Andrews, M., &amp; Kousta, S. (2009). <em>Toward a theory of semantic representation</em>. <em>1</em>(2), 219–247. <a href="https://doi.org/10.1515/LANGCOG.2009.011">https://doi.org/10.1515/LANGCOG.2009.011</a>
</div>
<div id="ref-vondermalsburgFalsePositivesOther2017" class="csl-entry">
von der Malsburg, T., &amp; Angele, B. (2017). False positives and other statistical errors in standard analyses of eye movements in reading. <em>Journal of Memory and Language</em>, <em>94</em>, 119–133. <a href="https://doi.org/10.1016/j.jml.2016.10.003">https://doi.org/10.1016/j.jml.2016.10.003</a>
</div>
<div id="ref-vukovic2015a" class="csl-entry">
Vukovic, N., &amp; Williams, J. N. (2015). Individual differences in spatial cognition influence mental simulation of language. <em>Cognition</em>, <em>142</em>, 110–122. <a href="https://doi.org/10.1016/j.cognition.2015.05.017">https://doi.org/10.1016/j.cognition.2015.05.017</a>
</div>
<div id="ref-wallentinChapterGenderDifferences2020" class="csl-entry">
Wallentin, M. (2020). Chapter 6 - <span>Gender</span> differences in language are small but matter for disorders. In R. Lanzenberger, G. S. Kranz, &amp; I. Savic (Eds.), <em>Handbook of <span>Clinical Neurology</span></em> (Vol. 175, pp. 81–102). <span>Elsevier</span>. <a href="https://doi.org/10.1016/B978-0-444-64123-6.00007-2">https://doi.org/10.1016/B978-0-444-64123-6.00007-2</a>
</div>
<div id="ref-wangSocialEmotionDimensional2021" class="csl-entry">
Wang, X., Li, G., Zhao, G., Li, Y., Wang, B., Lin, C.-P., Liu, X., &amp; Bi, Y. (2021). Social and emotion dimensional organizations in the abstract semantic space: The neuropsychological evidence. <em>Scientific Reports</em>, <em>11</em>(1, 1), 23572. <a href="https://doi.org/10.1038/s41598-021-02824-9">https://doi.org/10.1038/s41598-021-02824-9</a>
</div>
<div id="ref-williamsImprovingPsychologicalScience2014" class="csl-entry">
Williams, L. E. (2014). Improving psychological science requires theory, data, and caution: <span>Reflections</span> on <span>Lynott</span> et al. (2014). <em>Social Psychology</em>, <em>45</em>(4), 321–323.
</div>
<div id="ref-wingfieldUnderstandingRoleLinguistic2022" class="csl-entry">
Wingfield, C., &amp; Connell, L. (2022b). Understanding the role of linguistic distributional knowledge in cognition. <em>Language, Cognition and Neuroscience</em>, 1–51. <a href="https://doi.org/10.1080/23273798.2022.2069278">https://doi.org/10.1080/23273798.2022.2069278</a>
</div>
<div id="ref-winterVisionDominatesPerceptual2018" class="csl-entry">
Winter, B., Perlman, M., &amp; Majid, A. (2018). Vision dominates in perceptual language: <span>English</span> sensory vocabulary is optimized for usage. <em>Cognition</em>, <em>179</em>, 213–220. <a href="https://doi.org/10.1016/j.cognition.2018.05.008">https://doi.org/10.1016/j.cognition.2018.05.008</a>
</div>
<div id="ref-yap2012a" class="csl-entry">
Yap, M. J., Balota, D. A., Sibley, D. E., &amp; Ratcliff, R. (2012). Individual differences in visual word recognition: <span>Insights</span> from the <span>English Lexicon Project</span>. <em>Journal of Experimental Psychology: Human Perception and Performance</em>, <em>38, 1</em>, 53–79. <a href="https://doi.org/10.1037/a0024177">https://doi.org/10.1037/a0024177</a>
</div>
<div id="ref-yapAdditiveInteractiveEffects2013" class="csl-entry">
Yap, M. J., Balota, D. A., &amp; Tan, S. E. (2013). Additive and interactive effects in semantic priming: <span>Isolating</span> lexical and decision processes in the lexical decision task. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, <em>39</em>(1), 140–158. <a href="https://doi.org/10.1037/a0028520">https://doi.org/10.1037/a0028520</a>
</div>
<div id="ref-yap2017a" class="csl-entry">
Yap, M. J., Hutchison, K. A., &amp; Tan, L. C. (2017). Individual differences in semantic priming performance: <span>Insights</span> from the semantic priming project. In M. N. Jones (Ed.), <em>Frontiers of cognitive psychology. <span>Big</span> data in cognitive science</em> (pp. 203–226). <span>Routledge/Taylor &amp; Francis Group</span>.
</div>
<div id="ref-yapIndividualDifferencesJoint2009" class="csl-entry">
Yap, M. J., Tse, C.-S., &amp; Balota, D. A. (2009). Individual differences in the joint effects of semantic priming and word frequency revealed by <span>RT</span> distributional analyses: <span>The</span> role of lexical integrity. <em>Journal of Memory and Language</em>, <em>61</em>(3), 303–325. <a href="https://doi.org/10.1016/j.jml.2009.07.001">https://doi.org/10.1016/j.jml.2009.07.001</a>
</div>
<div id="ref-yeeColorlessGreenIdeas2012" class="csl-entry">
Yee, E., Ahmed, S. Z., &amp; Thompson-Schill, S. L. (2012). Colorless green ideas (can) prime furiously. <em>Psychological Science</em>, <em>23</em>(4), 364–369. <a href="https://doi.org/10.1177/0956797611430691">https://doi.org/10.1177/0956797611430691</a>
</div>
<div id="ref-zhongSensorimotorNormsChinese2022" class="csl-entry">
Zhong, Y., Wan, M., Ahrens, K., &amp; Huang, C.-R. (2022). Sensorimotor norms for <span>Chinese</span> nouns and their relationship with orthographic and semantic variables. <em>Language, Cognition and Neuroscience</em>, <em>0</em>(0), 1–23. <a href="https://doi.org/10.1080/23273798.2022.2035416">https://doi.org/10.1080/23273798.2022.2035416</a>
</div>
<div id="ref-zwaanReplicationsShouldBe2014" class="csl-entry">
Zwaan, R. A. (2014). Replications should be performed with power and precision: <span>A</span> response to <span>Rommers</span>, <span>Meyer</span>, and <span>Huettig</span> (2013). <em>Psychological Science</em>, <em>25</em>(1), 305–307. <a href="https://doi.org/10.1177/0956797613509634">https://doi.org/10.1177/0956797613509634</a>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="5">
<li id="fn5"><p>According to <span class="citation">Lamiell (<a href="#ref-lamiellStatisticalThinkingPsychology2019" role="doc-biblioref">2019</a>)</span>, ‘individual differences’ is a misnomer in that the analyses used to examine those (e.g, regression) are not participant-specific. While this may partly hold for the current study too, the use of by-participant random effects increases the role of individuals in the analysis.<a href="present-studies.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>The names of all variables used in the analyses were slightly adjusted for this text to facilitate their understanding—for instance, by replacing underscores with spaces (conversions reflected in the scripts available at <a href="http://doi.org/10.17605/OSF.IO/UERYQ">http://doi.org/10.17605/OSF.IO/UERYQ</a>). One specific case deserves further comment. We use the formula of the SOA in this paper, instead of the ‘interstimulus interval’ (ISI)—which we used in the analysis—, as the SOA has been more commonly used in previous papers <span class="citation">(e.g., <a href="#ref-hutchison2013a" role="doc-biblioref">Hutchison et al., 2013</a>; <a href="#ref-pecherDoesPizzaPrime1998" role="doc-biblioref">Pecher et al., 1998</a>; <a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>; <a href="#ref-yap2017a" role="doc-biblioref">Yap et al., 2017</a>)</span>. In our analysis, we used the ISI formula as it was the one present in the data set of <span class="citation">Hutchison et al. (<a href="#ref-hutchison2013a" role="doc-biblioref">2013</a>)</span>—retrieved from <a href="https://www.montana.edu/attmemlab/documents/all%20ldt%20subs_all%20trials3.xlsx">https://www.montana.edu/attmemlab/documents/all%20ldt%20subs_all%20trials3.xlsx</a>. The only difference between these formulas is that the ISI does not count the presentation of the prime word. In the current study <span class="citation">(<a href="#ref-hutchison2013a" role="doc-biblioref">Hutchison et al., 2013</a>)</span>, the presentation of the prime word lasted 150 ms. Therefore, the 50 ms ISI is equivalent to a 200 ms SOA, and the 1,050 ms ISI is equivalent to a 1,200 ms SOA. The use of either formula in the analysis would not affect our results, as the ISI conditions were recoded as -0.5 and 0.5 <span class="citation">(<a href="#ref-brauer2018a" role="doc-biblioref">Brauer &amp; Curtin, 2018</a>)</span>.<a href="present-studies.html#fnref6" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

<br>
<hr>

<!-- Enable disqus comments -->

<div id="disqus_thread"></div>
<script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://pablobernabeu.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

<hr>


<!-- Acknowledge authorship and 'bookdown' package -->

<div style='color:grey80; text-align:center;'>Pablo Bernabeu, 2022. Licence: <a href='https://creativecommons.org/licenses/by/4.0'>CC BY 4.0</a>.<br>Thesis: <a href='https://doi.org/10.17635/lancaster/thesis/1795'>https://doi.org/10.17635/lancaster/thesis/1795</a>.<br><br>Online book created using the R package <a href='https://bookdown.org/'>bookdown</a>.</div>

            </section>

          </div>
        </div>
      </div>
<a href="chapter-3-study-2.-language-and-vision-in-conceptual-processing-multilevel-analysis-and-statistical-power.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="general-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
