<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>General discussion of Study 2 | Language and sensorimotor simulation in conceptual processing: Multilevel analysis and statistical power</title>
  <meta name="description" content="Research has suggested that conceptual processing depends on both language-based and sensorimotor information. In this thesis, I investigate the nature of these systems and their interplay at three levels of the experimental structure—namely, individuals, words and tasks. In Study 1, I contributed to a multi-lab replication of the object orientation effect, which has been used to test sensorimotor simulation. The effect did not appear in any of the 18 languages examined, and it was not influenced by individual differences in mental rotation. Next, in Study 2, we drew on three existing data sets that implemented semantic priming, semantic decision and lexical decision. We extended these data sets with measures of language-based and vision-based information, and analysed their interactions with participants’ vocabulary size and gender, and with presentation speed. The analysis had a conservative structure of fixed and random effects. First, we found that language-based information was more important than vision-based information. Second, in the semantic priming study—whose task required distinguishing between words and nonwords—, both language-based and vision-based information were more influential when words were presented faster. Third, a ‘task-relevance advantage’ was identified in higher-vocabulary participants. Specifically, in lexical decision, higher-vocabulary participants were more sensitive to language-based information than lower-vocabulary participants, whereas in semantic decision, higher-vocabulary participants were more sensitive to word concreteness. Fourth, we demonstrated the influence of the analytical method on the results. Last, we estimated the sample size required to investigate various effects. We found that 300 participants were sufficient to examine the effect of language-based information in words, whereas more than 1,000 participants were necessary to examine the effect of vision-based information and the interactions of both former variables with vocabulary size, gender and presentation speed. This power analysis suggests that larger sample sizes are necessary to investigate perceptual simulation and individual differences in conceptual processing." />
  <meta name="generator" content="bookdown 0.33.3 and GitBook 2.6.7" />

  <meta property="og:title" content="General discussion of Study 2 | Language and sensorimotor simulation in conceptual processing: Multilevel analysis and statistical power" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Research has suggested that conceptual processing depends on both language-based and sensorimotor information. In this thesis, I investigate the nature of these systems and their interplay at three levels of the experimental structure—namely, individuals, words and tasks. In Study 1, I contributed to a multi-lab replication of the object orientation effect, which has been used to test sensorimotor simulation. The effect did not appear in any of the 18 languages examined, and it was not influenced by individual differences in mental rotation. Next, in Study 2, we drew on three existing data sets that implemented semantic priming, semantic decision and lexical decision. We extended these data sets with measures of language-based and vision-based information, and analysed their interactions with participants’ vocabulary size and gender, and with presentation speed. The analysis had a conservative structure of fixed and random effects. First, we found that language-based information was more important than vision-based information. Second, in the semantic priming study—whose task required distinguishing between words and nonwords—, both language-based and vision-based information were more influential when words were presented faster. Third, a ‘task-relevance advantage’ was identified in higher-vocabulary participants. Specifically, in lexical decision, higher-vocabulary participants were more sensitive to language-based information than lower-vocabulary participants, whereas in semantic decision, higher-vocabulary participants were more sensitive to word concreteness. Fourth, we demonstrated the influence of the analytical method on the results. Last, we estimated the sample size required to investigate various effects. We found that 300 participants were sufficient to examine the effect of language-based information in words, whereas more than 1,000 participants were necessary to examine the effect of vision-based information and the interactions of both former variables with vocabulary size, gender and presentation speed. This power analysis suggests that larger sample sizes are necessary to investigate perceptual simulation and individual differences in conceptual processing." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="General discussion of Study 2 | Language and sensorimotor simulation in conceptual processing: Multilevel analysis and statistical power" />
  
  <meta name="twitter:description" content="Research has suggested that conceptual processing depends on both language-based and sensorimotor information. In this thesis, I investigate the nature of these systems and their interplay at three levels of the experimental structure—namely, individuals, words and tasks. In Study 1, I contributed to a multi-lab replication of the object orientation effect, which has been used to test sensorimotor simulation. The effect did not appear in any of the 18 languages examined, and it was not influenced by individual differences in mental rotation. Next, in Study 2, we drew on three existing data sets that implemented semantic priming, semantic decision and lexical decision. We extended these data sets with measures of language-based and vision-based information, and analysed their interactions with participants’ vocabulary size and gender, and with presentation speed. The analysis had a conservative structure of fixed and random effects. First, we found that language-based information was more important than vision-based information. Second, in the semantic priming study—whose task required distinguishing between words and nonwords—, both language-based and vision-based information were more influential when words were presented faster. Third, a ‘task-relevance advantage’ was identified in higher-vocabulary participants. Specifically, in lexical decision, higher-vocabulary participants were more sensitive to language-based information than lower-vocabulary participants, whereas in semantic decision, higher-vocabulary participants were more sensitive to word concreteness. Fourth, we demonstrated the influence of the analytical method on the results. Last, we estimated the sample size required to investigate various effects. We found that 300 participants were sufficient to examine the effect of language-based information in words, whereas more than 1,000 participants were necessary to examine the effect of vision-based information and the interactions of both former variables with vocabulary size, gender and presentation speed. This power analysis suggests that larger sample sizes are necessary to investigate perceptual simulation and individual differences in conceptual processing." />
  

<meta name="author" content="Pablo César de Juan Bernabéu" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="misc/favicon.png" type="image/x-icon" />
<link rel="prev" href="lexicaldecision.html"/>
<link rel="next" href="chapter-4-general-discussion.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/codefolding-lua-1.1/codefolding-lua.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="misc/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href='./'>Language and sensorimotor simulation<br>in conceptual processing: Multilevel<br>analysis and statistical power</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="" data-path="acknowledgements-and-declaration.html"><a href="acknowledgements-and-declaration.html"><i class="fa fa-check"></i>Acknowledgements and declaration</a>
<ul>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="declaration.html"><a href="declaration.html"><i class="fa fa-check"></i>Declaration</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="setup-code.html"><a href="setup-code.html"><i class="fa fa-check"></i>Setup code</a></li>
<li class="chapter" data-level="" data-path="chapter-1-introduction.html"><a href="chapter-1-introduction.html"><i class="fa fa-check"></i>Chapter 1: Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="language-and-embodiment.html"><a href="language-and-embodiment.html"><i class="fa fa-check"></i>Language and embodiment</a></li>
<li class="chapter" data-level="" data-path="the-present-thesis.html"><a href="the-present-thesis.html"><i class="fa fa-check"></i>The present thesis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="chapter-2-study-1-investigating-object-orientation-effects-across-18-languages.html"><a href="chapter-2-study-1-investigating-object-orientation-effects-across-18-languages.html"><i class="fa fa-check"></i>Chapter 2 (Study 1): Investigating object orientation effects across 18 languages</a>
<ul>
<li class="chapter" data-level="" data-path="study-and-methods.html"><a href="study-and-methods.html"><i class="fa fa-check"></i>Study and methods</a></li>
<li class="chapter" data-level="" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i>Results</a></li>
<li class="chapter" data-level="" data-path="discussion.html"><a href="discussion.html"><i class="fa fa-check"></i>Discussion</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="chapter-3-study-2.-language-and-vision-in-conceptual-processing-multilevel-analysis-and-statistical-power.html"><a href="chapter-3-study-2.-language-and-vision-in-conceptual-processing-multilevel-analysis-and-statistical-power.html"><i class="fa fa-check"></i>Chapter 3 (Study 2). Language and vision in conceptual processing: Multilevel analysis and statistical power</a>
<ul>
<li class="chapter" data-level="" data-path="present-studies.html"><a href="present-studies.html"><i class="fa fa-check"></i>The present studies</a>
<ul>
<li class="chapter" data-level="" data-path="present-studies.html"><a href="present-studies.html#language"><i class="fa fa-check"></i>Language</a></li>
<li class="chapter" data-level="" data-path="present-studies.html"><a href="present-studies.html#embodiment-represented-by-vision-based-information"><i class="fa fa-check"></i>Embodiment represented by vision-based information</a></li>
<li class="chapter" data-level="" data-path="present-studies.html"><a href="present-studies.html#levels-of-analysis"><i class="fa fa-check"></i>Levels of analysis</a></li>
<li class="chapter" data-level="" data-path="present-studies.html"><a href="present-studies.html#hypotheses"><i class="fa fa-check"></i>Hypotheses</a></li>
<li class="chapter" data-level="" data-path="present-studies.html"><a href="present-studies.html#statistical-power-analysis"><i class="fa fa-check"></i>Statistical power analysis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="general-methods.html"><a href="general-methods.html"><i class="fa fa-check"></i>General methods</a>
<ul>
<li class="chapter" data-level="" data-path="general-methods.html"><a href="general-methods.html#covariates"><i class="fa fa-check"></i>Covariates</a></li>
<li class="chapter" data-level="" data-path="general-methods.html"><a href="general-methods.html#data-preprocessing-and-statistical-analysis"><i class="fa fa-check"></i>Data preprocessing and statistical analysis</a></li>
<li class="chapter" data-level="" data-path="general-methods.html"><a href="general-methods.html#statistical-power-analysis-1"><i class="fa fa-check"></i>Statistical power analysis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming.html"><a href="study-2.1-semantic-priming.html"><i class="fa fa-check"></i>Study 2.1: Semantic priming</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming.html"><a href="study-2.1-semantic-priming.html#language-vision-and-soa"><i class="fa fa-check"></i>Language, vision and SOA</a></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming.html"><a href="study-2.1-semantic-priming.html#language-vision-and-vocabulary-size"><i class="fa fa-check"></i>Language, vision and vocabulary size</a></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming.html"><a href="study-2.1-semantic-priming.html#the-present-study"><i class="fa fa-check"></i>The present study</a></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming.html"><a href="study-2.1-semantic-priming.html#methods"><i class="fa fa-check"></i>Methods</a></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming.html"><a href="study-2.1-semantic-priming.html#semanticpriming-results"><i class="fa fa-check"></i>Results of Study 2.1</a></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming.html"><a href="study-2.1-semantic-priming.html#discussion-of-study-2.1"><i class="fa fa-check"></i>Discussion of Study 2.1</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision.html"><a href="study-2.2-semantic-decision.html"><i class="fa fa-check"></i>Study 2.2: Semantic decision</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision.html"><a href="study-2.2-semantic-decision.html#methods-1"><i class="fa fa-check"></i>Methods</a></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision.html"><a href="study-2.2-semantic-decision.html#results-of-study-2.2"><i class="fa fa-check"></i>Results of Study 2.2</a></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision.html"><a href="study-2.2-semantic-decision.html#discussion-of-study-2.2"><i class="fa fa-check"></i>Discussion of Study 2.2</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="lexicaldecision.html"><a href="lexicaldecision.html"><i class="fa fa-check"></i>Study 2.3: Lexical decision</a>
<ul>
<li class="chapter" data-level="" data-path="lexicaldecision.html"><a href="lexicaldecision.html#methods-2"><i class="fa fa-check"></i>Methods</a></li>
<li class="chapter" data-level="" data-path="lexicaldecision.html"><a href="lexicaldecision.html#results-of-study-2.3"><i class="fa fa-check"></i>Results of Study 2.3</a></li>
<li class="chapter" data-level="" data-path="lexicaldecision.html"><a href="lexicaldecision.html#discussion-of-study-2.3"><i class="fa fa-check"></i>Discussion of Study 2.3</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="general-discussion-of-study-2.html"><a href="general-discussion-of-study-2.html"><i class="fa fa-check"></i>General discussion of Study 2</a>
<ul>
<li class="chapter" data-level="" data-path="general-discussion-of-study-2.html"><a href="general-discussion-of-study-2.html#operationalisation-of-variables-and-other-analytical-choices"><i class="fa fa-check"></i>Operationalisation of variables and other analytical choices</a></li>
<li class="chapter" data-level="" data-path="general-discussion-of-study-2.html"><a href="general-discussion-of-study-2.html#statistical-power"><i class="fa fa-check"></i>Statistical power</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="chapter-4-general-discussion.html"><a href="chapter-4-general-discussion.html"><i class="fa fa-check"></i>Chapter 4: General discussion</a>
<ul>
<li class="chapter" data-level="" data-path="key-findings.html"><a href="key-findings.html"><i class="fa fa-check"></i>Key findings</a></li>
<li class="chapter" data-level="" data-path="limitations-and-future-directions.html"><a href="limitations-and-future-directions.html"><i class="fa fa-check"></i>Limitations and future directions</a></li>
</ul></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="" data-path="appendix-A-lexical-covariates.html"><a href="appendix-A-lexical-covariates.html"><i class="fa fa-check"></i>Appendix A: Selection of lexical covariates</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming-1.html"><a href="study-2.1-semantic-priming-1.html"><i class="fa fa-check"></i>Study 2.1: Semantic priming</a></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-1.html"><a href="study-2.2-semantic-decision-1.html"><i class="fa fa-check"></i>Study 2.2: Semantic decision</a></li>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision.html"><a href="study-2.3-lexical-decision.html"><i class="fa fa-check"></i>Study 2.3: Lexical decision</a></li>
<li class="chapter" data-level="" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i>Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-B-frequentist-analysis-diagnostics.html"><a href="appendix-B-frequentist-analysis-diagnostics.html"><i class="fa fa-check"></i>Appendix B: Diagnostics for the frequentist analyses</a>
<ul>
<li class="chapter" data-level="" data-path="convergence-1.html"><a href="convergence-1.html"><i class="fa fa-check"></i>Convergence</a>
<ul>
<li class="chapter" data-level="" data-path="convergence-1.html"><a href="convergence-1.html#the-multiple-optimisers-sanity-check-from-lme4allfit"><i class="fa fa-check"></i>The multiple-optimisers sanity check from <code>lme4::allFit()</code></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="residual-errors-not-normally-distributed.html"><a href="residual-errors-not-normally-distributed.html"><i class="fa fa-check"></i>Residual errors not normally distributed</a>
<ul>
<li class="chapter" data-level="" data-path="residual-errors-not-normally-distributed.html"><a href="residual-errors-not-normally-distributed.html#method-a-robustlmm-model"><i class="fa fa-check"></i>Method A: <em>robustlmm</em> model</a></li>
<li class="chapter" data-level="" data-path="residual-errors-not-normally-distributed.html"><a href="residual-errors-not-normally-distributed.html#method-b-inverse-gaussian-model-with-identity-link-function"><i class="fa fa-check"></i>Method B: Inverse Gaussian model with identity link function</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming-2.html"><a href="study-2.1-semantic-priming-2.html"><i class="fa fa-check"></i>Study 2.1: Semantic priming</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming-2.html"><a href="study-2.1-semantic-priming-2.html#convergence-2"><i class="fa fa-check"></i>Convergence</a></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming-2.html"><a href="study-2.1-semantic-priming-2.html#residual-errors-not-normally-distributed-1"><i class="fa fa-check"></i>Residual errors not normally distributed</a></li>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming-2.html"><a href="study-2.1-semantic-priming-2.html#semantic-priming-model-including-visual-similarity"><i class="fa fa-check"></i>Semantic priming model including visual similarity</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-2.html"><a href="study-2.2-semantic-decision-2.html"><i class="fa fa-check"></i>Study 2.2: Semantic decision</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-2.html"><a href="study-2.2-semantic-decision-2.html#convergence-4"><i class="fa fa-check"></i>Convergence</a></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-2.html"><a href="study-2.2-semantic-decision-2.html#residual-errors-not-normally-distributed-3"><i class="fa fa-check"></i>Residual errors not normally distributed</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision-1.html"><a href="study-2.3-lexical-decision-1.html"><i class="fa fa-check"></i>Study 2.3: Lexical decision</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision-1.html"><a href="study-2.3-lexical-decision-1.html#convergence-5"><i class="fa fa-check"></i>Convergence</a></li>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision-1.html"><a href="study-2.3-lexical-decision-1.html#residual-errors-not-normally-distributed-4"><i class="fa fa-check"></i>Residual errors not normally distributed</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-C-Bayesian-analysis-diagnostics.html"><a href="appendix-C-Bayesian-analysis-diagnostics.html"><i class="fa fa-check"></i>Appendix C: Diagnostics for the Bayesian analyses</a>
<ul>
<li class="chapter" data-level="" data-path="study1-bayesian-diagnostics.html"><a href="study1-bayesian-diagnostics.html"><i class="fa fa-check"></i>Study 2.1: Semantic priming</a>
<ul>
<li class="chapter" data-level="" data-path="study1-bayesian-diagnostics.html"><a href="study1-bayesian-diagnostics.html#prior-predictive-checks"><i class="fa fa-check"></i>Prior predictive checks</a></li>
<li class="chapter" data-level="" data-path="study1-bayesian-diagnostics.html"><a href="study1-bayesian-diagnostics.html#posterior-predictive-checks"><i class="fa fa-check"></i>Posterior predictive checks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-3.html"><a href="study-2.2-semantic-decision-3.html"><i class="fa fa-check"></i>Study 2.2: Semantic decision</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-3.html"><a href="study-2.2-semantic-decision-3.html#prior-predictive-checks-1"><i class="fa fa-check"></i>Prior predictive checks</a></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-3.html"><a href="study-2.2-semantic-decision-3.html#posterior-predictive-checks-1"><i class="fa fa-check"></i>Posterior predictive checks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision-2.html"><a href="study-2.3-lexical-decision-2.html"><i class="fa fa-check"></i>Study 2.3: Lexical decision</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision-2.html"><a href="study-2.3-lexical-decision-2.html#prior-predictive-checks-2"><i class="fa fa-check"></i>Prior predictive checks</a></li>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision-2.html"><a href="study-2.3-lexical-decision-2.html#posterior-predictive-checks-2"><i class="fa fa-check"></i>Posterior predictive checks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-D-interaction-plots.html"><a href="appendix-D-interaction-plots.html"><i class="fa fa-check"></i>Appendix D: Further interaction plots</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming-3.html"><a href="study-2.1-semantic-priming-3.html"><i class="fa fa-check"></i>Study 2.1: Semantic priming</a></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-4.html"><a href="study-2.2-semantic-decision-4.html"><i class="fa fa-check"></i>Study 2.2: Semantic decision</a></li>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision-3.html"><a href="study-2.3-lexical-decision-3.html"><i class="fa fa-check"></i>Study 2.3: Lexical decision</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-E-Bayesian-analysis-results.html"><a href="appendix-E-Bayesian-analysis-results.html"><i class="fa fa-check"></i>Appendix E: Results from the Bayesian analyses</a>
<ul>
<li class="chapter" data-level="" data-path="study-2.1-semantic-priming-4.html"><a href="study-2.1-semantic-priming-4.html"><i class="fa fa-check"></i>Study 2.1: Semantic priming</a></li>
<li class="chapter" data-level="" data-path="study-2.2-semantic-decision-5.html"><a href="study-2.2-semantic-decision-5.html"><i class="fa fa-check"></i>Study 2.2: Semantic decision</a></li>
<li class="chapter" data-level="" data-path="study-2.3-lexical-decision-4.html"><a href="study-2.3-lexical-decision-4.html"><i class="fa fa-check"></i>Study 2.3: Lexical decision</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href='https://github.com/rstudio/bookdown' target='blank'>Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Language and sensorimotor simulation in conceptual processing: Multilevel analysis and statistical power</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">

<!-- Display citation of thesis at top of every page -->

<div class='alert alert-warning' role='alert' style='padding-bottom:10px; margin-bottom:30px; font-size:85%;'>

  This online book is a reprint of:

  <div style = 'text-indent:-2em; margin-left:2em; color:black;'>
  Bernabeu, P. (2022). <i>Language and sensorimotor simulation in conceptual processing: Multilevel analysis and statistical power</i>. Lancaster University. <a href='https://doi.org/https://doi.org/10.17635/lancaster/thesis/1795'>https://doi.org/https://doi.org/10.17635/lancaster/thesis/1795</a>
  </div>

  Materials: <a href='https://osf.io/vyb8k'>https://osf.io/vyb8k</a>

</div>
<div id="general-discussion-of-study-2" class="section level2 hasAnchor">
<h2>General discussion of Study 2<a href="general-discussion-of-study-2.html#general-discussion-of-study-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the present study, we have revisited three existing data sets in conceptual processing to investigate the interplay between language-based and vision-based information. Specifically, we have investigated how this interplay is modulated by individual differences in vocabulary size, by the linguistic and visual information contained in words, and by contextual demands such as semantic depth and presentation speed. Although both language and vision played significant roles in some contexts (detailed below), the main effects and the interactions of language-based information were larger than those of vision-based information, consistent with previous research <span class="citation">(<a href="#ref-banksLinguisticDistributionalKnowledge2021" role="doc-biblioref">Banks et al., 2021</a>; <a href="#ref-kiela2014a" role="doc-biblioref">Kiela &amp; Bottou, 2014</a>; <a href="#ref-lam2015a" role="doc-biblioref">Lam et al., 2015</a>; <a href="#ref-louwerse2015a" role="doc-biblioref">Louwerse et al., 2015</a>; <a href="#ref-pecherDoesPizzaPrime1998" role="doc-biblioref">Pecher et al., 1998</a>; <a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>)</span>.</p>
<p>In our current approach, the sensorimotor domain was represented by a single variable in each study, just as the language domain was represented by a single variable. In the sensorimotor domain, we focussed on the vision to its hegemonic role in the human brain <span class="citation">(<a href="#ref-reillyEnglishLexiconMirrors2020" role="doc-biblioref">Reilly et al., 2020</a>)</span> as well as in several languages <span class="citation">(<a href="#ref-bernabeuDutchModalityExclusivity2018" role="doc-biblioref">Bernabeu, 2018</a>; <a href="#ref-chenMandarinChineseModality2019" role="doc-biblioref">I.-H. Chen et al., 2019</a>; <a href="#ref-lynott2020a" role="doc-biblioref">Lynott et al., 2020</a>; <a href="#ref-miceliPerceptualInteroceptiveStrength2021" role="doc-biblioref">Miceli et al., 2021</a>; <a href="#ref-morucciAugmentedModalityExclusivity2019" role="doc-biblioref">Morucci et al., 2019</a>; <a href="#ref-roqueVisionVerbsDominate2015" role="doc-biblioref">Roque et al., 2015</a>; <a href="#ref-speedDutchSensoryModality2021" role="doc-biblioref">Speed &amp; Brybaert, 2021</a>; <a href="#ref-speedGroundingLanguageNeglected2020" role="doc-biblioref">Speed &amp; Majid, 2020</a>; <a href="#ref-vergallitoPerceptualModalityNorms2020" role="doc-biblioref">Vergallito et al., 2020</a>; <a href="#ref-winterVisionDominatesPerceptual2018" role="doc-biblioref">Winter et al., 2018</a>; <a href="#ref-zhongSensorimotorNormsChinese2022" role="doc-biblioref">Zhong et al., 2022</a>)</span>. Notably, vision was also the domain chosen in a recent study that strongly influenced the present study <span class="citation">(<a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>)</span>, as well as in previous studies <span class="citation">(<a href="#ref-bottiniConcretenessAdvantageLexical2021" role="doc-biblioref">Bottini et al., 2021</a>; <a href="#ref-dedeyneVisualAffectiveMultimodal2021" role="doc-biblioref">De Deyne et al., 2021</a>; <a href="#ref-pearsonHeterogeneityMentalRepresentation2015" role="doc-biblioref">Pearson &amp; Kosslyn, 2015</a>; <a href="#ref-yeeColorlessGreenIdeas2012" role="doc-biblioref">Yee et al., 2012</a>)</span>. In contrast to this parsimonious approach, more comprehensive alternatives could be used in future research to consider more sensorimotor domains. The first of these approaches is the preselection approach, which incorporates a step prior to the main analysis. In this prior step, a selection is performed among a large variety of word-level information, including visual, auditory and motor information, etc. <span class="citation">(<a href="#ref-bernabeu2021a" role="doc-biblioref">Bernabeu et al., 2021</a>)</span>. Selecting a single variable provides a convenient way to compare the role of sensorimotor information to that of linguistic information, if the latter is also represented by a single variable. The second approach is using a variable that aggregates sensorimotor information <span class="citation">(<a href="#ref-wingfieldSensorimotorDistanceGrounded2022" role="doc-biblioref">Wingfield &amp; Connell, 2022b</a>)</span>. Last, the third approach would be using more than one variable to represent sensorimotor information in the main analysis. This would complicate the analysis of interactions with other variables, as the overall number of terms in the model could quickly exceed the maximum normally encountered in mixed-effects models—that is, around 15. If random slopes are included for all those effects of interest <span class="citation">(see <a href="#ref-brauer2018a" role="doc-biblioref">Brauer &amp; Curtin, 2018</a>; <a href="#ref-singmann2019a" role="doc-biblioref">Singmann &amp; Kellen, 2019</a>)</span>, the model would most likely present convergence warnings. In the face of this challenge, authors could either probe into those warnings (see <a href="appendix-B-frequentist-analysis-diagnostics.html#appendix-B-frequentist-analysis-diagnostics">Appendix B</a>), or could opt for different method, such as linear regression or machine learning. Ultimately, in any selection of variables, there is a trade-off between parsimony and comprehensiveness, and negotiating this trade-off often involves a certain degree of arbitrariness. A time-consuming, stepwise selection can help reduce this arbitrariness (for an example, see <a href="appendix-A-lexical-covariates.html#appendix-A-lexical-covariates">Appendix A</a>).</p>
<p>Insofar as both ‘language’ and ‘vision’ were present in the models, it is (arguably) valid to make conclusions based on them <span class="citation">(see <a href="#ref-louwerseSymbolInterdependencySymbolic2011" role="doc-biblioref">Louwerse, 2011</a>; <a href="#ref-louwerseTasteWordsLinguistic2011" role="doc-biblioref">Louwerse &amp; Connell, 2011</a>; <a href="#ref-santosPropertyGenerationReflects2011" role="doc-biblioref">Santos et al., 2011</a>; <a href="#ref-simmonsFMRIEvidenceWord2008" role="doc-biblioref">Simmons et al., 2008</a>)</span>. In contrast, when only one of these variables is analysed, it may contain information from the other variable. If the superiority of language is genuine—rather than due to a bogus reflection of sensorimotor information—, the present results suggest that language is the main source of information in conceptual processing, whereas sensorimotor information provides extra help, especially for higher-vocabulary individuals (see Study 2.2, Semantic decision) and in deeper semantic tasks (refer to task-relevance advantage above). As the ultimate conclusion, should sensorimotor simulation be considered smaller but nonetheless important—especially for some individuals and in some contexts—, or should it be considered a negligible by-product of conceptual processing <span class="citation">(<a href="#ref-mahonCriticalLookEmbodied2008" role="doc-biblioref">Mahon &amp; Caramazza, 2008</a>)</span>? Although the jury is still out, the present results provide support for the tenet that sensorimotor simulation is smaller yet important, especially for some individuals and in some contexts, whereas language is important across the board.</p>
<p>Furthermore, it is necessary to acknowledge a longstanding caveat in the present topic, which also affects the present study. That is, it is extremely difficult to ascertain whether our variables encode what we intend for them to encode. Specifically, it is possible that the variables for language-based information encode some sensorimotor information, and vice versa. To address this caveat, future research could combine the use of continuous word-level variables—as used in the present study—with the use of brain-level measurements <span class="citation">(see <a href="#ref-borghesaniWordMeaningVentral2016" role="doc-biblioref">Borghesani et al., 2016</a>)</span>. Specifically, such an investigation should examine whether language-based information is primarily circumscribed to the brain regions in charge of semantic retrieval—such as the posterior left inferior frontal gyrus, the right posterior inferior frontal gyrus, the left anterior superior temporal gyrus and sulcus, and the left middle and posterior middle temporal gyrus <span class="citation">(<a href="#ref-hagoortCoreLanguagereadyBrain2017" role="doc-biblioref">Hagoort, 2017</a>; <a href="#ref-skeideOntogenyCorticalLanguage2016" role="doc-biblioref">Skeide &amp; Friederici, 2016</a>)</span>. Conversely, this investigation should also examine whether vision-based information is primarily circumscribed to the brain regions in charge of visual semantic information—such as Brodmann area 17, in the occipital lobe, corresponding to primary visual cortex <span class="citation">(<a href="#ref-borghesaniWordMeaningVentral2016" role="doc-biblioref">Borghesani et al., 2016</a>)</span>. Due to the importance of the time course, a method that provides both spatial and temporal resolution, such as magnetoencephalography, would be ideally suited for this research. If both sources of information are largely circumscribed to their regions of interest in the brain, we could conclude that the variables are valid. In contrast, if there are <em>drifts</em> in the processing—whereby language-based information is consistently associated with activation in primary visual cortex, or whereby vision-based information is associated with activation in the language regions of interest—, we would need to question the validity of the variables.</p>
<p>As an alternative to the above design, a thriftier method would be available by using two clusters of covariates. One of these clusters would be primarily associated with language-based information, whereas the other cluster would be primarily associated with vision-based information.<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a> This research should examine whether the variables in each cluster all behave similarly, or whether—instead—there are any drifts between the language and vision. As in the above design, the absence of drifts would validate the operationalisation of the two sides in the dichotomy, whereas the presence of drifts would question the validity.</p>
<p>The present analysis controlled important sources of variance in the fixed effects and in the random effects. First, in the fixed effects, covariates such as word concreteness and individual differences in general cognition were included in the models. It was important to include these covariates as they were substantially correlated with some of our variables of interest, and research has suggested that these covariates may represent fundamentally different processes from those of our variables of interest. For instance, word concreteness and visual strength were highly correlated. However, whereas visual strength indexes a perceptual component of semantic information, word concreteness might be circumscribed to the lexical level, which does not require the processing of meaning <span class="citation">(<a href="#ref-bottiniConcretenessAdvantageLexical2021" role="doc-biblioref">Bottini et al., 2021</a>; cf. <a href="#ref-connellStrengthPerceptualExperience2012" role="doc-biblioref">Connell &amp; Lynott, 2012</a>; <a href="#ref-pexman2018a" role="doc-biblioref">Pexman &amp; Yap, 2018</a>)</span>. Similarly, it was important to control for individual differences in general cognition measures as covariates of vocabulary size <span class="citation">(<a href="#ref-ratcliff2010a" role="doc-biblioref">Ratcliff et al., 2010</a>; also see <a href="#ref-james2018a" role="doc-biblioref">James et al., 2018</a>; <a href="#ref-pexman2018a" role="doc-biblioref">Pexman &amp; Yap, 2018</a>)</span>. We contend that controlling (or, in other words, statistically adjusting) for important covariates is a valuable asset of our present research. Furthermore, we think that the number of covariates we selected was enough but not excessive. We did not find any signs of overfitting in the models, as the variables that have been consistently influential in the literature were also influential in our current models. To further delve into the role of covariates in conceptual processing, we think that it would be valuable to investigate how the presence and the absence of several covariates in a model can affect the effect sizes and the significance results.<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a> Indeed, the differences between the results of Study 2.1 (semantic priming) and the results of <span class="citation">Petilli et al. (<a href="#ref-petilli2021a" role="doc-biblioref">2021</a>)</span> suggested that the influence of covariates can be very important. However, because these analyses differed in other aspects of the models, a study focussed on covariates would be insightful <span class="citation">(see <a href="#ref-botvinik-nezerVariabilityAnalysisSingle2020" role="doc-biblioref">Botvinik-Nezer et al., 2020</a>; <a href="#ref-perretWhichVariablesShould2019" role="doc-biblioref">Perret &amp; Bonin, 2019</a>; <a href="#ref-wagenmakersOneStatisticalAnalysis2022" role="doc-biblioref">E.-J. Wagenmakers et al., 2022</a>)</span>.</p>
<p>Second, in the random effects, the models contained a maximal structure that accounted for far more variance than the fixed effects, thus providing for a conservative analysis. Indeed, the maximal random-effects structure served to impede a violation of the independence of observations <span class="citation">(<a href="#ref-barrRandomEffectsStructure2013" role="doc-biblioref">Barr et al., 2013</a>; <a href="#ref-brauer2018a" role="doc-biblioref">Brauer &amp; Curtin, 2018</a>; <a href="#ref-singmann2019a" role="doc-biblioref">Singmann &amp; Kellen, 2019</a>)</span>. Specifically, random intercepts and slopes ensured that sources of dependence such as participants and stimuli were kept outside of the fixed effects, which are the relevant effects for the conclusions of this (and most other) research in conceptual processing.</p>
<p>The RTs of higher-vocabulary participants were influenced by a smaller number of variables than those of lower-vocabulary participants. This converges with previous findings suggesting that higher and lower-vocabulary participants are affected by different variables. In this regard, some research has suggested that the variables affecting higher-vocabulary participants most are especially relevant to the task <span class="citation">(<a href="#ref-lim2020a" role="doc-biblioref">Lim et al., 2020</a>; <a href="#ref-pexman2018a" role="doc-biblioref">Pexman &amp; Yap, 2018</a>; <a href="#ref-yap2012a" role="doc-biblioref">Yap et al., 2012</a>, <a href="#ref-yap2017a" role="doc-biblioref">2017</a>)</span>. Our results were consistent with the ‘task-relevance advantage’ associated with greater vocabulary knowledge. Specifically, in lexical decision, higher-vocabulary participants were more sensitive than lower-vocabulary participants to language-based information. In contrast, in semantic decision, higher-vocabulary participants were more sensitive to word concreteness. In summary, the present findings suggest that greater linguistic experience may be associated with greater task adaptabiity during cognitive performance, with better comprehenders able to selectively attend to task-relevant features compared to poorer comprehenders <span class="citation">(<a href="#ref-lim2020a" role="doc-biblioref">Lim et al., 2020</a>; <a href="#ref-pexman2018a" role="doc-biblioref">Pexman &amp; Yap, 2018</a>)</span>.</p>
<p>In addition, the semantic priming paradigm analysed in Study 2.1 revealed that both language and vision were more important with the short SOA (200 ms) than with the long SOA (1,200 ms). This finding replicates some of the previous literature <span class="citation">(<a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>)</span> while highlighting the importance of the time course and the level of semantic processing. That is, although the finding seems to be at odds with the theory that perceptual simulation peaks after language-based associations <span class="citation">(<a href="#ref-barsalouLanguageSimulationConceptual2008" role="doc-biblioref">Barsalou et al., 2008</a>; <a href="#ref-louwerseTasteWordsLinguistic2011" role="doc-biblioref">Louwerse &amp; Connell, 2011</a>)</span>, the long SOA may have been too long for perceptual simulation to be maintained in the lexical decision task that was performed by participants, which is semantically shallow <span class="citation">(<a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>)</span>.</p>
<div id="operationalisation-of-variables-and-other-analytical-choices" class="section level3 hasAnchor">
<h3>Operationalisation of variables and other analytical choices<a href="general-discussion-of-study-2.html#operationalisation-of-variables-and-other-analytical-choices" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We compared two measures of vision-based priming. The first measure—<code>visual-strength difference</code>—was operationalised as the difference in visual strength <span class="citation">(<a href="#ref-lynott2020a" role="doc-biblioref">Lynott et al., 2020</a>)</span> between the prime word and the target word in each trial. The second measure—<code>vision-based similarity</code>—, created by <span class="citation">Petilli et al. (<a href="#ref-petilli2021a" role="doc-biblioref">2021</a>)</span>, was based on vector representations trained on images. The results revealed that both measures—including their interactions with other variables—produced similar effect sizes. This underscores the consistency that exists between human ratings and computational approximations to meaning <span class="citation">(e.g., <a href="#ref-charbonnierPredictingWordConcreteness2019" role="doc-biblioref">Charbonnier &amp; Wartena, 2019</a>, <a href="#ref-charbonnierPredictingConcretenessGerman2020" role="doc-biblioref">2020</a>; <a href="#ref-guenther2016a" role="doc-biblioref">Günther et al., 2016b</a>; <a href="#ref-louwerse2015a" role="doc-biblioref">Louwerse et al., 2015</a>; <a href="#ref-mandera2017a" role="doc-biblioref">Mandera et al., 2017</a>; <a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>; <a href="#ref-solovyevConcretenessAbstractnessConcept2021" role="doc-biblioref">Solovyev, 2021</a>; <a href="#ref-wingfieldUnderstandingRoleLinguistic2022" role="doc-biblioref">Wingfield &amp; Connell, 2022a</a>)</span>. However, the effect of the human-based variable was slightly larger, which is consistent with previous comparisons of human-based and computational measures <span class="citation">(<a href="#ref-de2016a" role="doc-biblioref">De Deyne et al., 2016</a>, <a href="#ref-de2019a" role="doc-biblioref">2019</a>; <a href="#ref-gagneProcessingEnglishCompounds2016" role="doc-biblioref">Gagné et al., 2016</a>; <a href="#ref-schmidtke2018a" role="doc-biblioref">Schmidtke et al., 2018</a>; cf. <a href="#ref-michaelovClozeFarN4002022" role="doc-biblioref">Michaelov et al., 2022</a>; <a href="#ref-snefjella2020a" role="doc-biblioref">Snefjella &amp; Blank, 2020</a>)</span>.</p>
<p>In contrast to the results of <span class="citation">Petilli et al. (<a href="#ref-petilli2021a" role="doc-biblioref">2021</a>)</span>, vision-based similarity did not significantly interact with SOA. Furthermore, in contrast to the main analysis, this sub-analysis did not present a significant interaction between language-based similarity and SOA. These two differences demonstrate how the results of our analyses can be critically influenced by analytical choices such as the operationalisation of variables and the degree of complexity of statistical models. In this regard, we must draw attention to an often-overlooked difference between the variables used to operationalise the language system—usually, text-based measures based on large corpora—and the variables used to operationalise the embodiment system—usually, human-based measures based on ratings. Critically, the literature contains many comparisons of text-based variables <span class="citation">(<a href="#ref-dedeyneBetterExplanationsLexical2013" role="doc-biblioref">De Deyne et al., 2013</a>, <a href="#ref-de2016a" role="doc-biblioref">2016</a>; <a href="#ref-guntherLatentSemanticAnalysis2016" role="doc-biblioref">Günther et al., 2016a</a>, <a href="#ref-guenther2016a" role="doc-biblioref">2016b</a>; <a href="#ref-jones2006a" role="doc-biblioref">M. N. Jones et al., 2006</a>; <a href="#ref-lund1996a" role="doc-biblioref">Lund &amp; Burgess, 1996</a>; <a href="#ref-mandera2017a" role="doc-biblioref">Mandera et al., 2017</a>; <a href="#ref-mikolovEfficientEstimationWord2013" role="doc-biblioref">Mikolov et al., 2013</a>; <a href="#ref-wingfieldUnderstandingRoleLinguistic2022" role="doc-biblioref">Wingfield &amp; Connell, 2022a</a>)</span>, whereas the work on embodiment variables is more sparse and tends to compare different <em>modalities</em>—e.g., valence, visual strength, auditory strength, etc. <span class="citation">(<a href="#ref-lynott2020a" role="doc-biblioref">Lynott et al., 2020</a>; <a href="#ref-lynottModalityExclusivityNorms2009" role="doc-biblioref">Lynott &amp; Connell, 2009</a>; <a href="#ref-newcombeEffectsEmotionalSensorimotor2012" role="doc-biblioref">Newcombe et al., 2012</a>; for an exception, see <a href="#ref-vergallitoPerceptualModalityNorms2020" role="doc-biblioref">Vergallito et al., 2020</a>)</span>. This accident of history might in part account for the superiority of linguistic information over embodied information <span class="citation">(see <a href="#ref-banksLinguisticDistributionalKnowledge2021" role="doc-biblioref">Banks et al., 2021</a>; <a href="#ref-kiela2014a" role="doc-biblioref">Kiela &amp; Bottou, 2014</a>; <a href="#ref-lam2015a" role="doc-biblioref">Lam et al., 2015</a>; <a href="#ref-louwerse2015a" role="doc-biblioref">Louwerse et al., 2015</a>; <a href="#ref-pecherDoesPizzaPrime1998" role="doc-biblioref">Pecher et al., 1998</a>; <a href="#ref-petilli2021a" role="doc-biblioref">Petilli et al., 2021</a>)</span>. Therefore, it may be important to consider whether <em>engineering work</em> should be devoted to the betterment of embodiment variables. On a more general conclusion, the present results suggest that research findings are fundamentally dependent on research methods.</p>
</div>
<div id="statistical-power" class="section level3 hasAnchor">
<h3>Statistical power<a href="general-discussion-of-study-2.html#statistical-power" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Power analyses were performed to estimate the sample sizes required to reliably investigate a range of effects. The results suggested that 300 participants were sufficient to examine the effect of language-based information contained in words, whereas more than 1,000 participants were necessary for the effect of vision-based information and for the interactions of both former variables with vocabulary size, gender and presentation speed. Regarding interactions specifically, The large sample sizes required to investigate some of the effects relevant to embodied cognition and individual differences are not easily attainable with the usual organisation of funding in Psychology and Neuroscience.</p>
</div>
</div>
<!-- </div> -->
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-banksLinguisticDistributionalKnowledge2021" class="csl-entry">
Banks, B., Wingfield, C., &amp; Connell, L. (2021). Linguistic distributional knowledge and sensorimotor grounding both contribute to semantic category production. <em>Cognitive Science</em>, <em>45</em>(10), e13055. <a href="https://doi.org/10.1111/cogs.13055">https://doi.org/10.1111/cogs.13055</a>
</div>
<div id="ref-barrRandomEffectsStructure2013" class="csl-entry">
Barr, D. J., Levy, R., Scheepers, C., &amp; Tily, H. J. (2013). Random effects structure for confirmatory hypothesis testing: <span>Keep</span> it maximal. <em>Journal of Memory and Language</em>, <em>68</em>(3), 255–278. <a href="https://doi.org/10.1016/j.jml.2012.11.001">https://doi.org/10.1016/j.jml.2012.11.001</a>
</div>
<div id="ref-barsalouLanguageSimulationConceptual2008" class="csl-entry">
Barsalou, L. W., Santos, A., Simmons, W. K., &amp; Wilson, C. D. (2008). Language and simulation in conceptual processing. In <em>Symbols and <span>Embodiment</span></em>. <span>Oxford University Press</span>. <a href="https://doi.org/10.1093/acprof:oso/9780199217274.003.0013">https://doi.org/10.1093/acprof:oso/9780199217274.003.0013</a>
</div>
<div id="ref-bernabeuDutchModalityExclusivity2018" class="csl-entry">
Bernabeu, P. (2018). <em>Dutch modality exclusivity norms for 336 properties and 411 concepts</em>. <span>PsyArXiv</span>. <a href="https://doi.org/10.31234/osf.io/s2c5h">https://doi.org/10.31234/osf.io/s2c5h</a>
</div>
<div id="ref-bernabeu2021a" class="csl-entry">
Bernabeu, P., Lynott, D., &amp; Connell, L. (2021). <em>Preregistration: <span>The</span> interplay between linguistic and embodied systems in conceptual processing</em>. <span>OSF</span>. <a href="https://osf.io/ftydw">https://osf.io/ftydw</a>
</div>
<div id="ref-borghesaniWordMeaningVentral2016" class="csl-entry">
Borghesani, V., Pedregosa, F., Buiatti, M., Amadon, A., Eger, E., &amp; Piazza, M. (2016). Word meaning in the ventral visual path: <span>A</span> perceptual to conceptual gradient of semantic coding. <em>NeuroImage</em>, <em>143</em>, 128–140. <a href="https://doi.org/10.1016/j.neuroimage.2016.08.068">https://doi.org/10.1016/j.neuroimage.2016.08.068</a>
</div>
<div id="ref-bottiniConcretenessAdvantageLexical2021" class="csl-entry">
Bottini, R., Morucci, P., D’Urso, A., Collignon, O., &amp; Crepaldi, D. (2021). The concreteness advantage in lexical decision does not depend on perceptual simulations. <em>Journal of Experimental Psychology: General</em>. <a href="https://doi.org/10.1037/xge0001090">https://doi.org/10.1037/xge0001090</a>
</div>
<div id="ref-botvinik-nezerVariabilityAnalysisSingle2020" class="csl-entry">
Botvinik-Nezer, R., Holzmeister, F., Camerer, C. F., Dreber, A., Huber, J., Johannesson, M., Kirchler, M., Iwanir, R., Mumford, J. A., Adcock, R. A., Avesani, P., Baczkowski, B. M., Bajracharya, A., Bakst, L., Ball, S., Barilari, M., Bault, N., Beaton, D., Beitner, J., … Schonberg, T. (2020). Variability in the analysis of a single neuroimaging dataset by many teams. <em>Nature</em>, <em>582</em>(7810, 7810), 84–88. <a href="https://doi.org/10.1038/s41586-020-2314-9">https://doi.org/10.1038/s41586-020-2314-9</a>
</div>
<div id="ref-brauer2018a" class="csl-entry">
Brauer, M., &amp; Curtin, J. J. (2018). Linear mixed-effects models and the analysis of nonindependent data: <span>A</span> unified framework to analyze categorical and continuous independent variables that vary within-subjects and/or within-items. <em>Psychological Methods</em>, <em>23</em>(3), 389–411. <a href="https://doi.org/10.1037/met0000159">https://doi.org/10.1037/met0000159</a>
</div>
<div id="ref-charbonnierPredictingWordConcreteness2019" class="csl-entry">
Charbonnier, J., &amp; Wartena, C. (2019). Predicting word concreteness and imagery. <em>Proceedings of the 13th <span>International Conference</span> on <span>Computational Semantics</span> - <span>Long Papers</span></em>, 176–187. <a href="https://doi.org/10.18653/v1/W19-0415">https://doi.org/10.18653/v1/W19-0415</a>
</div>
<div id="ref-charbonnierPredictingConcretenessGerman2020" class="csl-entry">
Charbonnier, J., &amp; Wartena, C. (2020). Predicting the concreteness of <span>German</span> words. <em>Proceedings of the 5th <span>Swiss Text Analytics Conference</span> (<span>SwissText</span>)</em>, <em>2624</em>. <a href="https://doi.org/10.25968/opus-2075">https://doi.org/10.25968/opus-2075</a>
</div>
<div id="ref-chenMandarinChineseModality2019" class="csl-entry">
Chen, I.-H., Zhao, Q., Long, Y., Lu, Q., &amp; Huang, C.-R. (2019). Mandarin <span>Chinese</span> modality exclusivity norms. <em>PLOS ONE</em>, <em>14</em>(2), e0211336. <a href="https://doi.org/10.1371/journal.pone.0211336">https://doi.org/10.1371/journal.pone.0211336</a>
</div>
<div id="ref-connellStrengthPerceptualExperience2012" class="csl-entry">
Connell, L., &amp; Lynott, D. (2012). Strength of perceptual experience predicts word processing performance better than concreteness or imageability. <em>Cognition</em>, <em>125</em>(3), 452–465. <a href="https://doi.org/10.1016/j.cognition.2012.07.010">https://doi.org/10.1016/j.cognition.2012.07.010</a>
</div>
<div id="ref-dedeyneVisualAffectiveMultimodal2021" class="csl-entry">
De Deyne, S., Navarro, D. J., Collell, G., &amp; Perfors, A. (2021). Visual and affective multimodal models of word meaning in language and mind. <em>Cognitive Science</em>, <em>45</em>(1), e12922. <a href="https://doi.org/10.1111/cogs.12922">https://doi.org/10.1111/cogs.12922</a>
</div>
<div id="ref-de2019a" class="csl-entry">
De Deyne, S., Navarro, D. J., Perfors, A., Brysbaert, M., &amp; Storms, G. (2019). The <span>“<span>Small World</span> of <span>Words</span>”</span> <span>English</span> word association norms for over 12,000 cue words. <em>Behavior Research Methods</em>, <em>51</em>, 987–1006. <a href="https://doi.org/10.3758/s13428-018-1115-7">https://doi.org/10.3758/s13428-018-1115-7</a>
</div>
<div id="ref-dedeyneBetterExplanationsLexical2013" class="csl-entry">
De Deyne, S., Navarro, D. J., &amp; Storms, G. (2013). Better explanations of lexical and semantic cognition using networks derived from continued rather than single-word associations. <em>Behavior Research Methods</em>, <em>45</em>(2), 480–498. <a href="https://doi.org/10.3758/s13428-012-0260-7">https://doi.org/10.3758/s13428-012-0260-7</a>
</div>
<div id="ref-de2016a" class="csl-entry">
De Deyne, S., Perfors, A., &amp; Navarro, D. (2016). Predicting human similarity judgments with distributional models: <span>The</span> value of word associations. <em>Proceedings of <span>COLING</span> 2016, the 26th International Conference on Computational Linguistics: <span>Technical</span> Papers</em>, 1861–1870.
</div>
<div id="ref-gagneProcessingEnglishCompounds2016" class="csl-entry">
Gagné, C. L., Spalding, T. L., &amp; Nisbet, K. A. (2016). Processing <span>English</span> compounds: <span>Investigating</span> semantic transparency. <em>SKASE Journal of Theoretical Linguistics</em>, <em>13</em>(2), 2–22. <a href="https://link.gale.com/apps/doc/A469757337/LitRC?u=anon~b6a332f4&amp;xid=9960afc7">https://link.gale.com/apps/doc/A469757337/LitRC?u=anon~b6a332f4&amp;xid=9960afc7</a>
</div>
<div id="ref-guntherLatentSemanticAnalysis2016" class="csl-entry">
Günther, F., Dudschig, C., &amp; Kaup, B. (2016a). Latent semantic analysis cosines as a cognitive similarity measure: <span>Evidence</span> from priming studies. <em>Quarterly Journal of Experimental Psychology</em>, <em>69</em>(4), 626–653. <a href="https://doi.org/10.1080/17470218.2015.1038280">https://doi.org/10.1080/17470218.2015.1038280</a>
</div>
<div id="ref-guenther2016a" class="csl-entry">
Günther, F., Dudschig, C., &amp; Kaup, B. (2016b). Predicting lexical priming effects from distributional semantic similarities: <span>A</span> replication with extension. <em>Frontiers in Psychology</em>, <em>7</em>, 1646. <a href="https://doi.org/10.3389/fpsyg.2016.01646">https://doi.org/10.3389/fpsyg.2016.01646</a>
</div>
<div id="ref-hagoortCoreLanguagereadyBrain2017" class="csl-entry">
Hagoort, P. (2017). The core and beyond in the language-ready brain. <em>Neuroscience &amp; Biobehavioral Reviews</em>, <em>81</em>, 194–204. <a href="https://doi.org/10.1016/j.neubiorev.2017.01.048">https://doi.org/10.1016/j.neubiorev.2017.01.048</a>
</div>
<div id="ref-james2018a" class="csl-entry">
James, A. N., Fraundorf, S. H., Lee, E. K., &amp; Watson, D. G. (2018). Individual differences in syntactic processing: <span>Is</span> there evidence for reader-text interactions? <em>Journal of Memory and Language</em>, <em>102</em>, 155–181. <a href="https://doi.org/10.1016/j.jml.2018.05.006">https://doi.org/10.1016/j.jml.2018.05.006</a>
</div>
<div id="ref-jones2006a" class="csl-entry">
Jones, M. N., Kintsch, W., &amp; Mewhort, D. J. (2006). High-dimensional semantic space accounts of priming. <em>Journal of Memory and Language</em>, <em>55</em>(4), 534–552. <a href="https://doi.org/10.1016/j.jml.2006.07.003">https://doi.org/10.1016/j.jml.2006.07.003</a>
</div>
<div id="ref-kiela2014a" class="csl-entry">
Kiela, D., &amp; Bottou, L. (2014). Learning image embeddings using convolutional neural networks for improved multi-modal semantics. <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (<span>EMNLP</span></em>, 36–45. <a href="https://doi.org/10.3115/v1/D14-1005">https://doi.org/10.3115/v1/D14-1005</a>
</div>
<div id="ref-lam2015a" class="csl-entry">
Lam, K. J., Dijkstra, T., &amp; Rueschemeyer, S. A. (2015). Feature activation during word recognition: Action, visual, and associative-semantic priming effects. <em>Frontiers in Psychology</em>, <em>6</em>, 659. <a href="https://doi.org/10.3389/fpsyg.2015.00659">https://doi.org/10.3389/fpsyg.2015.00659</a>
</div>
<div id="ref-lim2020a" class="csl-entry">
Lim, R. Y., Yap, M. J., &amp; Tse, C.-S. (2020). Individual differences in <span>Cantonese Chinese</span> word recognition: <span>Insights</span> from the <span>Chinese Lexicon Project</span>. <em>Quarterly Journal of Experimental Psychology</em>, <em>73</em>(4), 504–518. <a href="https://doi.org/10.1177/1747021820906566">https://doi.org/10.1177/1747021820906566</a>
</div>
<div id="ref-louwerseSymbolInterdependencySymbolic2011" class="csl-entry">
Louwerse, M. M. (2011). Symbol interdependency in symbolic and embodied cognition. <em>Topics in Cognitive Science</em>, <em>3</em>(2), 273–302. <a href="https://doi.org/10.1111/j.1756-8765.2010.01106.x">https://doi.org/10.1111/j.1756-8765.2010.01106.x</a>
</div>
<div id="ref-louwerseTasteWordsLinguistic2011" class="csl-entry">
Louwerse, M. M., &amp; Connell, L. (2011). A taste of words: Linguistic context and perceptual simulation predict the modality of words. <em>Cognitive Science</em>, <em>35</em>(2), 381–398. <a href="https://doi.org/10.1111/j.1551-6709.2010.01157.x">https://doi.org/10.1111/j.1551-6709.2010.01157.x</a>
</div>
<div id="ref-louwerse2015a" class="csl-entry">
Louwerse, M. M., Hutchinson, S., Tillman, R., &amp; Recchia, G. (2015). Effect size matters: <span>The</span> role of language statistics and perceptual simulation in conceptual processing. <em>Language, Cognition and Neuroscience</em>, <em>30</em>(4), 430–447. <a href="https://doi.org/10.1080/23273798.2014.981552">https://doi.org/10.1080/23273798.2014.981552</a>
</div>
<div id="ref-lund1996a" class="csl-entry">
Lund, K., &amp; Burgess, C. (1996). Producing high-dimensional semantic spaces from lexical co-occurrence. <em>Behavior Research Methods, Instruments, &amp; Computers</em>, <em>28</em>(2), 203–208. <a href="https://doi.org/10.3758/BF03204766">https://doi.org/10.3758/BF03204766</a>
</div>
<div id="ref-lynottModalityExclusivityNorms2009" class="csl-entry">
Lynott, D., &amp; Connell, L. (2009). Modality exclusivity norms for 423 object properties. <em>Behavior Research Methods</em>, <em>41</em>(2), 558–564. <a href="https://doi.org/10.3758/BRM.41.2.558">https://doi.org/10.3758/BRM.41.2.558</a>
</div>
<div id="ref-lynott2020a" class="csl-entry">
Lynott, D., Connell, L., Brysbaert, M., Brand, J., &amp; Carney, J. (2020). The <span>Lancaster Sensorimotor Norms</span>: <span>Multidimensional</span> measures of perceptual and action strength for 40,000 <span>English</span> words. <em>Behavior Research Methods</em>, <em>52</em>, 1271–1291. <a href="https://doi.org/10.3758/s13428-019-01316-z">https://doi.org/10.3758/s13428-019-01316-z</a>
</div>
<div id="ref-mahonCriticalLookEmbodied2008" class="csl-entry">
Mahon, B. Z., &amp; Caramazza, A. (2008). A critical look at the embodied cognition hypothesis and a new proposal for grounding conceptual content. <em>Journal of Physiology-Paris</em>, <em>102</em>(1), 59–70. <a href="https://doi.org/10.1016/j.jphysparis.2008.03.004">https://doi.org/10.1016/j.jphysparis.2008.03.004</a>
</div>
<div id="ref-mandera2017a" class="csl-entry">
Mandera, P., Keuleers, E., &amp; Brysbaert, M. (2017). Explaining human performance in psycholinguistic tasks with models of semantic similarity based on prediction and counting: <span>A</span> review and empirical validation. <em>Journal of Memory and Language</em>, <em>92</em>, 57–78. <a href="https://doi.org/10.1016/j.jml.2016.04.001">https://doi.org/10.1016/j.jml.2016.04.001</a>
</div>
<div id="ref-miceliPerceptualInteroceptiveStrength2021" class="csl-entry">
Miceli, A., Wauthia, E., Lefebvre, L., Ris, L., &amp; Simoes Loureiro, I. (2021). Perceptual and interoceptive strength norms for 270 french words. <em>Frontiers in Psychology</em>, <em>12</em>. <a href="https://www.frontiersin.org/article/10.3389/fpsyg.2021.667271">https://www.frontiersin.org/article/10.3389/fpsyg.2021.667271</a>
</div>
<div id="ref-michaelovClozeFarN4002022" class="csl-entry">
Michaelov, J. A., Coulson, S., &amp; Bergen, B. K. (2022). So cloze yet so far: <span>N400</span> amplitude is better predicted by distributional information than human predictability judgements. <em>IEEE Transactions on Cognitive and Developmental Systems</em>, 1–1. <a href="https://doi.org/10.1109/TCDS.2022.3176783">https://doi.org/10.1109/TCDS.2022.3176783</a>
</div>
<div id="ref-mikolovEfficientEstimationWord2013" class="csl-entry">
Mikolov, T., Chen, K., Corrado, G., &amp; Dean, J. (2013). <em>Efficient estimation of word representations in vector space</em> (Version 3). <span>arXiv</span>. <a href="https://doi.org/10.48550/arXiv.1301.3781">https://doi.org/10.48550/arXiv.1301.3781</a>
</div>
<div id="ref-morucciAugmentedModalityExclusivity2019" class="csl-entry">
Morucci, P., Bottini, R., &amp; Crepaldi, D. (2019). Augmented modality exclusivity norms for concrete and abstract <span>Italian</span> property words. <em>Journal of Cognition</em>, <em>2</em>(1), 42. <a href="https://doi.org/10.5334/joc.88">https://doi.org/10.5334/joc.88</a>
</div>
<div id="ref-newcombeEffectsEmotionalSensorimotor2012" class="csl-entry">
Newcombe, P., Campbell, C., Siakaluk, P., &amp; Pexman, P. (2012). Effects of emotional and sensorimotor knowledge in semantic processing of concrete and abstract nouns. <em>Frontiers in Human Neuroscience</em>, <em>6</em>(275). <a href="https://doi.org/10.3389/fnhum.2012.00275">https://doi.org/10.3389/fnhum.2012.00275</a>
</div>
<div id="ref-pearsonHeterogeneityMentalRepresentation2015" class="csl-entry">
Pearson, J., &amp; Kosslyn, S. M. (2015). The heterogeneity of mental representation: <span>Ending</span> the imagery debate. <em>Proceedings of the National Academy of Sciences</em>, <em>112</em>(33), 10089–10092. <a href="https://doi.org/10.1073/pnas.1504933112">https://doi.org/10.1073/pnas.1504933112</a>
</div>
<div id="ref-pecherDoesPizzaPrime1998" class="csl-entry">
Pecher, D., Zeelenberg, R., &amp; Raaijmakers, J. G. W. (1998). Does pizza prime coin? <span>Perceptual</span> priming in lexical decision and pronunciation. <em>Journal of Memory and Language</em>, <em>38</em>(4), 401–418. <a href="https://doi.org/10.1006/jmla.1997.2557">https://doi.org/10.1006/jmla.1997.2557</a>
</div>
<div id="ref-perretWhichVariablesShould2019" class="csl-entry">
Perret, C., &amp; Bonin, P. (2019). Which variables should be controlled for to investigate picture naming in adults? <span>A Bayesian</span> meta-analysis. <em>Behavior Research Methods</em>, <em>51</em>(6), 2533–2545. <a href="https://doi.org/10.3758/s13428-018-1100-1">https://doi.org/10.3758/s13428-018-1100-1</a>
</div>
<div id="ref-petilli2021a" class="csl-entry">
Petilli, M. A., Günther, F., Vergallito, A., Ciapparelli, M., &amp; Marelli, M. (2021). Data-driven computational models reveal perceptual simulation in word processing. <em>Journal of Memory and Language</em>, <em>117</em>, 104194. <a href="https://doi.org/10.1016/j.jml.2020.104194">https://doi.org/10.1016/j.jml.2020.104194</a>
</div>
<div id="ref-pexman2018a" class="csl-entry">
Pexman, P. M., &amp; Yap, M. J. (2018). Individual differences in semantic processing: <span>Insights</span> from the <span>Calgary</span> semantic decision project. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, <em>44</em>(7), 1091–1112. <a href="https://doi.org/10.1037/xlm0000499">https://doi.org/10.1037/xlm0000499</a>
</div>
<div id="ref-ratcliff2010a" class="csl-entry">
Ratcliff, R., Thapar, A., &amp; McKoon, G. (2010). Individual differences, aging, and <span>IQ</span> in two-choice tasks. <em>Cognitive Psychology</em>, <em>60</em>, 127–157. <a href="https://doi.org/10.1016/j.cogpsych.2009.09.001">https://doi.org/10.1016/j.cogpsych.2009.09.001</a>
</div>
<div id="ref-reillyEnglishLexiconMirrors2020" class="csl-entry">
Reilly, J., Flurie, M., &amp; Peelle, J. E. (2020). The <span>English</span> lexicon mirrors functional brain activation for a sensory hierarchy dominated by vision and audition: <span class="nocase">Point-counterpoint</span>. <em>Journal of Neurolinguistics</em>, <em>55</em>, 100895. <a href="https://doi.org/10.1016/j.jneuroling.2020.100895">https://doi.org/10.1016/j.jneuroling.2020.100895</a>
</div>
<div id="ref-roqueVisionVerbsDominate2015" class="csl-entry">
Roque, L. S., Kendrick, K. H., Norcliffe, E., Brown, P., Defina, R., Dingemanse, M., Dirksmeyer, T., Enfield, N. J., Floyd, S., Hammond, J., Rossi, G., Tufvesson, S., Putten, S. van, &amp; Majid, A. (2015). Vision verbs dominate in conversation across cultures, but the ranking of non-visual verbs varies. <em>Cognitive Linguistics</em>, <em>26</em>(1), 31–60. <a href="https://doi.org/10.1515/cog-2014-0089">https://doi.org/10.1515/cog-2014-0089</a>
</div>
<div id="ref-santosPropertyGenerationReflects2011" class="csl-entry">
Santos, A., Chaigneau, S. E., Simmons, W. K., &amp; Barsalou, L. W. (2011). Property generation reflects word association and situated simulation. <em>Language and Cognition</em>, <em>3</em>(1), 83–119. <a href="https://doi.org/10.1515/langcog.2011.004">https://doi.org/10.1515/langcog.2011.004</a>
</div>
<div id="ref-schmidtke2018a" class="csl-entry">
Schmidtke, D., Van Dyke, J. A., &amp; Kuperman, V. (2018). Individual variability in the semantic processing of <span>English</span> compound words. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, <em>44</em>(3), 421–439. <a href="https://doi.org/10.1037/xlm0000442">https://doi.org/10.1037/xlm0000442</a>
</div>
<div id="ref-simmonsFMRIEvidenceWord2008" class="csl-entry">
Simmons, W. K., Hamann, S. B., Harenski, C. L., Hu, X. P., &amp; Barsalou, L. W. (2008). <span class="nocase">fMRI</span> evidence for word association and situated simulation in conceptual processing. <em>Journal of Physiology-Paris</em>, <em>102</em>(1), 106–119. <a href="https://doi.org/10.1016/j.jphysparis.2008.03.014">https://doi.org/10.1016/j.jphysparis.2008.03.014</a>
</div>
<div id="ref-singmann2019a" class="csl-entry">
Singmann, H., &amp; Kellen, D. (2019). An introduction to mixed models for experimental psychology. In D. H. Spieler &amp; E. Schumacher (Eds.), <em>New methods in cognitive psychology</em> (pp. 4–31). <span>Psychology Press</span>.
</div>
<div id="ref-skeideOntogenyCorticalLanguage2016" class="csl-entry">
Skeide, M. A., &amp; Friederici, A. D. (2016). The ontogeny of the cortical language network. <em>Nature Reviews Neuroscience</em>, <em>17</em>(5, 5), 323–332. <a href="https://doi.org/10.1038/nrn.2016.23">https://doi.org/10.1038/nrn.2016.23</a>
</div>
<div id="ref-snefjella2020a" class="csl-entry">
Snefjella, B., &amp; Blank, I. (2020). <em>Semantic norm extrapolation is a missing data problem</em>. <span>PsyArXiv</span>. <a href="https://doi.org/10.31234/osf.io/y2gav">https://doi.org/10.31234/osf.io/y2gav</a>
</div>
<div id="ref-solovyevConcretenessAbstractnessConcept2021" class="csl-entry">
Solovyev, V. (2021). Concreteness/abstractness concept: State of the art. In B. M. Velichkovsky, P. M. Balaban, &amp; V. L. Ushakov (Eds.), <em>Advances in <span>Cognitive Research</span>, <span>Artificial Intelligence</span> and <span>Neuroinformatics</span></em> (pp. 275–283). <span>Springer International Publishing</span>. <a href="https://doi.org/10.1007/978-3-030-71637-0_33">https://doi.org/10.1007/978-3-030-71637-0_33</a>
</div>
<div id="ref-speedDutchSensoryModality2021" class="csl-entry">
Speed, L. J., &amp; Brybaert, M. (2021). Dutch sensory modality norms. <em>Behavior Research Methods</em>. <a href="https://doi.org/10.3758/s13428-021-01656-9">https://doi.org/10.3758/s13428-021-01656-9</a>
</div>
<div id="ref-speedGroundingLanguageNeglected2020" class="csl-entry">
Speed, L. J., &amp; Majid, A. (2020). Grounding language in the neglected senses of touch, taste, and smell. <em>Cognitive Neuropsychology</em>, <em>37</em>(5-6), 363–392. <a href="https://doi.org/10.1080/02643294.2019.1623188">https://doi.org/10.1080/02643294.2019.1623188</a>
</div>
<div id="ref-vergallitoPerceptualModalityNorms2020" class="csl-entry">
Vergallito, A., Petilli, M. A., &amp; Marelli, M. (2020). Perceptual modality norms for 1,121 <span>Italian</span> words: <span>A</span> comparison with concreteness and imageability scores and an analysis of their impact in word processing tasks. <em>Behavior Research Methods</em>, <em>52</em>(4), 1599–1616. <a href="https://doi.org/10.3758/s13428-019-01337-8">https://doi.org/10.3758/s13428-019-01337-8</a>
</div>
<div id="ref-wagenmakersOneStatisticalAnalysis2022" class="csl-entry">
Wagenmakers, E.-J., Sarafoglou, A., &amp; Aczel, B. (2022). One statistical analysis must not rule them all. <em>Nature</em>, <em>605</em>(7910), 423–425. <a href="https://doi.org/10.1038/d41586-022-01332-8">https://doi.org/10.1038/d41586-022-01332-8</a>
</div>
<div id="ref-wingfieldUnderstandingRoleLinguistic2022" class="csl-entry">
Wingfield, C., &amp; Connell, L. (2022a). Understanding the role of linguistic distributional knowledge in cognition. <em>Language, Cognition and Neuroscience</em>, 1–51. <a href="https://doi.org/10.1080/23273798.2022.2069278">https://doi.org/10.1080/23273798.2022.2069278</a>
</div>
<div id="ref-wingfieldSensorimotorDistanceGrounded2022" class="csl-entry">
Wingfield, C., &amp; Connell, L. (2022b). Sensorimotor distance: <span>A</span> grounded measure of semantic similarity for 800 million concept pairs. <em>Behavior Research Methods</em>. <a href="https://doi.org/10.3758/s13428-022-01965-7">https://doi.org/10.3758/s13428-022-01965-7</a>
</div>
<div id="ref-winterVisionDominatesPerceptual2018" class="csl-entry">
Winter, B., Perlman, M., &amp; Majid, A. (2018). Vision dominates in perceptual language: <span>English</span> sensory vocabulary is optimized for usage. <em>Cognition</em>, <em>179</em>, 213–220. <a href="https://doi.org/10.1016/j.cognition.2018.05.008">https://doi.org/10.1016/j.cognition.2018.05.008</a>
</div>
<div id="ref-yap2012a" class="csl-entry">
Yap, M. J., Balota, D. A., Sibley, D. E., &amp; Ratcliff, R. (2012). Individual differences in visual word recognition: <span>Insights</span> from the <span>English Lexicon Project</span>. <em>Journal of Experimental Psychology: Human Perception and Performance</em>, <em>38, 1</em>, 53–79. <a href="https://doi.org/10.1037/a0024177">https://doi.org/10.1037/a0024177</a>
</div>
<div id="ref-yap2017a" class="csl-entry">
Yap, M. J., Hutchison, K. A., &amp; Tan, L. C. (2017). Individual differences in semantic priming performance: <span>Insights</span> from the semantic priming project. In M. N. Jones (Ed.), <em>Frontiers of cognitive psychology. <span>Big</span> data in cognitive science</em> (pp. 203–226). <span>Routledge/Taylor &amp; Francis Group</span>.
</div>
<div id="ref-yeeColorlessGreenIdeas2012" class="csl-entry">
Yee, E., Ahmed, S. Z., &amp; Thompson-Schill, S. L. (2012). Colorless green ideas (can) prime furiously. <em>Psychological Science</em>, <em>23</em>(4), 364–369. <a href="https://doi.org/10.1177/0956797611430691">https://doi.org/10.1177/0956797611430691</a>
</div>
<div id="ref-zhongSensorimotorNormsChinese2022" class="csl-entry">
Zhong, Y., Wan, M., Ahrens, K., &amp; Huang, C.-R. (2022). Sensorimotor norms for <span>Chinese</span> nouns and their relationship with orthographic and semantic variables. <em>Language, Cognition and Neuroscience</em>, <em>0</em>(0), 1–23. <a href="https://doi.org/10.1080/23273798.2022.2035416">https://doi.org/10.1080/23273798.2022.2035416</a>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="18">
<li id="fn18"><p>Thank you to Prof. Max Louwerse for suggesting this idea.<a href="general-discussion-of-study-2.html#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>Thank you to Prof. Max Louwerse for this idea.<a href="general-discussion-of-study-2.html#fnref19" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

<br>
<hr>

<!-- Enable disqus comments -->

<div id="disqus_thread"></div>
<script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://pablobernabeu.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

<hr>


<!-- Acknowledge authorship and 'bookdown' package -->

<div style='color:grey80; text-align:center;'>Pablo Bernabeu, 2022. Licence: <a href='https://creativecommons.org/licenses/by/4.0'>CC BY 4.0</a>.<br>Thesis: <a href='https://doi.org/10.17635/lancaster/thesis/1795'>https://doi.org/10.17635/lancaster/thesis/1795</a>.<br><br>Online book created using the R package <a href='https://bookdown.org/'>bookdown</a>.</div>

            </section>

          </div>
        </div>
      </div>
<a href="lexicaldecision.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter-4-general-discussion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
