
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pablo Bernabeu</title>
    <link>https://pablobernabeu.github.io/post/</link>
    <description>Recent content in Posts on Pablo Bernabeu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-uk</language>
    <copyright>Pablo Bernabeu, 2015—{year}. Licence: [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/). Email: pcbernabeu@gmail.com. Cookies only used by third-party systems such as [Disqus](https://help.disqus.com/en/articles/1717155-use-of-cookies).</copyright>
    <lastBuildDate>Tue, 27 Jan 2026 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://pablobernabeu.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Secure, private transcription at scale with Whisper and GitHub Copilot</title>
      <link>https://pablobernabeu.github.io/2026/secure-private-transcription-at-scale-with-whisper-and-github-copilot/</link>
      <pubDate>Tue, 27 Jan 2026 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2026/secure-private-transcription-at-scale-with-whisper-and-github-copilot/</guid>
      <description>Case study showcasing how secure, private transcription at scale can be achieved using Whisper and GitHub Copilot, demonstrating practical applications of AI in research environments while maintaining data privacy and security standards.</description>
      
            <category>AI</category>
      
            <category>machine learning</category>
      
            <category>transcription</category>
      
            <category>Whisper</category>
      
            <category>GitHub Copilot</category>
      
            <category>data privacy</category>
      
            <category>automation</category>
      
            <category>research tools</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Beyond the paper: Why open science is the new research standard</title>
      <link>https://pablobernabeu.github.io/2025/motivating-open-science-practices/</link>
      <pubDate>Thu, 18 Dec 2025 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2025/motivating-open-science-practices/</guid>
      <description>Examination of the global shift toward open science as a new research standard, outlining how preregistration and open sharing of data and materials create benefits for funders, researchers, the scientific community, and society through transparency and reproducibility.</description>
      
            <category>open science</category>
      
            <category>preregistration</category>
      
            <category>open data</category>
      
            <category>open materials</category>
      
            <category>research methods</category>
      
    </item>
    
    <item>
      <title>Secure and scalable speech transcription for local and HPC</title>
      <link>https://pablobernabeu.github.io/2025/speech-transcription-python/</link>
      <pubDate>Wed, 12 Nov 2025 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2025/speech-transcription-python/</guid>
      <description>A production-ready local transcription workflow leveraging OpenAI&#39;s Whisper models that addresses the limitations of cloud-based solutions through complete data sovereignty, unlimited scale, reproducible processing and advanced quality control, while maintaining GDPR compliance.</description>
      
            <category>s</category>
      
            <category>software</category>
      
            <category>speech-to-text</category>
      
            <category>speech recognition</category>
      
            <category>transcription</category>
      
            <category>Whisper</category>
      
            <category>machine learning</category>
      
            <category>huggingface</category>
      
            <category>Python</category>
      
            <category>OpenAI</category>
      
            <category>natural language processing</category>
      
            <category>audio processing</category>
      
            <category>GDPR</category>
      
            <category>data protection</category>
      
            <category>data privacy</category>
      
            <category>high-performance computing</category>
      
            <category>privacy</category>
      
    </item>
    
    <item>
      <title>&lt;code&gt;4authors-year-doi-url&lt;/code&gt;: Minimal, numeric CSL style for documents with extreme space constraints</title>
      <link>https://pablobernabeu.github.io/2025/4authors-year-doi-url/</link>
      <pubDate>Wed, 22 Oct 2025 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2025/4authors-year-doi-url/</guid>
      <description>&lt;code&gt;4authors-year-doi-url&lt;/code&gt; is a CSL style designed to be as compact as possible while retaining the three most critical pieces of information for a reference: who (authors), when (year), and where to find it (DOI/URL).</description>
      
            <category>bibliometrics</category>
      
            <category>CSL</category>
      
            <category>reference styles</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Prototype workflow for semi-automatic processing of speech and co-speech gestures</title>
      <link>https://pablobernabeu.github.io/2025/prototype-workflow-for-semi-automatic-processing-of-speech-and-cospeech-gestures/</link>
      <pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2025/prototype-workflow-for-semi-automatic-processing-of-speech-and-cospeech-gestures/</guid>
      <description>Understanding the interplay between speech and gesture is crucial for linguistic and cognitive research. The current prototype, available on GitHub, aims to automate the analysis of temporal alignment between spoken demonstrative pronouns and pointing gestures in video recordings. By integrating computer vision (via Google’s MediaPipe) and speech recognition (using language-specific Vosk models) using Python, the workflow provides enriched video annotations and alignment data, offering valuable insights into deictic communication.</description>
      
            <category>Python</category>
      
            <category>MediaPipe</category>
      
            <category>computer vision</category>
      
            <category>linguistics</category>
      
            <category>gestures</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Reducing the impedance in electroencephalography using a blunt needle, electrolyte gel and wiggling</title>
      <link>https://pablobernabeu.github.io/2024/lowering-impedance-in-electroencephalography-using-a-blunt-needle-electrolyte-gel-and-wiggling/</link>
      <pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2024/lowering-impedance-in-electroencephalography-using-a-blunt-needle-electrolyte-gel-and-wiggling/</guid>
      <description>Reducing the impedance in electroencephalography (EEG) is crucial for capturing high-quality brain activity signals. This process involves ensuring that electrodes make optimal contact with the skin without harming the participant. Below are a few tips to achieve this using a blunt needle, electrolyte gel and gentle wiggling.</description>
      
            <category>electroencephalography</category>
      
            <category>impedance</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Passive constructions and asymmetries between languages</title>
      <link>https://pablobernabeu.github.io/2024/passive-constructions-and-asymmetries-between-languages/</link>
      <pubDate>Sat, 21 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2024/passive-constructions-and-asymmetries-between-languages/</guid>
      <description>Researchers often make participants jump through hoops. Due to our personal blind spots, it seems easier to realise the full extent of these acrobatics when we consider the work of other researchers. In linguistic research, the acrobatics are often spurred by unnatural grammatical constructions.</description>
      
            <category>linguistics</category>
      
            <category>syntax</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>A makeshift EEG lab</title>
      <link>https://pablobernabeu.github.io/2024/makeshift-eeg-lab/</link>
      <pubDate>Mon, 12 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2024/makeshift-eeg-lab/</guid>
      <description>Say, you need to set up a makeshift EEG lab in an office? Easy-peasy&amp;mdash;only, try to move the hardware as little as possible, especially laptops with dongles sticking out. The rest is a trail of snapshots devoid of captions, a sink, a shower room and other paraphernalia, as this is only an ancillary, temporary, extraordinary little lab, and all those staples are within reach in our mainstream lab (see Ledwidge et al., 2018; Luck, 2014).</description>
      
            <category>electroencephalography</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>R functions for checking and fixing vmrk files from BrainVision</title>
      <link>https://pablobernabeu.github.io/2024/r-functions-for-checking-and-fixing-vmrk-files-from-brainvision/</link>
      <pubDate>Sun, 30 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2024/r-functions-for-checking-and-fixing-vmrk-files-from-brainvision/</guid>
      <description>Electroencephalography (EEG) has become a cornerstone for understanding the intricate workings of the human brain in the field of neuroscience. However, EEG software and hardware come with their own set of constraints, particularly in the management of markers, also known as triggers. This article aims to shed light on these limitations and future prospects of marker management in EEG studies, while also introducing R functions that can help deal with vmrk files from BrainVision.</description>
      
            <category>research methods</category>
      
            <category>electroencephalography</category>
      
            <category>EEG</category>
      
            <category>BrainVision</category>
      
            <category>event-related potentials</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Preventing muscle artifacts in electroencephalography sessions</title>
      <link>https://pablobernabeu.github.io/2024/preventing-muscle-artifacts-in-electroencephalography-sessions/</link>
      <pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2024/preventing-muscle-artifacts-in-electroencephalography-sessions/</guid>
      <description>Electroencephalographic (EEG) signals are often contaminated by muscle artifacts such as blinks, jaw clenching and (of course) yawns, which generate electrical activity that can obscure the brain signals of interest. These artifacts typically manifest as large, abrupt changes in the EEG signal, complicating data interpretation and analysis. To mitigate these issues, participants can be instructed during the preparatory phase of the session to minimize blinking and to keep their facial muscles relaxed. Additionally, researchers can emphasize the importance of staying still and provide practice sessions to help participants become aware of their movements, thereby reducing the likelihood of muscle artifacts affecting the EEG recordings.</description>
      
            <category>electroencephalography</category>
      
            <category>BrainVision</category>
      
            <category>muscle artifacts</category>
      
            <category>event-related potentials</category>
      
            <category>ERPs</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Job: Part-time research assistant in experimental research</title>
      <link>https://pablobernabeu.github.io/2024/job-part-time-research-assistant-in-experimental-research/</link>
      <pubDate>Wed, 27 Mar 2024 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2024/job-part-time-research-assistant-in-experimental-research/</guid>
      <description>Part-time research assistant position to help recruit participants and conduct an EEG experiment on language learning and multilingualism at UiT The Arctic University of Norway.</description>
      
            <category>job</category>
      
            <category>research assistant</category>
      
            <category>UIT The Arctic University of Norway</category>
      
            <category>Tromsø</category>
      
            <category>electroencephalography</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>rscopus_plus: An extension of the rscopus package</title>
      <link>https://pablobernabeu.github.io/2024/rscopus-plus-an-extension-of-the-rscopus-package/</link>
      <pubDate>Wed, 21 Feb 2024 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2024/rscopus-plus-an-extension-of-the-rscopus-package/</guid>
      <description>Sometimes it’s useful to do a bibliometric analysis. To this end, the rscopus_plus functions (Bernabeu, 2024) extend the R package rscopus (Muschelli, 2022) to administer the search quota and enable specific searches and comparisons.
scopus_search_plus runs rscopus::scopus_search as many times as necessary based on the number of results and the search quota.
scopus_search_DOIs gets DOIs from scopus_search_plus, which can then be imported into a reference manager, such as Zotero, to create a list of references.</description>
      
            <category>bibliometrics</category>
      
            <category>R</category>
      
            <category>research methods</category>
      
            <category>research software</category>
      
            <category>second language</category>
      
            <category>third language</category>
      
            <category>executive functions</category>
      
            <category>working memory</category>
      
            <category>inhibition</category>
      
            <category>implicit learning</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>How to end trial after timeout in jsPsych</title>
      <link>https://pablobernabeu.github.io/2024/how-to-end-trial-after-timeout-in-jspsych/</link>
      <pubDate>Mon, 29 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2024/how-to-end-trial-after-timeout-in-jspsych/</guid>
      <description>I would like to ask for advice regarding a custom plugin for a serial reaction time task, that was created by @vekteo, and is available in Gorilla, where the code can be edited and tested. By default, trials are self-paced, but I would need them to time out after 2,000 ms. I am struggling to achieve this, and would be very grateful if someone could please advise me a bit.</description>
      
            <category>javascript</category>
      
            <category>jsPsych</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>A session logbook for a longitudinal study using conditional formatting in Excel</title>
      <link>https://pablobernabeu.github.io/2023/a-session-logbook-for-a-longitudinal-study-using-conditional-formatting-in-excel/</link>
      <pubDate>Sat, 02 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/a-session-logbook-for-a-longitudinal-study-using-conditional-formatting-in-excel/</guid>
      <description>An Excel workbook template with conditional formatting to facilitate planning, registration, and tracking of sessions in longitudinal studies involving multiple session conductors.</description>
      
            <category>research methods</category>
      
            <category>session logbook</category>
      
            <category>longitudinal study</category>
      
            <category>Excel formulas</category>
      
            <category>conditional formatting</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Motivating a preregistration (especially in experimental linguistics)</title>
      <link>https://pablobernabeu.github.io/2023/motivating-a-preregistration-especially-in-experimental-linguistics/</link>
      <pubDate>Fri, 24 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/motivating-a-preregistration-especially-in-experimental-linguistics/</guid>
      <description>The best argument to motivate a preregistration may be that it doesn’t take any extra time. It just requires frontloading an important portion of the work. As a reward, the paper will receive greater trust from the reviewers and the readers at large. Preregistration is not perfect, but is a lesser evil that reduces the misuse of statistical analysis in science.</description>
      
            <category>prereg</category>
      
            <category>preregistration</category>
      
            <category>research methods</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Do you speak a Scandinavian language(s) and English, but no other languages? Delta i et EEG-eksperiment</title>
      <link>https://pablobernabeu.github.io/2023/do-you-speak-a-scandinavian-language-s-and-english-but-no-other-languages-delta-i-et-eeg-eksperiment/</link>
      <pubDate>Tue, 14 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/do-you-speak-a-scandinavian-language-s-and-english-but-no-other-languages-delta-i-et-eeg-eksperiment/</guid>
      <description>Recruitment announcement in Norwegian for participants who speak a Scandinavian language and English (but no other languages) to participate in a paid EEG experiment at UiT The Arctic University of Norway in Tromsø.</description>
      
            <category>vitenskap</category>
      
            <category>electroencephalography</category>
      
            <category>eksperiment</category>
      
            <category>tromsø</category>
      
            <category>tromso</category>
      
            <category>uit</category>
      
            <category>norges arktiske universitet</category>
      
            <category>arctic university of norway</category>
      
            <category>universitetet i tromsø</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Learning how to use Zotero</title>
      <link>https://pablobernabeu.github.io/2023/learning-how-to-use-zotero/</link>
      <pubDate>Fri, 10 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/learning-how-to-use-zotero/</guid>
      <description>Learning Zotero requires approximately 10 hours of investment that will pay off through time savings in formatting and correcting references.</description>
      
            <category>research methods</category>
      
            <category>science</category>
      
            <category>writing</category>
      
            <category>academic writing</category>
      
            <category>phdchat</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>FAQs on mixed-effects models</title>
      <link>https://pablobernabeu.github.io/2023/faqs-on-mixed-effects-models/</link>
      <pubDate>Sat, 04 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/faqs-on-mixed-effects-models/</guid>
      <description>Frequently asked questions about mixed-effects models, covering the necessity of random slopes, appropriate p-value calculation methods, parallelization limitations, convergence issues, and optimizer selection.</description>
      
            <category>linear-mixed effects models</category>
      
            <category>R</category>
      
            <category>research methods</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>FAIR standards for the creation of research materials, with examples</title>
      <link>https://pablobernabeu.github.io/2023/fair-standards-for-the-creation-of-research-materials-with-examples/</link>
      <pubDate>Thu, 02 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/fair-standards-for-the-creation-of-research-materials-with-examples/</guid>
      <description>In the fast-paced world of scientific research, establishing minimum standards for the creation of research materials is essential. Whether it&#39;s stimuli, custom software for data collection, or scripts for statistical analysis, the quality and transparency of these materials significantly impact the reproducibility and credibility of research. This blog post explores the importance of adhering to FAIR (Findable, Accessible, Interoperable, Reusable) principles, and offers practical examples for researchers, with a focus on the cognitive sciences.</description>
      
            <category>research materials</category>
      
            <category>experimental stimuli</category>
      
            <category>research methods</category>
      
            <category>programming</category>
      
            <category>R</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Two-second delay after logger in OpenSesame</title>
      <link>https://pablobernabeu.github.io/2023/two-second-delay-after-logger/</link>
      <pubDate>Wed, 01 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/two-second-delay-after-logger/</guid>
      <description>The result shows a varying delay of around 2 seconds on average. It would be very helpful for us if we could cut down this delay, as it adds up. To try to achieve this, I reduced the number of variables logged, from the default 363 to 34 important variables. Unfortunately, this change did not result in a reduction of the delay.</description>
      
            <category>OpenSesame</category>
      
            <category>stimulus presentation</category>
      
            <category>experiment</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Preprocessing the Norwegian Web as Corpus (NoWaC) in R</title>
      <link>https://pablobernabeu.github.io/2023/preprocessing-the-norwegian-web-as-corpus-nowac-in-r/</link>
      <pubDate>Thu, 28 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/preprocessing-the-norwegian-web-as-corpus-nowac-in-r/</guid>
      <description>An R script for preprocessing frequency list data from the Norwegian Web as Corpus (NoWaC), including instructions for downloading and preparing the corpus data.</description>
      
            <category>R</category>
      
            <category>corpora</category>
      
            <category>corpus</category>
      
            <category>Norwegian</category>
      
            <category>NoWaC</category>
      
            <category>linguistics</category>
      
            <category>language</category>
      
            <category>research methods</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>A Python inline script for OpenSesame to send EEG triggers via serial port</title>
      <link>https://pablobernabeu.github.io/2023/an-inline-script-for-opensesame-to-send-eeg-triggers-via-serial-port/</link>
      <pubDate>Sat, 09 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/an-inline-script-for-opensesame-to-send-eeg-triggers-via-serial-port/</guid>
      <description>The OpenSesame user base is skyrocketing but—of course—remains small in comparison to many other user bases that we are used to. Therefore, when developing an experiment in OpenSesame, there are still many opportunities to break the mould. When you need to do something beyond the standard operating procedure, it may take longer to find suitable resources than it takes when a more widespread tool is used. So, why would you still want to use OpenSesame?</description>
      
            <category>electroencephalography</category>
      
            <category>BrainVision</category>
      
            <category>event-related potentials</category>
      
            <category>OpenSesame</category>
      
            <category>opensource</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>A Python inline script for OpenSesame to send EEG triggers via serial port</title>
      <link>https://pablobernabeu.github.io/2023/an-inline-script-for-opensesame-to-send-eeg-triggers-via-the-serial-port/</link>
      <pubDate>Sat, 09 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/an-inline-script-for-opensesame-to-send-eeg-triggers-via-the-serial-port/</guid>
      <description>The OpenSesame user base is skyrocketing but—of course—remains small in comparison to many other user bases that we are used to. Therefore, when developing an experiment in OpenSesame, there are still many opportunities to break the mould. When you need to do something beyond the standard operating procedure, it may take longer to find suitable resources than it takes when a more widespread tool is used. So, why would you still want to use OpenSesame?</description>
      
            <category></category>
      
    </item>
    
    <item>
      <title>How to correctly encode triggers in Python and send them to BrainVision through serial port (useful for OpenSesame and PsychoPy)</title>
      <link>https://pablobernabeu.github.io/2023/encode-triggers-in-python-and-send-them-to-brainvision-through-serial-port-useful-for-opensesame-and-psychopy/</link>
      <pubDate>Thu, 17 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/encode-triggers-in-python-and-send-them-to-brainvision-through-serial-port-useful-for-opensesame-and-psychopy/</guid>
      <description>I&#39;m sending the triggers in a binary format because Python requires this. For instance, to send the trigger 1, I run the code serialport.write(b&#39;1&amp;rsquo;). I have succeeded in sending triggers in this way. However, I encounter two problems. First, the triggers are converted in a way I cannot entirely decipher. For instance, when I run the code serialport.write(b&#39;1&amp;rsquo;), the trigger displayed in BrainVision Recorder is S 49, not S 1 as I would hope (please see Appendix below). Second, I cannot send two triggers with the same code one after the other. For instance, if I run serialport.write(b&#39;1&amp;rsquo;), a trigger appears in BrainVision Recorder, but if I run the same afterwards (no matter how many times), no trigger appears. I tried to solve these problems by opening the parallel port in addition to the serial port, but the problems persist.</description>
      
            <category>electroencephalography</category>
      
            <category>BrainVision</category>
      
            <category>triggers</category>
      
            <category>serial port</category>
      
            <category>python</category>
      
            <category>OpenSesame</category>
      
            <category>PsychoPy</category>
      
            <category>encoding</category>
      
            <category>binary</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>ggplotting power curves from the simr package</title>
      <link>https://pablobernabeu.github.io/2023/ggplotting-power-curves-from-simr-package/</link>
      <pubDate>Tue, 27 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/ggplotting-power-curves-from-simr-package/</guid>
      <description>A custom R function to create ggplot2 visualizations of power curves generated by the simr package&#39;s powerCurve function for mixed-effects models.</description>
      
            <category>power analysis</category>
      
            <category>statistical power</category>
      
            <category>simr</category>
      
            <category>research methods</category>
      
            <category>visualisation</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>How to discretise the colour variable in sjPlot::plot_model into equally-sized intervals</title>
      <link>https://pablobernabeu.github.io/2023/how-to-discretise-colour-variable-in-sjplot-plot-model-into-equally-sized-intervals/</link>
      <pubDate>Sat, 24 Jun 2023 16:54:46 +0200</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/how-to-discretise-colour-variable-in-sjplot-plot-model-into-equally-sized-intervals/</guid>
      <description>Whereas the direction of main effects can be interpreted from the sign of the estimate, the interpretation of interaction effects often requires plots. This task is facilitated by the R package sjPlot. For instance, using the plot_model function, I plotted the interaction between two continuous variables.
library(lme4)#&amp;gt; Loading required package: Matrixlibrary(sjPlot)#&amp;gt; Learn more about sjPlot with &amp;#39;browseVignettes(&amp;quot;sjPlot&amp;quot;)&amp;#39;.library(ggplot2)theme_set(theme_sjplot())# Create data partially based on code by Ben Bolker # from https://stackoverflow.</description>
      
            <category>visualisation</category>
      
            <category>linear-mixed effects models</category>
      
            <category>interactions</category>
      
            <category>binning</category>
      
            <category>sjPlot</category>
      
            <category>individual differences</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>How to map more informative values onto fill argument of sjPlot::plot_model</title>
      <link>https://pablobernabeu.github.io/2023/how-to-map-more-informative-values-onto-fill-argument-of-sjplot-plot-model/</link>
      <pubDate>Sat, 24 Jun 2023 16:51:11 +0200</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/how-to-map-more-informative-values-onto-fill-argument-of-sjplot-plot-model/</guid>
      <description>Whereas the direction of main effects can be interpreted from the sign of the estimate, the interpretation of interaction effects often requires plots. This task is facilitated by the R package sjPlot. For instance, using the plot_model function, I plotted the interaction between a continuous variable and a categorical variable. The categorical variable was passed to the fill argument of plot_model.
library(lme4)#&amp;gt; Loading required package: Matrixlibrary(sjPlot)#&amp;gt; Install package &amp;quot;strengejacke&amp;quot; from GitHub (`devtools::install_github(&amp;quot;strengejacke/strengejacke&amp;quot;)`) to load all sj-packages at once!</description>
      
            <category>linear-mixed effects models</category>
      
            <category>interactions</category>
      
            <category>sjPlot</category>
      
            <category>alias</category>
      
            <category>recode</category>
      
            <category>visualisation</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>How to visually assess the convergence of a mixed-effects model by plotting various optimizers</title>
      <link>https://pablobernabeu.github.io/2023/how-to-visually-assess-the-convergence-of-a-mixed-effects-model-by-plotting-various-optimizers/</link>
      <pubDate>Sat, 24 Jun 2023 16:42:34 +0200</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/how-to-visually-assess-the-convergence-of-a-mixed-effects-model-by-plotting-various-optimizers/</guid>
      <description>A custom R function to create ggplot2 visualizations of fixed effects from models refitted with multiple optimizers using lme4&#39;s allFit function, enabling visual assessment of convergence validity in mixed-effects models.</description>
      
            <category>convergence</category>
      
            <category>research methods</category>
      
            <category>statistics</category>
      
            <category>linear-mixed effects models</category>
      
            <category>visualisation</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Intermixing stimuli from two loops randomly in OpenSesame</title>
      <link>https://pablobernabeu.github.io/2023/intermixing-stimuli-from-two-loops-randomly-in-opensesame/</link>
      <pubDate>Sat, 24 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/intermixing-stimuli-from-two-loops-randomly-in-opensesame/</guid>
      <description>I’m developing a slightly tricky design in OpenSesame (a Python-based experiment builder). My stimuli comprise two kinds of sentences that contain different elements, and different numbers of elements. These sentences must be presented word by word. Furthermore, I need to attach triggers to some words in the first kind of sentences but not in the second kind. Last, these kinds of sentences must be intermixed within a block (or a sequence) of trials, because the first kind are targets and the second kind are fillers.</description>
      
            <category>OpenSesame</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Simultaneously sampling from two variables in jsPsych</title>
      <link>https://pablobernabeu.github.io/2023/simultaneously-sampling-from-two-variables-in-jspsych/</link>
      <pubDate>Sat, 24 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/simultaneously-sampling-from-two-variables-in-jspsych/</guid>
      <description>I am using jsPsych to create an experiment and I am struggling to sample from two variables simultaneously. Specifically, in each trial, I would like to present a primeWord and a targetWord by randomly sampling each of them from its own variable.
I have looked into several resources—such as sampling without replacement, custom sampling and position indices—but to no avail. I’m a beginner at this, so it’s possible that one of these resources was relevant (especially the last one, I think).</description>
      
            <category>jsPsych</category>
      
            <category>javascript</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Table joins with conditional &ldquo;fuzzy&rdquo; string matching in R</title>
      <link>https://pablobernabeu.github.io/2023/table-joins-with-conditional-fuzzy-string-matching-in-r/</link>
      <pubDate>Sat, 24 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/table-joins-with-conditional-fuzzy-string-matching-in-r/</guid>
      <description>Here’s an example of fuzzy-matching strings in R that I shared on StackOverflow. In stringdist_join, the max_dist argument is used to constrain the degree of fuzziness.
library(fuzzyjoin)library(dplyr)#&amp;gt; #&amp;gt; Attaching package: &amp;#39;dplyr&amp;#39;#&amp;gt; The following objects are masked from &amp;#39;package:stats&amp;#39;:#&amp;gt; #&amp;gt; filter, lag#&amp;gt; The following objects are masked from &amp;#39;package:base&amp;#39;:#&amp;gt; #&amp;gt; intersect, setdiff, setequal, unionlibrary(knitr)small_tab = data.frame(Food.Name = c(&amp;#39;Corn&amp;#39;, &amp;#39;Squash&amp;#39;, &amp;#39;Peppers&amp;#39;), Food.Code = c(NA, NA, NA))large_tab = data.</description>
      
            <category>string matching</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>A new function to plot convergence diagnostics from lme4::allFit()</title>
      <link>https://pablobernabeu.github.io/2023/a-new-function-to-plot-convergence-diagnostics-from-lme4-allfit/</link>
      <pubDate>Thu, 22 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/a-new-function-to-plot-convergence-diagnostics-from-lme4-allfit/</guid>
      <description>When a model has struggled to find enough information in the data to account for every predictor&amp;mdash;especially for every random effect&amp;mdash;, convergence warnings appear (Brauer &amp;amp; Curtin, 2018; Singmann &amp;amp; Kellen, 2019). In this article, I review the issue of convergence before presenting a new plotting function in R that facilitates the visualisation of the fixed effects fitted by different optimization algorithms (also dubbed optimizers).</description>
      
            <category>s</category>
      
            <category>R</category>
      
            <category>linear mixed-effects models</category>
      
            <category>visualisation</category>
      
            <category>statistics</category>
      
    </item>
    
    <item>
      <title>Assigning participant-specific parameters automatically in OpenSesame</title>
      <link>https://pablobernabeu.github.io/2023/assigning-participant-specific-parameters-automatically-in-opensesame/</link>
      <pubDate>Wed, 17 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/assigning-participant-specific-parameters-automatically-in-opensesame/</guid>
      <description>OpenSesame offers options to counterbalance properties of the stimulus across participants. However, in cases of more involved assignments of session parameters across participants, it becomes necessary to write a bit of Python code in an inline script, which should be placed at the top of the timeline. In such a script, the participant-specific parameters are loaded in from a csv file. Below is a minimal example of the csv file.</description>
      
            <category>research methods</category>
      
            <category>OpenSesame</category>
      
            <category>python</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Pronominal object clitics in preverbal position are a hard nut to crack for Google Translate</title>
      <link>https://pablobernabeu.github.io/2023/pronominal-object-clitics-in-preverbal-position-are-a-hard-nut-to-crack-for-google-translate/</link>
      <pubDate>Wed, 17 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/pronominal-object-clitics-in-preverbal-position-are-a-hard-nut-to-crack-for-google-translate/</guid>
      <description>Unlike English, some Romance languages not only allow—but sometimes require—pronominal object clitics in preverbal position (Hanson &amp;amp; Carlson, 2014; Labotka et al., 2023). That is, instead of saying La maestra ha detto il nome (Italian) ‘The teacher has said the name’, Italian allows Il nome lo ha detto la maestra (literally, ‘The name it has said the teacher’), which could translate as ‘The name has been said by the teacher’, ‘The teacher has said the name’, or even ‘It is the teacher that has said the name’.</description>
      
            <category>linguistics</category>
      
            <category>syntax</category>
      
            <category>translation</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Specifying version number in OSF download links</title>
      <link>https://pablobernabeu.github.io/2023/specifying-version-number-in-osf-download-links/</link>
      <pubDate>Tue, 16 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/specifying-version-number-in-osf-download-links/</guid>
      <description>How to append version numbers to OSF download links using the &amp;lsquo;?version=X&amp;rsquo; parameter to document and preserve the exact versions of files used in research projects.</description>
      
            <category>research methods</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Covariates are necessary to validate the variables of interest and to prevent bogus theories</title>
      <link>https://pablobernabeu.github.io/2023/covariates-are-necessary-to-validate-the-variables-of-interest-and-to-prevent-bogus-theories/</link>
      <pubDate>Mon, 15 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/covariates-are-necessary-to-validate-the-variables-of-interest-and-to-prevent-bogus-theories/</guid>
      <description>The need for covariates—or nuisance variables—in statistical analyses is twofold. The first reason is purely statistical and the second reason is academic.
First, the use of covariates is often necessary when the variable(s) of interest in a study may be connected to, and affected by, some satellite variables (Bottini et al., 2022; Elze et al., 2017; Sassenhagen &amp;amp; Alday, 2016). This complex scenario is the most common one due to the multivariate, dynamic, interactive nature of the real world.</description>
      
            <category>research methods</category>
      
            <category>statistics</category>
      
            <category>conflation</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Cannot open plots created with &lt;code&gt;brms::mcmc_plot&lt;/code&gt; due to lack of &lt;code&gt;discrete_range&lt;/code&gt; function</title>
      <link>https://pablobernabeu.github.io/2023/cannot-open-plots-created-with-brms-mcmc-plot-due-to-lack-of-discrete-range-function/</link>
      <pubDate>Tue, 11 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2023/cannot-open-plots-created-with-brms-mcmc-plot-due-to-lack-of-discrete-range-function/</guid>
      <description>I would like to ask for advice regarding some plots that were created using brms::mcmc_plot(), and cannot be opened in R now. The plots were created last year using brms 2.17.0, and were saved in RDS objects. The problem I have is that I cannot open the plots in R now because I get an error related to a missing function. I would be very grateful if someone could please advise me if they can think of a possible reason or solution.</description>
      
            <category>statistics</category>
      
            <category>Bayesian statistics</category>
      
            <category>linear-mixed effects models</category>
      
            <category>brms</category>
      
            <category>plotting</category>
      
            <category>data visualisation</category>
      
            <category>R</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>A table of results for Bayesian mixed-effects models: Grouping variables and specifying random slopes</title>
      <link>https://pablobernabeu.github.io/2022/a-table-of-results-for-bayesian-mixed-effects-models-grouping-variables-and-specifying-random-slopes/</link>
      <pubDate>Thu, 29 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2022/a-table-of-results-for-bayesian-mixed-effects-models-grouping-variables-and-specifying-random-slopes/</guid>
      <description>Here I share the format applied to tables presenting the results of Bayesian models in Bernabeu (2022). The sample table presents a mixed-effects model that was fitted using the R package &amp;lsquo;brms&amp;rsquo; (Bürkner et al., 2022).</description>
      
            <category>R</category>
      
            <category>statistics</category>
      
            <category>rstats</category>
      
            <category>brms</category>
      
            <category>credible intervals</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>A table of results for frequentist mixed-effects models: Grouping variables and specifying random slopes</title>
      <link>https://pablobernabeu.github.io/2022/a-table-of-results-for-frequentist-mixed-effects-models-grouping-variables-and-specifying-random-slopes/</link>
      <pubDate>Thu, 29 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2022/a-table-of-results-for-frequentist-mixed-effects-models-grouping-variables-and-specifying-random-slopes/</guid>
      <description>Here I share the format applied to tables presenting the results of frequentist models in Bernabeu (2022). The sample table presents a mixed-effects model that was fitted using the R package &amp;lsquo;lmerTest&amp;rsquo; (Kuznetsova et al., 2022).</description>
      
            <category>R</category>
      
            <category>statistics</category>
      
            <category>rstats</category>
      
            <category>lmerTest</category>
      
            <category>lme4</category>
      
            <category>confidence intervals</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Plotting two-way interactions from mixed-effects models using alias variables</title>
      <link>https://pablobernabeu.github.io/2022/plotting-two-way-interactions-from-mixed-effects-models-using-alias-variables/</link>
      <pubDate>Mon, 26 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2022/plotting-two-way-interactions-from-mixed-effects-models-using-alias-variables/</guid>
      <description>Whereas the direction of main effects can be interpreted from the sign of the estimate, the interpretation of interaction effects often requires plots. This task is facilitated by the R package sjPlot (Lüdecke, 2022). In Bernabeu (2022), the sjPlot function called plot_model served as the basis for the creation of some custom functions. One of these functions is alias_interaction_plot, which allows the plotting of interactions between a continuous variable and a categorical variable.</description>
      
            <category>R</category>
      
            <category>visualisation</category>
      
            <category>plotting</category>
      
            <category>alias</category>
      
            <category>sjPlot</category>
      
            <category>linear mixed-effects models</category>
      
            <category>statistics</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Plotting two-way interactions from mixed-effects models using ten or six bins</title>
      <link>https://pablobernabeu.github.io/2022/plotting-two-way-interactions-from-mixed-effects-models-using-ten-or-six-bins/</link>
      <pubDate>Mon, 26 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2022/plotting-two-way-interactions-from-mixed-effects-models-using-ten-or-six-bins/</guid>
      <description>Whereas the direction of main effects can be interpreted from the sign of the estimate, the interpretation of interaction effects often requires plots. This task is facilitated by the R package sjPlot (Lüdecke, 2022). In Bernabeu (2022), the sjPlot function called plot_model served as the basis for the creation of some custom functions. Two of these functions are deciles_interaction_plot and sextiles_interaction_plot. These functions allow the plotting of interactions between two continuous variables.</description>
      
            <category>R</category>
      
            <category>visualisation</category>
      
            <category>plotting</category>
      
            <category>deciles</category>
      
            <category>sextiles</category>
      
            <category>sjPlot</category>
      
            <category>linear mixed-effects models</category>
      
            <category>individual differences</category>
      
            <category>statistics</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Why can&#39;t we be friends? Plotting frequentist (lmerTest) and Bayesian (brms) mixed-effects models</title>
      <link>https://pablobernabeu.github.io/2022/why-can-t-we-be-friends-plotting-frequentist-lmertest-and-bayesian-brms-mixed-effects-models/</link>
      <pubDate>Fri, 23 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2022/why-can-t-we-be-friends-plotting-frequentist-lmertest-and-bayesian-brms-mixed-effects-models/</guid>
      <description>Frequentist and Bayesian statistics are sometimes regarded as fundamentally different philosophies. Indeed, can both qualify as philosophies or is one of them just a pointless ritual? Is frequentist statistics only about $p$ values? Are frequentist estimates diametrically opposed to Bayesian posterior distributions? Are confidence intervals and credible intervals irreconcilable? Will R crash if lmerTest and brms are simultaneously loaded?</description>
      
            <category>statistics</category>
      
            <category>Bayesian statistics</category>
      
            <category>frequentist statistics</category>
      
            <category>linear-mixed effects models</category>
      
            <category>lmerTest</category>
      
            <category>lme4</category>
      
            <category>brms</category>
      
            <category>plotting</category>
      
            <category>data visualisation</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Bayesian workflow: Prior determination, predictive checks and sensitivity analyses</title>
      <link>https://pablobernabeu.github.io/2022/bayesian-workflow-prior-determination-predictive-checks-and-sensitivity-analyses/</link>
      <pubDate>Thu, 22 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2022/bayesian-workflow-prior-determination-predictive-checks-and-sensitivity-analyses/</guid>
      <description>This post presents a run-through of a Bayesian workflow in R. The content is &lt;em&gt;closely&lt;/em&gt; based on Bernabeu (2022), which was in turn based on lots of other references, also cited here.</description>
      
            <category>Bayesian statistics</category>
      
            <category>linear mixed-effects models</category>
      
            <category>priors</category>
      
            <category>predictive checks</category>
      
            <category>sensitivity analysis</category>
      
            <category>R</category>
      
            <category>visualisation</category>
      
            <category>brms</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Deception in a survey from Polar Insight / Polar Intelligence</title>
      <link>https://pablobernabeu.github.io/2022/deception-in-a-survey-from-polar-insight-/-polar-intelligence/</link>
      <pubDate>Tue, 15 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2022/deception-in-a-survey-from-polar-insight-/-polar-intelligence/</guid>
      <description>I recommend caution when receiving an invitation from Polar Insight (also dubbed ‘Polar Intelligence’) to complete a survey. When I received one, it ended up in a deceptive change of the terms. The deception emerged after two emails exchanged with the company’s managing director, James Tattersfield, and an employee.
The case began when the managing director invited me to complete two tasks in exchange for a $125 USD voucher. The two tasks were a survey (‘short form’, in the director’s words) and an hour-long interview.</description>
      
            <category>survey</category>
      
            <category>scam</category>
      
            <category>fraud</category>
      
    </item>
    
    <item>
      <title>Avoiding (R) Markdown knitting errors using knit_deleting_service_files()</title>
      <link>https://pablobernabeu.github.io/2021/avoiding-knitting-errors-in-r-markdown-using-knit-deleting-service-files/</link>
      <pubDate>Fri, 17 Dec 2021 21:46:06 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2021/avoiding-knitting-errors-in-r-markdown-using-knit-deleting-service-files/</guid>
      <description>The function knit_deleting_service_files() helps avoid (R) Markdown knitting errors caused by files and folders remaining from previous knittings (e.g., manuscript.tex, ZHJhZnQtYXBhLlJtZA==.Rmd, manuscript.synctex.gz). The only obligatory argument for this function is the name of a .Rmd or .md file. The optional argument is a path to a directory containing this file. The function first offers szeleting potential service files and folders in the directory. A confirmation is required in the console (see screenshot below). Next, the document is knitted. Last, the function offers deleting potential service files and folders again.</description>
      
            <category>s</category>
      
            <category>R Markdown</category>
      
            <category>papaja</category>
      
            <category>render</category>
      
    </item>
    
    <item>
      <title>Walking the line between reproducibility and efficiency in R Markdown: Three methods</title>
      <link>https://pablobernabeu.github.io/2021/walking-the-line-between-reproducibility-and-efficiency-in-r-markdown-three-methods/</link>
      <pubDate>Sun, 14 Nov 2021 00:10:08 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2021/walking-the-line-between-reproducibility-and-efficiency-in-r-markdown-three-methods/</guid>
      <description>As technology and research methods advance, the data sets tend to be larger and the methods more exhaustive. Consequently, the analyses take longer to run. This poses a challenge when the results are to be presented using R Markdown. One has to balance reproducibility and efficiency. On the one hand, it is desirable to keep the R Markdown document as self-contained as possible, so that those who may later examine the document can easily test and edit the code.</description>
      
            <category>s</category>
      
            <category>R</category>
      
            <category>R Markdown</category>
      
    </item>
    
    <item>
      <title>Tackling knitting errors in R Markdown</title>
      <link>https://pablobernabeu.github.io/2021/tackling-knitting-errors-in-r-markdown/</link>
      <pubDate>Sat, 13 Nov 2021 18:11:22 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2021/tackling-knitting-errors-in-r-markdown/</guid>
      <description>When knitting an R Markdown document after the first time, errors may sometimes appear. Three tips are recommended below.
1. Close PDF reader windowWhen the document is knitted through the ‘Knit’ button, a PDF reader window opens to present the result. Closing this window can help resolve errors.
2. Delete service filesEvery time the Rmd is knitted, some service files are created. Some of these files have the ‘.</description>
      
            <category>s</category>
      
            <category>R</category>
      
            <category>R Markdown</category>
      
    </item>
    
    <item>
      <title>Parallelizing simr::powercurve() in R</title>
      <link>https://pablobernabeu.github.io/2021/parallelizing-simr-powercurve/</link>
      <pubDate>Fri, 23 Jul 2021 16:46:54 +0100</pubDate>
      
      <guid>https://pablobernabeu.github.io/2021/parallelizing-simr-powercurve/</guid>
      <description>The powercurve function from the R package ‘simr’ (Green &amp;amp; MacLeod, 2016) can incur very long running times when the method used for the calculation of p values is Kenward-Roger or Satterthwaite (see Luke, 2017). Here I suggest three ways for cutting down this time.
Where possible, use a high-performance (or high-end) computing cluster. This removes the need to use personal computers for these long jobs.
In case you’re using the fixed() parameter of the powercurve function, and calculating the power for different effects, run these at the same time (‘in parallel’) on different machines, rather than one after another.</description>
      
            <category>s</category>
      
            <category>power analysis</category>
      
    </item>
    
    <item>
      <title>Surviving discrimination and confronting it</title>
      <link>https://pablobernabeu.github.io/2021/surviving-discrimination-and-confronting-it/</link>
      <pubDate>Wed, 21 Jul 2021 14:34:04 +0100</pubDate>
      
      <guid>https://pablobernabeu.github.io/2021/surviving-discrimination-and-confronting-it/</guid>
      <description>This blog post does not provide a complete overview of the atmosphere at university or in academia, where I think that fairness is far more common than discrimination. Let&#39;s keep up the good work and be mindful of the rest.There is discrimination at European universities and in the corresponding academia. Minorities are too often oppressed and abused through the use of casual remarks, concerted attacks, unequal respect towards different groups, unfair hiring decisions and other negligent behaviours.</description>
      
    </item>
    
    <item>
      <title>Brief Clarifications, Open Questions: Commentary on Liu et al. (2018)</title>
      <link>https://pablobernabeu.github.io/2021/brief-clarifications-open-questions-commentary-on-liu-et-al-2018/</link>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2021/brief-clarifications-open-questions-commentary-on-liu-et-al-2018/</guid>
      <description>Critical examination of Liu et al. (2018) claims about methodological inconsistencies in ERP studies of conceptual modality switching, arguing that their conclusions overlook theoretical and methodological justifications for varying analytical approaches.</description>
      
            <category>s</category>
      
            <category>conceptual modality switch</category>
      
            <category>conceptual processing</category>
      
            <category>cognition</category>
      
            <category>conceptual replication</category>
      
            <category>word recognition</category>
      
            <category>research methods</category>
      
            <category>event-related potentials</category>
      
            <category>experiment</category>
      
            <category>statistics</category>
      
            <category>Bayesian</category>
      
            <category>frequentist</category>
      
            <category>bias</category>
      
            <category>methodology</category>
      
    </item>
    
    <item>
      <title>Collaboration while using R Markdown</title>
      <link>https://pablobernabeu.github.io/2020/collaboration-while-using-r-markdown/</link>
      <pubDate>Sat, 03 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2020/collaboration-while-using-r-markdown/</guid>
      <description>Based on Michael Frank&#39;s presentation, three methods for collaborating on R Markdown documents: using GitHub for version control, copying text to trackable editors while preserving code, or knitting to Word/PDF formats.</description>
      
            <category>s</category>
      
            <category>R</category>
      
            <category>R Markdown</category>
      
    </item>
    
    <item>
      <title>Notes about punctuation in formal writing</title>
      <link>https://pablobernabeu.github.io/2020/formal-punctuation/</link>
      <pubDate>Sat, 03 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2020/formal-punctuation/</guid>
      <description>Common punctuation pitfalls in formal writing, including run-on sentences, comma splices, and the appropriate use of the Oxford comma based on whether disambiguation is needed.</description>
      
            <category>s</category>
      
            <category>writing</category>
      
            <category>punctuation</category>
      
    </item>
    
    <item>
      <title>Stray meetings in Microsoft Teams</title>
      <link>https://pablobernabeu.github.io/2020/stray-meetings-in-microsoft-teams/</link>
      <pubDate>Sat, 03 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2020/stray-meetings-in-microsoft-teams/</guid>
      <description>Unwanted, stranded meetings, overlapping with a general one in a channel, can occur when people click on the &lt;kbd&gt;Meet (now)&lt;/kbd&gt;/:camera: button, instead of clicking on the same &lt;kbd&gt;Join&lt;/kbd&gt; button in the chat field. This may especially happen to those who reach the channel first, or who cannot see the &lt;kbd&gt;Join&lt;/kbd&gt; button in the chat field because this field has been taken up by messages.</description>
      
            <category>s</category>
      
            <category>communications</category>
      
    </item>
    
    <item>
      <title>R Markdown amidst Madison parks</title>
      <link>https://pablobernabeu.github.io/2020/r-markdown-amidst-madison-parks/</link>
      <pubDate>Fri, 14 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2020/r-markdown-amidst-madison-parks/</guid>
      <description>This document is part of teaching materials created for the workshop &amp;lsquo;Open data and reproducibility v2.1: R Markdown, dashboards and Binder&amp;rsquo;, delivered at the CarpentryCon 2020 conference. The purpose of this specific document is to practise R Markdown, including basic features such as Markdown markup and code chunks, along with more special features such as cross-references for figures, tables, code chunks, etc. Since this conference was originally going to take place in Madison, let&#39;s look at some open data from the City of Madison.</description>
      
            <category>s</category>
      
            <category>R</category>
      
            <category>R Markdown</category>
      
            <category>CarpentryCon</category>
      
            <category>workshop</category>
      
            <category>RStudio</category>
      
            <category>bookdown</category>
      
            <category>cross-references</category>
      
    </item>
    
    <item>
      <title>What&#39;s in a fluke? The problem of trust and distrust</title>
      <link>https://pablobernabeu.github.io/2020/whats-in-a-fluke/</link>
      <pubDate>Thu, 25 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2020/whats-in-a-fluke/</guid>
      <description>The label &amp;lsquo;fluke&amp;rsquo; may in principle be skewed by the eye of the beholder, the mind of the perceiver and the availability or lack of data.</description>
      
            <category>fluke</category>
      
            <category>false positive</category>
      
            <category>false negative</category>
      
            <category>perception</category>
      
            <category>bias</category>
      
            <category>discrimination</category>
      
            <category>trust</category>
      
            <category>distrust</category>
      
    </item>
    
    <item>
      <title>How to engage Research Group Leaders in sustainable software practices</title>
      <link>https://pablobernabeu.github.io/2020/how-to-engage-research-group-leaders-in-sustainable-software-practices/</link>
      <pubDate>Fri, 29 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2020/how-to-engage-research-group-leaders-in-sustainable-software-practices/</guid>
      <description>There is an increasing number of training courses introducing early career researchers to sustainable software practices but relatively little aimed at Research Group Leaders and Principal Investigators. Expecting group leaders to personally acquire such skills through training such as a two-day Carpentries workshop is unrealistic, as these require a significant time investment and are less directly applicable in the role of research director. In addition, many group leaders would not consider their group as outputting software, or are less aware of the full range of benefits that sustainable practice brings and will thus be less likely to signpost such training to their team members. Even where they do identify benefits, they may have concerns about releasing group software or may feel overwhelmed by the potential scale of the task, especially with respect to legacy projects.</description>
      
            <category>s</category>
      
            <category>research</category>
      
            <category>sustainable practices</category>
      
    </item>
    
    <item>
      <title>Incentives for good research software practices</title>
      <link>https://pablobernabeu.github.io/2020/incentives-for-good-research-software-practices/</link>
      <pubDate>Fri, 29 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2020/incentives-for-good-research-software-practices/</guid>
      <description>Software is increasingly becoming recognised as fundamental to research. In a 2014 survey of UK researchers undertaken by the Institute, 7 out of 10 researchers supported the view that it would be impossible to conduct research without software. As software continues to underpin more research activities, we must engage a variety of stakeholders to incentivise the uptake of best practice in software development to ensure the quality of research software keeps pace with the research it supports.</description>
      
            <category>s</category>
      
            <category>research software</category>
      
            <category>best practices</category>
      
    </item>
    
    <item>
      <title>Data is present: Workshops and datathons</title>
      <link>https://pablobernabeu.github.io/2020/data-is-present-workshops-and-datathons/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2020/data-is-present-workshops-and-datathons/</guid>
      <description>This project offers free activities to learn and practise reproducible data presentation. Pablo Bernabeu organises these events in the context of a Software Sustainability Institute Fellowship. Programming languages such as R and Python offer free, powerful resources for data processing, visualisation and analysis. Experience in these programs is highly valued in data-intensive disciplines. Original data has become a public good in many research fields thanks to cultural and technological advances. On the internet, we can find innumerable data sets from sources such as scientific journals and repositories (e.g., OSF), local and national governments, non-governmental organisations (e.g., data.world), etc. Activities comprise free workshops and datathons.</description>
      
            <category>s</category>
      
            <category>programming</category>
      
            <category>education</category>
      
            <category>workshop</category>
      
            <category>datathon</category>
      
            <category>data presentation</category>
      
            <category>data visualisation</category>
      
            <category>dashboard</category>
      
            <category>reproducibility</category>
      
            <category>open science</category>
      
            <category>open data</category>
      
            <category>statistics</category>
      
            <category>R</category>
      
            <category>R Shiny</category>
      
            <category>Flexdashboard</category>
      
            <category>HTML</category>
      
            <category>CSS</category>
      
            <category>Software Sustainability Institute Fellowship</category>
      
    </item>
    
    <item>
      <title>Event-related potentials: Why and how I used them</title>
      <link>https://pablobernabeu.github.io/2020/event-related-potentials-why-and-how-i-used-them/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2020/event-related-potentials-why-and-how-i-used-them/</guid>
      <description>Overview of event-related potentials as a research method, covering electroencephalography fundamentals, ERP definitions and processing, and their application to studying the time course of cognitive processes like conceptual processing.</description>
      
            <category>s</category>
      
            <category>event-related potentials</category>
      
            <category>electroencephalography</category>
      
            <category>electrodes</category>
      
            <category>preprocessing</category>
      
            <category>methodology</category>
      
            <category>cognitive neuroscience</category>
      
            <category>Brain Vision</category>
      
            <category>R</category>
      
            <category>statistics</category>
      
            <category>linear mixed-effects models</category>
      
            <category>Max Planck Institute for Psycholinguistics</category>
      
    </item>
    
    <item>
      <title>Naive principal component analysis in R</title>
      <link>https://pablobernabeu.github.io/2018/naive-principal-component-analysis-in-r/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2018/naive-principal-component-analysis-in-r/</guid>
      <description>Principal Component Analysis (PCA) is a technique used to find the core components that underlie different variables. It comes in very useful whenever doubts arise about the true origin of three or more variables. There are two main methods for performing a PCA: naive or less naive. In the naive method, you first check some conditions in your data which will determine the essentials of the analysis. In the less-naive method, you set those yourself based on whatever prior information or purposes you had. The &amp;lsquo;naive&amp;rsquo; approach is characterized by a first stage that checks whether the PCA should actually be performed with your current variables, or if some should be removed. The variables that are accepted are taken to a second stage which identifies the number of principal components that seem to underlie your set of variables.</description>
      
            <category>s</category>
      
            <category>principal component analysis</category>
      
            <category>statistics</category>
      
            <category>dimensionality reduction</category>
      
            <category>R</category>
      
    </item>
    
    <item>
      <title>Review of the Landscape Model of reading: Composition, dynamics and application</title>
      <link>https://pablobernabeu.github.io/2018/review-of-the-landscape-model-of-reading-composition-dynamics-and-application/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2018/review-of-the-landscape-model-of-reading-composition-dynamics-and-application/</guid>
      <description>Throughout the 1990s, two opposing theories were used to explain how people understand texts, later bridged by the Landscape Model of reading (van den Broek, Young, Tzeng, &amp;amp; Linderholm, 1999). A review is offered below, including a schematic representation of the Landscape Model.
Memory-based viewThe memory-based view presented reading as an autonomous, unconscious, effortless process. Readers were purported to achieve an understanding of a text as a whole by combining the concepts, and implications readily afforded, in the text with their own background knowledge (Myers &amp;amp; O’Brien, 1998; O’Brien &amp;amp; Myers, 1999).</description>
      
            <category>s</category>
      
            <category>reading</category>
      
            <category>psycholinguistics</category>
      
            <category>cognition</category>
      
    </item>
    
    <item>
      <title>Denken met woorden</title>
      <link>https://pablobernabeu.github.io/2017/denken-met-woorden/</link>
      <pubDate>Mon, 20 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2017/denken-met-woorden/</guid>
      <description>Het menselijk brein begrijpt de wereld om ons heen op een taalkundige en zintuiglijke manier. Pablo Bernabeu (Language and Communication) onderzocht waarom dat zo is.</description>
      
            <category>cognition</category>
      
            <category>cognitive neuroscience</category>
      
            <category>conceptual modality switch</category>
      
            <category>conceptual processing</category>
      
            <category>language comprehension</category>
      
            <category>psycholinguistics</category>
      
            <category>reading</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>At Greg, 8 am</title>
      <link>https://pablobernabeu.github.io/2017/at-greg-8-am/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2017/at-greg-8-am/</guid>
      <description>The single dependent variable, RT, was accompanied by other variables which could be analyzed as independent variables. These included Group, Trial Number, and a within-subjects Condition. What had to be done first off, in order to take the usual table? The trials!</description>
      
            <category>s</category>
      
            <category>R</category>
      
            <category>statistics</category>
      
            <category>aggregate</category>
      
            <category>trials</category>
      
            <category>repeated measures</category>
      
            <category>assumption</category>
      
            <category>independence of observations</category>
      
            <category>variability</category>
      
            <category>standard error</category>
      
            <category>central assumption</category>
      
    </item>
    
    <item>
      <title>Modality switch effects emerge early and increase throughout conceptual processing: Evidence from ERPs</title>
      <link>https://pablobernabeu.github.io/2017/modality-switch-effects-emerge-early-and-increase-throughout-conceptual-processing-evidence-from-erps/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2017/modality-switch-effects-emerge-early-and-increase-throughout-conceptual-processing-evidence-from-erps/</guid>
      <description>An ERP study demonstrating that conceptual modality switch effects emerge within 200ms and increase throughout processing, supporting the role of perceptual simulation in conceptual processing while suggesting that both amodal and modal systems contribute to cognition.</description>
      
            <category>s</category>
      
            <category>psycholinguistics</category>
      
            <category>conceptual processing</category>
      
            <category>experiment</category>
      
            <category>event-related potentials</category>
      
            <category>language comprehension</category>
      
            <category>open data</category>
      
            <category>cognition</category>
      
            <category>conceptual modality switch</category>
      
            <category>modality exclusivity norms</category>
      
            <category>reading</category>
      
            <category>statistics</category>
      
            <category>linear mixed-effects models</category>
      
            <category>ResearchGate</category>
      
    </item>
    
    <item>
      <title>The case for data dashboards: First steps in R Shiny</title>
      <link>https://pablobernabeu.github.io/2017/the-case-for-data-dashboards-first-steps-in-r-shiny/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2017/the-case-for-data-dashboards-first-steps-in-r-shiny/</guid>
      <description>Dashboards for data visualisation, such as R Shiny and Tableau, allow the interactive exploration of data by means of drop-down lists and checkboxes, with no coding required from the final users. These web applications run on internet browsers, allowing for three viewing modes, catered to both analysts and the public at large: (1) private viewing (useful during analysis), (2) selective sharing (used within work groups), and (3) internet publication. Among the available platforms, R Shiny and Tableau stand out due to being relatively accessible to new users. Apps serve a broad variety of purposes. In science and beyond, these apps allow us to go the extra mile in sharing data. Alongside files and code shared in repositories, we can present the data in a website, in the form of plots or tables. This facilitates the public exploration of each section of the data (groups, participants, trials&amp;hellip;) to anyone interested, and allows researchers to account for their proceeding in the analysis.</description>
      
            <category>s</category>
      
            <category>data presentation</category>
      
            <category>dashboard</category>
      
            <category>reproducibility</category>
      
            <category>open science</category>
      
            <category>open data</category>
      
            <category>R</category>
      
            <category>R Shiny</category>
      
            <category>Flexdashboard</category>
      
    </item>
    
    <item>
      <title>EEG error: datasets missing channels</title>
      <link>https://pablobernabeu.github.io/2016/eeg-error-datasets-missing-channels/</link>
      <pubDate>Tue, 16 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2016/eeg-error-datasets-missing-channels/</guid>
      <description>Most of the recordings are perfectly fine, but a few present a big error. Out of 64 original electrodes, only two appear. These are the right mastoid (RM) and the left eye sensor (LEOG). Both are bipolar electrodes. RM is to be re-referenced to the online reference electrode, while LEOG is to be re-referenced to the right eye electrode.</description>
      
            <category>event-related potentials</category>
      
            <category>electroencephalography</category>
      
            <category>BrainVision</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>Modality exclusivity norms for 747 properties and concepts in Dutch: A replication of English</title>
      <link>https://pablobernabeu.github.io/2016/modality-exclusivity-norms-for-747-properties-and-concepts-in-dutch-a-replication-of-english/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2016/modality-exclusivity-norms-for-747-properties-and-concepts-in-dutch-a-replication-of-english/</guid>
      <description>This study is a cross-linguistic, conceptual replication of Lynott and Connell’s (2009, 2013) modality exclusivity norms. The properties and concepts tested therein were translated into Dutch, and independently rated and analyzed (Bernabeu, 2018).</description>
      
            <category>research methods</category>
      
            <category>stimuli</category>
      
            <category>linguistic norms</category>
      
            <category>modality exclusivity norms</category>
      
            <category>conceptual modality switch</category>
      
            <category>dimensionality reduction</category>
      
            <category>conceptual replication</category>
      
            <category>Dutch</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title>The Louisiana-Minnesota-Texas crisis across media and time: A big data exercise</title>
      <link>https://pablobernabeu.github.io/2016/the-louisiana-minnesota-texas-crisis-across-media-and-time-a-big-data-exercise/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2016/the-louisiana-minnesota-texas-crisis-across-media-and-time-a-big-data-exercise/</guid>
      <description>Racism has long been ingrained in human societies. Ancient Greek Aristotle already claimed that non-Greeks were slaves by nature, as they easily submitted to despotic government (Reilly, Kaufman, &amp;amp; Bodino, 2002). This study focuses on racism in the United States, which extends from the foundation of the country, when black people were generally born into slavery, and were at any rate regarded as an inferior people. US racism stands out globally for two reasons. First, the country has played a hegemonic part in the World since soon after its foundation. Second, the US is regarded as the most advanced society technology-wise, as it sets the minutes for the technology sector worldwide. In spite of these advantages, the country has long suffered the plague of widespread racism. Indeed, the abolition of slavery in the mid-nineteenth century did not grant equal citizen rights to the black population. Over time, the black population started to confront this situation. Especially the mid-nineteenth century saw large uprisings and a patent division of different societal sectors, as reflected in literary works such as Ellison’s &amp;lsquo;Invisible Man&amp;rsquo; (1952). Inequality and confrontation about racism has extended to date, and the costs thereof have been large in terms of lives and otherwise (Feagin, 2004).</description>
      
            <category>big data</category>
      
            <category>data mining</category>
      
            <category>racism</category>
      
            <category>web scraping</category>
      
            <category>R</category>
      
            <category>API</category>
      
            <category>social media</category>
      
            <category>news media</category>
      
    </item>
    
    <item>
      <title>Conceptual modality switch effect measured at first word?</title>
      <link>https://pablobernabeu.github.io/2015/conceptual-modality-switch-effect-measured-at-first-word/</link>
      <pubDate>Sat, 31 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/2015/conceptual-modality-switch-effect-measured-at-first-word/</guid>
      <description>Traditionally, the second word presented (whether noun or adjective) has been the point of measure, both for RTs and ERPs. Yet, could it be better to measure at the first word?</description>
      
            <category>psycholinguistics</category>
      
            <category>conceptual modality switch</category>
      
            <category>conceptual processing</category>
      
            <category>word recognition</category>
      
            <category>semantic processing</category>
      
            <category>event-related potentials</category>
      
            <category>embodied cognition</category>
      
            <category>s</category>
      
    </item>
    
    <item>
      <title></title>
      <link>https://pablobernabeu.github.io/1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pablobernabeu.github.io/1/</guid>
      <description></description>
      
    </item>
    
  </channel>
</rss>
