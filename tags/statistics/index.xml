<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>statistics | Pablo Bernabeu</title>
    <link>/tags/statistics/</link>
      <atom:link href="/tags/statistics/index.xml" rel="self" type="application/rss+xml" />
    <description>statistics</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-uk</language><copyright>¬© Pablo Bernabeu, 2020. [CC BY Attribution licence](https://creativecommons.org/licenses/by/4.0/). Cookies only used by Disqus to enable comments ([see details](https://help.disqus.com/en/articles/1717155-use-of-cookies)).</copyright><lastBuildDate>Wed, 01 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/pablobernabeu_image_sharing.png</url>
      <title>statistics</title>
      <link>/tags/statistics/</link>
    </image>
    
    <item>
      <title>Data is present: workshops and datathons</title>
      <link>/2020/01/01/data-is-present-workshops-and-datathons/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/2020/01/01/data-is-present-workshops-and-datathons/</guid>
      <description>


&lt;div id=&#34;enhanced-data-presentation-using-reproducible-documents-and-dashboards&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Enhanced data presentation using reproducible documents and dashboards&lt;/h2&gt;
&lt;div id=&#34;calendar&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Calendar&lt;/h3&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;col width=&#34;14%&#34; /&gt;
&lt;col width=&#34;21%&#34; /&gt;
&lt;col width=&#34;15%&#34; /&gt;
&lt;col width=&#34;19%&#34; /&gt;
&lt;col width=&#34;23%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;Date&lt;/th&gt;
&lt;th&gt;Title&lt;/th&gt;
&lt;th&gt;Event and location&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Registration&lt;/th&gt;
&lt;th&gt;Attendance funding&lt;/th&gt;
&lt;th&gt;Organisation funding&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;To follow&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/pablobernabeu/Data-is-present/blob/master/N8-CIR-workshops.md/&#34;&gt;Data dashboards and Binder environments&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;University of York&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://n8cir.org.uk/events/&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://n8cir.org.uk/events/&#34;&gt;N8 CIR&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://n8cir.org.uk/events/&#34;&gt;N8 CIR&lt;/a&gt;, &lt;br&gt; &lt;a href=&#34;https://www.software.ac.uk/programmes-and-events/fellowship-programme&#34;&gt;SSI Fellowship&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;To follow&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/pablobernabeu/Data-is-present/blob/master/N8-CIR-workshops.md/&#34;&gt;Introduction to R and R Markdown&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Durham University&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://n8cir.org.uk/events/&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://n8cir.org.uk/events/&#34;&gt;N8 CIR&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://n8cir.org.uk/events/&#34;&gt;N8 CIR&lt;/a&gt;, &lt;br&gt; &lt;a href=&#34;https://www.software.ac.uk/programmes-and-events/fellowship-programme&#34;&gt;SSI Fellowship&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;25 Aug 2020&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://wp.lancs.ac.uk/lcicd/programme/&#34;&gt;R is for Resources, Reproducibility and oppRtunities&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://wp.lancs.ac.uk/lcicd/programme/&#34;&gt;Lancaster Conference on Infant and Early Child Development&lt;/a&gt;, Lancaster University&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://wp.lancs.ac.uk/lcicd/registration/&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;27 July 2020&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.ukclc2020.com/pre-conference&#34;&gt;Open data and reproducibility 2.0&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.ukclc2020.com/&#34;&gt;UK Cognitive Linguistics Conference&lt;/a&gt;, University of Birmingham&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.ukclc2020.com/registration&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.software.ac.uk/programmes-and-events/fellowship-programme&#34;&gt;SSI Fellowship&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;To follow&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/pablobernabeu/Data-is-present/blob/master/N8-CIR-workshops.md&#34;&gt;Data dashboards and Binder environments&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;University of Liverpool&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://n8cir.org.uk/events/&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://n8cir.org.uk/events/&#34;&gt;N8 CIR&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://n8cir.org.uk/events/&#34;&gt;N8 CIR&lt;/a&gt;, &lt;br&gt; &lt;a href=&#34;https://www.software.ac.uk/programmes-and-events/fellowship-programme&#34;&gt;SSI Fellowship&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;To follow&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/pablobernabeu/Data-is-present/blob/master/N8-CIR-workshops.md/&#34;&gt;Introduction to R and R Markdown&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;University of Manchester&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://n8cir.org.uk/events/&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://n8cir.org.uk/events/&#34;&gt;N8 CIR&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://n8cir.org.uk/events/&#34;&gt;N8 CIR&lt;/a&gt;, &lt;br&gt; &lt;a href=&#34;https://www.software.ac.uk/programmes-and-events/fellowship-programme&#34;&gt;SSI Fellowship&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;Event cancelled&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://newcastle2020.satrdays.org/&#34;&gt;Open data and reproducibility 2.0&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://newcastle2020.satrdays.org/&#34;&gt;SatRday Newcastle upon Tyne&lt;/a&gt;, Newcastle University&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://newcastle2020.satrdays.org/&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.software.ac.uk/programmes-and-events/fellowship-programme&#34;&gt;SSI Fellowship&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;background&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Background&lt;/h3&gt;
&lt;p&gt;This project offers free activities to learn and practise reproducible data presentation across the UK. &lt;a href=&#34;https://www.software.ac.uk/about/fellows/pablo-bernabeu&#34;&gt;Pablo Bernabeu&lt;/a&gt; organises these events thanks to a &lt;a href=&#34;https://www.software.ac.uk/programmes-and-events/fellowship-programme&#34;&gt;Software Sustainability Institute Fellowship&lt;/a&gt; that covers organisation costs on a &lt;a href=&#34;https://www.software.ac.uk/fellowship-programme/2020/terms-and-conditions&#34;&gt;budget basis&lt;/a&gt;, and thanks to further support from the &lt;a href=&#34;https://n8cir.org.uk/events/&#34;&gt;N8 CIR&lt;/a&gt;. If you would like to bring any of these events to your institution at no cost, please submit a request (see &lt;a href=&#34;#contact&#34;&gt;Contact&lt;/a&gt;).&lt;/p&gt;
&lt;div id=&#34;open-source-software&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Open-source software&lt;/h4&gt;
&lt;p&gt;Programming languages such as &lt;a href=&#34;https://www.r-project.org/about.html&#34;&gt;R&lt;/a&gt; and &lt;a href=&#34;https://www.python.org/&#34;&gt;Python&lt;/a&gt; offer free, powerful resources for data processing, visualisation and analysis. Experience in these programs is highly valued in data-intensive disciplines.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;open-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Open data&lt;/h4&gt;
&lt;p&gt;Original data has become a &lt;a href=&#34;https://www.nature.com/articles/d41586-019-01506-x&#34;&gt;public good in many research fields&lt;/a&gt; thanks to cultural and technological advances. On the internet, we can find innumerable data sets from sources such as scientific journals and repositories (e.g., &lt;a href=&#34;https://osf.io&#34;&gt;OSF&lt;/a&gt;), local and national governments (e.g., &lt;a href=&#34;https://data.london.gov.uk/&#34;&gt;London&lt;/a&gt;, UK [&lt;a href=&#34;https://www.ukdataservice.ac.uk/&#34;&gt;1&lt;/a&gt;, &lt;a href=&#34;https://data.gov.uk/&#34;&gt;2&lt;/a&gt;]), non-governmental organisations (e.g., &lt;a href=&#34;https://data.world/datasets/ngo&#34;&gt;data.world&lt;/a&gt;), etc. Researchers inside and outside academia nowadays share a lot of their data under attribution licences (e.g., &lt;a href=&#34;https://creativecommons.org/&#34;&gt;Creative Commons&lt;/a&gt;, the UK &lt;a href=&#34;http://www.nationalarchives.gov.uk/doc/open-government-licence/version/1/&#34;&gt;Open Government Licence&lt;/a&gt;, etc.). This allows any external analysts to access these raw data, create (additional) visualisations and analyses, and share these. In society, making data more accessible can &lt;a href=&#34;https://digitalcommons.law.yale.edu/cgi/viewcontent.cgi?article=1140&amp;amp;context=yhrdlj&#34;&gt;demonstrably benefit citizens&lt;/a&gt; (despite &lt;a href=&#34;https://firstmonday.org/ojs/index.php/fm/article/view/3316/2764#author&#34;&gt;limitations&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;activities&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Activities&lt;/h2&gt;
&lt;p&gt;Activities comprise free &lt;strong&gt;workshops&lt;/strong&gt; and &lt;a href=&#34;#datathons-creating-reproducible-documents-and-dashboards&#34;&gt;&lt;strong&gt;datathons&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;workshops&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Workshops&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.r-project.org&#34;&gt;R is a programming language&lt;/a&gt; greatly equipped for the creation of reproducible documents and dashboards. Four workshops are offered that cover a suite of interrelated tools‚ÄîR, R Markdown, data dashboards and Binder environments‚Äî, all underlain by reproducible workflows and open-source software.&lt;/p&gt;
&lt;p&gt;Each workshop includes &lt;strong&gt;taught and practical sections&lt;/strong&gt;. The practice provides a chance for participants to experience and address common issues with the code. The level of taught sections is largely tailored to participants; similarly, practice sections are individually adaptable by means of easier and tougher tasks. The duration is also flexible, and some of the workshops can be combined into the same session.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://rstudio.com/&#34;&gt;RStudio&lt;/a&gt; interface is used in all workshops. Multi-levelled, real code examples are used. Throughout the workshops, and especially in the practice sections, individual questions will be encouraged.&lt;/p&gt;
&lt;div id=&#34;workshop-1-introduction-to-r&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Workshop 1: Introduction to R&lt;/h4&gt;
&lt;p&gt;This workshop can serve as an introduction to R or a revision. It demonstrates what can be done in R, and provides resources for individual training. Since the duration is limited, online courses are also recommended (&lt;a href=&#34;https://www.coursera.org/courses?query=r&#34;&gt;see examples&lt;/a&gt; and &lt;a href=&#34;https://learner.coursera.help/hc/en-us/articles/209819033-Apply-for-Financial-Aid-or-a-Scholarship&#34;&gt;fee waivers for full content&lt;/a&gt;).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://adv-r.had.co.nz/Data-structures.html&#34;&gt;Data structures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.sthda.com/english/wiki/installing-and-using-r-packages&#34;&gt;Packages&lt;/a&gt;: general-purpose examples (e.g., &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;tidyverse&lt;/a&gt;) and more specific ones (e.g., for &lt;a href=&#34;https://cran.r-project.org/web/packages/lsr/lsr.pdf&#34;&gt;statistics&lt;/a&gt; or &lt;a href=&#34;https://cran.r-project.org/web/packages/GEOmap/GEOmap.pdf&#34;&gt;geography&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/rio/vignettes/rio.html&#34;&gt;Loading and writing data, in native and foreign formats&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Wide&lt;/em&gt; format (also dubbed ‚Äòuntidy‚Äô) versus &lt;em&gt;tidy&lt;/em&gt; format (also dubbed ‚Äòlong‚Äô or ‚Äònarrow‚Äô). For most processes in R, &lt;a href=&#34;https://r4ds.had.co.nz/tidy-data.html&#34;&gt;data needs to be in a tidy format&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p align=&#34;center&#34;&gt;
&lt;a href = &#39;https://doi.org/10.1371/journal.pbio.3000202.g001&#39;&gt; &lt;img width = &#39;25%&#39; src = &#39;https://journals.plos.org/plosbiology/article/file?id=10.1371/journal.pbio.3000202.g001&amp;type=large&#39; alt = &#39;Illustration of wide and tidy data formats, from Postma and Goedhart (2019)&#39; /&gt; &lt;/a&gt;
&lt;p align=&#34;center&#34; style=&#34;text-align:center;&#34;&gt;
Image from Postma and Goedhart (2019; &lt;a href=&#34;https://doi.org/10.1371/journal.pbio.3000202.g001&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1371/journal.pbio.3000202.g001&lt;/a&gt;).
&lt;/p&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://psyteachr.github.io/msc-data-skills/joins.html#joins&#34;&gt;Combining data sets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cookbook-r.com/Manipulating_data/Summarizing_data/&#34;&gt;Data summaries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://philmcaleer.github.io/ug2-practical/visualisation-through-ggplot2.html&#34;&gt;Plots with &lt;code&gt;ggplot2::ggplot()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://plot.ly/ggplot2/&#34;&gt;Interactive plots with &lt;code&gt;plotly::ggplotly()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://learningstatisticswithr-bookdown.netlify.com/part-v-statistical-tools.html&#34;&gt;Statistics&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://psych.wisc.edu/Brauer/BrauerLab/wp-content/uploads/2014/04/Brauer_and_Curtin_LMEMs-2017-Psych_Methods.pdf&#34;&gt;Linear mixed-effects models&lt;/a&gt; (see also &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0749596X20300061?dgcid=coauthor#b0670&#34;&gt;a review of practices&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://swcarpentry.github.io/r-novice-inflammation/02-func-R/&#34;&gt;How functions work&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Debugging&lt;/em&gt;. Code errors are known as bugs. They can tiresome, but also interesting sometimes! üòÖ Some tips for the first many years of experience include: reading and investigating error messages, in both source and console windows; controlling letter case and typos; closing parentheses and inverted commas; ensuring to have the necessary packages installed and loaded; following the format required by each function. To debug, break up code into subcomponents and test each of those to find out the source of the error. Once we act on that, the best outcome is seeing the code work, but sometimes different errors overlap, in which case we may see one error disappearing before another one appears. Debugging soon leads to proficient information seeking. The search process often begins on an internet search engine and extends to user communities, package documentation, tutorials, blogs‚Ä¶ (see &lt;a href=&#34;https://youtu.be/Nj9J5iCSMB0?t=2687&#34;&gt;video explanation&lt;/a&gt;). &lt;a href=&#34;https://adv-r.hadley.nz/debugging.html&#34;&gt;Advanced debugging tools are also available&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Vast availability of free resources on the internet, from &lt;a href=&#34;https://www.coursera.org/courses?query=r%20programming&#34;&gt;Coursera&lt;/a&gt; and other MOOC sites, &lt;a href=&#34;https://education.rstudio.com/&#34;&gt;RStudio&lt;/a&gt;, &lt;a href=&#34;https://psyteachr.github.io/&#34;&gt;University of Glasgow&lt;/a&gt;, &lt;a href=&#34;http://swcarpentry.github.io/r-novice-inflammation/&#34;&gt;Carpentries&lt;/a&gt;, etc.&lt;/li&gt;
&lt;li&gt;Community: &lt;a href=&#34;https://stackoverflow.com/&#34;&gt;StackOverflow&lt;/a&gt;, &lt;a href=&#34;https://community.rstudio.com/&#34;&gt;RStudio Community&lt;/a&gt;, &lt;a href=&#34;https://github.com&#34;&gt;Github issues&lt;/a&gt; (e.g., for R packages), etc. Using and contributing back.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rstudio.cloud/&#34;&gt;RStudio Cloud&lt;/a&gt;: a personal RStudio environment on the internet&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;workshop-2-r-markdown-documents&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Workshop 2: R Markdown documents&lt;/h4&gt;
&lt;p&gt;Set your input and output in stone with &lt;a href=&#34;https://rmarkdown.rstudio.com/&#34;&gt;R Markdown&lt;/a&gt;. These reports may be enriched with website features (HTML/CSS) and published as websites, PDF, or Word. Moreover, with R packages such as &lt;code&gt;bookdown&lt;/code&gt;, &lt;code&gt;bookdownplus&lt;/code&gt;, &lt;code&gt;blogdown&lt;/code&gt; and &lt;code&gt;flexdashboard&lt;/code&gt;, documents can be formatted into &lt;a href=&#34;https://awesome-blogdown.com/&#34;&gt;websites&lt;/a&gt;, &lt;a href=&#34;https://bookdown.org/&#34;&gt;digital books&lt;/a&gt; and &lt;a href=&#34;http://rpubs.com/pcbernabeu/Dutch-modality-exclusivity-norms&#34;&gt;data dashboards&lt;/a&gt;. Other useful packages include &lt;code&gt;rmarkdown&lt;/code&gt;, &lt;code&gt;knitr&lt;/code&gt;, &lt;code&gt;kableExtra&lt;/code&gt; and &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
&lt;a href = &#39;https://bookdownplus.netlify.com/portfolio/&#39;&gt; &lt;img width = &#39;50%&#39; src = &#39;https://github.com/pablobernabeu/bookdownplus/blob/master/inst2/copernicus/showcase/copernicus2.png?raw=true&#39; alt = &#39;Example of paper created with bookdownplus (image retrieved from R bookdownplus package)&#39;/&gt; &lt;/a&gt;
&lt;p align=&#34;center&#34; style=&#34;text-align:center;&#34;&gt;
Image from bookdownplus package (&lt;a href=&#34;https://bookdownplus.netlify.com/portfolio/&#34; class=&#34;uri&#34;&gt;https://bookdownplus.netlify.com/portfolio/&lt;/a&gt;).
&lt;/p&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;workshop-3-introduction-to-data-dashboards&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Workshop 3: Introduction to data dashboards&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01782/full&#34;&gt;Data dashboards are web applications used to visualise data&lt;/a&gt; in detail through tables and plots. They assist in explaining and accounting for our data processing and analysis. They don‚Äôt require any coding from the end user.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
&lt;a href = &#39;https://www.linkedin.com/pulse/shiny-data-presentation-added-value-pablo-bernabeu/&#39;&gt; &lt;img width = &#39;40%&#39; src = &#39;https://media-exp1.licdn.com/dms/image/C4D12AQHYcdpmcmSypg/article-inline_image-shrink_1500_2232/0?e=1585785600&amp;v=beta&amp;t=0xfTYFRu_OsWN4lkwnO1IonW6HgAuJD79443sf1-4Ms&#39; alt = &#39;Illustration of the usage of dashboards alongside data repositories&#39; /&gt; &lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;These all-reproducible dashboards are published as websites, and thus, they can include hyperlinks and downloadable files. Some of the R packages used are &lt;code&gt;knitr&lt;/code&gt;, &lt;code&gt;kableExtra&lt;/code&gt;, &lt;code&gt;reactable&lt;/code&gt;, &lt;code&gt;ggplot2&lt;/code&gt;, &lt;code&gt;plotly&lt;/code&gt;, &lt;code&gt;rmarkdown&lt;/code&gt;, &lt;code&gt;flexdashboard&lt;/code&gt; and &lt;code&gt;shiny&lt;/code&gt;. The aim of this workshop is to practise creating different forms of dashboards‚Äî&lt;a href=&#34;https://rmarkdown.rstudio.com/flexdashboard/&#34;&gt;Flexdashboard&lt;/a&gt; and &lt;a href=&#34;https://shiny.rstudio.com/&#34;&gt;Shiny&lt;/a&gt;‚Äîthe latter of which offers greater features, and to practise also with the hosting platforms fitting each type‚Äîsuch as personal websites, &lt;a href=&#34;https://rpubs.com/&#34;&gt;RPubs&lt;/a&gt;, &lt;a href=&#34;https://mybinder.org/&#34;&gt;Binder&lt;/a&gt;, &lt;a href=&#34;https://www.shinyapps.io/&#34;&gt;Shinyapps&lt;/a&gt; and &lt;a href=&#34;https://rstudio.com/products/shiny/shiny-server/&#34;&gt;custom servers&lt;/a&gt;. A great thing about dashboards is that they may be made very simple, but they can also be taken to the next level using some HTML, CSS or Javascript code (on top of the back-end code present in the R packages used), which is addressed in the next workshop.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;workshop-4-binder-environments-and-improving-data-dashboards&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Workshop 4: Binder environments and improving data dashboards&lt;/h4&gt;
&lt;div id=&#34;binder&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;Binder&lt;/h5&gt;
&lt;p&gt;&lt;a href=&#34;https://mybinder.org/&#34;&gt;Binder&lt;/a&gt; is a tool to facilitate public access to software environments‚Äîfor instance, by publishing an RStudio environment on the internet. Binder can also host Shiny apps. It is generously free &lt;a href=&#34;https://discourse.jupyter.org/t/mybinder-org-cost-updates/2426&#34;&gt;for users&lt;/a&gt;. After looking at the &lt;a href=&#34;https://github.com/binder-examples/r&#34;&gt;nuts and bolts of a deployment&lt;/a&gt;, participants will be able to deploy their own Binder environments and check the result by the end of the workshop. For this purpose, it‚Äôs recommended to have data and R code ready, ideally in a GitHub repository.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;improving-data-dashboards&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;Improving data dashboards&lt;/h5&gt;
&lt;p&gt;We will practise how to improve the functionality of dashboards using some HTML, CSS and Javascript code, which is &lt;a href=&#34;https://www.w3schools.com/whatis/&#34;&gt;the basis of websites&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;!-- Javascript function to enable a hovering tooltip --&amp;gt;
&amp;lt;script&amp;gt;
$(document).ready(function(){
    $(&amp;#39;[data-toggle=&amp;quot;tooltip1&amp;quot;]&amp;#39;).tooltip();
});
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p align=&#34;center&#34;&gt;
&lt;a href = &#39;https://shiny.rstudio.com/gallery/&#39;&gt; &lt;img align = &#39;center&#39; width = &#39;60%&#39; src = &#39;https://raw.githubusercontent.com/pablobernabeu/data-is-present/master/dashboard%20gif.gif&#39; alt = &#39;Examples of data dashboards&#39; /&gt; &lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;trade-offs-among-dashboards&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;Trade-offs among dashboards&lt;/h5&gt;
&lt;p&gt;Next, we will practise with three dashboard types‚Äî&lt;a href=&#34;https://rmarkdown.rstudio.com/flexdashboard/using.html&#34;&gt;Flexdashboard&lt;/a&gt;, &lt;a href=&#34;https://shiny.rstudio.com/tutorial/&#34;&gt;Shiny&lt;/a&gt; and &lt;a href=&#34;https://rmarkdown.rstudio.com/flexdashboard/shiny.html&#34;&gt;Flexdashboard-Shiny&lt;/a&gt;‚Äîand with the suitable hosting platforms. Firstly, the strength of Flexdashboard (&lt;a href=&#34;http://rpubs.com/pcbernabeu/Dutch-modality-exclusivity-norms&#34;&gt;example&lt;/a&gt;) is its basis on R Markdown, yielding an unmatched user interface (&lt;em&gt;front-end&lt;/em&gt;). Secondly, the strength of Shiny (&lt;a href=&#34;https://mybinder.org/v2/gh/pablobernabeu/Modality-switch-effects-emerge-early-and-increase-throughout-conceptual-processing/master?urlpath=shiny/Shiny-app/&#34;&gt;example&lt;/a&gt;) is the input reactivity (&lt;em&gt;back-end&lt;/em&gt;) it offers, allowing users to download sections of data they select, in various formats. Last, Flexdashboard-Shiny (&lt;a href=&#34;https://pablobernabeu.shinyapps.io/dutch-modality-exclusivity-norms/&#34;&gt;example&lt;/a&gt;) combines the best of both worlds.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
‚òÖ &lt;b&gt; Flexdashboard &lt;/b&gt; ‚òÖ
&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
‚òÖ ‚òÖ &lt;b&gt; Shiny &lt;/b&gt; ‚òÖ ‚òÖ
&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
‚òÖ ‚òÖ ‚òÖ &lt;b&gt; Flexdashboard-Shiny &lt;/b&gt; ‚òÖ ‚òÖ ‚òÖ
&lt;/p&gt;
&lt;p&gt;Flexdashboard types are rendered as an HTML document‚Äîsimple websites‚Äî, and can therefore be easily published on personal sites or &lt;a href=&#34;https://rpubs.com/&#34;&gt;RPubs&lt;/a&gt;. This is convenient because no special hosting is required. In contrast, Shiny and Flexdashboard-Shiny types offer greater features, but require Shiny servers. Fortunately, the shinyapps.io server is available for free, up to some &lt;a href=&#34;https://www.shinyapps.io/&#34;&gt;usage limit&lt;/a&gt;. This server can host any of the three dashboards mentioned here. Another good option is presented by Binder environments, which can host the Shiny-type dashboards with no (explicit) limit. Yet, the Flexdashboard-Shiny type cannot be hosted in this server (&lt;a href=&#34;https://github.com/jupyter/repo2docker/issues/799&#34;&gt;as of January 2020, at least&lt;/a&gt;). Consequently, greater functionality may come at a cost for dashboards that have any considerable traffic, whereas dashboards with low traffic may do well on shinyapps.io. Knowing these trade-offs can help navigate &lt;a href=&#34;https://support.rstudio.com/hc/en-us/articles/217592947-What-are-the-limits-of-the-shinyapps-io-Free-plan-&#34;&gt;usage limits&lt;/a&gt;, save on web hosting fees, and increase the availability of our dashboards online, as we can offer fall-back versions on different platforms, as in the example below:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚Ä¶ &lt;em&gt;&lt;a href=&#34;https://pablobernabeu.shinyapps.io/dutch-modality-exclusivity-norms/&#34;&gt;preferred-dashboard&lt;/a&gt; (in case of downtime, please visit this &lt;a href=&#34;http://rpubs.com/pcbernabeu/Dutch-modality-exclusivity-norms&#34;&gt;alternative&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Transforming dashboards into the different versions can be as easy as enabling or disabling some features, especially input reactivity. For instance, if we want to downgrade a Flexdashboard-Shiny to a Flexdashboard, to publish it outside of a Shiny server (see &lt;a href=&#34;https://github.com/pablobernabeu/Modality-exclusivity-norms-Bernabeu-et-al/blob/master/Dutch-modality-exclusivity-norms-RPubs.Rmd&#34;&gt;example&lt;/a&gt;), we must add a setting in the header of the script,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding) })&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and disable reactive features.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Number of words selected on sidebar
# reactive(cat(paste0(&amp;#39;Words selected below: &amp;#39;, nrow(selected_props()))))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;free-accounts-and-tips&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;Free accounts and tips&lt;/h5&gt;
&lt;p&gt;Hosting sites have specific terms of use. For instance, &lt;a href=&#34;https://www.shinyapps.io/&#34;&gt;shinyapps.io&lt;/a&gt; has a free starter license with limited use. Free apps can handle a large but limited amount of data, and up to five apps may be created. Beyond this, RStudio offers a wide range of subscriptions starting at $9/month.&lt;/p&gt;
&lt;p&gt;Memory and traffic limits of the free shinyapps.io account can sometimes present problems when heavy data data sets are used, or there are many visits to the app. The memory overload issue is often flagged as &lt;code&gt;Shiny cannot use on-disk bookmarking&lt;/code&gt;, whereas excessive traffic may see the app not loading. Fortunately, usage limits need not always require a paid subscription or a &lt;a href=&#34;https://www.r-bloggers.com/alternative-approaches-to-scaling-shiny-with-rstudio-shiny-server-shinyproxy-or-custom-architecture/&#34;&gt;custom server&lt;/a&gt;, thanks to the following workarounds:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;develop app locally as far as possible, and only deploy to shinyapps.io only at the last stage;&lt;/li&gt;
&lt;li&gt;prune data set, leaving only the necessary data;&lt;/li&gt;
&lt;li&gt;if necessary, unlink data by splitting it into different sets, reducing computational demands;&lt;/li&gt;
&lt;li&gt;if necessary, use various apps (five are allowed in each free shinyapps.io account);&lt;/li&gt;
&lt;li&gt;&lt;p&gt;if necessary, link from the app to a PDF with visualisations requiring heavy, interlinked data. High-resolution plots can be rendered into a PDF document in a snap, using code such as below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;df(&amp;#39;List of plots per page&amp;#39;, width = 13, height = 5)
print(plot1)
print(plot2)
# ...
print(plot150)
dev.off()&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Conveniently, all text in a PDF‚Äîeven in plots‚Äîis indexed, so it can be searched [ Ctrl+f / Cmd+f / üîç ] (see &lt;a href=&#34;https://osf.io/2tpxn/&#34;&gt;example&lt;/a&gt;). Furthermore, you may also &lt;a href=&#34;http://www.ilovepdf.com/&#34;&gt;merge the rendered PDF with any other documents&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;prerequisites-and-suggestions-for-participation-in-each-workshop&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Prerequisites and suggestions for participation in each workshop&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Necessary:&lt;/em&gt; laptop or computer with &lt;a href=&#34;https://www.r-project.org/&#34;&gt;R&lt;/a&gt; and &lt;a href=&#34;https://rstudio.com/products/rstudio/download/&#34;&gt;RStudio&lt;/a&gt; installed, or access to &lt;a href=&#34;https://rstudio.cloud/&#34;&gt;RStudio Cloud&lt;/a&gt;; familiarity with the content of the preceding workshops through the web links herein.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Suggested:&lt;/em&gt; having your own data and R code ready (on a Github repository if participating in Workshop 4); participation in some of the preceding workshops.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;datathons-creating-reproducible-documents-and-dashboards&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Datathons: creating reproducible documents and dashboards&lt;/h3&gt;
&lt;p&gt;In these coding meetups, participants collaborate to create reproducible documents or dashboards using the data and software they prefer (see &lt;a href=&#34;https://github.com/pablobernabeu/Data-is-present/tree/master/examples-documents-dashboards&#34;&gt;examples&lt;/a&gt;). Since the work can be split across different people and sections, some nice products may be achieved within a session. Any programming languages may be used.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data used:&lt;/strong&gt; academic or non-academic data of your own or from open-access sources such as &lt;a href=&#34;https://osf.io&#34;&gt;OSF&lt;/a&gt;, scientific journals, governments, international institutions, NGOs, etc.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Inspired by the great &lt;a href=&#34;https://reprohack.github.io/reprohack-hq/&#34;&gt;Reprohacks&lt;/a&gt;, content suggestions are encouraged. That is, if you‚Äôd like to have a reproducible document or dashboard created for a certain, open-access data set, please let us know, and some participants may take it on. Suggestions may be posted as &lt;a href=&#34;https://github.com/pablobernabeu/Data-is-present/issues&#34;&gt;issues&lt;/a&gt; or emailed to &lt;a href=&#34;mailto:p.bernabeu@lancaster.ac.uk&#34; class=&#34;email&#34;&gt;p.bernabeu@lancaster.ac.uk&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Purposes&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;collaborating to visualise data in novel ways using reproducible documents or interactive dashboards. For this purpose, participants sometimes draw on additional data to look at a bigger picture;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;reflecting on the process by reviewing the techniques applied and challenges encountered.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Output:&lt;/strong&gt; A key aspect of datathons is the creation of output. Documents and dashboards are (co-)authored by the participants who work on them, who can then publish them on their websites, or on &lt;a href=&#34;https://rpubs.com/&#34;&gt;RPubs&lt;/a&gt;, &lt;a href=&#34;https://mybinder.org/&#34;&gt;Binder&lt;/a&gt;, &lt;a href=&#34;https://www.shinyapps.io/&#34;&gt;Shinyapps&lt;/a&gt; or &lt;a href=&#34;https://rstudio.com/products/shiny/shiny-server/&#34;&gt;custom servers&lt;/a&gt;. Time constraints notwithstanding, a lot of this output may be very enticing for further development by the same participants, or even by other people if the code is shared online. Just like with data, an attribution licence can be attached to the code.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;prerequisites-and-suggestions-for-participation-in-datathons&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Prerequisites and suggestions for participation in datathons&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Necessary:&lt;/em&gt; basic knowledge of reproducible documents or dashboards.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Suggested:&lt;/em&gt; familiarity with the development of reproducible documents or dashboards; an idea about the data you‚Äôd like to work with and the kind of document or dashboard you want to create.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;contact&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Contact&lt;/h2&gt;
&lt;p&gt;Please submit any queries or requests by &lt;a href=&#34;https://github.com/pablobernabeu/Data-is-present/issues&#34;&gt;posting an issue&lt;/a&gt; or emailing &lt;a href=&#34;mailto:p.bernabeu@lancaster.ac.uk&#34; class=&#34;email&#34;&gt;p.bernabeu@lancaster.ac.uk&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Naive principal component analysis in R</title>
      <link>/2018/01/01/naive-principal-component-analysis-in-r/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>/2018/01/01/naive-principal-component-analysis-in-r/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Principal_component_analysis&#34;&gt;Principal Component Analysis (PCA)&lt;/a&gt; is a technique used to find the core components that underlie different variables. It comes in very useful whenever doubts arise about the true origin of three or more variables. There are two main methods for performing a PCA: naive or less naive. In the naive method, you first check some conditions in your data which will determine the essentials of the analysis. In the less-naive method, you set those yourself based on whatever prior information or purposes you had. The latter method is appropriate when you already have enough information about the intercorrelations, or when you are required to select a specific number of components. I will tackle the naive method, mainly by following the guidelines in &lt;a href=&#34;https://freethegeogbooks.files.wordpress.com/2016/08/book-for-r-language-stats.pdf&#34;&gt;Field, Miles, and Field (2012)&lt;/a&gt;, with updated code where necessary. A &lt;a href=&#34;https://freethegeogbooks.files.wordpress.com/2016/08/book-for-r-language-stats.pdf&#34;&gt;manual by Charles M. Friel&lt;/a&gt; (Sam Houston State University) was also useful.&lt;/p&gt;
&lt;p&gt;The ‚Äònaive‚Äô approach is characterized by a first stage that checks whether the PCA should actually be performed with your current variables, or if some should be removed. The variables that are accepted are taken to a second stage which identifies the number of principal components that seem to underlie your set of variables.&lt;/p&gt;
&lt;div id=&#34;stage-1.-determine-whether-pca-is-appropriate-at-all-considering-the-variables&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;STAGE 1. Determine whether PCA is appropriate at all, considering the variables&lt;/h4&gt;
&lt;p&gt;&lt;img style = &#34;float: right; margin-left: 30px;&#34; width = &#34;45%&#34; src=&#34;https://media-exp1.licdn.com/dms/image/C5612AQE7vLkOVSIaVQ/article-inline_image-shrink_1500_2232/0?e=1585785600&amp;v=beta&amp;t=ABp_9l8pA-tyTuMANjTv7nCBPKXSBTm4c8X3ocX7yYs&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Variables should be &lt;strong&gt;inter-correlated enough but not too much.&lt;/strong&gt; Field et al. (2012) provide some thresholds, suggesting that no variable should have many correlations below .30, or &lt;em&gt;any&lt;/em&gt; correlation at all above .90. Thus, in the example here, variable Q06 should probably be excluded from the PCA.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Bartlett‚Äôs test&lt;/strong&gt;, on the nature of the intercorrelations, should be significant. Significance suggests that the variables are not an ‚Äòidentity matrix‚Äô in which correlations are a sampling error.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;KMO&lt;/strong&gt; (Kaiser-Meyer-Olkin), a measure of sampling adequacy based on common variance (so similar purpose as Bartlett‚Äôs). As Field et al.¬†review, ‚Äòvalues between .5 and .7 are mediocre, values between .7 and .8 are good, values between .8 and .9 are great and values above .9 are superb‚Äô (p.¬†761). There‚Äôs a general score as well as one per variable. The general one will often be good, whereas the individual scores may more likely fail. Any variable with a score below .5 should probably be removed, and the test should be run again.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Determinant:&lt;/strong&gt; A formula about multicollinearity. The result should preferably fall below .00001.
Note that some of these tests are run on the dataframe and others on a correlation matrix of the data, as distinguished below.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;
# Necessary libraries
library(ltm)
library(lattice)
library(psych)
library(car)
library(pastecs)
library(scales)
library(ggplot2)
library(arules)
library(plyr)
library(Rmisc)
library(GPArotation)
library(gdata)
library(MASS)
library(qpcR)
library(dplyr)
library(gtools)
library(Hmisc)

# Select variables of interest for the PCA
dataset = mydata[, c(&amp;#39;select_var1&amp;#39;,&amp;#39;select_var1&amp;#39;,&amp;#39;select_var2&amp;#39;,&amp;#39;select_var3&amp;#39;,&amp;#39;select_var4&amp;#39;,&amp;#39;select_var5&amp;#39;,&amp;#39;select_var6&amp;#39;,&amp;#39;select_var7&amp;#39;)]

# Create matrix: some tests will require it
data_matrix = cor(dataset, use = &amp;#39;complete.obs&amp;#39;)

# See intercorrelations
round(data_matrix, 2)

# Bartlett&amp;#39;s
cortest.bartlett(dataset)

# KMO (Kaiser-Meyer-Olkin)
KMO(data_matrix)

# Determinant
det(data_matrix)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;stage-2.-identify-number-of-components-aka-factors&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;STAGE 2. Identify number of components (aka factors)&lt;/h4&gt;
&lt;p&gt;In this stage, principal components (formally called ‚Äòfactors‚Äô at this stage) are identified among the set of variables.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The identification is done through a basic, ‚Äòunrotated‚Äô PCA. The number of components set a priori must equal the number of variables that are being tested.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;# Start off with unrotated PCA

pc1 = psych::principal(dataset, nfactors = length(dataset), rotate=&amp;quot;none&amp;quot;)
pc1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Below is an example result:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Principal Components Analysis
## Call: psych::principal(r = eng_prop, nfactors = 3, rotate = &amp;quot;none&amp;quot;)
## Standardized loadings (pattern matrix) based upon correlation matrix
##           PC1   PC2  PC3 h2       u2 com
## Aud_eng -0.89  0.13 0.44  1 -2.2e-16 1.5
## Hap_eng  0.64  0.75 0.15  1  1.1e-16 2.0
## Vis_eng  0.81 -0.46 0.36  1 -4.4e-16 2.0
## 
##                        PC1  PC2  PC3
## SS loadings           1.87 0.79 0.34
## Proportion Var        0.62 0.26 0.11
## Cumulative Var        0.62 0.89 1.00
## Proportion Explained  0.62 0.26 0.11
## Cumulative Proportion 0.62 0.89 1.00
## 
## Mean item complexity =  1.9
## Test of the hypothesis that 3 components are sufficient.
## 
## The root mean square of the residuals (RMSR) is  0 
##  with the empirical chi square  0  with prob &amp;lt;  NA 
## 
## Fit based upon off diagonal values = 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Among the columns, there are first the correlations between variables and components, followed by a column (h2) with the &lt;strong&gt;‚Äòcommunalities‚Äô&lt;/strong&gt;. If less factors than variables had been selected, communality values would be below 1. Then there is the uniqueness column (u2): &lt;strong&gt;uniqueness&lt;/strong&gt; is equal to 1 minus the communality. Next is ‚Äòcom‚Äô, which reflects the &lt;strong&gt;complexity&lt;/strong&gt; with which a variable relates to the principal components. Those components are precisely found below. The first row contains the sums of squared loadings, or eigenvalues, namely, the total variance explained by each linear component. This value corresponds to the number of units explained out of all possible factors (which were three in the above example). The rows below all cut from the same cloth. &lt;em&gt;Proportion var&lt;/em&gt; = variance explained over a total of 1. This is the result of dividing the eigenvalue by the number of components. Multiply by 100 and you get the percentage of total variance explained, which becomes useful. In the example, 99% of the variance has been explained. Aside from the meddling maths, we should actually expect 100% there because the number of factors equaled the number of variables. &lt;em&gt;Cumulative var:&lt;/em&gt; variance added consecutively up to the last component. &lt;em&gt;Proportion explained:&lt;/em&gt; variance explained over what has actually been explained (only when variables = factors is this the same as Proportion var). &lt;em&gt;Cumulative proportion:&lt;/em&gt; the actually explained variance added consecutively up to the last component (Field et al., 2012).&lt;/p&gt;
&lt;p&gt;According to Field et al. (2012), two criteria will determine the number of components to select for the next stage:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kaiser‚Äôs criterion: components with SS loadings &amp;gt; 1. In our example, only PC1.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A more lenient alternative is Joliffe‚Äôs criterion, SS loadings &amp;gt; .7.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Scree plot: the number of points after point of inflexion. For this plot, call:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;plot(pc1$values, type = &amp;#39;b&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img style = &#34;float: right; margin-left: 30px;&#34; width = &#34;35%&#34; src=&#34;https://media-exp1.licdn.com/dms/image/C5612AQF7TVqF5FFS6Q/article-inline_image-shrink_1000_1488/0?e=1585785600&amp;v=beta&amp;t=bEdWqeoT08j0nSiERX2ZPAlEcyPjUhRsEiucZy3wvBM&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Imagine a straight line &lt;strong&gt;from the first point on the right.&lt;/strong&gt; Once this line bends considerably, count the points after the bend and up to the last point on the left. The number of points is the number of components to select. The example here is probably the most complicated (two components were finally chosen), but normally it‚Äôs &lt;a href=&#34;https://www.google.nl/search?q=select+principal+components+scree+plot+point+inflexion&amp;amp;source=lnms&amp;amp;tbm=isch&amp;amp;sa=X&amp;amp;ved=0ahUKEwi00ujoto_WAhXJbVAKHbTCBAgQ_AUICigB&amp;amp;biw=1280&amp;amp;bih=619&#34;&gt;not difficult&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Based on both criteria, go ahead and select the definitive number of components.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;stage-3.-run-definitive-pca&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;STAGE 3. Run definitive PCA&lt;/h4&gt;
&lt;p&gt;Run a very similar command as you did before, but now with a more advanced method. The first PCA, a heuristic one, worked essentially on the inter-correlations. The definitive PCA, in contrast, will implement a prior shuffling known as ‚Äòrotation‚Äô, to ensure that the result is robust enough (just like cards are shuffled). Explained variance is captured better this way. The go-to rotation method is the orthogonal, or ‚Äòvarimax‚Äô (though others may be considered too).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Now with varimax rotation, Kaiser-normalized by default:
pc2 = psych::principal(dataset, nfactors=2, rotate = &amp;quot;varimax&amp;quot;, 
scores = TRUE)
pc2
pc2$loadings

# Healthcheck
pc2$residual
pc2$fit
pc2$communality
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to Field et al. (2012), we would want:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Less than half of &lt;strong&gt;residuals&lt;/strong&gt; with absolute values &amp;gt; 0.05&lt;/li&gt;
&lt;li&gt;Model &lt;strong&gt;fit&lt;/strong&gt; &amp;gt; .9&lt;/li&gt;
&lt;li&gt;All &lt;strong&gt;communalities&lt;/strong&gt; &amp;gt; .7&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If any of this fails, consider changing the number of factors. Next, the rotated components that have been ‚Äòextracted‚Äô from the core of the set of variables can be added to the dataset. This would enable the use of these components as new variables that might prove powerful and useful (as in &lt;a href=&#34;http://onlinelibrary.wiley.com/doi/10.1111/j.1551-6709.2010.01157.x/full&#34;&gt;this research&lt;/a&gt;).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dataset = cbind(dataset, pc2$scores)
summary(dataset$RC1, dataset$RC2)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;stage-4.-determine-ascription-of-each-variable-to-components&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;STAGE 4. Determine ascription of each variable to components&lt;/h4&gt;
&lt;p&gt;&lt;img style = &#34;float: right; margin-left: 30px;&#34; width = &#34;55%&#34; src=&#34;https://media-exp1.licdn.com/dms/image/C5612AQH-p0mz8hnoqw/article-inline_image-shrink_1500_2232/0?e=1585785600&amp;v=beta&amp;t=TMS7L_jyaDzlTZ1nlxmJ5b_3CHbeIkKkQKerQww0DqA&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Check the main summary by just calling pc2, and see how each variable correlates with the rotated components. This is essential because it reveals how variables load on each component, or in other words, to which component a variable belongs. For instance, the table shown here belongs to a &lt;a href=&#34;https://www.linkedin.com/pulse/modality-exclusivity-norms-336-properties-411-dutch-english-bernabeu/?published=t&amp;amp;lipi=urn%3Ali%3Apage%3Ad_flagship3_pulse_read%3BRIskxEq5Rgq59xHemwzpdw%3D%3D&#34;&gt;study about meaning of words&lt;/a&gt;. These results suggest that the visual and haptic modalities of words are quite related, whereas the auditory modality is relatively unique. When the analysis works out well, a cut-off point of &lt;em&gt;r&lt;/em&gt; = .8 may be applied for considering a variable as part of a component.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;stage-5.-enjoy-the-plot&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;STAGE 5. Enjoy the plot&lt;/h4&gt;
&lt;p&gt;The plot is perhaps the coolest part about PCA. It really makes an awesome illustration of the power of data analysis.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ggplot(eng_props,
  aes(RC1, RC2, label = as.character(main_eng))) + stat_density2d (color = &amp;quot;gray87&amp;quot;) +
  geom_text(size = ifelse(eng_props$word_eng %in% w_set, 12, 7),
    fontface = ifelse(eng_props$word_eng %in% w_set, &amp;#39;bold&amp;#39;, &amp;#39;plain&amp;#39;)) +
  geom_point(data=eng_props[eng_props$word_eng %in% w_set,], pch=21, fill=NA, size=14, stroke=2, alpha=.6) +
  labs(subtitle=&amp;#39;(Data from Lynott &amp;amp; Connell, 2009)&amp;#39;, x = &amp;quot;Varimax-rotated Principal Component 1&amp;quot;, 
    y = &amp;quot;Varimax-rotated Principal Component 2&amp;quot;) +  theme_bw() +   
  theme( plot.background = element_blank(), panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(), panel.border = element_blank(),
    axis.line = element_line(color = &amp;#39;black&amp;#39;),
    axis.title.x = element_text(colour = &amp;#39;black&amp;#39;, size = 23, margin=margin(15,15,15,15)),
    axis.title.y = element_text(colour = &amp;#39;black&amp;#39;, size = 23, margin=margin(15,15,15,15)),
    axis.text.x = element_text(size=16), axis.text.y  = element_text(size=16),
    plot.title = element_text(hjust = 0.5, size = 32, face = &amp;quot;bold&amp;quot;, margin=margin(15,15,15,15)),
    plot.subtitle = element_text(hjust = 0.5, size = 20, margin=margin(2,15,15,15)) ) +
  geom_label_repel(data = eng_props[eng_props$word_eng %in% w_set,], aes(label = word_eng), size = 8, 
    alpha = 0.77, color = &amp;#39;black&amp;#39;, box.padding = 1.5 )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Below is an example combining PCA plots with code similar to the above. These plots illustrate something further with regard to the relationships among modalities. In property words, the different modalities spread out more clearly than they do in concept words. This makes sense because in language, properties define concepts (&lt;a href=&#34;https://www.linkedin.com/pulse/modality-exclusivity-norms-336-properties-411-dutch-english-bernabeu?published=t&amp;amp;lipi=urn%3Ali%3Apage%3Ad_flagship3_pulse_read%3BRIskxEq5Rgq59xHemwzpdw%3D%3D&#34;&gt;see more&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media-exp1.licdn.com/dms/image/C4D12AQF1aTAK4IAm9w/article-inline_image-shrink_1500_2232/0?e=1585785600&amp;amp;v=beta&amp;amp;t=3iXYQJBTSa0elkK9n0Qcnr9CzUt1xOySVsRqxp-XA9s&#34; /&gt;&lt;/p&gt;
&lt;p&gt;An example of these analyses is &lt;a href=&#34;https://mybinder.org/v2/gh/pablobernabeu/Modality-exclusivity-norms-747-Dutch-English-replication/master?urlpath=rstudio&#34;&gt;available in available in this RStudio environment&lt;/a&gt;, in the &lt;code&gt;norms.R&lt;/code&gt; script.&lt;/p&gt;
&lt;p&gt;References&lt;/p&gt;
&lt;div style=&#34;text-indent:-2em; margin-left:2em;&#34;&gt;
&lt;p&gt;Field, A. P., Miles, J., &amp;amp; Field, Z. (2012). &lt;em&gt;Discovering Statistics Using R&lt;/em&gt;. London, UK: Sage.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>At Greg, 8 am</title>
      <link>/2017/01/01/at-greg-8-am/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/2017/01/01/at-greg-8-am/</guid>
      <description>


&lt;p&gt;The clock strikes a certain hour, below all the Greg‚Äôs teaspoons at play. Results o‚Äôclock. The usual, please.&lt;/p&gt;
&lt;p&gt;Usual table. &lt;code&gt;summaryby&lt;/code&gt; (having to get the first peek in the cafeteria can only add zest). &lt;code&gt;summaryBy(RT ~ list(Ptp, Group, Cond), behdata, FUN=summary)&lt;/code&gt;. So, hardly any of the 95% Confidence Intervals contain 0. Does this really mean‚Ä¶?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ÄòFor example, the hypothesis of equality of population means will be rejected at the 0.05 level if and only if a 95% CI for the mean difference does not contain 0.‚Äô&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;‚Äî Dallal (2002; &lt;a href=&#34;http://www.jerrydallal.com/lhsp/pval.htm&#34; class=&#34;uri&#34;&gt;http://www.jerrydallal.com/lhsp/pval.htm&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Of course. The CI just has that and more. The window is showing a chilly 1999 morning. Let‚Äôs see the summary again. Wee standard deviations. By card, please.&lt;/p&gt;
&lt;p&gt;Mmm, the air outside is worth gingering up‚Ä¶&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The trials!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The assumption of independence spoils another morning.&lt;/p&gt;
&lt;p&gt;This new data consisted of response times (RT) that had been collected over several trials. The single dependent variable, RT, was accompanied by other variables which could be analyzed as independent variables. These included &lt;em&gt;Group&lt;/em&gt;, &lt;em&gt;Trial Number&lt;/em&gt;, and a within-subjects &lt;em&gt;Condition&lt;/em&gt;. &lt;strong&gt;What had to be done first off, in order to take the usual table?&lt;/strong&gt; &lt;em&gt;The trials!&lt;/em&gt;&lt;/p&gt;
&lt;div id=&#34;assumption-of-independence-of-observations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumption of independence of observations&lt;/h2&gt;
&lt;p&gt;One must account for any redundant measures below the level of participants (the experimental trials, in this case), so that the sample size (&lt;em&gt;N&lt;/em&gt;) used for any summary statistics match the number of participants (or the largest group, &lt;em&gt;n&lt;/em&gt;). Why? This is a &lt;a href=&#34;https://stats.stackexchange.com/questions/130019/standard-error-for-aggregated-proportions&#34;&gt;central assumption in statistics&lt;/a&gt;: observations must be independent. We can observe the independence assumption differently, depending on whether we‚Äôre summarizing data or performing statistical tests.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For &lt;em&gt;descriptive tables and plots&lt;/em&gt; (involving Standard Error/Deviation, Confidence Intervals, etc), &lt;em&gt;the data ought to be aggregated to the level from which you want to generalize&lt;/em&gt;. That level is‚Äîin this case and very often‚Äî&lt;em&gt;participants&lt;/em&gt;. Trials do not normally serve for statistical generalization (they‚Äôre good for experimental validity). This realization may come as a bummer if you have first seen the effect sizes in the un-aggregated data. The mirage (see red lines on the left table below) is caused by an inflated &lt;em&gt;N&lt;/em&gt; (cf.¬†red lines on the right-hand table). As an illustration, the tables below summarize data with an actual sample &lt;em&gt;n&lt;/em&gt; = 23. However, the table on the right includes repeated measures that should have been aggregated, massively inflating &lt;em&gt;n&lt;/em&gt;. The inflation of the sample size equals the product of all repeated measures that failed to be aggregated under participants.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;inflated.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img style = &#34;float: right; margin-left: 30px;&#34; width = &#39;30%&#39; src=&#39;SD.jpg&#39; /&gt;&lt;/p&gt;
&lt;p&gt;Measures of variance such as the Standard Deviation divide by the sample size. Thus, the larger the sample (N), the smaller the Standard Deviation, Standard Error, Confidence Interval‚Ä¶‚Äîthat is, the variation or noise.&lt;/p&gt;
&lt;p&gt;Aggregating is a snap. For example, with the aggregate() function in R, you just have to include all of your variables except that or those of the repeated measures:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;behdata_aggreg = aggregate(behdata$RT, list(behdata$Ptp, behdata$Group, behdata$Cond), 
  data=behdata, FUN=mean)&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;In statistical tests, repeated measures below the participant level‚Äìe.g., trials‚Äìnormally must be either factored in or aggregated. Barr and colleagues provide an easy, focused &lt;a href=&#34;http://talklab.psy.gla.ac.uk/simgen/faq.html#sec-3&#34;&gt;guide on this procedure&lt;/a&gt;. This is necessary because when the N in the analyses is augmented by unaccounted, redundant observations, &lt;em&gt;the famous assumption of independence of observations is violated&lt;/em&gt;, and the results may be invalid, as &lt;a href=&#34;https://arxiv.org/pdf/1601.01126.pdf&#34;&gt;Vasishth and Nicenboim (2016, p.¬†3)&lt;/a&gt; put it:&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;‚Äòif we were to do a t-test on the unaggregated data, we would violate the independence assumption and the result of the t-test would be invalid.‚Äô&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now, usually the repetitions that concern us are the multiple trials or items in experiments, or other sub-participant measures. So what about participants‚Äìwhat are they never aggregated? &lt;a href=&#34;http://tandfonline.com.sci-hub.cc/doi/abs/10.1080/01933922.2016.1264520?journalCode=usgw20&#34;&gt;McCarthy, Whittaker, Boyle, and Eyal (2017, p.10)&lt;/a&gt; note:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ÄòIt has also been proposed that researchers aggregate the responses of participants within the same group and use the groups/clusters as the unit of analysis (Stevens, 2007). However, because this would result in losing sample size at the participant level, this approach is not optimal given the already small numbers of groups typically studied in group work research.‚Äô&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;different-procedure-in-linear-mixed-effects-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Different procedure in linear mixed-effects models&lt;/h2&gt;
&lt;p&gt;Aggregation is no longer necessary, where linear mixed-effects models can be used. These models allow us to &lt;a href=&#34;http://talklab.psy.gla.ac.uk/simgen/faq.html#sec-3&#34;&gt;account for any clusters (Participants, Trials, Items‚Ä¶) by signing them into the error term&lt;/a&gt; (&lt;a href=&#34;https://psych.wisc.edu/Brauer/BrauerLab/wp-content/uploads/2014/04/Brauer_and_Curtin_LMEMs-2017-Psych_Methods.pdf&#34;&gt;Brauer &amp;amp; Curtin, 2017&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Dutch modality exclusivity norms</title>
      <link>/data-dashboards/bernabeu-etal-2017-modalitynorms/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/data-dashboards/bernabeu-etal-2017-modalitynorms/</guid>
      <description>&lt;a href=&#39;../../dashboards/Dutch-modality-exclusivity-norms/d.html&#39;&gt;
      &lt;button style = &#34;background-color: white; color: black; border: 2px solid #4CAF50; border-radius: 12px;&#34;&gt;
      &lt;h3 style = &#34;margin-top: 7px !important; margin-left: 9px !important; margin-right: 9px !important;&#34;&gt; 
      &lt;span style=&#34;color:#DBE6DA;&#34;&gt;&lt;i class=&#34;fas fa-mouse-pointer&#34;&gt;&lt;/i&gt;&lt;/span&gt;&amp;nbsp; Flexdashboard &lt;/h3&gt;&lt;/button&gt;&lt;/a&gt; &amp;nbsp; 
&lt;a href=&#39;https://pablobernabeu.shinyapps.io/Dutch-modality-exclusivity-norms&#39;&gt;
      &lt;button style = &#34;background-color: white; color: black; border: 2px solid #196F27; border-radius: 12px;&#34;&gt;
      &lt;h3 style = &#34;margin-top: 7px !important; margin-left: 9px !important; margin-right: 9px !important;&#34;&gt; 
      &lt;span style=&#34;color:#DBE6DA;&#34;&gt;&lt;i class=&#34;fas fa-mouse-pointer&#34;&gt;&lt;/i&gt;&lt;/span&gt;&amp;nbsp; Flexdashboard-Shiny &lt;/h3&gt;&lt;/button&gt;&lt;/a&gt;
&lt;br&gt;
&lt;br&gt;
&lt;p&gt;This Flexdashboard-Shiny app presents linguistic data over several tabs. The code combines the great front-end of Flexdashboard‚Äîbased on R Markdown and yielding an unmatched user interface‚Äî, with the great back-end of Shiny‚Äîallowing users to download sections of data they select, in various formats.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A cool, recent finding was the reactable package, which puts Javascript into the cells, allowing coloured bars, etc.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  
Auditory = colDef(header = with_tooltip(&#39;Auditory Rating&#39;,
                                        &#39;Mean rating of each word on the auditory modality across participants.&#39;),
                  cell = function(value) {
                    width &amp;lt;- paste0(value / max(table_data$Auditory) * 100, &amp;quot;%&amp;quot;)
                    value = sprintf(&amp;quot;%.2f&amp;quot;, round(value,2))  # Round to two digits, keeping trailing zeros
                    bar_chart(value, width = width, fill = &#39;#ff3030&#39;)
                    },
                  align = &#39;left&#39;),
  
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;One of the hardest nuts to crack was allowing the full functionality of tables‚Äîi.e, scaling to screen, frozen header, and vertical and horizontal scrolling‚Äîwhilst having tweaked the vertical/horizontal orientation of the dashboard sections. Initial clashes were sorted by adjusting the section&amp;rsquo;s CSS styles&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Table {#table style=&amp;quot;background-color:#FCFCFC;&amp;quot;}
=======================================================================
  
Inputs {.sidebar style=&#39;position:fixed; padding-top: 65px; padding-bottom:30px;&#39;}
-----------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and by also adjusting the reactable settings.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  
renderReactable({
  reactable(selected_words(),
            defaultSorted = list(cat = &#39;desc&#39;, word = &#39;asc&#39;),
            defaultColDef = colDef(footerStyle = list(fontWeight = &amp;quot;bold&amp;quot;)),
            height = 840, striped = TRUE, pagination = FALSE, highlight = TRUE,
  
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A nice feature, especially suited to Flexdashboard, was the use of different formats across tabs. Whereas the Info tab presents long text using HTML and CSS styling, along with rmarkdown code output, the other tabs rely more strongly on Javascript features, enabled by R packages such as ‚Äòshiny‚Äô and sweetalert (e.g., allowing modal dialogs‚Äîpop-ups), reactable and plotly (e.g., allowing information opened by hovering‚Äîtooltips).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```{r}
  
# reactive for the word bar
highlighted_properties = reactive(input$highlighted_properties)
  
renderPlotly({
 ggplotly(
  ggplot( selected_props(), aes(RC1, RC2, label = as.character(word), color = main, 
    # Html tags below used for format. Decimals rounded to two.
    text = paste0(&#39; &#39;, &#39;&amp;lt;span style=&amp;quot;padding-top:3px; padding-bottom:3px; font-size:2.2em; color:#EEEEEE&amp;quot;&amp;gt;&#39;, capitalize(word), &#39;&amp;lt;/span&amp;gt; &#39;, &#39;&amp;lt;br&amp;gt;&#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Dominant modality: &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, main, &#39; &#39;,
     &#39; &#39;, &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Modality exclusivity: &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, sprintf(&amp;quot;%.2f&amp;quot;, round(Exclusivity, 2)), &#39;% &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Perceptual strength: &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, sprintf(&amp;quot;%.2f&amp;quot;, round(Perceptualstrength, 2)),
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Auditory rating: &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, sprintf(&amp;quot;%.2f&amp;quot;, round(Auditory, 2)), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Haptic rating: &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, sprintf(&amp;quot;%.2f&amp;quot;, round(Haptic, 2)), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Visual rating: &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, sprintf(&amp;quot;%.2f&amp;quot;, round(Visual, 2)), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Concreteness (Brysbaert et al., 2014): &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, 
       sprintf(&amp;quot;%.2f&amp;quot;, round(concrete_Brysbaertetal2014, 2)), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Number of letters: &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, letters, &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Number of phonemes (DutchPOND): &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, 
     round(phonemes_DUTCHPOND, 2), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Contextual diversity (lg10CD SUBTLEX-NL): &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;,
       sprintf(&amp;quot;%.2f&amp;quot;, round(freq_lg10CD_SUBTLEXNL, 2)), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Word frequency (lg10WF SUBTLEX-NL): &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;,
       sprintf(&amp;quot;%.2f&amp;quot;, round(freq_lg10WF_SUBTLEXNL, 2)), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Lemma frequency (CELEX): &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, 
       sprintf(&amp;quot;%.2f&amp;quot;, round(freq_CELEX_lem, 2)), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Phonological neighbourhood size (DutchPOND): &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, 
     round(phon_neighbours_DUTCHPOND, 2), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Orthographic neighbourhood size (DutchPOND): &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;,
     round(orth_neighbours_DUTCHPOND, 2), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Age of acquisition (Brysbaert et al., 2014): &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;,
     sprintf(&amp;quot;%.2f&amp;quot;, round(AoA_Brysbaertetal2014, 2)), &#39; &#39;, &#39;&amp;lt;br&amp;gt; &#39;
     ) ) ) +
  geom_text(size = ifelse(selected_props()$word %in% highlighted_properties(), 7,
             ifelse(is.null(highlighted_properties()), 3, 2.8)),
      fontface = ifelse(selected_props()$word %in% highlighted_properties(), &#39;bold&#39;, &#39;plain&#39;)) +
geom_point(alpha = 0) +  # This geom_point helps to colour the tooltip according to the dominant modality
scale_colour_manual(values = colours, drop = FALSE) + theme_bw() + ggtitle(&#39;Property words&#39;) +
labs(x = &#39;Varimax-rotated Principal Component 1&#39;, y = &#39;Varimax-rotated Principal Component 2&#39;) +
guides(color = guide_legend(title = &#39;Main&amp;lt;br&amp;gt;modality&#39;)) +
theme( plot.background = element_blank(), panel.grid.major = element_blank(),
   panel.grid.minor = element_blank(), panel.border = element_blank(),
   axis.line = element_line(color = &#39;black&#39;), plot.title = element_text(size = 14, hjust = .5),
   axis.title.x = element_text(colour = &#39;black&#39;, size = 12, margin = margin(15,15,0,15)),
   axis.title.y = element_text(colour = &#39;black&#39;, size = 12, margin = margin(0,15,15,5)),
   axis.text.x = element_text(size = 8), axis.text.y  = element_text(size = 8),
   legend.background = element_rect(size = 2), legend.position = &#39;none&#39;,
 legend.title = element_blank(),
 legend.text = element_text(colour = colours, size = 13) ),
tooltip = &#39;text&#39;
)
})
  
# For download, save plot without the interactive &#39;plotly&#39; part
  
properties_png = reactive({ ggplot(selected_props(), aes(RC1, RC2, color = main, label = as.character(word))) +
geom_text(show.legend = FALSE, size = ifelse(selected_props()$word %in% highlighted_properties(), 7,
         ifelse(is.null(highlighted_properties()), 3, 2.8)),
      fontface = ifelse(selected_props()$word %in% highlighted_properties(), &#39;bold&#39;, &#39;plain&#39;)) +
geom_point(alpha = 0) + scale_colour_manual(values = colours, drop = FALSE) + theme_bw() +
guides(color = guide_legend(title = &#39;Main&amp;lt;br&amp;gt;modality&#39;, override.aes = list(size = 7, alpha = 1))) +
ggtitle( paste0(&#39;Properties&#39;, &#39; (showing &#39;, nrow(selected_props()), &#39; out of &#39;, nrow(props), &#39;)&#39;) ) + 
labs(x = &#39;Varimax-rotated Principal Component 1&#39;, y = &#39;Varimax-rotated Principal Component 2&#39;) +
theme( plot.background = element_blank(), panel.grid.major = element_blank(),
   panel.grid.minor = element_blank(), panel.border = element_blank(),
   axis.line = element_line(color = &#39;black&#39;), plot.title = element_text(size = 17, hjust = .5, margin = margin(3,3,7,3)),
   axis.title.x = element_text(colour = &#39;black&#39;, size = 12, margin = margin(10,10,2,10)),
   axis.title.y = element_text(colour = &#39;black&#39;, size = 12, margin = margin(10,10,10,5)),
   axis.text.x = element_text(size = 8), axis.text.y  = element_text(size = 8),
   legend.background = element_rect(size = 2), legend.position = &#39;right&#39;,
   legend.title = element_blank(), legend.text = element_text(size = 15))
})
  
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The only instance in which I drew on javascript code outside R packages was to enable tooltips beyond the packages‚Äô limits‚Äîfor instance, in the side bar. This javascript feature is created at the top of the script, in the head area.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;!-- Javascript function to enable a hovering tooltip --&amp;gt;
&amp;lt;script&amp;gt;
$(document).ready(function(){
   $(&#39;[data-toggle=&amp;quot;tooltip1&amp;quot;]&#39;).tooltip();
});
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the side bar, I added a reactive mean for each variable, complementing the range selector.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;reactive(cat(paste0(&#39;Mean = &#39;, 
  sprintf(&amp;quot;%.2f&amp;quot;, round(mean(selected_words()$Exclusivity),2)))))
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;non-shiny-version-published-in-rpubs&#34;&gt;Non-Shiny version published in RPubs&lt;/h2&gt;
&lt;p&gt;A reduced, non-Shiny version was also created to increase the availability of the content. Removing Shiny features allows publication as a simple website. To create the Flexdashboard-only version departing from the Flexdashboard-Shiny version, I added a setting in the header of the script&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding) })
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and disabled reactive features.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```{r}
# Number of words selected on sidebar
# reactive(cat(paste0(&#39;Words selected below: &#39;, nrow(selected_props()))))
```
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;div style = &#34;text-indent:-2em; margin-left:2em;&#34;&gt;
&lt;p&gt;Bernabeu, P., Willems, R. M., &amp;amp; Louwerse, M. M. (2017). Modality switch effects emerge early and increase throughout conceptual processing: Evidence from ERPs [Data dashboard for modality exclusivity norms]. Retrieved from &lt;a href=&#34;https://pablobernabeu.shinyapps.io/ERP-waveform-visualization_CMS-experiment/&#34;&gt;https://pablobernabeu.shinyapps.io/ERP-waveform-visualization_CMS-experiment/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Modality switch effects emerge early and increase throughout conceptual processing: evidence from ERPs [Blog]</title>
      <link>/2017/01/01/modality-switch-effects-emerge-early-and-increase-throughout-conceptual-processing-evidence-from-erps/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/2017/01/01/modality-switch-effects-emerge-early-and-increase-throughout-conceptual-processing-evidence-from-erps/</guid>
      <description>&lt;p&gt;Research has extensively investigated whether conceptual processing is modality-specific‚Äîthat is, whether meaning is processed to a large extent on the basis of perceptual and motor affordances (Barsalou, 2016). This possibility challenges long-established theories. It suggests a strong link between physical experience and language which is not borne out of the paradigmatic arbitrariness of words (see Lockwood, Dingemanse, &amp;amp; Hagoort, 2016). Modality-specificity also clashes with models of language that have no link to sensory and motor systems (Barsalou, 2016).&lt;/p&gt;
&lt;a href=&#39;https://psyarxiv.com/a5pcz/download&#39;&gt;
      &lt;button style = &#34;background-color: white; color: black; border: 2px solid #4CAF50; border-radius: 12px;&#34;&gt;
      &lt;h3 style = &#34;margin-top: 7px !important; margin-left: 9px !important; margin-right: 9px !important;&#34;&gt; 
      &lt;span style=&#34;color:#DBE6DA;&#34;&gt;&lt;i class=&#34;fas fa-mouse-pointer&#34;&gt;&lt;/i&gt;&lt;/span&gt;&amp;nbsp; Article &lt;/h3&gt;&lt;/button&gt;&lt;/a&gt; &amp;nbsp; 
&lt;a href=&#39;https://psyarxiv.com/5gjvk/download&#39;&gt;
      &lt;button style = &#34;background-color: white; color: black; border: 2px solid #196F27; border-radius: 12px;&#34;&gt;
      &lt;h3 style = &#34;margin-top: 7px !important; margin-left: 9px !important; margin-right: 9px !important;&#34;&gt; 
      &lt;span style=&#34;color:#DBE6DA;&#34;&gt;&lt;i class=&#34;fas fa-mouse-pointer&#34;&gt;&lt;/i&gt;&lt;/span&gt;&amp;nbsp; Thesis &lt;/h3&gt;&lt;/button&gt;&lt;/a&gt; &amp;nbsp; 
&lt;br&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.researchgate.net/post/Conceptual_modality_switch_effect_measured_at_first_word&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Early discussion on ResearchGate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://osf.io/97unm/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Data and code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://mybinder.org/v2/gh/pablobernabeu/Modality-switch-effects-emerge-early-and-increase-throughout-conceptual-processing/master?urlpath=rstudio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Analysis environment in RStudio&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the Conceptual Modality Switch (CMS) paradigm, participants perform a property verification task, deciding whether certain property words can reasonably describe concept words. Covertly, the conceptual modality of consecutive trials is manipulated in order to produce specific switches in conceptual modality. For instance, after the trial &lt;em&gt;Soundless Answer&lt;/em&gt;, which is primarily auditory, the following trial may match in modality‚Äî&lt;em&gt;Loud Welcome&lt;/em&gt;‚Äîor mismatch‚Äî&lt;em&gt;Fine Selection&lt;/em&gt; (visual).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;designoverview.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Modality switches incur processing costs, as reflected in brain signals linked to semantic violation, and in longer response times (RTs) (Scerrati, Lugli, Nicoletti, &amp;amp; Borghi, 2016). This effect suggests that perceptual features of concepts are accessed during conceptual processing. More recently, however, the CMS effect was reanalysed using a non-perceptual alternative. Louwerse and Connell (2011) found that language statistics (the co-occurrence of words in a language) were able to approximately predict visual/haptic, olfactory/gustatory, and auditory modalities, but not the subtler differences between visual and haptic and between olfactory and gustatory, which seemed to be reserved for perceptual simulations. Moreover, faster response times (RTs) were best explained by language statistics, whereas slower RTs were best explained by perceptual simulations.&lt;/p&gt;
&lt;p&gt;The time course of word processing is important. Research suggests that word processing spans one second, during which different processes‚Äîsemantic and post-semantic‚Äîgradually accumulate (Hauk, 2016). The later an effect, the more reasons to question it. Yet, having an early emergence does not either make an effect lexicosemantic, as the meaning encoded could have gone through working memory before activating the actual system of interest, e.g., sensorimotor (Mahon &amp;amp; Caramazza, 2008). Research also suggests that modal systems may contribute to conceptual processing early on‚Äîwithin 200 ms (Vukovic, Feurra, Shpektor, Myachykov, &amp;amp; Shtyrov, 2017). Thus, measuring effects online may prove valuable.&lt;/p&gt;
&lt;h2 id=&#34;experiment&#34;&gt;Experiment&lt;/h2&gt;
&lt;p&gt;Bernabeu, Willems and Louwerse (2017) investigated whether CMS reflects a functionally relevant process of simulation or instead arises only after basic conceptual processing has been attained. We also examined whether different processing systems, amodal and modal, may compatibly operate.&lt;/p&gt;
&lt;p&gt;We measured CMS online by time-locking Event-Related brain Potentials (ERPs) to the onset of the first word in the target trials, in order to assess how strongly CMS may be influenced by post-semantic processes. Previous research would predict an increase in the CMS effect over time because earlier processing is relatively amodal (Louwerse &amp;amp; Hutchinson, 2012).&lt;/p&gt;
&lt;p&gt;We tested the compatibility of amodal and modal processing by drawing on Louwerse and Connell‚Äôs (2011) findings. In this conceptual replication, we split participants into a Quick and a Slow group based on RT. Maintaining CMS as a within-subjects factor, we predicted that the larger modality switches (e.g., auditory to visual) would be picked up equally by both groups, whereas the subtler switches (e.g., haptic to visual) would be picked up only‚Äîor more clearly‚Äîby the Slow group.&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;p&gt;The stimuli were normed (Bernabeu, Louwerse, &amp;amp; Willems, in prep.). Three CMS conditions were created‚ÄîAuditory-to-visual, Haptic-to-visual, Visual-to-visual‚Äî, each with 36 target trials. The property verification task was pretested valid (&lt;em&gt;N&lt;/em&gt; = 19).&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;All participants but one responded correctly to over half of the trials, with an overall accuracy of 63%.&lt;/p&gt;
&lt;p&gt;ERPs showed a CMS effect from time window 1 on, larger after 350 ms. It appeared with both switch conditions, and was characterized by a more negative amplitude for the switch conditions compared to the no-switch condition. It was generally stronger in the posterior brain regions, and in the Slow group. The results are illustrated in the figure below, which includes 95% Confidence Intervals and time windows.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;stackERPs.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img style = &#34;float: right; margin-left: 30px;&#34; width = &#39;50%&#39; src=&#39;results.jpg&#39; /&gt;&lt;/p&gt;
&lt;p&gt;The analysis was done with Linear Mixed Effects models. Final models presented good fits, with R&lt;sup&gt;2&lt;/sup&gt; ranging from .748 to .862. First, the CMS effect in time window 1 was confirmed significant. Such an early emergence is unprecedented in the CMS literature, and it may have been enabled by the time-locking of ERPs to the first word in target trials. In this time window, the only process not lexicosemantic is possibly working memory (Hauk, 2016), and therefore this early emergence adds support to the possibility that CMS was directly caused by perceptual simulation.&lt;/p&gt;
&lt;p&gt;Whereas, in time window 1, the effect was circumscribed to an interaction with Brain Area, by time window 2 a main effect of CMS emerged, and in windows 3 and 4 the only critical effect was CMS.&lt;/p&gt;
&lt;p&gt;Bonferroni-corrected, planned ANOVA contrasts into CMS conditions revealed that the no-switch condition differed significantly from the switch conditions. By contrast, the switch conditions (Haptic-to-visual and Auditory-to-visual) hardly differed from each other, underscoring the CMS effect.&lt;/p&gt;
&lt;p&gt;Although the interaction of Group and CMS was only significant in time windows 1 and 2, windows 2 to 4 presented a pattern fitting our predictions (Louwerse &amp;amp; Connell, 2011). While the Slow group picked up the switches across all modalities similarly, the Quick group picked up the Auditory-to-visual switch more clearly than the Haptic-to-visual switch.&lt;/p&gt;
&lt;h2 id=&#34;discussion&#34;&gt;Discussion&lt;/h2&gt;
&lt;p&gt;Results broadly suggest that cognition may operate on qualitatively different systems for the same task. In conceptual processing, one of these systems appears to be modality-independent, potentially based on linguistic co-occurrences, whereas another system is modality-specific, linked to physical experience.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;div style = &#34;text-indent:-2em; margin-left:2em;&#34;&gt;
&lt;p&gt;Barsalou, L. W. (2016). On staying grounded and avoiding quixotic dead ends. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review, 23&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Bernabeu, P., Louwerse, M. M., &amp;amp; Willems, R. M. (in prep.). Modality exclusivity norms for 747 properties and concepts in Dutch: a replication of English. Retrieved from &lt;a href=&#34;https://osf.io/brkjw/&#34;&gt;https://osf.io/brkjw/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bernabeu, P., Willems, R. M., &amp;amp; Louwerse, M. M. (2017). Modality switch effects emerge early and increase throughout conceptual processing: Evidence from ERPs. In G. Gunzelmann, A. Howes, T. Tenbrink, &amp;amp; E. J. Davelaar (Eds.), Proceedings of the 39th Annual Conference of the Cognitive Science Society (pp. 1629-1634). Austin, TX: Cognitive Science Society.&lt;/p&gt;
&lt;p&gt;Hauk, O. (2016). Only time will tell‚ÄîWhy temporal information is essential for our neuroscientific understanding of semantics. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review, 23&lt;/em&gt;, 4, 1072-1079.&lt;/p&gt;
&lt;p&gt;Lockwood, G., Hagoort, P., &amp;amp; Dingemanse, M. (2016). How iconicity helps people learn new words: neural correlates and individual differences in sound-symbolic bootstrapping. &lt;em&gt;Collabra, 2&lt;/em&gt;, 1, 7.&lt;/p&gt;
&lt;p&gt;Louwerse, M., &amp;amp; Connell, L. (2011). A taste of words: linguistic context and perceptual simulation predict the modality of words. &lt;em&gt;Cognitive Science, 35&lt;/em&gt;, 2, 381-98.&lt;/p&gt;
&lt;p&gt;Louwerse, M., &amp;amp; Hutchinson, S. (2012). Neurological evidence linguistic processes precede perceptual simulation in conceptual processing. &lt;em&gt;Frontiers in Psychology, 3&lt;/em&gt;, 385.&lt;/p&gt;
&lt;p&gt;Mahon, B. Z., &amp;amp; Caramazza, A. (2008). A critical look at the Embodied Cognition Hypothesis and a new proposal for grounding conceptual content. &lt;em&gt;Journal of Physiology - Paris, 102&lt;/em&gt;, 59-70.&lt;/p&gt;
&lt;p&gt;Scerrati, E., Lugli, L., Nicoletti, R., &amp;amp; Borghi, A. M. (2016). The Multilevel Modality-Switch Effect: What Happens When We See the Bees Buzzing and Hear the Diamonds Glistening. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, doi:10.3758/s13423-016-1150-2.&lt;/p&gt;
&lt;p&gt;Vukovic, V., Feurra, M., Shpektor, A., Myachykov, A., &amp;amp; Shtyrov, Y. (2017). Primary motor cortex functionally contributes to language comprehension: An online rTMS study. &lt;em&gt;Neuropsychologia, 96&lt;/em&gt;, 222-229.&lt;/p&gt;
&lt;/div&gt;
&lt;h3 id=&#34;bonus-a-conference-poster-with-a-few-further-analyses&#34;&gt;Bonus: A conference poster with a few further analyses&lt;/h3&gt;
&lt;p&gt;
&lt;a href=&#34;http://www.researchgate.net/publication/318542811_Poster_Modality_switch_effects_emerge_early_and_increase_throughout_conceptual_processing_Evidence_from_ERPs?ev=prf_ov_fet_res&amp;amp;_iepl%5BviewId%5D=e31Maxb6SKANvzfuN34ZwpgC9bmvI6w5TsJY&amp;amp;_iepl%5Bcontexts%5D%5B0%5D=prfhpi&amp;amp;_iepl%5Bdata%5D%5BstandardItemCount%5D=1&amp;amp;_iepl%5Bdata%5D%5BuserSelectedItemCount%5D=2&amp;amp;_iepl%5Bdata%5D%5BtopHighlightCount%5D=1&amp;amp;_iepl%5Bdata%5D%5BstandardItemIndex%5D=1&amp;amp;_iepl%5Bdata%5D%5BstandardItem1of1%5D=1&amp;amp;_iepl%5BtargetEntityId%5D=PB%3A318542811&amp;amp;_iepl%5BinteractionType%5D=publicationTitle&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;poster.jpg&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Modality switch effects emerge early and increase throughout conceptual processing: evidence from ERPs [Paper]</title>
      <link>/publication/bernabeu-etal-2017/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/publication/bernabeu-etal-2017/</guid>
      <description>&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;div style = &#34;text-indent:-2em; margin-left:2em;&#34;&gt;
&lt;p&gt;Bernabeu, P., Willems, R. M., &amp;amp; Louwerse, M. M. (2017). Modality switch effects emerge early and increase throughout conceptual processing: Evidence from ERPs. In G. Gunzelmann, A. Howes, T. Tenbrink, &amp;amp; E. J. Davelaar (Eds.), &lt;em&gt;Proceedings of the 39th Annual Conference of the Cognitive Science Society&lt;/em&gt; (pp. 1629-1634). Austin, TX: Cognitive Science Society. &lt;a href=&#34;https://mindmodeling.org/cogsci2017/papers/0318/&#34;&gt;https://mindmodeling.org/cogsci2017/papers/0318/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
