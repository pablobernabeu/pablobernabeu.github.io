<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>linguistics | Pablo Bernabeu</title>
    <link>https://pablobernabeu.github.io/tags/linguistics/</link>
      <atom:link href="https://pablobernabeu.github.io/tags/linguistics/index.xml" rel="self" type="application/rss+xml" />
    <description>linguistics</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-uk</language><copyright>Pablo Bernabeu, 2015—2026. Licence: [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/). Email: pcbernabeu@gmail.com. Cookies only used by third-party systems such as [Disqus](https://help.disqus.com/en/articles/1717155-use-of-cookies).</copyright><lastBuildDate>Fri, 28 Mar 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://pablobernabeu.github.io/img/default_preview_image.png</url>
      <title>linguistics</title>
      <link>https://pablobernabeu.github.io/tags/linguistics/</link>
    </image>
    
    <item>
      <title>Prototype workflow for semi-automatic processing of speech and co-speech gestures</title>
      <link>https://pablobernabeu.github.io/2025/prototype-workflow-for-semi-automatic-processing-of-speech-and-cospeech-gestures/</link>
      <pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/2025/prototype-workflow-for-semi-automatic-processing-of-speech-and-cospeech-gestures/</guid>
      <description>


&lt;div id=&#34;integrating-speech-and-gesture-processing-for-linguistic-analysis-using-python&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Integrating Speech and Gesture Processing for Linguistic Analysis using Python&lt;/h2&gt;
&lt;p&gt;Understanding the interplay between speech and gesture is crucial for linguistic and cognitive research. The current prototype, available &lt;a href=&#34;https://github.com/pablobernabeu/prototype-process-pronouns-gestures&#34;&gt;on GitHub&lt;/a&gt;, aims to automate the analysis of temporal alignment between spoken demonstrative pronouns and pointing gestures in video recordings. By integrating computer vision (via Google’s &lt;a href=&#34;https://ai.google.dev/edge/mediapipe/solutions/guide&#34;&gt;MediaPipe&lt;/a&gt;) and speech recognition (using &lt;a href=&#34;https://alphacephei.com/vosk/models&#34;&gt;language-specific Vosk models&lt;/a&gt;) using Python, the workflow provides enriched video annotations and alignment data, offering valuable insights into deictic communication.&lt;/p&gt;
&lt;p&gt;For reference, the GitHub repository includes an &lt;a href=&#34;https://github.com/pablobernabeu/prototype-process-pronouns-gestures/blob/main/ELAN&#34;&gt;&lt;em&gt;ELAN&lt;/em&gt; folder&lt;/a&gt; containing output from a traditional annotation process using the &lt;a href=&#34;https://archive.mpi.nl/tla/elan&#34;&gt;ELAN program&lt;/a&gt;. Ultimately, the performance of the semi-automated prototype must be validated against manual annotations created using ELAN or a similar program. For reference, below is a plot of manually-annotated data for the alignment between demonstrative pronouns and pointing gestures (see &lt;a href=&#34;https://github.com/pablobernabeu/prototype-process-pronouns-gestures/blob/main/ELAN/plot_alignment.R&#34;&gt;R code for the plot&lt;/a&gt;).&lt;/p&gt;
&lt;div style=&#34;margin-top: 4%;&#34;&gt;

&lt;/div&gt;
&lt;p&gt;&lt;img src=&#39;https://github.com/pablobernabeu/prototype-process-pronouns-gestures/blob/main/ELAN/plots/1_scatterplot.png?raw=true&#39; alt=&#39;Plot of manually-annotated data for the alignment between demonstrative pronouns and pointing gestures.&#39; style=&#39;margin-top:2px;&#39;&gt;&lt;/img&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-it-works-running-the-program&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How It Works: Running the Program&lt;/h2&gt;
&lt;p&gt;The prototype system, which is available &lt;a href=&#34;https://github.com/pablobernabeu/prototype-process-pronouns-gestures&#34;&gt;on GitHub&lt;/a&gt;, requires primary data in the form of video and corresponding audio files, which should be placed in &lt;code&gt;mnt/primary data&lt;/code&gt;. They video-audio pairs should be named in the same way (e.g., &lt;code&gt;1.mp4&lt;/code&gt; and &lt;code&gt;1.wav&lt;/code&gt;). The video should feature a person in a medium or medium close-up shot.&lt;/p&gt;
&lt;p&gt;Running the following command initiates the processing pipeline:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python main.py --audio_folder &amp;quot;mnt/primary data/audio&amp;quot; \
               --video_folder &amp;quot;mnt/primary data/video&amp;quot; \
               --model &amp;quot;mnt/primary data/vosk-model-de-0.21&amp;quot; \
               --words_of_interest &amp;quot;der,die,das,den,dem,denen,dessen,deren,dieser,diese,dieses,diesen,diesem&amp;quot; \
               --output &amp;quot;mnt/output&amp;quot; \
               --max_time_diff 800&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command processes the data and stores results in the designated output directory.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;breaking-down-the-processing-pipeline&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Breaking Down the Processing Pipeline&lt;/h2&gt;
&lt;div id=&#34;audio-transcription-and-word-onset-extraction-audio_processing.py&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;1. Audio Transcription and Word Onset Extraction (&lt;a href=&#34;https://github.com/pablobernabeu/prototype-process-pronouns-gestures/blob/main/audio_processing.py&#34;&gt;&lt;code&gt;audio_processing.py&lt;/code&gt;&lt;/a&gt;)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The speech recognition model transcribes spoken content and identifies demonstrative pronouns from a predefined list.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Onset times of these pronouns are extracted to facilitate alignment analysis.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Outputs include a plain text transcript and a WebVTT subtitle file.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;script-container&#34; data-src=&#34;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Fprototype-process-pronouns-gestures%2Fblob%2Fmain%2Faudio_processing.py&amp;amp;style=a11y-dark&amp;amp;type=code&amp;amp;showFullPath=on&amp;amp;showCopy=on&amp;amp;showLineNumbers=on&amp;amp;showFileMeta=on&#34;&gt;
&lt;button class=&#34;toggle-script&#34;&gt;Show script&lt;/button&gt;
&lt;div class=&#34;script-wrapper&#34;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;gesture-detection-video_processing.py&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;2. Gesture Detection (&lt;a href=&#34;https://github.com/pablobernabeu/prototype-process-pronouns-gestures/blob/main/video_processing.py&#34;&gt;&lt;code&gt;video_processing.py&lt;/code&gt;&lt;/a&gt;)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://ai.google.dev/edge/mediapipe/solutions/vision/hand_landmarker&#34;&gt;MediaPipe’s hand landmark estimation&lt;/a&gt; detects pointing gestures based on the position of the wrist (landmark &lt;code&gt;0&lt;/code&gt;) and the tip of the index finger (landmark &lt;code&gt;8&lt;/code&gt;). The &lt;a href=&#34;https://mediapipe-studio.webapps.google.com/demo/hand_landmarker&#34;&gt;online demonstration&lt;/a&gt; is worth a check.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A pointing gesture is recognised at the moment when these landmarks are maximally distant from each other.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;script-container&#34; data-src=&#34;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Fprototype-process-pronouns-gestures%2Fblob%2Fmain%2Fvideo_processing.py&amp;amp;style=a11y-dark&amp;amp;type=code&amp;amp;showFullPath=on&amp;amp;showCopy=on&amp;amp;showLineNumbers=on&amp;amp;showFileMeta=on&#34;&gt;
&lt;button class=&#34;toggle-script&#34;&gt;Show script&lt;/button&gt;
&lt;div class=&#34;script-wrapper&#34;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;alignment-analysis-alignment_analysis.py&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;3. Alignment Analysis (&lt;a href=&#34;https://github.com/pablobernabeu/prototype-process-pronouns-gestures/blob/main/alignment_analysis.py&#34;&gt;&lt;code&gt;alignment_analysis.py&lt;/code&gt;&lt;/a&gt;)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The extracted demonstrative pronoun onsets are compared with detected gesture apices. Both categories are paired on a case-by-case basis if the distance between them is smaller than the maximum gap (&lt;code&gt;max_time_diff&lt;/code&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Temporal differences between speech and gesture events are calculated.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A CSV file containing word-gesture alignment data is generated.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A scatter plot is created for each recording to illustrate the alignment between the words of interest and the closest pointing gesture within the &lt;code&gt;max_time_diff&lt;/code&gt; window.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div style=&#34;margin-top: 4%;&#34;&gt;

&lt;/div&gt;
&lt;p&gt;&lt;img src=&#39;https://github.com/pablobernabeu/prototype-process-pronouns-gestures/blob/main/mnt/output/1_scatterplot.png?raw=true&#39; alt=&#39;Plot of data for the alignment between demonstrative pronouns and pointing gestures, obtained using a semi-automated workflow in Python.&#39; style=&#39;margin-top:2px; margin-bottom:-2px;&#39;&gt;&lt;/img&gt;&lt;/p&gt;
&lt;div class=&#34;script-container&#34; data-src=&#34;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Fprototype-process-pronouns-gestures%2Fblob%2Fmain%2Falignment_analysis.py&amp;amp;style=a11y-dark&amp;amp;type=code&amp;amp;showFullPath=on&amp;amp;showCopy=on&amp;amp;showLineNumbers=on&amp;amp;showFileMeta=on&#34;&gt;
&lt;button class=&#34;toggle-script&#34;&gt;Show script&lt;/button&gt;
&lt;div class=&#34;script-wrapper&#34;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;video-processing-and-annotation-video_editing.py&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;4. Video Processing and Annotation (&lt;a href=&#34;https://github.com/pablobernabeu/prototype-process-pronouns-gestures/blob/main/video_editing.py&#34;&gt;&lt;code&gt;video_editing.py&lt;/code&gt;&lt;/a&gt;)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The system overlays the transcribed speech as subtitles.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Gesture peaks are highlighted to make alignment patterns visible.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The original audio is merged into the video for reference.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;script-container&#34; data-src=&#34;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Fprototype-process-pronouns-gestures%2Fblob%2Fmain%2Fvideo_editing.py&amp;amp;style=a11y-dark&amp;amp;type=code&amp;amp;showFullPath=on&amp;amp;showCopy=on&amp;amp;showLineNumbers=on&amp;amp;showFileMeta=on&#34;&gt;
&lt;button class=&#34;toggle-script&#34;&gt;Show script&lt;/button&gt;
&lt;div class=&#34;script-wrapper&#34;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;automated-execution-main.py&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;5. Automated Execution (&lt;a href=&#34;https://github.com/pablobernabeu/prototype-process-pronouns-gestures/blob/main/main.py&#34;&gt;&lt;code&gt;main.py&lt;/code&gt;&lt;/a&gt;)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The main script coordinates the entire process.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Multiple audio-video file pairs can be processed simultaneously.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Results are systematically organised in the output directory.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;script-container&#34; data-src=&#34;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Fprototype-process-pronouns-gestures%2Fblob%2Fmain%2Fmain.py&amp;amp;style=a11y-dark&amp;amp;type=code&amp;amp;showFullPath=on&amp;amp;showCopy=on&amp;amp;showLineNumbers=on&amp;amp;showFileMeta=on&#34;&gt;
&lt;button class=&#34;toggle-script&#34;&gt;Show script&lt;/button&gt;
&lt;div class=&#34;script-wrapper&#34;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;current-challenges-and-next-steps&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Current Challenges and Next Steps&lt;/h2&gt;
&lt;div id=&#34;improving-pronoun-identification&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;1. Improving Pronoun Identification&lt;/h4&gt;
&lt;p&gt;One limitation of the current system is the overidentification of demonstrative pronouns. In languages such as English, French and German, many definite articles are mistakenly included because they share the same form as demonstrative pronouns. This issue could be addressed by replacing the current current fuzzy &lt;code&gt;words_of_interest&lt;/code&gt; list with a more precise list, where each pronoun is contextualised by its preceding and subsequent words.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;enhancing-gesture-detection-accuracy&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;2. Enhancing Gesture Detection Accuracy&lt;/h4&gt;
&lt;p&gt;The system underidentifies pointing gestures, which impacts the overall analysis. Improving MediaPipe’s detection implementation and incorporating additional filtering methods—such as movement velocity thresholds—could significantly enhance accuracy.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This prototype represents an important step towards automating the analysis of speech-gesture interactions. By bridging linguistic and computer vision technologies, the system offers a scalable method for studying deictic communication, paving the way for further refinements in multimodal linguistic analysis.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Passive constructions and asymmetries between languages</title>
      <link>https://pablobernabeu.github.io/2024/passive-constructions-and-asymmetries-between-languages/</link>
      <pubDate>Sat, 21 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/2024/passive-constructions-and-asymmetries-between-languages/</guid>
      <description>


&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34; style=&#34;padding-bottom: 0; margin-bottom: 6%;&#34;&gt;
&lt;p&gt;Given all of the data that E&amp;amp;L [Evans &amp;amp; Levinson, 2009] cite, how could anyone maintain the notion of a universal grammar with linguistic content? Traditionally, there have been three basic strategies. First, just as we may force English grammar into the Procrustean bed of Latin grammar – that is how I was taught the structure of English in grade school – the grammars of the world’s so-called exotic languages may be forced into an abstract scheme based mainly on European languages.&lt;/p&gt;
&lt;p&gt;— &lt;strong&gt;Tomasello (2009)&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Researchers often make participants jump through hoops. Due to our personal blind spots, it seems easier to realise the full extent of these acrobatics when we consider the work of other researchers. In linguistic research, the acrobatics are often spurred by unnatural grammatical constructions. For instance, in Spanish, &lt;em&gt;be&lt;/em&gt;-based passive constructions—such as &lt;em&gt;La guerra fue empezada por …&lt;/em&gt; ‘The war was started by …’—are much less frequent than in English. In Spanish, &lt;em&gt;be&lt;/em&gt;-passives are mostly reserved for the formal, written discourse. Outside of that register, the left-dislocation of the patient is more commonly achieved through the following constructions. One construction hinges on the reflexive pronoun &lt;em&gt;se&lt;/em&gt;—e.g., &lt;em&gt;El apartamento se vendió&lt;/em&gt; ‘The apartment was sold’ (Takagaki, 2005). The other construction implements a pronominal object clitic (usually in preverbal position), as illustrated below.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; The latter construction, though not strictly passive, is thematically equivalent to many passives in English (Hidalgo Downing &amp;amp; Downing, 2012).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#39;images/guerra-la-empezo.png&#39; alt=&#39;Comparing the frequency of the English-like, *be*-based passive to the construction that implements a pronominal object clitic in preverbal position, in Spanish.&#39; style=&#39;margin-top:2px; margin-bottom:-2px;&#39;&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size:90%; color: #899499;&#34;&gt;Comparing the frequency of the English-like, &lt;em&gt;be&lt;/em&gt;-based passive to the construction that implements a pronominal object clitic in preverbal position.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The ratio of 8 to 5,300 results suggests that &lt;em&gt;be&lt;/em&gt;-passives are much less common than the construction implementing a preverbal clitic. In the light of this ratio, it is surprising to find linguistic research that seems to overlook the asymmetry between English and Spanish regarding passives. For instance, in a study on crosslinguistic syntactic priming in bilingual children, Vasilyeva et al. (2010) used stimuli such as &lt;em&gt;El gato fue lavado por el perro&lt;/em&gt; ‘The cat was washed by the dog’. Through a quick-and-dirty corpus analysis using a search engine, we can examine the limitations of these stimuli. Whereas the English form ‘The cat was washed’ is common enough, the literal translations &lt;em&gt;El gato fue lavado&lt;/em&gt; and &lt;em&gt;La gata fue lavada&lt;/em&gt; are essentially negligible.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#39;images/cat-washed.png&#39; alt=&#39;Comparing the frequency of passive constructions in English and in Spanish.&#39; style=&#39;margin-top:2px; margin-bottom:-2px;&#39;&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#39;images/gato-lavado.png&#39; alt=&#39;Comparing the frequency of passive constructions in English and in Spanish.&#39; style=&#39;margin-top:2px; margin-bottom:-2px;&#39;&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#39;images/gata-lavada.png&#39; alt=&#39;Comparing the frequency of passive constructions in English and in Spanish.&#39; style=&#39;margin-top:2px; margin-bottom:-2px;&#39;&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size:90%; color: #899499;&#34;&gt;Comparing the frequency of passive constructions in English and in Spanish.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Vasilyeva et al. (2010) observed that, when primed with English-like, &lt;em&gt;be&lt;/em&gt;-based passives in Spanish, the children increased their use of passive constructions in English. In contrast, exposure to English passives in the prime sentences did not lead to a greater use of the English-like passives in Spanish. The authors described this contrast as an &lt;em&gt;asymmetry&lt;/em&gt;, which has been profusely echoed in the subsequent literature on crosslinguistic syntactic priming (Serratrice, 2022). The caveat about this finding is that the stimuli &lt;em&gt;themselves&lt;/em&gt; contained an asymmetry, as the &lt;em&gt;be&lt;/em&gt;-passive is infelicitous in Spanish, certainly when compared to &lt;em&gt;be&lt;/em&gt;-passives in English (Hartsuiker &amp;amp; Bernolet, 2017; Vasilyeva et al., 2010), and especially among children, who use passives even less frequently.&lt;/p&gt;
&lt;p&gt;Syntactic isomorphism is less common than it may seem. That is, syntactic structures cannot always be mapped on a one-to-one basis across languages. Even when the same structures exist in two languages, their frequencies may be fundamentally different, as in the case of &lt;em&gt;be&lt;/em&gt;-based passives in English and Spanish. Thus, where possible, stimuli should capture the functional equivalents between languages, not just the surface-level structural forms, to avoid skewed results. By this means, it will become easier to interpret the results of crosslinguistic priming. At the same time, seeking crosslinguistic overlaps may be like looking for a needle in a haystack.&lt;/p&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;Evans, N., &amp;amp; Levinson, S. C. (2009). The myth of language universals: Language diversity and its importance for cognitive science. &lt;em&gt;Behavioral and Brain Sciences, 32&lt;/em&gt;(5), 429-448. &lt;a href=&#34;https://doi.org/10.1017/S0140525X0999094X&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1017/S0140525X0999094X&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hartsuiker, R. J., &amp;amp; Bernolet, S. (2017). The development of shared syntax in second language learning. &lt;em&gt;Bilingualism: Language and Cognition, 20&lt;/em&gt;(2), 219-234. &lt;a href=&#34;https://doi.org/10.1017/S1366728915000164&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1017/S1366728915000164&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hidalgo Downing, R., &amp;amp; Downing, A. (2012). Topic and topicality in text: A contrastive study of English and Spanish narrative texts. &lt;em&gt;Linguistics and the Human Sciences, 6&lt;/em&gt;, 193–217. &lt;a href=&#34;https://doi.org/10.1558/lhs.v6i1-3.193&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1558/lhs.v6i1-3.193&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Serratrice, L. (2022). What can syntactic priming tell us about crosslinguistic influence? In Messenger, K. (Ed.), &lt;em&gt;Syntactic priming in language acquisition: Representations, mechanisms and applications&lt;/em&gt; (pp. 129–156). Amsterdam: John Benjamins. &lt;a href=&#34;https://doi.org/10.1075/tilar.31&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1075/tilar.31&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Takagaki, T. (2005). On the productivity of the Spanish passive constructions. In Takagaki et al. (Eds.), &lt;em&gt;Corpus-based approaches to sentence structures&lt;/em&gt; (pp. 289–309). Amsterdam: John Benjamins. &lt;a href=&#34;https://doi.org/10.1075/ubli.2&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1075/ubli.2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tomasello, M. (2009). Universal grammar is dead. &lt;em&gt;Behavioral and Brain Sciences, 32&lt;/em&gt;(5), 470–471. &lt;a href=&#34;https://doi.org/10.1017/S0140525X09990744&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1017/S0140525X09990744&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Vasilyeva, M., Waterfall, H., Gámez, P. B., Gómez, L. E., Bowers, E., &amp;amp; Shimpi, P. (2010). Cross-linguistic syntactic priming in bilingual children. &lt;em&gt;Journal of Child Language, 37&lt;/em&gt;(5), 1047–1064. &lt;a href=&#34;https://doi.org/10.1017/S0305000909990213&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1017/S0305000909990213&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes footnotes-end-of-document&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;For a couple of more ideas about pronominal object clitics, see &lt;a href=&#34;https://pablobernabeu.github.io/2023/pronominal-object-clitics-in-preverbal-position-are-a-hard-nut-to-crack-for-google-translate&#34;&gt;this other post&lt;/a&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Making research materials Findable, Accessible, Interoperable and Reusable</title>
      <link>https://pablobernabeu.github.io/presentation/making-research-materials-findable-accessible-interoperable-reusable-fair/</link>
      <pubDate>Thu, 05 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/presentation/making-research-materials-findable-accessible-interoperable-reusable-fair/</guid>
      <description>


&lt;a href=&#39;https://osf.io/h83yq&#39;&gt;
&lt;button style = &#34;background-color: white; color: black; border: 2px solid #196F27; border-radius: 12px;&#34;&gt;
&lt;h3 style=&#34;margin-top: 7px !important; margin-left: 9px !important; margin-right: 9px !important;&#34;&gt;
&lt;span style=&#34;color:#DBE6DA;&#34;&gt;&lt;/span&gt; Poster
&lt;/h3&gt;
&lt;/button&gt;
&lt;p&gt;&lt;/a&gt;  &lt;/p&gt;
&lt;div class=&#34;document-viewer-container&#34; style=&#34;height: 80vh; min-height: 400px;&#34;&gt;
&lt;iframe src=&#34;https://cdn.jsdelivr.net/gh/pablobernabeu/LESS-Project@main/presentations/Bernabeu%20et%20al%20FAIR%20at%20HILS%202024.pdf&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;border: none&#34; title=&#34;Document Viewer&#34; loading=&#34;lazy&#34;&gt;
&lt;p&gt;
Your browser does not support embedded PDFs. &lt;a href=&#34;https://cdn.jsdelivr.net/gh/pablobernabeu/LESS-Project@main/presentations/Bernabeu%20et%20al%20FAIR%20at%20HILS%202024.pdf&#34; target=&#34;_blank&#34;&gt;Download the PDF&lt;/a&gt; instead.
&lt;/p&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;div style=&#34;margin-top: 8%;&#34;&gt;

&lt;/div&gt;
&lt;div id=&#34;snippet-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Snippet 1&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;The use of code scripts facilitates the reproducibility, testability and expandability of materials.&lt;/em&gt;&lt;/p&gt;
&lt;div style=&#34;margin-top: 0; margin-bottom: 6%;&#34;&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;└── stimulus_preparation
    ├── Norway site, base stimuli.csv
    ├── Spain site, base stimuli.csv
    ├── base_images.R
    ├── R_functions
    │   ├── Session2_Pretraining_vocabulary.R
    │   ├── Session2_Training_gender_agreement.R
    │   ├── Session2_Test_gender_agreement.R
    │   ├── Session2_Experiment_gender_agreement.R
    ...
    ├── compile_all_stimuli.R&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;table-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Table 1&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;The minimal components of each language are contained in a base file.&lt;/em&gt;&lt;/p&gt;
&lt;div style=&#34;margin-top: 0; margin-bottom: 6%;&#34;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;verb_ID&lt;/th&gt;
&lt;th&gt;verb_type&lt;/th&gt;
&lt;th&gt;verb&lt;/th&gt;
&lt;th&gt;verb_contrast_ID&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;copula_be&lt;/td&gt;
&lt;td&gt;is&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;copula_be&lt;/td&gt;
&lt;td&gt;are&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;copula_look&lt;/td&gt;
&lt;td&gt;looks&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;copula_look&lt;/td&gt;
&lt;td&gt;look&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;transitive&lt;/td&gt;
&lt;td&gt;remembered&lt;/td&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;transitive&lt;/td&gt;
&lt;td&gt;forgot&lt;/td&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;transitive&lt;/td&gt;
&lt;td&gt;chose&lt;/td&gt;
&lt;td&gt;B&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;transitive&lt;/td&gt;
&lt;td&gt;refused&lt;/td&gt;
&lt;td&gt;B&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;snippet-2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Snippet 2&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Tests were set throughout the workflow to control the frequency of some categories (R code).&lt;/em&gt;&lt;/p&gt;
&lt;div style=&#34;margin-top: 0; margin-bottom: 6%;&#34;&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;columns_to_check = c(&amp;#39;noun1_gender&amp;#39;, &amp;#39;number&amp;#39;, &amp;#39;person&amp;#39;, 
                     &amp;#39;verb&amp;#39;, &amp;#39;noun1&amp;#39;, &amp;#39;wrapup_noun&amp;#39;)

for(i in seq_along(columns_to_check)) {
  column = columns_to_check[i]
  number_of_unique_frequencies = 
    combinations %&amp;gt;% 
    filter(complete.cases(get(column)), get(column) != &amp;#39;&amp;#39;) %&amp;gt;% 
    group_by(get(column)) %&amp;gt;% tally() %&amp;gt;% select(n) %&amp;gt;% 
    n_distinct()
  if(number_of_unique_frequencies != 1) {
    warning(paste0(&amp;#39;Some elements in the column `&amp;#39;, column, 
                   &amp;#39;` appear more often than others.&amp;#39;))
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;snippet-3&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Snippet 3&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Seamless adjustment of parameters in each OpenSesame session (Python code).&lt;/em&gt;&lt;/p&gt;
&lt;div style=&#34;margin-top: 0; margin-bottom: 6%;&#34;&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;participant_parameters = 
  pd.read_csv(exp.get_file(&amp;#39;../parameters per participant/&amp;#39; + 
              var.study_site + 
              &amp;#39; site, parameters per participant.csv&amp;#39;))

var.resting_state_order = 
  participant_parameters.loc[
    participant_parameters[&amp;#39;participant&amp;#39;] ==
    var.subject_nr][&amp;#39;Session2_resting_state_order&amp;#39;].iloc[0]

var.language = 
  participant_parameters.loc[participant_parameters[&amp;#39;participant&amp;#39;] == 
                             var.subject_nr][&amp;#39;language&amp;#39;].iloc[0]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;snippet-4&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Snippet 4&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Sending serial-port triggers in OpenSesame to record ERPs (Python code).&lt;/em&gt;&lt;/p&gt;
&lt;div style=&#34;margin-top: 0; margin-bottom: 6%;&#34;&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Open the first serial port available
serialport = serial.Serial(serial.tools.list_ports.comports()[0].device)

# Send triggers to the port
def send_trigger(trigger):
    serialport.write(trigger.to_bytes(length = 1, byteorder = &amp;#39;big&amp;#39;))
    # 10 ms separation from next trigger (see BrainVision Recorder manual)
    time.sleep(0.01) 
    # reset port
    serialport.write(int(0).to_bytes(length = 1, byteorder = &amp;#39;big&amp;#39;)) 
    return;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;References&lt;/h4&gt;
&lt;p&gt;Barsalou, L. W. (2019). Establishing generalizable mechanisms. &lt;em&gt;Psychological Inquiry, 30&lt;/em&gt;(4), 220–230. &lt;a href=&#34;https://doi.org/10.1080/1047840X.2019.1693857&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1080/1047840X.2019.1693857&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Cross, Z. R., Zou-Williams, L., Wilkinson, E. M., Schlesewsky, M., &amp;amp; Bornkessel-Schlesewsky, I. (2021). Mini Pinyin: A modified miniature language for studying language learning and incremental sentence processing. &lt;em&gt;Behavior Research Methods, 53(3)&lt;/em&gt;, 1218–1239. &lt;a href=&#34;https://doi.org/10.3758/s13428-020-01473-6&#34; class=&#34;uri&#34;&gt;https://doi.org/10.3758/s13428-020-01473-6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;González Alonso, J., Alemán Bañón, J., DeLuca, V., Miller, D., Pereira Soares, S. M., Puig-Mayenco, E., Slaats, S., &amp;amp; Rothman, J. (2020). Event related potentials at initial exposure in third language acquisition: Implications from an artificial mini-grammar study. &lt;em&gt;Journal of Neurolinguistics, 56&lt;/em&gt;, 100939. &lt;a href=&#34;https://doi.org/10.1016/j.jneuroling.2020.100939&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1016/j.jneuroling.2020.100939&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Mitrofanova, N., Leivada, E., &amp;amp; Westergaard, M. (2023). Crosslinguistic influence in L3 acquisition: Evidence from artificial language learning. &lt;em&gt;Linguistic Approaches to Bilingualism, 13&lt;/em&gt;(5), 717-742. &lt;a href=&#34;https://doi.org/10.1075/lab.22063.mit&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1075/lab.22063.mit&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Morgan-Short, K., Finger, I., Grey, S., &amp;amp; Ullman, M. T. (2012). Second language processing shows increased native-like neural responses after months of no exposure. &lt;em&gt;PLOS ONE, 7&lt;/em&gt;(3), e32974. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0032974&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1371/journal.pone.0032974&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pereira Soares, S. M., Kupisch, T., &amp;amp; Rothman, J. (2022). Testing potential transfer effects in heritage and adult L2 bilinguals acquiring a mini grammar as an additional language: An ERP approach. &lt;em&gt;Brain Sciences, 12&lt;/em&gt;(5), Article 5. &lt;a href=&#34;https://doi.org/10.3390/brainsci12050669&#34; class=&#34;uri&#34;&gt;https://doi.org/10.3390/brainsci12050669&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wilkinson, M. D., Dumontier, M., Aalbersberg, Ij. J., Appleton, G., Axton, M., Baak, A., Blomberg, N., Boiten, J.-W., da Silva Santos, L. B., Bourne, P. E., Bouwman, J., Brookes, A. J., Clark, T., Crosas, M., Dillo, I., Dumon, O., Edmunds, S., Evelo, C. T., Finkers, R., … Mons, B. (2016). The FAIR Guiding Principles for scientific data management and stewardship. &lt;em&gt;Scientific Data, 3&lt;/em&gt;(1), Article 1. &lt;a href=&#34;https://doi.org/10.1038/sdata.2016.18&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1038/sdata.2016.18&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Preprocessing the Norwegian Web as Corpus (NoWaC) in R</title>
      <link>https://pablobernabeu.github.io/2023/preprocessing-the-norwegian-web-as-corpus-nowac-in-r/</link>
      <pubDate>Thu, 28 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/2023/preprocessing-the-norwegian-web-as-corpus-nowac-in-r/</guid>
      <description>


&lt;div id=&#34;the-present-script-can-be-used-to-preprocess-data-from-a-frequency-list-of-the-norwegian-as-web-corpus-nowac-guevara-2010.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The present script can be used to preprocess data from a frequency list of the Norwegian as Web Corpus (NoWaC; Guevara, 2010).&lt;/h3&gt;
&lt;p&gt;Before using the script, the frequency list should be downloaded from &lt;a href=&#34;https://www.hf.uio.no/iln/english/about/organization/text-laboratory/projects/nowac/nowac-frequency.html&#34;&gt;this URL&lt;/a&gt;. The list is described as ‘frequency list sorted primary alphabetic and secondary by frequency within each character’, and &lt;a href=&#34;https://www.tekstlab.uio.no/nowac/download/nowac-1.1.lemma.frek.sort_alf_frek.txt.gz&#34;&gt;this is the direct URL&lt;/a&gt;. The download requires signing in to an institutional network. Last, the downloaded file should be unzipped.&lt;/p&gt;
&lt;p&gt;The script is shown below.&lt;/p&gt;
&lt;script src=&#34;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Fpreprocessing-NoWaC-Corpus-in-R%2Fblob%2Fmain%2Fpreprocessing_NoWaC_Corpus.R%23L19-L102&amp;style=a11y-dark&amp;type=code&amp;showLineNumbers=on&amp;showFileMeta=on&amp;showCopy=on&#34;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;Guevara, E. R. (2010). NoWaC: A large web-based corpus for Norwegian. In &lt;em&gt;Proceedings of the NAACL HLT 2010 Sixth Web as Corpus Workshop&lt;/em&gt; (pp. 1-7). &lt;a href=&#34;https://aclanthology.org/W10-1501&#34; class=&#34;uri&#34;&gt;https://aclanthology.org/W10-1501&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Rodina, Y., &amp;amp; Westergaard, M. (2015). Grammatical gender in Norwegian: Language acquisition and language change. &lt;em&gt;Journal of Germanic Linguistics, 27&lt;/em&gt;(2), 145–187. &lt;a href=&#34;https://doi.org/10.1017/S1470542714000245&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1017/S1470542714000245&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Rodina, Y., &amp;amp; Westergaard, M. (2021). Grammatical gender and declension class in language change: A study of the loss of feminine gender in Norwegian. &lt;em&gt;Journal of Germanic Linguistics, 33&lt;/em&gt;(3), 235–263. &lt;a href=&#34;https://doi.org/10.1017/S1470542719000217&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1017/S1470542719000217&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Discussion of Labotka et al. (2023)</title>
      <link>https://pablobernabeu.github.io/presentation/discussion-of-labotka-et-al-2023/</link>
      <pubDate>Mon, 22 May 2023 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/presentation/discussion-of-labotka-et-al-2023/</guid>
      <description>&lt;br&gt;
&lt;iframe src=&#34;https://www.slideshare.net/slideshow/embed_code/key/fe4PiNvEjnepIA&#34; width=&#34;700&#34; height=&#34;394&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; style=&#34;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&#34; allowfullscreen&gt; &lt;/iframe&gt; &lt;div style=&#34;margin-bottom:5px&#34;&gt; &lt;a href=&#34;https://www.slideshare.net/PabloBernabeu/presentation-of-labotka-et-al-2023&#34; title=&#34;Discussion of Labotka et al. (2023)&#34; target=&#34;_blank&#34;&gt;Slideshare&lt;/a&gt;&lt;/div&gt; 
&lt;hr&gt;
&lt;div class = &#39;hanging-indent&#39;&gt;
&lt;p&gt;Labotka, D., Sabo, E., Bonais, R., Gelman, S. A., &amp;amp; Baptista, M. (2023). Testing the effects of congruence in adult multilingual acquisition with implications for creole genesis. &lt;em&gt;Cognition, 235&lt;/em&gt;, 105387. &lt;a href=&#34;https://doi.org/10.1016/j.cognition.2023.105387&#34;&gt;https://doi.org/10.1016/j.cognition.2023.105387&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt; 
</description>
    </item>
    
    <item>
      <title>Pronominal object clitics in preverbal position are a hard nut to crack for Google Translate</title>
      <link>https://pablobernabeu.github.io/2023/pronominal-object-clitics-in-preverbal-position-are-a-hard-nut-to-crack-for-google-translate/</link>
      <pubDate>Wed, 17 May 2023 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/2023/pronominal-object-clitics-in-preverbal-position-are-a-hard-nut-to-crack-for-google-translate/</guid>
      <description>


&lt;p&gt;Unlike English, some Romance languages not only allow—but sometimes require—pronominal object clitics in preverbal position (Hanson &amp;amp; Carlson, 2014; Labotka et al., 2023). That is, instead of saying &lt;em&gt;La maestra ha detto il nome&lt;/em&gt; (Italian) ‘The teacher has said the name’, Italian allows &lt;em&gt;Il nome lo ha detto la maestra&lt;/em&gt; (literally, ‘The name it has said the teacher’), which could translate as ‘The name has been said by the teacher’, ‘&lt;em&gt;The teacher&lt;/em&gt; has said the name’, or even ‘It is the teacher that has said the name’. The form &lt;em&gt;Il nome lo ha detto la maestra&lt;/em&gt; is a marked phrasing that increases the attention to the agent of the action. Furthermore, when the clitic is in preverbal position, the degree of focus on the agent is also dependent on the context. For instance, the focus is light in &lt;em&gt;Lo ha detto la maestra&lt;/em&gt;, whereas it is stronger in &lt;em&gt;Lo ha detto la maestra, non l’assistente&lt;/em&gt; “It’s the teacher that’s said it, not the assistant”.&lt;/p&gt;
&lt;p&gt;The agent-focus can sometimes be relinquished in translations (‘The teacher has said it’). In other cases, it must be preserved by applying an intonational or written emphasis on the agent (‘&lt;em&gt;The teacher&lt;/em&gt; has said it’), or by implementing the idiomatic form ‘The teacher said’, or a marked syntax—for instance, with an it-cleft, as in “It’s the teacher that’s said it”, or by adding ‘oneself’, as in ‘The teacher said it herself’.&lt;/p&gt;
&lt;p&gt;Now, how does Google Translate (GT) deal with these translations in May 2023? To translate &lt;em&gt;Lo ha detto la maestra&lt;/em&gt;, GT opts for ‘The teacher said’, which is a good, idiomatic option. When it comes to translating to Spanish, GT returns ‘El profesor dijo’, which is the direct equivalent of the English translation.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; This option is valid in some varieties of Spanish in America. Nonetheless, it must be noted that a more direct translation from the Italian form would have been very good in Spanish (&lt;em&gt;Lo ha dicho la maestra&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;GT has greater trouble when the content of the sentence is slightly less frequent. For instance, &lt;em&gt;Lo cerca la maestra&lt;/em&gt; ‘Him is seeking the teacher’ is stripped of its markedness in GT’s rendering in English—i.e., ‘The teacher is looking for him’. Preserving the agent-focus—e.g., “It’s the teacher that’s looking for him”—would require some syntactic liberties, and hence entail some risks. So, playing it safe is understandable. Our next step is checking the translation to some Romance languages that allow the same movement to preverbal position present in the original Italian sentence &lt;em&gt;Lo cerca la maestra&lt;/em&gt;. Aside from GT, the sentence could be well translated into Romanian as &lt;em&gt;Îl caută dăscăliţa&lt;/em&gt;, or into Spanish as &lt;em&gt;Lo busca la profesora&lt;/em&gt;. In contrast, for both translations, GT returns the equivalents of the English translation—i.e., &lt;em&gt;Profesorul îl caută&lt;/em&gt; and &lt;em&gt;El profesor lo busca&lt;/em&gt;, again discarding the focus on the agent—unnecessarily in these cases due to the overlap in the grammars.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#39;images/Screenshot%202023-05-11%20162627.png&#39; alt=&#39;Suggesting a better translation in Google Translate&#39; style=&#39;margin-top:2px; margin-bottom:-2px;&#39;&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size:90%; color: #899499;&#34;&gt;Submitting a better translation is always an option.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In fairness, machine translation is an absolute feat overall, provided enough caution is practised. With the expansion of language models, machine translation is only going to improve. So, how much of a piece of cake will it be for GT to crack some of these syntactic details in time, and to preserve syntactic forms across languages when the systems match?&lt;/p&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;Hanson, A. E. S., &amp;amp; Carlson, M. T. (2014). The roles of first language and proficiency in L2 processing of Spanish clitics: Global effects. &lt;em&gt;Language Learning, 64&lt;/em&gt;(2), 310-342. &lt;a href=&#34;https://doi.org/10.1111/lang.12050&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1111/lang.12050&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Labotka, D., Sabo, E., Bonais, R., Gelman, S. A., &amp;amp; Baptista, M. (2023). Testing the effects of congruence in adult multilingual acquisition with implications for creole genesis. &lt;em&gt;Cognition, 235&lt;/em&gt;, 105387. &lt;a href=&#34;https://doi.org/10.1016/j.cognition.2023.105387&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1016/j.cognition.2023.105387&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes footnotes-end-of-document&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;We can again ignore the errors of grammatical gender in the translations.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;We can again ignore the errors of grammatical gender in the translations.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Discussion of Jost et al. (2019)</title>
      <link>https://pablobernabeu.github.io/presentation/discussion-of-jost-et-al-2019/</link>
      <pubDate>Mon, 30 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/presentation/discussion-of-jost-et-al-2019/</guid>
      <description>&lt;br&gt;
&lt;iframe src=&#34;https://www.slideshare.net/slideshow/embed_code/key/rpKeB2wZNGw6o1&#34; width=&#34;700&#34; height=&#34;394&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; style=&#34;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&#34; allowfullscreen&gt; &lt;/iframe&gt; &lt;div style=&#34;margin-bottom:5px&#34;&gt; &lt;a href=&#34;https://www.slideshare.net/PabloBernabeu/presentation-of-jost-et-al-2019&#34; title=&#34;Discussion of Labotka et al. (2023)&#34; target=&#34;_blank&#34;&gt;Slideshare&lt;/a&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;div class = &#39;hanging-indent&#39;&gt;
&lt;p&gt;Jost, E., Brill-Schuetz, K., Morgan-Short, K., &amp;amp; Christiansen, M. H. (2019). Input complexity affects long-term retention of statistically learned regularities in an artificial language learning task. &lt;em&gt;Frontiers in Human Neuroscience, 13&lt;/em&gt;, 358. &lt;a href=&#34;https://www.frontiersin.org/articles/10.3389/fnhum.2019.00358&#34;&gt;https://www.frontiersin.org/articles/10.3389/fnhum.2019.00358&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt; 
</description>
    </item>
    
    <item>
      <title>More refined typology and design in linguistic relativity: The case of motion event encoding</title>
      <link>https://pablobernabeu.github.io/publication/bernabeu-tillman-2019/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/publication/bernabeu-tillman-2019/</guid>
      <description>&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;div class = &#39;hanging-indent&#39;&gt;
&lt;p&gt;Bernabeu, P., &amp;amp; Tillman, R. (2019). More refined typology and design in linguistic relativity: The case of motion event encoding. &lt;em&gt;Dutch Journal of Applied Linguistics, 8&lt;/em&gt;(2), 163-171. &lt;a href=&#34;http://doi.org/10.1075/dujal.15019.ber&#34;&gt;http://doi.org/10.1075/dujal.15019.ber&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt; 
</description>
    </item>
    
    <item>
      <title>Dutch modality exclusivity norms</title>
      <link>https://pablobernabeu.github.io/applications-and-dashboards/bernabeu-2018-modalitynorms/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/applications-and-dashboards/bernabeu-2018-modalitynorms/</guid>
      <description>&lt;a href=&#39;https://pablobernabeu.shinyapps.io/Dutch-modality-exclusivity-norms&#39;&gt;
      &lt;button style = &#34;background-color: white; color: black; border: 2px solid #196F27; border-radius: 12px;&#34;&gt;
      &lt;h3 style = &#34;margin-top: 7px !important; margin-left: 9px !important; margin-right: 9px !important;&#34;&gt; 
      &lt;span style=&#34;color:#DBE6DA;&#34;&gt;&lt;/span&gt; Complete web application &lt;font style=&#39;font-size:60%;&#39;&gt;&lt;i&gt;Flexdashboard-Shiny&lt;/i&gt;&lt;/font&gt; &lt;/h3&gt;&lt;/button&gt;&lt;/a&gt;
&lt;br&gt;
&lt;br&gt;
&lt;a href=&#39;https://pablobernabeu.github.io/dashboards/Dutch-modality-exclusivity-norms&#39;&gt;
      &lt;button style = &#34;background-color: white; color: black; border: 2px solid #4CAF50; border-radius: 12px;&#34;&gt;
      &lt;h3 style = &#34;margin-top: 7px !important; margin-left: 9px !important; margin-right: 9px !important;&#34;&gt; 
      &lt;span style=&#34;color:#DBE6DA;&#34;&gt;&lt;/span&gt; Reduced dashboard &lt;font style=&#39;font-size:60%;&#39;&gt;&lt;i&gt;Flexdashboard&lt;/i&gt;&lt;/font&gt; &lt;/h3&gt;&lt;/button&gt;&lt;/a&gt; &amp;nbsp; 
&lt;br&gt;
&lt;br&gt;
&lt;p&gt;This web application presents linguistic data over several tabs. The code combines the great front-end of Flexdashboard—based on R Markdown and yielding an unmatched user interface—, with the great back-end of Shiny—allowing users to download sections of data they select, in various formats.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A nice find was the &amp;lsquo;reactable&amp;rsquo; package, which implements Javascript under the hood to allow the use of colours, bar charts, etc.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Auditory = colDef(header = with_tooltip(&#39;Auditory Rating&#39;,
                                        &#39;Mean rating of each word on the auditory modality across participants.&#39;),
                  cell = function(value) {
                    width &amp;lt;- paste0(value / max(table_data$Auditory) * 100, &amp;quot;%&amp;quot;)
                    value = sprintf(&amp;quot;%.2f&amp;quot;, round(value,2))  # Round to two digits, keeping trailing zeros
                    bar_chart(value, width = width, fill = &#39;#ff3030&#39;)
                    },
                  align = &#39;left&#39;),
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;One of the hardest nuts to crack was allowing the full functionality of tables—i.e, scaling to screen, frozen header, and vertical and horizontal scrolling—whilst having tweaked the vertical/horizontal orientation of the dashboard sections. Initial clashes were sorted by adjusting the section&#39;s CSS styles&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Table {#table style=&amp;quot;background-color:#FCFCFC;&amp;quot;}
=======================================================================
  
Inputs {.sidebar style=&#39;position:fixed; padding-top: 65px; padding-bottom:30px;&#39;}
-----------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and by also adjusting the reactable settings.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;renderReactable({
  reactable(selected_words(),
            defaultSorted = list(cat = &#39;desc&#39;, word = &#39;asc&#39;),
            defaultColDef = colDef(footerStyle = list(fontWeight = &amp;quot;bold&amp;quot;)),
            height = 840, striped = TRUE, pagination = FALSE, highlight = TRUE,
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A nice feature, especially suited to Flexdashboard, was the use of different formats across tabs. Whereas the Info tab presents long text using HTML and CSS styling, along with rmarkdown code output, the other tabs rely more strongly on Javascript features, enabled by R packages such as ‘shiny’ and sweetalert (e.g., allowing modal dialogs—pop-ups), reactable and plotly (e.g., allowing information opened by hovering—tooltips).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```{r}
  
# reactive for the word bar
highlighted_properties = reactive(input$highlighted_properties)
  
renderPlotly({
 ggplotly(
  ggplot( selected_props(), aes(RC1, RC2, label = as.character(word), color = main, 
    # Html tags below used for format. Decimals rounded to two.
    text = paste0(&#39; &#39;, &#39;&amp;lt;span style=&amp;quot;padding-top:3px; padding-bottom:3px; font-size:2.2em; color:#EEEEEE&amp;quot;&amp;gt;&#39;, capitalize(word), &#39;&amp;lt;/span&amp;gt; &#39;, &#39;&amp;lt;br&amp;gt;&#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Dominant modality: &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, main, &#39; &#39;,
     &#39; &#39;, &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Modality exclusivity: &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, sprintf(&amp;quot;%.2f&amp;quot;, round(Exclusivity, 2)), &#39;% &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Perceptual strength: &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, sprintf(&amp;quot;%.2f&amp;quot;, round(Perceptualstrength, 2)),
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Auditory rating: &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, sprintf(&amp;quot;%.2f&amp;quot;, round(Auditory, 2)), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Haptic rating: &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, sprintf(&amp;quot;%.2f&amp;quot;, round(Haptic, 2)), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Visual rating: &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, sprintf(&amp;quot;%.2f&amp;quot;, round(Visual, 2)), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Concreteness (Brysbaert et al., 2014): &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, 
       sprintf(&amp;quot;%.2f&amp;quot;, round(concrete_Brysbaertetal2014, 2)), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Number of letters: &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, letters, &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Number of phonemes (DutchPOND): &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, 
     round(phonemes_DUTCHPOND, 2), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Contextual diversity (lg10CD SUBTLEX-NL): &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;,
       sprintf(&amp;quot;%.2f&amp;quot;, round(freq_lg10CD_SUBTLEXNL, 2)), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Word frequency (lg10WF SUBTLEX-NL): &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;,
       sprintf(&amp;quot;%.2f&amp;quot;, round(freq_lg10WF_SUBTLEXNL, 2)), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Lemma frequency (CELEX): &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, 
       sprintf(&amp;quot;%.2f&amp;quot;, round(freq_CELEX_lem, 2)), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Phonological neighbourhood size (DutchPOND): &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;, 
     round(phon_neighbours_DUTCHPOND, 2), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Orthographic neighbourhood size (DutchPOND): &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;,
     round(orth_neighbours_DUTCHPOND, 2), &#39; &#39;,
     &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&amp;lt;span style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt; Age of acquisition (Brysbaert et al., 2014): &amp;lt;/span&amp;gt;&amp;lt;b style=&amp;quot;color:#EEEEEE&amp;quot;&amp;gt;&#39;,
     sprintf(&amp;quot;%.2f&amp;quot;, round(AoA_Brysbaertetal2014, 2)), &#39; &#39;, &#39;&amp;lt;br&amp;gt; &#39;
     ) ) ) +
  geom_text(size = ifelse(selected_props()$word %in% highlighted_properties(), 7,
             ifelse(is.null(highlighted_properties()), 3, 2.8)),
      fontface = ifelse(selected_props()$word %in% highlighted_properties(), &#39;bold&#39;, &#39;plain&#39;)) +
geom_point(alpha = 0) +  # This geom_point helps to colour the tooltip according to the dominant modality
scale_colour_manual(values = colours, drop = FALSE) + theme_bw() + ggtitle(&#39;Property words&#39;) +
labs(x = &#39;Varimax-rotated Principal Component 1&#39;, y = &#39;Varimax-rotated Principal Component 2&#39;) +
guides(color = guide_legend(title = &#39;Main&amp;lt;br&amp;gt;modality&#39;)) +
theme( plot.background = element_blank(), panel.grid.major = element_blank(),
   panel.grid.minor = element_blank(), panel.border = element_blank(),
   axis.line = element_line(color = &#39;black&#39;), plot.title = element_text(size = 14, hjust = .5),
   axis.title.x = element_text(colour = &#39;black&#39;, size = 12, margin = margin(15,15,0,15)),
   axis.title.y = element_text(colour = &#39;black&#39;, size = 12, margin = margin(0,15,15,5)),
   axis.text.x = element_text(size = 8), axis.text.y  = element_text(size = 8),
   legend.background = element_rect(size = 2), legend.position = &#39;none&#39;,
 legend.title = element_blank(),
 legend.text = element_text(colour = colours, size = 13) ),
tooltip = &#39;text&#39;
)
})
  
# For download, save plot without the interactive &#39;plotly&#39; part
  
properties_png = reactive({ ggplot(selected_props(), aes(RC1, RC2, color = main, label = as.character(word))) +
geom_text(show.legend = FALSE, size = ifelse(selected_props()$word %in% highlighted_properties(), 7,
         ifelse(is.null(highlighted_properties()), 3, 2.8)),
      fontface = ifelse(selected_props()$word %in% highlighted_properties(), &#39;bold&#39;, &#39;plain&#39;)) +
geom_point(alpha = 0) + scale_colour_manual(values = colours, drop = FALSE) + theme_bw() +
guides(color = guide_legend(title = &#39;Main&amp;lt;br&amp;gt;modality&#39;, override.aes = list(size = 7, alpha = 1))) +
ggtitle( paste0(&#39;Properties&#39;, &#39; (showing &#39;, nrow(selected_props()), &#39; out of &#39;, nrow(props), &#39;)&#39;) ) + 
labs(x = &#39;Varimax-rotated Principal Component 1&#39;, y = &#39;Varimax-rotated Principal Component 2&#39;) +
theme( plot.background = element_blank(), panel.grid.major = element_blank(),
   panel.grid.minor = element_blank(), panel.border = element_blank(),
   axis.line = element_line(color = &#39;black&#39;), plot.title = element_text(size = 17, hjust = .5, margin = margin(3,3,7,3)),
   axis.title.x = element_text(colour = &#39;black&#39;, size = 12, margin = margin(10,10,2,10)),
   axis.title.y = element_text(colour = &#39;black&#39;, size = 12, margin = margin(10,10,10,5)),
   axis.text.x = element_text(size = 8), axis.text.y  = element_text(size = 8),
   legend.background = element_rect(size = 2), legend.position = &#39;right&#39;,
   legend.title = element_blank(), legend.text = element_text(size = 15))
})
  
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The only instance in which I drew on javascript code outside R packages was to enable tooltips beyond the packages’ limits—for instance, in the side bar. This javascript feature is created at the top of the script, in the head area.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;!-- Javascript function to enable a hovering tooltip --&amp;gt;
&amp;lt;script&amp;gt;
$(document).ready(function(){
   $(&#39;[data-toggle=&amp;quot;tooltip1&amp;quot;]&#39;).tooltip();
});
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the side bar, I added a reactive mean for each variable, complementing the range selector.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;reactive(cat(paste0(&#39;Mean = &#39;, 
  sprintf(&amp;quot;%.2f&amp;quot;, round(mean(selected_words()$Exclusivity),2)))))
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;static-version-published-on-rpubs&#34;&gt;Static version published on RPubs&lt;/h2&gt;
&lt;p&gt;A reduced, &lt;a href=&#34;https://rpubs.com/pcbernabeu/Dutch-modality-exclusivity-norms&#34;&gt;&lt;em&gt;static&lt;/em&gt; version&lt;/a&gt; was also created to increase the availability of the content. Removing some reactivity features allows the dashboard to be published as a standard website (i.e., on a personal website, on &lt;a href=&#34;https://rpubs.com/&#34;&gt;RPubs&lt;/a&gt;, etc.), without the need for a back-end Shiny server. Note that this type of website is dubbed &amp;lsquo;static&amp;rsquo;, but it can retain multiple interactive features thanks to Javascript-based tools under the hood, allowed by R packages such as &lt;code&gt;leaflet&lt;/code&gt; for maps, &lt;code&gt;DT&lt;/code&gt; for tables, &lt;code&gt;plotly&lt;/code&gt; for plots, etc.&lt;/p&gt;
&lt;p&gt;To create the Flexdashboard-only version departing from the Flexdashboard-Shiny version, I deleted &lt;code&gt;runtime: shiny&lt;/code&gt; from the YAML header, and disabled Shiny reactive inputs and objects, as below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```{r}
# Number of words selected on sidebar
# reactive(cat(paste0(&#39;Words selected below: &#39;, nrow(selected_props()))))
```
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;div class = &#39;hanging-indent&#39;&gt;
&lt;p&gt;Bernabeu, P. (2018). Dutch modality exclusivity norms for 336 properties and 411 concepts [Web application]. Retrieved from &lt;a href=&#34;https://pablobernabeu.shinyapps.io/Dutch-Modality-Exclusivity-Norms&#34;&gt;https://pablobernabeu.shinyapps.io/Dutch-Modality-Exclusivity-Norms&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Dutch modality exclusivity norms for 336 properties and 411 concepts</title>
      <link>https://pablobernabeu.github.io/publication/dutch-modality-exclusivity-norms-for-336-properties-and-411-concepts/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/publication/dutch-modality-exclusivity-norms-for-336-properties-and-411-concepts/</guid>
      <description>&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;div class = &#39;hanging-indent&#39;&gt;
&lt;p&gt;Bernabeu, P. (2018). &lt;em&gt;Dutch modality exclusivity norms for 336 properties and 411 concepts&lt;/em&gt;. PsyArXiv. &lt;a href=&#34;https://doi.org/10.31234/osf.io/s2c5h&#34;&gt;https://doi.org/10.31234/osf.io/s2c5h&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h3 id=&#34;related-podcast&#34;&gt;Related podcast&lt;/h3&gt;
&lt;p&gt;&lt;i class=&#34;fa-solid fa-wand-magic-sparkles&#34; style=&#39;color:darkgrey;&#39;&gt;&lt;/i&gt; &lt;span style=&#39;color:darkgrey; font-style:italic; font-size:85%;&#39;&gt;Created using Google Gemini and NotebookLM.&lt;/span&gt;&lt;/p&gt;
&lt;iframe allow=&#34;autoplay *; encrypted-media *; fullscreen *; clipboard-write&#34; frameborder=&#34;0&#34; height=&#34;175&#34; style=&#34;width:100%;max-width:660px;overflow:hidden;border-radius:10px;&#34; sandbox=&#34;allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation&#34; src=&#34;https://embed.podcasts.apple.com/us/podcast/behind-the-curtains-methods-used-to-investigate/id1837010092?i=1000725594999&#34;&gt;&lt;/iframe&gt;
&lt;h3 id=&#34;related-references&#34;&gt;Related references&lt;/h3&gt;
&lt;div class = &#39;related-references&#39;&gt;
&lt;div class = &#39;hanging-indent&#39;&gt;
&lt;p&gt;Anderson, A. J., Binder, J. R., Fernandino, L., Humphries, C. J., Conant, L. L., Aguilar, M., Wang, X., Doko, D., &amp;amp; Raizada, R. D. S. (2016). Predicting Neural Activity Patterns Associated with Sentences Using a Neurobiologically Motivated Model of Semantic Representation. &lt;em&gt;Cerebral Cortex&lt;/em&gt;, cercor;bhw240v1. &lt;a href=&#34;https://doi.org/10.1093/cercor/bhw240&#34;&gt;https://doi.org/10.1093/cercor/bhw240&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Anderson, A. J., Binder, J. R., Fernandino, L., Humphries, C. J., Conant, L. L., Raizada, R. D. S., Lin, F., &amp;amp; Lalor, E. C. (2019). An Integrated Neural Decoder of Linguistic and Experiential Meaning. &lt;em&gt;The Journal of Neuroscience&lt;/em&gt;, &lt;em&gt;39&lt;/em&gt;(45), 8969&amp;ndash;8987. &lt;a href=&#34;https://doi.org/10.1523/JNEUROSCI.2575-18.2019&#34;&gt;https://doi.org/10.1523/JNEUROSCI.2575-18.2019&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Anderson, A. J., &amp;amp; Lin, F. (2019). How pattern information analyses of semantic brain activity elicited in language comprehension could contribute to the early identification of Alzheimer&#39;s Disease. &lt;em&gt;NeuroImage: Clinical&lt;/em&gt;, &lt;em&gt;22&lt;/em&gt;, 101788. &lt;a href=&#34;https://doi.org/10.1016/j.nicl.2019.101788&#34;&gt;https://doi.org/10.1016/j.nicl.2019.101788&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bagli, M. (2023). How to Point with Language: English Source-Based Language to Describe Taste Qualities. &lt;em&gt;Lublin Studies in Modern Languages and Literature&lt;/em&gt;, &lt;em&gt;42&lt;/em&gt;(2), 31&amp;ndash;46. &lt;a href=&#34;https://doi.org/10.17951/lsmll.2023.47.2.31-46&#34;&gt;https://doi.org/10.17951/lsmll.2023.47.2.31-46&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Banks, B., Borghi, A. M., Fargier, R., Fini, C., Jonauskaite, D., Mazzuca, C., Montalti, M., Villani, C., &amp;amp; Woodin, G. (2023). Consensus Paper: Current Perspectives on Abstract Concepts and Future Research Directions. &lt;em&gt;Journal of Cognition&lt;/em&gt;, &lt;em&gt;6&lt;/em&gt;(1), 62. &lt;a href=&#34;https://doi.org/10.5334/joc.238&#34;&gt;https://doi.org/10.5334/joc.238&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bolognesi, M., Burgers, C., &amp;amp; Caselli, T. (2020). On abstraction: Decoupling conceptual concreteness and categorical specificity. &lt;em&gt;Cognitive Processing&lt;/em&gt;, &lt;em&gt;21&lt;/em&gt;(3), 365&amp;ndash;381. &lt;a href=&#34;https://doi.org/10.1007/s10339-020-00965-9&#34;&gt;https://doi.org/10.1007/s10339-020-00965-9&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Borghi, A. M., Mazzuca, C., Gervasi, A. M., Mannella, F., &amp;amp; Tummolini, L. (2023). Grounded cognition can be multimodal all the way down. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, 1&amp;ndash;5. &lt;a href=&#34;https://doi.org/10.1080/23273798.2023.2210238&#34;&gt;https://doi.org/10.1080/23273798.2023.2210238&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bottini, R., Morucci, P., D&#39;Urso, A., Collignon, O., &amp;amp; Crepaldi, D. (2022). The concreteness advantage in lexical decision does not depend on perceptual simulations. &lt;em&gt;Journal of Experimental Psychology: General&lt;/em&gt;, &lt;em&gt;151&lt;/em&gt;(3), 731&amp;ndash;738. &lt;a href=&#34;https://doi.org/10.1037/xge0001090&#34;&gt;https://doi.org/10.1037/xge0001090&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bruffaerts, R., De Deyne, S., Meersmans, K., Liuzzi, A. G., Storms, G., &amp;amp; Vandenberghe, R. (2019). Redefining the resolution of semantic knowledge in the brain: Advances made by the introduction of models of semantics in neuroimaging. &lt;em&gt;Neuroscience &amp;amp; Biobehavioral Reviews&lt;/em&gt;, &lt;em&gt;103&lt;/em&gt;, 3&amp;ndash;13. &lt;a href=&#34;https://doi.org/10.1016/j.neubiorev.2019.05.015&#34;&gt;https://doi.org/10.1016/j.neubiorev.2019.05.015&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Caballero, R., &amp;amp; Paradis, C. (2020). Soundscapes in English and Spanish: A corpus investigation of verb constructions. &lt;em&gt;Language and Cognition&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(4), 705&amp;ndash;728. &lt;a href=&#34;https://doi.org/10.1017/langcog.2020.19&#34;&gt;https://doi.org/10.1017/langcog.2020.19&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Caballero, R., &amp;amp; Paradis, C. (2023). Sharing Perceptual Experiences through Language. &lt;em&gt;Journal of Intelligence&lt;/em&gt;, &lt;em&gt;11&lt;/em&gt;(7), 129. &lt;a href=&#34;https://doi.org/10.3390/jintelligence11070129&#34;&gt;https://doi.org/10.3390/jintelligence11070129&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Calzavarini, F. (2023). Rethinking modality-specificity in the cognitive neuroscience of concrete word meaning: A position paper. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, 1&amp;ndash;23. &lt;a href=&#34;https://doi.org/10.1080/23273798.2023.2173789&#34;&gt;https://doi.org/10.1080/23273798.2023.2173789&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Carney, J. (2020). Thinking avant la lettre: A Review of 4E Cognition. &lt;em&gt;Evolutionary Studies in Imaginative Culture&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(1), 77&amp;ndash;90. &lt;a href=&#34;https://doi.org/10.26613/esic.4.1.172&#34;&gt;https://doi.org/10.26613/esic.4.1.172&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Charmhun Jo, Sun-A Kim, &amp;amp; Chu-Ren Huang. (2022). Linguistic synesthesia in Korean: A compound word-based study of cross-modal directionality. &lt;em&gt;Linguistic Research&lt;/em&gt;, &lt;em&gt;39&lt;/em&gt;(2), 275&amp;ndash;296. &lt;a href=&#34;https://doi.org/10.17250/KHISLI.39.2.202206.002&#34;&gt;https://doi.org/10.17250/KHISLI.39.2.202206.002&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chedid, G., Brambati, S. M., Bedetti, C., Rey, A. E., Wilson, M. A., &amp;amp; Vallet, G. T. (2019). Visual and auditory perceptual strength norms for 3,596 French nouns and their relationship with other psycholinguistic variables. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;51&lt;/em&gt;(5), 2094&amp;ndash;2105. &lt;a href=&#34;https://doi.org/10.3758/s13428-019-01254-w&#34;&gt;https://doi.org/10.3758/s13428-019-01254-w&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chedid, G., Wilson, M. A., Bedetti, C., Rey, A. E., Vallet, G. T., &amp;amp; Brambati, S. M. (2019). Norms of conceptual familiarity for 3,596 French nouns and their contribution in lexical decision. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;51&lt;/em&gt;(5), 2238&amp;ndash;2247. &lt;a href=&#34;https://doi.org/10.3758/s13428-018-1106-8&#34;&gt;https://doi.org/10.3758/s13428-018-1106-8&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chen, I.-H., Zhao, Q., Long, Y., Lu, Q., &amp;amp; Huang, C.-R. (2019). Mandarin Chinese modality exclusivity norms. &lt;em&gt;PLOS ONE&lt;/em&gt;, &lt;em&gt;14&lt;/em&gt;(2), e0211336. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0211336&#34;&gt;https://doi.org/10.1371/journal.pone.0211336&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Connell, L. (2019). What have labels ever done for us? The linguistic shortcut in conceptual processing. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;34&lt;/em&gt;(10), 1308&amp;ndash;1318. &lt;a href=&#34;https://doi.org/10.1080/23273798.2018.1471512&#34;&gt;https://doi.org/10.1080/23273798.2018.1471512&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Connell, L., Lynott, D., &amp;amp; Banks, B. (2018). Interoception: The forgotten modality in perceptual grounding of abstract and concrete concepts. &lt;em&gt;Philosophical Transactions of the Royal Society B: Biological Sciences&lt;/em&gt;, &lt;em&gt;373&lt;/em&gt;(1752), 20170143. &lt;a href=&#34;https://doi.org/10.1098/rstb.2017.0143&#34;&gt;https://doi.org/10.1098/rstb.2017.0143&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Corciulo, S., Bioglio, L., Basile, V., Patti, V., &amp;amp; Damiano, R. (2023). The DEEP Sensorium: A multidimensional approach to sensory domain labelling. &lt;em&gt;Companion Proceedings of the ACM Web Conference 2023&lt;/em&gt;, 661&amp;ndash;668. &lt;a href=&#34;https://doi.org/10.1145/3543873.3587631&#34;&gt;https://doi.org/10.1145/3543873.3587631&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Davis, C. P., &amp;amp; Yee, E. (2021). Building semantic memory from embodied and distributional language experience. &lt;em&gt;WIREs Cognitive Science&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(5), e1555. &lt;a href=&#34;https://doi.org/10.1002/wcs.1555&#34;&gt;https://doi.org/10.1002/wcs.1555&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;De Deyne, S., Navarro, D. J., Perfors, A., Brysbaert, M., &amp;amp; Storms, G. (2019). The &amp;ldquo;Small World of Words&amp;rdquo; English word association norms for over 12,000 cue words. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;51&lt;/em&gt;(3), 987&amp;ndash;1006. &lt;a href=&#34;https://doi.org/10.3758/s13428-018-1115-7&#34;&gt;https://doi.org/10.3758/s13428-018-1115-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dellantonio, S., &amp;amp; Pastore, L. (2017). The &amp;lsquo;Proprioceptive&amp;rsquo; Component of Abstract Concepts. In S. Dellantonio &amp;amp; L. Pastore, &lt;em&gt;Internal Perception&lt;/em&gt; (Vol. 40, pp. 297&amp;ndash;357). Springer Berlin Heidelberg. &lt;a href=&#34;https://doi.org/10.1007/978-3-662-55763-1_6&#34;&gt;https://doi.org/10.1007/978-3-662-55763-1_6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Díez-Álamo, A. M., Díez, E., Alonso, M. Á., Vargas, C. A., &amp;amp; Fernandez, A. (2018). Normative ratings for perceptual and motor attributes of 750 object concepts in Spanish. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;50&lt;/em&gt;(4), 1632&amp;ndash;1644. &lt;a href=&#34;https://doi.org/10.3758/s13428-017-0970-y&#34;&gt;https://doi.org/10.3758/s13428-017-0970-y&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Díez-Álamo, A. M., Díez, E., Wojcik, D. Z., Alonso, M. A., &amp;amp; Fernandez, A. (2019). Sensory experience ratings for 5,500 Spanish words. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;51&lt;/em&gt;(3), 1205&amp;ndash;1215. &lt;a href=&#34;https://doi.org/10.3758/s13428-018-1057-0&#34;&gt;https://doi.org/10.3758/s13428-018-1057-0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dove, G. (2021). The Challenges of Abstract Concepts. In M. D. Robinson &amp;amp; L. E. Thomas (Eds.), &lt;em&gt;Handbook of Embodied Psychology&lt;/em&gt; (pp. 171&amp;ndash;195). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-78471-3_8&#34;&gt;https://doi.org/10.1007/978-3-030-78471-3_8&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dymarska, A., Connell, L., &amp;amp; Banks, B. (2023). More is not necessarily better: How different aspects of sensorimotor experience affect recognition memory for words. &lt;em&gt;Journal of Experimental Psychology: Learning, Memory, and Cognition&lt;/em&gt;, &lt;em&gt;49&lt;/em&gt;(10), 1572&amp;ndash;1587. &lt;a href=&#34;https://doi.org/10.1037/xlm0001265&#34;&gt;https://doi.org/10.1037/xlm0001265&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Fischer, M. H., &amp;amp; Shaki, S. (2018). Number concepts: Abstract and embodied. &lt;em&gt;Philosophical Transactions of the Royal Society B: Biological Sciences&lt;/em&gt;, &lt;em&gt;373&lt;/em&gt;(1752), 20170125. &lt;a href=&#34;https://doi.org/10.1098/rstb.2017.0125&#34;&gt;https://doi.org/10.1098/rstb.2017.0125&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Fishman, A. (2022). The picture looks like my music sounds: Directional preferences in synesthetic metaphors in the absence of lexical factors. &lt;em&gt;Language and Cognition&lt;/em&gt;, &lt;em&gt;14&lt;/em&gt;(2), 208&amp;ndash;227. &lt;a href=&#34;https://doi.org/10.1017/langcog.2022.2&#34;&gt;https://doi.org/10.1017/langcog.2022.2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gangemi, A. (2020). Closing the Loop between knowledge patterns in cognition and the Semantic Web. &lt;em&gt;Semantic Web&lt;/em&gt;, &lt;em&gt;11&lt;/em&gt;(1), 139&amp;ndash;151. &lt;a href=&#34;https://doi.org/10.3233/SW-190383&#34;&gt;https://doi.org/10.3233/SW-190383&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ghandhari, M., Fini, C., Da Rold, F., &amp;amp; Borghi, A. M. (2020). Different kinds of embodied language: A comparison between Italian and Persian languages. &lt;em&gt;Brain and Cognition&lt;/em&gt;, &lt;em&gt;142&lt;/em&gt;, 105581. &lt;a href=&#34;https://doi.org/10.1016/j.bandc.2020.105581&#34;&gt;https://doi.org/10.1016/j.bandc.2020.105581&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gijssels, T., &amp;amp; Casasanto, D. (2020). Hand-use norms for Dutch and English manual action verbs: Implicit measures from a pantomime task. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;52&lt;/em&gt;(4), 1744&amp;ndash;1767. &lt;a href=&#34;https://doi.org/10.3758/s13428-020-01347-x&#34;&gt;https://doi.org/10.3758/s13428-020-01347-x&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Harpaintner, M., Sim, E.-J., Trumpp, N. M., Ulrich, M., &amp;amp; Kiefer, M. (2020). The grounding of abstract concepts in the motor and visual system: An fMRI study. &lt;em&gt;Cortex&lt;/em&gt;, &lt;em&gt;124&lt;/em&gt;, 1&amp;ndash;22. &lt;a href=&#34;https://doi.org/10.1016/j.cortex.2019.10.014&#34;&gt;https://doi.org/10.1016/j.cortex.2019.10.014&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Harpaintner, M., Trumpp, N. M., &amp;amp; Kiefer, M. (2018). The Semantic Content of Abstract Concepts: A Property Listing Study of 296 Abstract Words. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;, 1748. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2018.01748&#34;&gt;https://doi.org/10.3389/fpsyg.2018.01748&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Harpaintner, M., Trumpp, N. M., &amp;amp; Kiefer, M. (2022). Time course of brain activity during the processing of motor- and vision-related abstract concepts: Flexibility and task dependency. &lt;em&gt;Psychological Research&lt;/em&gt;, &lt;em&gt;86&lt;/em&gt;(8), 2560&amp;ndash;2582. &lt;a href=&#34;https://doi.org/10.1007/s00426-020-01374-5&#34;&gt;https://doi.org/10.1007/s00426-020-01374-5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hartman, J., &amp;amp; Paradis, C. (2023). The language of sound: Events and meaning multitasking of words. &lt;em&gt;Cognitive Linguistics&lt;/em&gt;, &lt;em&gt;34&lt;/em&gt;(3&amp;ndash;4), 445&amp;ndash;477. &lt;a href=&#34;https://doi.org/10.1515/cog-2022-0006&#34;&gt;https://doi.org/10.1515/cog-2022-0006&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hörberg, T., Larsson, M., &amp;amp; Olofsson, J. K. (2022). The Semantic Organization of the English Odor Vocabulary. &lt;em&gt;Cognitive Science&lt;/em&gt;, &lt;em&gt;46&lt;/em&gt;(11), e13205. &lt;a href=&#34;https://doi.org/10.1111/cogs.13205&#34;&gt;https://doi.org/10.1111/cogs.13205&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Huang, C.-R., &amp;amp; Xiong, J. (2019). Linguistic synaesthesia in Chinese. In C.-R. Huang, Z. Jing-Schmidt, &amp;amp; B. Meisterernst (Eds.), &lt;em&gt;The Routledge Handbook of Chinese Applied Linguistics&lt;/em&gt; (1st ed., pp. 294&amp;ndash;312). Routledge. &lt;a href=&#34;https://doi.org/10.4324/9781315625157-20&#34;&gt;https://doi.org/10.4324/9781315625157-20&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Iatropoulos, G., Herman, P., Lansner, A., Karlgren, J., Larsson, M., &amp;amp; Olofsson, J. K. (2018). The language of smell: Connecting linguistic and psychophysical properties of odor descriptors. &lt;em&gt;Cognition&lt;/em&gt;, &lt;em&gt;178&lt;/em&gt;, 37&amp;ndash;49. &lt;a href=&#34;https://doi.org/10.1016/j.cognition.2018.05.007&#34;&gt;https://doi.org/10.1016/j.cognition.2018.05.007&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Jacobs, A. M., &amp;amp; Kinder, A. (2017). &lt;em&gt;&amp;ldquo;The Brain Is the Prisoner of Thought&amp;rdquo;&lt;/em&gt;: A Machine-Learning Assisted Quantitative Narrative Analysis of Literary Metaphors for Use in Neurocognitive Poetics. &lt;em&gt;Metaphor and Symbol&lt;/em&gt;, &lt;em&gt;32&lt;/em&gt;(3), 139&amp;ndash;160. &lt;a href=&#34;https://doi.org/10.1080/10926488.2017.1338015&#34;&gt;https://doi.org/10.1080/10926488.2017.1338015&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Jo, C. (2022). Linguistic Synesthesia in Korean: Universality and Variation. &lt;em&gt;SAGE Open&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(3), 215824402211178. &lt;a href=&#34;https://doi.org/10.1177/21582440221117804&#34;&gt;https://doi.org/10.1177/21582440221117804&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Johns, B. T. (2022). Accounting for item-level variance in recognition memory: Comparing word frequency and contextual diversity. &lt;em&gt;Memory &amp;amp; Cognition&lt;/em&gt;, &lt;em&gt;50&lt;/em&gt;(5), 1013&amp;ndash;1032. &lt;a href=&#34;https://doi.org/10.3758/s13421-021-01249-z&#34;&gt;https://doi.org/10.3758/s13421-021-01249-z&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Jones, L. L., Wurm, L. H., Calcaterra, R. D., &amp;amp; Ofen, N. (2017). Integrative Priming of Compositional and Locative Relations. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2017.00359&#34;&gt;https://doi.org/10.3389/fpsyg.2017.00359&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Julich-Warpakowski, N., &amp;amp; Pérez Sobrino, P. (2023). Introduction: Current challenges in metaphor research. &lt;em&gt;Metaphor and the Social World&lt;/em&gt;, &lt;em&gt;13&lt;/em&gt;(1), 1&amp;ndash;15. &lt;a href=&#34;https://doi.org/10.1075/msw.00026.jul&#34;&gt;https://doi.org/10.1075/msw.00026.jul&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kaiser, E. (2021). Consequences of Sensory Modality for Perspective-Taking: Comparing Visual, Olfactory and Gustatory Perception. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;, 701486. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2021.701486&#34;&gt;https://doi.org/10.3389/fpsyg.2021.701486&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kernot, D., Bossomaier, T., &amp;amp; Bradbury, R. (2017). Novel Text Analysis for Investigating Personality: Identifying the Dark Lady in Shakespeare&#39;s Sonnets. &lt;em&gt;Journal of Quantitative Linguistics&lt;/em&gt;, &lt;em&gt;24&lt;/em&gt;(4), 255&amp;ndash;272. &lt;a href=&#34;https://doi.org/10.1080/09296174.2017.1304049&#34;&gt;https://doi.org/10.1080/09296174.2017.1304049&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kernot, D., Bossomaier, T., &amp;amp; Bradbury, R. (2018). Using Shakespeare&#39;s Sotto Voce to Determine True Identity From Text. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;, 289. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2018.00289&#34;&gt;https://doi.org/10.3389/fpsyg.2018.00289&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kernot, D., Bossomaier, T., &amp;amp; Bradbury, R. (2019). The Stylometric Impacts of Ageing and Life Events on Identity. &lt;em&gt;Journal of Quantitative Linguistics&lt;/em&gt;, &lt;em&gt;26&lt;/em&gt;(1), 1&amp;ndash;21. &lt;a href=&#34;https://doi.org/10.1080/09296174.2017.1405719&#34;&gt;https://doi.org/10.1080/09296174.2017.1405719&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Khatin-Zadeh, O., Hu, J., Banaruee, H., &amp;amp; Marmolejo-Ramos, F. (2023). How emotions are metaphorically embodied: Measuring hand and head action strengths of typical emotional states. &lt;em&gt;Cognition and Emotion&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(3), 486&amp;ndash;498. &lt;a href=&#34;https://doi.org/10.1080/02699931.2023.2181314&#34;&gt;https://doi.org/10.1080/02699931.2023.2181314&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kiefer, M., Pielke, L., &amp;amp; Trumpp, N. M. (2022). Differential temporo-spatial pattern of electrical brain activity during the processing of abstract concepts related to mental states and verbal associations. &lt;em&gt;NeuroImage&lt;/em&gt;, &lt;em&gt;252&lt;/em&gt;, 119036. &lt;a href=&#34;https://doi.org/10.1016/j.neuroimage.2022.119036&#34;&gt;https://doi.org/10.1016/j.neuroimage.2022.119036&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kim, M.-K., Müller, H. M., &amp;amp; Weiss, S. (2021). What you &amp;ldquo;mean&amp;rdquo; is not what I &amp;ldquo;mean&amp;rdquo;: Categorization of verbs by Germans and Koreans using the semantic differential. &lt;em&gt;Lingua&lt;/em&gt;, &lt;em&gt;252&lt;/em&gt;, 103012. &lt;a href=&#34;https://doi.org/10.1016/j.lingua.2020.103012&#34;&gt;https://doi.org/10.1016/j.lingua.2020.103012&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Koblet, O., &amp;amp; Purves, R. S. (2020). From online texts to Landscape Character Assessment: Collecting and analysing first-person landscape perception computationally. &lt;em&gt;Landscape and Urban Planning&lt;/em&gt;, &lt;em&gt;197&lt;/em&gt;, 103757. &lt;a href=&#34;https://doi.org/10.1016/j.landurbplan.2020.103757&#34;&gt;https://doi.org/10.1016/j.landurbplan.2020.103757&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Körner, A., Castillo, M., Drijvers, L., Fischer, M. H., Günther, F., Marelli, M., Platonova, O., Rinaldi, L., Shaki, S., Trujillo, J. P., Tsaregorodtseva, O., &amp;amp; Glenberg, A. M. (2023). Embodied Processing at Six Linguistic Granularity Levels: A Consensus Paper. &lt;em&gt;Journal of Cognition&lt;/em&gt;, &lt;em&gt;6&lt;/em&gt;(1), 60. &lt;a href=&#34;https://doi.org/10.5334/joc.231&#34;&gt;https://doi.org/10.5334/joc.231&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Krishna, P. P., Arulmozi, S., &amp;amp; Mishra, R. K. (2022). &amp;ldquo;Do You See and Hear More? A Study on Telugu Perception Verbs.&amp;rdquo; &lt;em&gt;Journal of Psycholinguistic Research&lt;/em&gt;, &lt;em&gt;51&lt;/em&gt;(3), 473&amp;ndash;484. &lt;a href=&#34;https://doi.org/10.1007/s10936-021-09827-7&#34;&gt;https://doi.org/10.1007/s10936-021-09827-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kumcu, A. (2021). Linguistic Synesthesia in Turkish: A Corpus-based Study of Crossmodal Directionality. &lt;em&gt;Metaphor and Symbol&lt;/em&gt;, &lt;em&gt;36&lt;/em&gt;(4), 241&amp;ndash;255. &lt;a href=&#34;https://doi.org/10.1080/10926488.2021.1921557&#34;&gt;https://doi.org/10.1080/10926488.2021.1921557&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lau, S. H., Huang, Y., Ferreira, V. S., &amp;amp; Vul, E. (2019). Perceptual features predict word frequency asymmetry across modalities. &lt;em&gt;Attention, Perception, &amp;amp; Psychophysics&lt;/em&gt;, &lt;em&gt;81&lt;/em&gt;(4), 1076&amp;ndash;1087. &lt;a href=&#34;https://doi.org/10.3758/s13414-019-01682-y&#34;&gt;https://doi.org/10.3758/s13414-019-01682-y&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lee, J., &amp;amp; Shin, J.-A. (2023). The cross-linguistic comparison of perceptual strength norms for Korean, English and L2 English. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;14&lt;/em&gt;, 1188909. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2023.1188909&#34;&gt;https://doi.org/10.3389/fpsyg.2023.1188909&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Li, M., Lu, Q., Long, Y., &amp;amp; Gui, L. (2017). Inferring Affective Meanings of Words from Word Embedding. &lt;em&gt;IEEE Transactions on Affective Computing&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;(4), 443&amp;ndash;456. &lt;a href=&#34;https://doi.org/10.1109/TAFFC.2017.2723012&#34;&gt;https://doi.org/10.1109/TAFFC.2017.2723012&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Littlemore, J., Sobrino, P. P., Houghton, D., Shi, J., &amp;amp; Winter, B. (2018). What makes a good metaphor? A cross-cultural study of computer-generated metaphor appreciation. &lt;em&gt;Metaphor and Symbol&lt;/em&gt;, &lt;em&gt;33&lt;/em&gt;(2), 101&amp;ndash;122. &lt;a href=&#34;https://doi.org/10.1080/10926488.2018.1434944&#34;&gt;https://doi.org/10.1080/10926488.2018.1434944&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Liu, W., Bansal, D., Daruna, A., &amp;amp; Chernova, S. (2023). Learning instance-level N-ary semantic knowledge at scale for robots operating in everyday environments. &lt;em&gt;Autonomous Robots&lt;/em&gt;, &lt;em&gt;47&lt;/em&gt;(5), 529&amp;ndash;547. &lt;a href=&#34;https://doi.org/10.1007/s10514-023-10099-4&#34;&gt;https://doi.org/10.1007/s10514-023-10099-4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Liu, W., Bansal, D., Daruna, A., &amp;amp; Chernova, S. (2021, July 12). Learning Instance-Level N-Ary Semantic Knowledge At Scale For Robots Operating in Everyday Environments. &lt;em&gt;Robotics: Science and Systems XVII&lt;/em&gt;. Robotics: Science and Systems 2021. &lt;a href=&#34;https://doi.org/10.15607/RSS.2021.XVII.035&#34;&gt;https://doi.org/10.15607/RSS.2021.XVII.035&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Long, Y., Xiang, R., Lu, Q., Huang, C.-R., &amp;amp; Li, M. (2021). Improving Attention Model Based on Cognition Grounded Data for Sentiment Analysis. &lt;em&gt;IEEE Transactions on Affective Computing&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(4), 900&amp;ndash;912. &lt;a href=&#34;https://doi.org/10.1109/TAFFC.2019.2903056&#34;&gt;https://doi.org/10.1109/TAFFC.2019.2903056&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lynott, D., Connell, L., Brysbaert, M., Brand, J., &amp;amp; Carney, J. (2020). The Lancaster Sensorimotor Norms: Multidimensional measures of perceptual and action strength for 40,000 English words. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;52&lt;/em&gt;(3), 1271&amp;ndash;1291. &lt;a href=&#34;https://doi.org/10.3758/s13428-019-01316-z&#34;&gt;https://doi.org/10.3758/s13428-019-01316-z&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Mahmood, A., &amp;amp; Yeganegi, S. (2023). Lexical sophistication and crowdfunding outcomes. &lt;em&gt;Venture Capital&lt;/em&gt;, 1&amp;ndash;32. &lt;a href=&#34;https://doi.org/10.1080/13691066.2023.2265565&#34;&gt;https://doi.org/10.1080/13691066.2023.2265565&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Marson, F., Paoletti, P., Naor-Ziv, R., Carducci, F., &amp;amp; Ben-Soussan, T. D. (2023). Embodied empathy and abstract concepts&amp;rsquo; concreteness: Evidence from contemplative practices. In &lt;em&gt;Progress in Brain Research&lt;/em&gt; (Vol. 277, pp. 181&amp;ndash;209). Elsevier. &lt;a href=&#34;https://doi.org/10.1016/bs.pbr.2022.12.005&#34;&gt;https://doi.org/10.1016/bs.pbr.2022.12.005&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Márton, Z. C., Türker, S., Rink, C., Brucker, M., Kriegel, S., Bodenmüller, T., &amp;amp; Riedel, S. (2018). Improving object orientation estimates by considering multiple viewpoints: Orientation histograms of symmetries and measurement models for view selection. &lt;em&gt;Autonomous Robots&lt;/em&gt;, &lt;em&gt;42&lt;/em&gt;(2), 423&amp;ndash;442. &lt;a href=&#34;https://doi.org/10.1007/s10514-017-9633-1&#34;&gt;https://doi.org/10.1007/s10514-017-9633-1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Miceli, A., Wauthia, E., Kandana Arachchige, K., Lefebvre, L., Ris, L., &amp;amp; Simoes Loureiro, I. (2023). Perceptual strength influences lexical decision in Alzheimer&#39;s disease. &lt;em&gt;Journal of Neurolinguistics&lt;/em&gt;, &lt;em&gt;68&lt;/em&gt;, 101144. &lt;a href=&#34;https://doi.org/10.1016/j.jneuroling.2023.101144&#34;&gt;https://doi.org/10.1016/j.jneuroling.2023.101144&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Miceli, A., Wauthia, E., Lefebvre, L., Ris, L., &amp;amp; Simoes Loureiro, I. (2021). Perceptual and Interoceptive Strength Norms for 270 French Words. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;, 667271. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2021.667271&#34;&gt;https://doi.org/10.3389/fpsyg.2021.667271&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Miceli, A., Wauthia, E., Lefebvre, L., Vallet, G. T., Ris, L., &amp;amp; Loureiro, I. S. (2022). Differences related to aging in sensorimotor knowledge: Investigation of perceptual strength and body object interaction. &lt;em&gt;Archives of Gerontology and Geriatrics&lt;/em&gt;, &lt;em&gt;102&lt;/em&gt;, 104715. &lt;a href=&#34;https://doi.org/10.1016/j.archger.2022.104715&#34;&gt;https://doi.org/10.1016/j.archger.2022.104715&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Miklashevsky, A. (2018). Perceptual Experience Norms for 506 Russian Nouns: Modality Rating, Spatial Localization, Manipulability, Imageability and Other Variables. &lt;em&gt;Journal of Psycholinguistic Research&lt;/em&gt;, &lt;em&gt;47&lt;/em&gt;(3), 641&amp;ndash;661. &lt;a href=&#34;https://doi.org/10.1007/s10936-017-9548-1&#34;&gt;https://doi.org/10.1007/s10936-017-9548-1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Morucci, P., Bottini, R., &amp;amp; Crepaldi, D. (2019). Augmented Modality Exclusivity Norms for Concrete and Abstract Italian Property Words. &lt;em&gt;Journal of Cognition&lt;/em&gt;, &lt;em&gt;2&lt;/em&gt;(1), 42. &lt;a href=&#34;https://doi.org/10.5334/joc.88&#34;&gt;https://doi.org/10.5334/joc.88&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Okuno, H. Y., &amp;amp; Guedes, G. (2020). Automatic XML creation for Multisensorial Books. &lt;em&gt;2020 XV Conferencia Latinoamericana de Tecnologias de Aprendizaje (LACLO)&lt;/em&gt;, 1&amp;ndash;6. &lt;a href=&#34;https://doi.org/10.1109/LACLO50806.2020.9381139&#34;&gt;https://doi.org/10.1109/LACLO50806.2020.9381139&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pathak, A., Velasco, C., Petit, O., &amp;amp; Calvert, G. A. (2019). Going to great lengths in the pursuit of luxury: How longer brand names can enhance the luxury perception of a brand. &lt;em&gt;Psychology &amp;amp; Marketing&lt;/em&gt;, &lt;em&gt;36&lt;/em&gt;(10), 951&amp;ndash;963. &lt;a href=&#34;https://doi.org/10.1002/mar.21247&#34;&gt;https://doi.org/10.1002/mar.21247&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pérez-Sánchez, M. Á., Stadthagen-Gonzalez, H., Guasch, M., Hinojosa, J. A., Fraga, I., Marín, J., &amp;amp; Ferré, P. (2021). EmoPro &amp;ndash; Emotional prototypicality for 1286 Spanish words: Relationships with affective and psycholinguistic variables. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;53&lt;/em&gt;(5), 1857&amp;ndash;1875. &lt;a href=&#34;https://doi.org/10.3758/s13428-020-01519-9&#34;&gt;https://doi.org/10.3758/s13428-020-01519-9&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Perlman, M., Little, H., Thompson, B., &amp;amp; Thompson, R. L. (2018). Iconicity in Signed and Spoken Vocabulary: A Comparison Between American Sign Language, British Sign Language, English, and Spanish. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;, 1433. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2018.01433&#34;&gt;https://doi.org/10.3389/fpsyg.2018.01433&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pexman, P. M., Muraki, E., Sidhu, D. M., Siakaluk, P. D., &amp;amp; Yap, M. J. (2019). Quantifying sensorimotor experience: Body&amp;ndash;object interaction ratings for more than 9,000 English words. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;51&lt;/em&gt;(2), 453&amp;ndash;466. &lt;a href=&#34;https://doi.org/10.3758/s13428-018-1171-z&#34;&gt;https://doi.org/10.3758/s13428-018-1171-z&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Plekhanov Russian University of Economics, Simonenko, M. A., Kazaryan, S. Y., &amp;amp; Plekhanov Russian University of Economics. (2023). Synaesthetic metaphor and its reproduction in Russian-to-English translation: A frame-based study. &lt;em&gt;RESEARCH RESULT Theoretical and Applied Linguistics&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;(3). &lt;a href=&#34;https://doi.org/10.18413/2313-8912-2023-9-3-0-2&#34;&gt;https://doi.org/10.18413/2313-8912-2023-9-3-0-2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pollock, L. (2018). Statistical and methodological problems with concreteness and other semantic variables: A list memory experiment case study. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;50&lt;/em&gt;(3), 1198&amp;ndash;1216. &lt;a href=&#34;https://doi.org/10.3758/s13428-017-0938-y&#34;&gt;https://doi.org/10.3758/s13428-017-0938-y&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Popović Stijačić, M., &amp;amp; Filipović Đurđević, D. (2022). Perceptual richness of words and its role in free and cued recall. &lt;em&gt;Primenjena Psihologija&lt;/em&gt;, &lt;em&gt;15&lt;/em&gt;(3), 355&amp;ndash;381. &lt;a href=&#34;https://doi.org/10.19090/pp.v15i3.2400&#34;&gt;https://doi.org/10.19090/pp.v15i3.2400&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Purves, R. S., Striedl, P., Kong, I., &amp;amp; Majid, A. (2023). Conceptualizing Landscapes Through Language: The Role of Native Language and Expertise in the Representation of Waterbody Related Terms. &lt;em&gt;Topics in Cognitive Science&lt;/em&gt;, &lt;em&gt;15&lt;/em&gt;(3), 560&amp;ndash;583. &lt;a href=&#34;https://doi.org/10.1111/tops.12652&#34;&gt;https://doi.org/10.1111/tops.12652&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Raj, R., Hörberg, T., Lindroos, R., Larsson, M., Herman, P., Laukka, E. J., &amp;amp; Olofsson, J. K. (2023). Odor identification errors reveal cognitive aspects of age-associated smell loss. &lt;em&gt;Cognition&lt;/em&gt;, &lt;em&gt;236&lt;/em&gt;, 105445. &lt;a href=&#34;https://doi.org/10.1016/j.cognition.2023.105445&#34;&gt;https://doi.org/10.1016/j.cognition.2023.105445&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Repetto, C., Rodella, C., Conca, F., Santi, G. C., &amp;amp; Catricalà, E. (2022). The Italian Sensorimotor Norms: Perception and action strength measures for 959 words. &lt;em&gt;Behavior Research Methods&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.3758/s13428-022-02004-1&#34;&gt;https://doi.org/10.3758/s13428-022-02004-1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Rey, A. E., Riou, B., Vallet, G. T., &amp;amp; Versace, R. (2017). The automatic visual simulation of words: A memory reactivated mask slows down conceptual access. &lt;em&gt;Canadian Journal of Experimental Psychology / Revue Canadienne de Psychologie Expérimentale&lt;/em&gt;, &lt;em&gt;71&lt;/em&gt;(1), 14&amp;ndash;22. &lt;a href=&#34;https://doi.org/10.1037/cep0000100&#34;&gt;https://doi.org/10.1037/cep0000100&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Reymore, L. (2022). Characterizing prototypical musical instrument timbres with timbre trait profiles. &lt;em&gt;Musicae Scientiae&lt;/em&gt;, &lt;em&gt;26&lt;/em&gt;(3), 648&amp;ndash;674. &lt;a href=&#34;https://doi.org/10.1177/10298649211001523&#34;&gt;https://doi.org/10.1177/10298649211001523&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;San Roque, L., Kendrick, K. H., Norcliffe, E., &amp;amp; Majid, A. (2018). Universal meaning extensions of perception verbs are grounded in interaction. &lt;em&gt;Cognitive Linguistics&lt;/em&gt;, &lt;em&gt;29&lt;/em&gt;(3), 371&amp;ndash;406. &lt;a href=&#34;https://doi.org/10.1515/cog-2017-0034&#34;&gt;https://doi.org/10.1515/cog-2017-0034&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Scerrati, E., Lugli, L., Nicoletti, R., &amp;amp; Borghi, A. M. (2017). The Multilevel Modality-Switch Effect: What Happens When We See the Bees Buzzing and Hear the Diamonds Glistening. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;24&lt;/em&gt;(3), 798&amp;ndash;803. &lt;a href=&#34;https://doi.org/10.3758/s13423-016-1150-2&#34;&gt;https://doi.org/10.3758/s13423-016-1150-2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Schulte Im Walde, S., &amp;amp; Frassinelli, D. (2022). Distributional Measures of Semantic Abstraction. &lt;em&gt;Frontiers in Artificial Intelligence&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;, 796756. &lt;a href=&#34;https://doi.org/10.3389/frai.2021.796756&#34;&gt;https://doi.org/10.3389/frai.2021.796756&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Sidhu, D. M., &amp;amp; Pexman, P. M. (2018). Lonely sensational icons: Semantic neighbourhood density, sensory experience and iconicity. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;33&lt;/em&gt;(1), 25&amp;ndash;31. &lt;a href=&#34;https://doi.org/10.1080/23273798.2017.1358379&#34;&gt;https://doi.org/10.1080/23273798.2017.1358379&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speed, L. J., &amp;amp; Brybaert, M. (2022). Dutch sensory modality norms. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;54&lt;/em&gt;(3), 1306&amp;ndash;1318. &lt;a href=&#34;https://doi.org/10.3758/s13428-021-01656-9&#34;&gt;https://doi.org/10.3758/s13428-021-01656-9&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speed, L. J., &amp;amp; Majid, A. (2017). Dutch modality exclusivity norms: Simulating perceptual modality in space. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;49&lt;/em&gt;(6), 2204&amp;ndash;2218. &lt;a href=&#34;https://doi.org/10.3758/s13428-017-0852-3&#34;&gt;https://doi.org/10.3758/s13428-017-0852-3&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speed, L. J., &amp;amp; Majid, A. (2018). An Exception to Mental Simulation: No Evidence for Embodied Odor Language. &lt;em&gt;Cognitive Science&lt;/em&gt;, &lt;em&gt;42&lt;/em&gt;(4), 1146&amp;ndash;1178. &lt;a href=&#34;https://doi.org/10.1111/cogs.12593&#34;&gt;https://doi.org/10.1111/cogs.12593&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speed, L. J., &amp;amp; Majid, A. (2020). Grounding language in the neglected senses of touch, taste, and smell. &lt;em&gt;Cognitive Neuropsychology&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(5&amp;ndash;6), 363&amp;ndash;392. &lt;a href=&#34;https://doi.org/10.1080/02643294.2019.1623188&#34;&gt;https://doi.org/10.1080/02643294.2019.1623188&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speed, L. J., Papies, E. K., &amp;amp; Majid, A. (2023). Mental simulation across sensory modalities predicts attractiveness of food concepts. &lt;em&gt;Journal of Experimental Psychology: Applied&lt;/em&gt;, &lt;em&gt;29&lt;/em&gt;(3), 557&amp;ndash;571. &lt;a href=&#34;https://doi.org/10.1037/xap0000461&#34;&gt;https://doi.org/10.1037/xap0000461&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Strik Lievers, F., &amp;amp; Winter, B. (2018). Sensory language across lexical categories. &lt;em&gt;Lingua&lt;/em&gt;, &lt;em&gt;204&lt;/em&gt;, 45&amp;ndash;61. &lt;a href=&#34;https://doi.org/10.1016/j.lingua.2017.11.002&#34;&gt;https://doi.org/10.1016/j.lingua.2017.11.002&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Su, C., Wang, X., Wang, Z., &amp;amp; Chen, Y. (2019). A model of synesthetic metaphor interpretation based on cross-modality similarity. &lt;em&gt;Computer Speech &amp;amp; Language&lt;/em&gt;, &lt;em&gt;58&lt;/em&gt;, 1&amp;ndash;16. &lt;a href=&#34;https://doi.org/10.1016/j.csl.2019.03.003&#34;&gt;https://doi.org/10.1016/j.csl.2019.03.003&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tatiya, G., Hosseini, R., Hughes, M. C., &amp;amp; Sinapov, J. (2019). Sensorimotor Cross-Behavior Knowledge Transfer for Grounded Category Recognition. &lt;em&gt;2019 Joint IEEE 9th International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob)&lt;/em&gt;, 1&amp;ndash;6. &lt;a href=&#34;https://doi.org/10.1109/DEVLRN.2019.8850715&#34;&gt;https://doi.org/10.1109/DEVLRN.2019.8850715&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tatiya, G., Hosseini, R., Hughes, M. C., &amp;amp; Sinapov, J. (2020). A Framework for Sensorimotor Cross-Perception and Cross-Behavior Knowledge Transfer for Object Categorization. &lt;em&gt;Frontiers in Robotics and AI&lt;/em&gt;, &lt;em&gt;7&lt;/em&gt;, 522141. &lt;a href=&#34;https://doi.org/10.3389/frobt.2020.522141&#34;&gt;https://doi.org/10.3389/frobt.2020.522141&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tatiya, G., &amp;amp; Sinapov, J. (2019). Deep Multi-Sensory Object Category Recognition Using Interactive Behavioral Exploration. &lt;em&gt;2019 International Conference on Robotics and Automation (ICRA)&lt;/em&gt;, 7872&amp;ndash;7878. &lt;a href=&#34;https://doi.org/10.1109/ICRA.2019.8794095&#34;&gt;https://doi.org/10.1109/ICRA.2019.8794095&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Teodorescu, H.-N., &amp;amp; Bolea, S. C. (2019). Text Sectioning based on Stylometric Distances. &lt;em&gt;2019 International Conference on Speech Technology and Human-Computer Dialogue (SpeD)&lt;/em&gt;, 1&amp;ndash;6. &lt;a href=&#34;https://doi.org/10.1109/SPED.2019.8906616&#34;&gt;https://doi.org/10.1109/SPED.2019.8906616&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thomason, J., Padmakumar, A., Sinapov, J., Walker, N., Jiang, Y., Yedidsion, H., Hart, J., Stone, P., &amp;amp; Mooney, R. (2020). Jointly Improving Parsing and Perception for Natural Language Commands through Human-Robot Dialog. &lt;em&gt;Journal of Artificial Intelligence Research&lt;/em&gt;, &lt;em&gt;67&lt;/em&gt;, 327&amp;ndash;374. &lt;a href=&#34;https://doi.org/10.1613/jair.1.11485&#34;&gt;https://doi.org/10.1613/jair.1.11485&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tjuka, A., Forkel, R., &amp;amp; List, J.-M. (2021). Linking norms, ratings, and relations of words and concepts across multiple language varieties. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;54&lt;/em&gt;(2), 864&amp;ndash;884. &lt;a href=&#34;https://doi.org/10.3758/s13428-021-01650-1&#34;&gt;https://doi.org/10.3758/s13428-021-01650-1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tomsk State University, Rezanova, Z. I., Nekrasova, E. D., Tomsk State University, Miklashevsky, А. А., &amp;amp; Tomsk State University. (2018). INVESTIGATION OF PSYCHO-LINGUISTIC AND COGNITIVE ASPECTS OF LANGUAGE CONTACTING IN THE PROJECT &amp;ldquo;LINGUISTIC AND ETHNOCULTURAL DIVERSITY OF SOUTHERN SIBERIA IN SYNCHRONY AND DIAHRONY: INTERACTION OF LANGUAGES AND CULTURES.&amp;rdquo; &lt;em&gt;Rusin&lt;/em&gt;, &lt;em&gt;52&lt;/em&gt;, 107&amp;ndash;117. &lt;a href=&#34;https://doi.org/10.17223/18572685/52/8&#34;&gt;https://doi.org/10.17223/18572685/52/8&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tomsk State University, Vladimirova, V. E., Rezanova, Z. I., Tomsk State University, Korshunova, I. S., &amp;amp; Tomsk State University. (2022). Ethno-linguistic contact as reflected in language cognition: Does bilingualism affect subjective assessments of perceptual semantics?*. &lt;em&gt;Rusin&lt;/em&gt;, &lt;em&gt;70&lt;/em&gt;, 214&amp;ndash;231. &lt;a href=&#34;https://doi.org/10.17223/18572685/70/12&#34;&gt;https://doi.org/10.17223/18572685/70/12&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Troche, J., Crutch, S. J., &amp;amp; Reilly, J. (2017). Defining a Conceptual Topography of Word Concreteness: Clustering Properties of Emotion, Sensation, and Magnitude among 750 English Words. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;, 1787. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2017.01787&#34;&gt;https://doi.org/10.3389/fpsyg.2017.01787&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Van De Weijer, J., Bianchi, I., &amp;amp; Paradis, C. (2023). Sensory modality profiles of antonyms. &lt;em&gt;Language and Cognition&lt;/em&gt;, 1&amp;ndash;15. &lt;a href=&#34;https://doi.org/10.1017/langcog.2023.20&#34;&gt;https://doi.org/10.1017/langcog.2023.20&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Vergallito, A., Petilli, M. A., &amp;amp; Marelli, M. (2020). Perceptual modality norms for 1,121 Italian words: A comparison with concreteness and imageability scores and an analysis of their impact in word processing tasks. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;52&lt;/em&gt;(4), 1599&amp;ndash;1616. &lt;a href=&#34;https://doi.org/10.3758/s13428-019-01337-8&#34;&gt;https://doi.org/10.3758/s13428-019-01337-8&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Verheyen, S., De Deyne, S., Linsen, S., &amp;amp; Storms, G. (2020). Lexicosemantic, affective, and distributional norms for 1,000 Dutch adjectives. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;52&lt;/em&gt;(3), 1108&amp;ndash;1121. &lt;a href=&#34;https://doi.org/10.3758/s13428-019-01303-4&#34;&gt;https://doi.org/10.3758/s13428-019-01303-4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Vigliocco, G., Zhang, Y., Del Maschio, N., Todd, R., &amp;amp; Tuomainen, J. (2020). Electrophysiological signatures of English onomatopoeia. &lt;em&gt;Language and Cognition&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(1), 15&amp;ndash;35. &lt;a href=&#34;https://doi.org/10.1017/langcog.2019.38&#34;&gt;https://doi.org/10.1017/langcog.2019.38&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Villani, C., D&#39;Ascenzo, S., Borghi, A. M., Roversi, C., Benassi, M., &amp;amp; Lugli, L. (2022). Is justice grounded? How expertise shapes conceptual representation of institutional concepts. &lt;em&gt;Psychological Research&lt;/em&gt;, &lt;em&gt;86&lt;/em&gt;(8), 2434&amp;ndash;2450. &lt;a href=&#34;https://doi.org/10.1007/s00426-021-01492-8&#34;&gt;https://doi.org/10.1007/s00426-021-01492-8&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Villani, C., Lugli, L., Liuzza, M. T., &amp;amp; Borghi, A. M. (2019). Varieties of abstract concepts and their multiple dimensions. &lt;em&gt;Language and Cognition&lt;/em&gt;, &lt;em&gt;11&lt;/em&gt;(3), 403&amp;ndash;430. &lt;a href=&#34;https://doi.org/10.1017/langcog.2019.23&#34;&gt;https://doi.org/10.1017/langcog.2019.23&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wan, M., Su, Q., Ahrens, K., &amp;amp; Huang, C.-R. (2023). Perceptional and actional enrichment for metaphor detection with sensorimotor norms. &lt;em&gt;Natural Language Engineering&lt;/em&gt;, 1&amp;ndash;29. &lt;a href=&#34;https://doi.org/10.1017/S135132492300044X&#34;&gt;https://doi.org/10.1017/S135132492300044X&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wang, X., Su, C., &amp;amp; Chen, Y. (2019). A Method of Abstractness Ratings for Chinese Concepts. In A. Lotfi, H. Bouchachia, A. Gegov, C. Langensiepen, &amp;amp; M. McGinnity (Eds.), &lt;em&gt;Advances in Computational Intelligence Systems&lt;/em&gt; (Vol. 840, pp. 217&amp;ndash;226). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-319-97982-3_18&#34;&gt;https://doi.org/10.1007/978-3-319-97982-3_18&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wang, Y., &amp;amp; Zeng, Y. (2022a). Multisensory Concept Learning Framework Based on Spiking Neural Networks. &lt;em&gt;Frontiers in Systems Neuroscience&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;, 845177. &lt;a href=&#34;https://doi.org/10.3389/fnsys.2022.845177&#34;&gt;https://doi.org/10.3389/fnsys.2022.845177&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wang, Y., &amp;amp; Zeng, Y. (2022b). Statistical Analysis of Multisensory and Text-Derived Representations on Concept Learning. &lt;em&gt;Frontiers in Computational Neuroscience&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;, 861265. &lt;a href=&#34;https://doi.org/10.3389/fncom.2022.861265&#34;&gt;https://doi.org/10.3389/fncom.2022.861265&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wicke, P., &amp;amp; Bolognesi, M. (2020). Emoji-based semantic representations for abstract and concrete concepts. &lt;em&gt;Cognitive Processing&lt;/em&gt;, &lt;em&gt;21&lt;/em&gt;(4), 615&amp;ndash;635. &lt;a href=&#34;https://doi.org/10.1007/s10339-020-00971-x&#34;&gt;https://doi.org/10.1007/s10339-020-00971-x&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B. (2019). &lt;em&gt;Statistics for Linguists: An Introduction Using R&lt;/em&gt; (1st ed.). Routledge. &lt;a href=&#34;https://doi.org/10.4324/9781315165547&#34;&gt;https://doi.org/10.4324/9781315165547&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B. (2022). Mapping the landscape of exploratory and confirmatory data analysis in linguistics. In D. Tay &amp;amp; M. X. Pan (Eds.), &lt;em&gt;Data Analytics in Cognitive Linguistics&lt;/em&gt; (pp. 13&amp;ndash;48). De Gruyter. &lt;a href=&#34;https://doi.org/10.1515/9783110687279-002&#34;&gt;https://doi.org/10.1515/9783110687279-002&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B. (2023). Abstract concepts and emotion: Cross-linguistic evidence and arguments against affective embodiment. &lt;em&gt;Philosophical Transactions of the Royal Society B: Biological Sciences&lt;/em&gt;, &lt;em&gt;378&lt;/em&gt;(1870), 20210368. &lt;a href=&#34;https://doi.org/10.1098/rstb.2021.0368&#34;&gt;https://doi.org/10.1098/rstb.2021.0368&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B., Lupyan, G., Perry, L. K., Dingemanse, M., &amp;amp; Perlman, M. (2023). Iconicity ratings for 14,000+ English words. &lt;em&gt;Behavior Research Methods&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.3758/s13428-023-02112-6&#34;&gt;https://doi.org/10.3758/s13428-023-02112-6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B., &amp;amp; Perlman, M. (2021). Size sound symbolism in the English lexicon. &lt;em&gt;Glossa: A Journal of General Linguistics&lt;/em&gt;, &lt;em&gt;6&lt;/em&gt;(1). &lt;a href=&#34;https://doi.org/10.5334/gjgl.1646&#34;&gt;https://doi.org/10.5334/gjgl.1646&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B., Perlman, M., &amp;amp; Majid, A. (2018). Vision dominates in perceptual language: English sensory vocabulary is optimized for usage. &lt;em&gt;Cognition&lt;/em&gt;, &lt;em&gt;179&lt;/em&gt;, 213&amp;ndash;220. &lt;a href=&#34;https://doi.org/10.1016/j.cognition.2018.05.008&#34;&gt;https://doi.org/10.1016/j.cognition.2018.05.008&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B., Perlman, M., Perry, L. K., &amp;amp; Lupyan, G. (2017). Which words are most iconic?: Iconicity in English sensory words. &lt;em&gt;Interaction Studies. Social Behaviour and Communication in Biological and Artificial Systems&lt;/em&gt;, &lt;em&gt;18&lt;/em&gt;(3), 443&amp;ndash;464. &lt;a href=&#34;https://doi.org/10.1075/is.18.3.07win&#34;&gt;https://doi.org/10.1075/is.18.3.07win&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B., Sóskuthy, M., Perlman, M., &amp;amp; Dingemanse, M. (2022). Trilled /r/ is associated with roughness, linking sound and touch across spoken languages. &lt;em&gt;Scientific Reports&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(1), 1035. &lt;a href=&#34;https://doi.org/10.1038/s41598-021-04311-7&#34;&gt;https://doi.org/10.1038/s41598-021-04311-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B., &amp;amp; Strik-Lievers, F. (2023). Semantic distance predicts metaphoricity and creativity judgments in synesthetic metaphors. &lt;em&gt;Metaphor and the Social World&lt;/em&gt;, &lt;em&gt;13&lt;/em&gt;(1), 59&amp;ndash;80. &lt;a href=&#34;https://doi.org/10.1075/msw.00029.win&#34;&gt;https://doi.org/10.1075/msw.00029.win&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wu, C., &amp;amp; Mu, X. (2023). Sensory experience ratings (SERs) for 1,130 Chinese words: Relationships with other semantic and lexical psycholinguistic variables. &lt;em&gt;Linguistics Vanguard&lt;/em&gt;, &lt;em&gt;0&lt;/em&gt;(0). &lt;a href=&#34;https://doi.org/10.1515/lingvan-2022-0083&#34;&gt;https://doi.org/10.1515/lingvan-2022-0083&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Xiong, J., &amp;amp; Huang, C.-R. (2018). Somewhere in COLDNESS Lies Nibbāna: Lexical Manifestations of COLDNESS. In J.-F. Hong, Q. Su, &amp;amp; J.-S. Wu (Eds.), &lt;em&gt;Chinese Lexical Semantics&lt;/em&gt; (Vol. 11173, pp. 70&amp;ndash;81). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-04015-4_6&#34;&gt;https://doi.org/10.1007/978-3-030-04015-4_6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Yin Zhong, &amp;amp; Chu-Ren Huang. (2020). Sweetness or Mouthfeel: A corpus-based study of the conceptualization of taste. &lt;em&gt;Linguistic Research&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(3), 359&amp;ndash;387. &lt;a href=&#34;https://doi.org/10.17250/KHISLI.37.3.202012.001&#34;&gt;https://doi.org/10.17250/KHISLI.37.3.202012.001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zeng, Y., Zhao, D., Zhao, F., Shen, G., Dong, Y., Lu, E., Zhang, Q., Sun, Y., Liang, Q., Zhao, Y., Zhao, Z., Fang, H., Wang, Y., Li, Y., Liu, X., Du, C., Kong, Q., Ruan, Z., &amp;amp; Bi, W. (2023). BrainCog: A spiking neural network based, brain-inspired cognitive intelligence engine for brain-inspired AI and brain simulation. &lt;em&gt;Patterns&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(8), 100789. &lt;a href=&#34;https://doi.org/10.1016/j.patter.2023.100789&#34;&gt;https://doi.org/10.1016/j.patter.2023.100789&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhang, X., Amiri, S., Sinapov, J., Thomason, J., Stone, P., &amp;amp; Zhang, S. (2023). Multimodal embodied attribute learning by robots for object-centric action policies. &lt;em&gt;Autonomous Robots&lt;/em&gt;, &lt;em&gt;47&lt;/em&gt;(5), 505&amp;ndash;528. &lt;a href=&#34;https://doi.org/10.1007/s10514-023-10098-5&#34;&gt;https://doi.org/10.1007/s10514-023-10098-5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhang, X., Sinapov, J., &amp;amp; Zhang, S. (2021, July 12). Planning Multimodal Exploratory Actions for Online Robot Attribute Learning. &lt;em&gt;Robotics: Science and Systems XVII&lt;/em&gt;. Robotics: Science and Systems 2021. &lt;a href=&#34;https://doi.org/10.15607/RSS.2021.XVII.005&#34;&gt;https://doi.org/10.15607/RSS.2021.XVII.005&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q. (2020a). From Linguistic Synaesthesia to Conceptual Metaphor Theory. In Q. Zhao, &lt;em&gt;Embodied Conceptualization or Neural Realization&lt;/em&gt; (Vol. 10, pp. 115&amp;ndash;128). Springer Singapore. &lt;a href=&#34;https://doi.org/10.1007/978-981-32-9315-1_7&#34;&gt;https://doi.org/10.1007/978-981-32-9315-1_7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q. (2020b). Methodology: A Corpus-Driven Approach. In Q. Zhao, &lt;em&gt;Embodied Conceptualization or Neural Realization&lt;/em&gt; (Vol. 10, pp. 19&amp;ndash;34). Springer Singapore. &lt;a href=&#34;https://doi.org/10.1007/978-981-32-9315-1_2&#34;&gt;https://doi.org/10.1007/978-981-32-9315-1_2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q., Ahrens, K., &amp;amp; Huang, C.-R. (2022). Linguistic synesthesia is metaphorical: A lexical-conceptual account. &lt;em&gt;Cognitive Linguistics&lt;/em&gt;, &lt;em&gt;33&lt;/em&gt;(3), 553&amp;ndash;583. &lt;a href=&#34;https://doi.org/10.1515/cog-2021-0098&#34;&gt;https://doi.org/10.1515/cog-2021-0098&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q., Huang, C.-R., &amp;amp; Ahrens, K. (2019). Directionality of linguistic synesthesia in Mandarin: A corpus-based study. &lt;em&gt;Lingua&lt;/em&gt;, &lt;em&gt;232&lt;/em&gt;, 102744. &lt;a href=&#34;https://doi.org/10.1016/j.lingua.2019.102744&#34;&gt;https://doi.org/10.1016/j.lingua.2019.102744&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q., &amp;amp; Long, Y. (2022). A Diachronic Study on Linguistic Synesthesia in Chinese. In M. Dong, Y. Gu, &amp;amp; J.-F. Hong (Eds.), &lt;em&gt;Chinese Lexical Semantics&lt;/em&gt; (Vol. 13250, pp. 84&amp;ndash;94). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-031-06547-7_6&#34;&gt;https://doi.org/10.1007/978-3-031-06547-7_6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q., Long, Y., &amp;amp; Huang, C.-R. (2020). Linguistic Synaesthesia of Mandarin Sensory Adjectives: Corpus-Based and Experimental Approaches. In J.-F. Hong, Y. Zhang, &amp;amp; P. Liu (Eds.), &lt;em&gt;Chinese Lexical Semantics&lt;/em&gt; (Vol. 11831, pp. 139&amp;ndash;146). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-38189-9_14&#34;&gt;https://doi.org/10.1007/978-3-030-38189-9_14&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhong, Y., Ahrens, K., &amp;amp; Huang, C.-R. (2023). Entity, event, and sensory modalities: An onto-cognitive account of sensory nouns. &lt;em&gt;Humanities and Social Sciences Communications&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(1), 255. &lt;a href=&#34;https://doi.org/10.1057/s41599-023-01677-z&#34;&gt;https://doi.org/10.1057/s41599-023-01677-z&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhong, Y., Huang, C.-R., &amp;amp; Dong, S. (2022). Bodily sensation and embodiment: A corpus-based study of gustatory vocabulary in Mandarin Chinese. &lt;em&gt;Journal of Chinese Linguistics&lt;/em&gt;, &lt;em&gt;50&lt;/em&gt;(1), 196&amp;ndash;230. &lt;a href=&#34;https://doi.org/10.1353/jcl.2022.0008&#34;&gt;https://doi.org/10.1353/jcl.2022.0008&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhong, Y., Wan, M., Ahrens, K., &amp;amp; Huang, C.-R. (2022). Sensorimotor norms for Chinese nouns and their relationship with orthographic and semantic variables. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(8), 1000&amp;ndash;1022. &lt;a href=&#34;https://doi.org/10.1080/23273798.2022.2035416&#34;&gt;https://doi.org/10.1080/23273798.2022.2035416&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhu, S., Wang, X., &amp;amp; Liu, P. (2021). Who Killed Sanmao and Virginia Woolf? A Comparative Study of Writers with Suicidal Attempt Based on a Quantitative Linguistic Method. In M. Liu, C. Kit, &amp;amp; Q. Su (Eds.), &lt;em&gt;Chinese Lexical Semantics&lt;/em&gt; (Vol. 12278, pp. 408&amp;ndash;420). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-81197-6_34&#34;&gt;https://doi.org/10.1007/978-3-030-81197-6_34&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Language evolution: Current status and future directions</title>
      <link>https://pablobernabeu.github.io/publication/bernabeu_vogt2015/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/publication/bernabeu_vogt2015/</guid>
      <description>&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;div class = &#39;hanging-indent&#39;&gt;
&lt;p&gt;Bernabeu, P., &amp;amp; Vogt, P. (2015). Language evolution: Current status and future directions. &lt;em&gt;Tenth Language at the University of Essex (LangUE) Postgraduate Conference&lt;/em&gt;. &lt;a href=&#34;https://researchgate.net/publication/280858062/&#34;&gt;https://researchgate.net/publication/280858062/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
