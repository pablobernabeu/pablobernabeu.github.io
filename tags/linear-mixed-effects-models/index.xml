<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>linear-mixed effects models | Pablo Bernabeu</title>
    <link>https://pablobernabeu.github.io/tags/linear-mixed-effects-models/</link>
      <atom:link href="https://pablobernabeu.github.io/tags/linear-mixed-effects-models/index.xml" rel="self" type="application/rss+xml" />
    <description>linear-mixed effects models</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-uk</language><copyright>Pablo Bernabeu, 2015—2023. Licence: [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/). Email: pcbernabeu@gmail.com. No cookies operated by this website. Cookies only used by third-party systems such as [Disqus](https://help.disqus.com/en/articles/1717155-use-of-cookies).</copyright><lastBuildDate>Sat, 04 Nov 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://pablobernabeu.github.io/img/default_preview_image.png</url>
      <title>linear-mixed effects models</title>
      <link>https://pablobernabeu.github.io/tags/linear-mixed-effects-models/</link>
    </image>
    
    <item>
      <title>FAQs on mixed-effects models</title>
      <link>https://pablobernabeu.github.io/2023/faqs-on-mixed-effects-models/</link>
      <pubDate>Sat, 04 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/2023/faqs-on-mixed-effects-models/</guid>
      <description>


&lt;blockquote style=&#34;color: black; background-color: #FFF9F3; margin-bottom: 30px;&#34;&gt;
&lt;p&gt;I am dealing with nested data, and I remember from an article by &lt;a href=&#34;https://doi.org/10.1016/S0022-5371(73)80014-3&#34;&gt;Clark (1973)&lt;/a&gt; that nested should be analysed using special models. I’ve looked into mixed-effects models, and I’ve reached a structure with random intercepts by subjects and by items. Is this fine?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div style=&#34;padding-left: 60px;&#34;&gt;
&lt;blockquote style=&#34;color: black; background-color: #F4FFF3; margin-bottom: 45px;&#34;&gt;
&lt;p&gt;In early days, researchers would aggregate the data across these repeated measures to prevent the violation of the assumption of independence of observations, which is one of the most important assumptions in statistics. With the advent of mixed-effects models, researchers began accounting for these repeated measures using random intercepts and slopes. However, problems of convergence led many researchers to remove random slopes. This became widespread until, over the past few years, we have realised that random slopes are necessary to prevent an inflation of the Type I error due to the violation of the assumption of independence (&lt;a href=&#34;https://psych.wisc.edu/Brauer/BrauerLab/wp-content/uploads/2014/04/Brauer-Curtin-2018-on-LMEMs.pdf&#34;&gt;Brauer &amp;amp; Curtin, 2018&lt;/a&gt;; &lt;a href=&#34;http://singmann.org/download/publications/singmann_kellen-introduction-mixed-models.pdf&#34;&gt;Singmann &amp;amp; Kellen, 2019&lt;/a&gt;). Please see Table 17 in Brauer and Curtin (2018). Due to the present reasons, the models in the current article are anti-conservative. To redress this problem, please consider the inclusion of random slopes by participant for all between-items variables [e.g., &lt;code&gt;(stimulus_condition | participant)&lt;/code&gt;], and random slopes by item for all between-participants variables [e.g., &lt;code&gt;(extraversion | item)&lt;/code&gt;]. Interaction terms should also have the corresponding slopes, except when the variables in the interaction vary within different units, that is, one between participants and one between items (&lt;a href=&#34;https://psych.wisc.edu/Brauer/BrauerLab/wp-content/uploads/2014/04/Brauer-Curtin-2018-on-LMEMs.pdf&#34;&gt;Brauer &amp;amp; Curtin, 2018&lt;/a&gt;). Each of the random intercepts and random slopes included in the model should be noted in the main text, for instance using footnotes in the results table (see &lt;a href=&#34;https://bookdown.org/pablobernabeu/language-sensorimotor-conceptual-processing-statistical-power/study-2.1-semantic-priming.html#semanticpriming-results&#34;&gt;example&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;blockquote style=&#34;color: black; background-color: #FFF9F3; margin-bottom: 30px;&#34;&gt;
&lt;p&gt;I calculated the &lt;em&gt;p&lt;/em&gt; values by comparing minimally-different models using the &lt;code&gt;anova&lt;/code&gt; function. Is this fine?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div style=&#34;padding-left: 60px;&#34;&gt;
&lt;blockquote style=&#34;color: black; background-color: #F4FFF3; margin-bottom: 45px;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://doi.org/10.3758/s13428-016-0809-y&#34;&gt;Luke (2017)&lt;/a&gt; warns that the &lt;em&gt;p&lt;/em&gt; values calculated by model comparison—which are based on likelihood ratio tests—can be anti-conservative. Therefore, the Kenward-Roger and the Satterthwaite methods are recommended instead (both available in other packages, such as &lt;a href=&#34;https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf&#34;&gt;lmerTest&lt;/a&gt; and &lt;a href=&#34;https://cran.r-project.org/web/packages/afex/afex.pdf&#34;&gt;afex&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;blockquote style=&#34;color: black; background-color: #FFF9F3; margin-bottom: 30px;&#34;&gt;
&lt;p&gt;The lme4 package only runs on one thread (CPU) but the computer has 8. Do you have any advice on making the model run using more of the threads? It’s taking a very long time. I’ve seen these two possible solutions online from 2018 (&lt;a href=&#34;https://stackoverflow.com/questions/48315268/how-can-i-make-r-using-more-than-1-core-8-available-on-a-ubuntu-rstudio-server&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q3/027170.html&#34;&gt;here&lt;/a&gt;) but would like some advice if they have any or have attempted either of these solutions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div style=&#34;padding-left: 60px;&#34;&gt;
&lt;blockquote style=&#34;color: black; background-color: #F4FFF3; margin-bottom: 45px;&#34;&gt;
&lt;p&gt;From the information I have seen in the past as well as right now, parallelising (g)lmer intentionally would be very involved. There is certainly interest in it, as your resources show (also see &lt;a href=&#34;https://github.com/lme4/lme4/issues?q=is%3Aissue+parallel&#34;&gt;here&lt;/a&gt;). However, the current information suggests to me that it is not possible.&lt;/p&gt;
&lt;p&gt;Interestingly, some isolated cases of unintentional parallelisation have been documented, and the developers of the &lt;a href=&#34;https://cran.r-project.org/web/packages/lme4/lme4.pdf&#34;&gt;lme4&lt;/a&gt; package were &lt;a href=&#34;&#34;&gt;surprised about them&lt;/a&gt; because they have not created this feature (see &lt;a href=&#34;https://github.com/lme4/lme4/issues/492&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://github.com/lme4/lme4/issues/627&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;I think the best approach may be running your model(s) in a high-performance computing (HPC) cluster. Although this would not reduce the amount of time required for each model, it would have two advantages. First, your own computers wouldn’t be busy for days, and second, you could even run several models at the same time without exhausting your own computers. I still have access to the HPC at my previous university, and it would be fine for me to send your model(s) there if that would help you. Feel free to let me know. Otherwise I can see that your university has this facility too.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;blockquote style=&#34;color: black; background-color: #FFF9F3; margin-bottom: 30px;&#34;&gt;
&lt;p&gt;We took your advice and ran the model on a supercomputer - it took roughly 2.5 days, which is what it took for the model to run on my iMac and a gaming laptop Vivienne has.&lt;/p&gt;
&lt;p&gt;The model, however, didn’t converge. We have read that you can use &lt;code&gt;allFit()&lt;/code&gt; to try the fit with all available optimizers. Do you have any experience using this? If you did, I wondered where this would sit in the code for the model? How and where do I add this in to check all available optimizers, please?&lt;/p&gt;
&lt;p&gt;I have attached my code in a txt file and the data in excel for you to see, in case it is of any use.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div style=&#34;padding-left: 60px;&#34;&gt;
&lt;blockquote style=&#34;color: black; background-color: #F4FFF3; margin-bottom: 45px;&#34;&gt;
&lt;p&gt;The multi-optimizer check is indeed a way (albeit tentative) to probe into the convergence. Convergence has long been a fuzzy subject, as there are different standpoints depending on the degree of conservativeness that is sought after by the analysts.&lt;/p&gt;
&lt;p&gt;On Page 124 in my thesis (&lt;a href=&#34;https://osf.io/97u5c&#34; class=&#34;uri&#34;&gt;https://osf.io/97u5c&lt;/a&gt;), you can find this multi-optimizer check (also see this &lt;a href=&#34;https://pablobernabeu.github.io/2021/a-new-function-to-plot-convergence-diagnostics-from-lme4-allfit&#34;&gt;blog post&lt;/a&gt;). All the code is available on OSF. More generally, I discuss the issue of convergence throughout the thesis.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;blockquote style=&#34;color: black; background-color: #FFF9F3; margin-bottom: 30px;&#34;&gt;
&lt;p&gt;I have run the model with &lt;code&gt;optimizer=&#34;nloptwrap&#34;&lt;/code&gt; and &lt;code&gt;algorithm=&#34;NLOPT_LN_BOBYQA&#34;&lt;/code&gt; and received the following warning message (once the model ran) -&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;In optwrap(optimizer, devfun, start, rho$lower, control = control, :
convergence code 5 from nloptwrap: NLOPT_MAXEVAL_REACHED: optimization stopped becasue maxeval (above) was reached.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Does this mean that the model didn’t converge? I’m only asking because I wasn’t given a statement saying it didn’t converge, as it did with Nelder_Mead. It was stated (at the end of summary table)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Optimizer (Nelder_Mead) convergence code: 4 (failure to converge in 10000 evaluations)
failure to converge in 10000 evaluations&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;div style=&#34;padding-left: 60px;&#34;&gt;
&lt;blockquote style=&#34;color: black; background-color: #F4FFF3; margin-bottom: 45px;&#34;&gt;
&lt;p&gt;Please try &lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/frequentist_analysis/semanticpriming_lmerTest.R#L109&#34;&gt;increasing the max number of iterations&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;blockquote style=&#34;color: black; background-color: #FFF9F3; margin-bottom: 30px;&#34;&gt;
&lt;p&gt;We increased the max number of iterations to 1e6 and then 1e7, and the model didn’t converge. But it has converged with &lt;code&gt;maxeval=1e8&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I wanted to ask please, do you know of any issues with the max iterations being this high and effecting the interpretability of the model? Or is it completely fine?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div style=&#34;padding-left: 60px;&#34;&gt;
&lt;blockquote style=&#34;color: black; background-color: #F4FFF3; margin-bottom: 45px;&#34;&gt;
&lt;p&gt;There are no side-effects to increasing the number of iterations (see Remedy 6 in &lt;a href=&#34;https://psych.wisc.edu/Brauer/BrauerLab/wp-content/uploads/2014/04/Brauer-Curtin-2018-on-LMEMs.pdf&#34;&gt;Brauer &amp;amp; Curtin, 2018&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Who&#39;s through with convergence warnings? A list of papers that used &#39;allFit&#39; to check &#39;coefficients&#39; across &#39;optimizers&#39;</title>
      <link>https://pablobernabeu.github.io/2023/who-s-through-with-convergence-warnings-a-list-of-papers-that-used-allfit-to-check-coefficients-across-optimizers/</link>
      <pubDate>Sat, 08 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/2023/who-s-through-with-convergence-warnings-a-list-of-papers-that-used-allfit-to-check-coefficients-across-optimizers/</guid>
      <description>


</description>
    </item>
    
    <item>
      <title>How to break down colour variable in sjPlot::plot_model into equally-sized bins</title>
      <link>https://pablobernabeu.github.io/2023/how-to-break-down-colour-variable-in-sjplot-plot-model-into-equally-sized-bins/</link>
      <pubDate>Sat, 24 Jun 2023 16:54:46 +0200</pubDate>
      <guid>https://pablobernabeu.github.io/2023/how-to-break-down-colour-variable-in-sjplot-plot-model-into-equally-sized-bins/</guid>
      <description>


&lt;p&gt;Whereas the direction of main effects can be interpreted from the sign of the estimate, the interpretation of interaction effects often requires plots. This task is facilitated by the R package &lt;a href=&#34;https://strengejacke.github.io/sjPlot&#34;&gt;&lt;code&gt;sjPlot&lt;/code&gt;&lt;/a&gt;. For instance, using the &lt;code&gt;plot_model&lt;/code&gt; function, I plotted the interaction between two continuous variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lme4)
#&amp;gt; Loading required package: Matrix
library(sjPlot)
#&amp;gt; Learn more about sjPlot with &amp;#39;browseVignettes(&amp;quot;sjPlot&amp;quot;)&amp;#39;.
library(ggplot2)

theme_set(theme_sjplot())

# Create data partially based on code by Ben Bolker  
# from https://stackoverflow.com/a/38296264/7050882

set.seed(101)

spin = runif(800, 1, 24)

trait = rep(1:40, each = 20)

ID = rep(1:80, each = 10)

testdata &amp;lt;- data.frame(spin, trait, ID)

testdata$fatigue &amp;lt;- 
  testdata$spin * testdata$trait / 
  rnorm(800, mean = 6, sd = 2)

# Model
fit = lmer(fatigue ~ spin * trait + (1|ID),
           data = testdata, REML = TRUE)
#&amp;gt; boundary (singular) fit: see help(&amp;#39;isSingular&amp;#39;)

plot_model(fit, type = &amp;#39;pred&amp;#39;, terms = c(&amp;#39;spin&amp;#39;, &amp;#39;trait&amp;#39;))
#&amp;gt; Warning: Ignoring unknown parameters: linewidth&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/7VTcfLu.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;Created on 2023-06-24 with &lt;a href=&#34;https://reprex.tidyverse.org&#34;&gt;reprex v2.0.2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;However, I needed an extra feature, as sjPlot by default breaks down the colour (&lt;code&gt;fill&lt;/code&gt;) variable into few levels that do not include the minimum or the maximum values in my variable. What I would like to do is to stratify the colour variable into equally-sized levels that include the minimum and the maximum values.&lt;/p&gt;
&lt;p&gt;Furthermore, in the legend, I would also like to display the number of levels of a grouping variable (&lt;code&gt;ID&lt;/code&gt;) that are contained in each level of the colour variable.&lt;/p&gt;
&lt;p&gt;Below is a solution using &lt;a href=&#34;https://pablobernabeu.github.io/2022/plotting-two-way-interactions-from-mixed-effects-models-using-ten-or-six-bins&#34;&gt;custom functions called &lt;code&gt;deciles_interaction_plot&lt;/code&gt; and &lt;code&gt;sextiles_interaction_plot&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lme4)
#&amp;gt; Loading required package: Matrix
library(sjPlot)
library(ggplot2)

theme_set(theme_sjplot())

# Create data partially based on code by Ben Bolker  
# from https://stackoverflow.com/a/38296264/7050882

set.seed(101)

spin = runif(800, 1, 24)

trait = rep(1:40, each = 20)

ID = rep(1:80, each = 10)

testdata &amp;lt;- data.frame(spin, trait, ID)

testdata$fatigue &amp;lt;- 
  testdata$spin * testdata$trait / 
  rnorm(800, mean = 6, sd = 2)

# Model
fit = lmer(fatigue ~ spin * trait + (1|ID),
           data = testdata, REML = TRUE)
#&amp;gt; boundary (singular) fit: see help(&amp;#39;isSingular&amp;#39;)

# plot_model(fit, type = &amp;#39;pred&amp;#39;, terms = c(&amp;#39;spin&amp;#39;, &amp;#39;trait&amp;#39;))

# Binning the colour variable into ten levels (deciles)

# Read in function from GitHub
source(&amp;#39;https://raw.githubusercontent.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/main/R_functions/deciles_interaction_plot.R&amp;#39;)

deciles_interaction_plot(
  model = fit, 
  x = &amp;#39;spin&amp;#39;,
  fill = &amp;#39;trait&amp;#39;,
  fill_nesting_factor = &amp;#39;ID&amp;#39;
)
#&amp;gt; Loading required package: dplyr
#&amp;gt; 
#&amp;gt; Attaching package: &amp;#39;dplyr&amp;#39;
#&amp;gt; The following objects are masked from &amp;#39;package:stats&amp;#39;:
#&amp;gt; 
#&amp;gt;     filter, lag
#&amp;gt; The following objects are masked from &amp;#39;package:base&amp;#39;:
#&amp;gt; 
#&amp;gt;     intersect, setdiff, setequal, union
#&amp;gt; Loading required package: RColorBrewer
#&amp;gt; Loading required package: ggtext
#&amp;gt; Loading required package: Cairo
#&amp;gt; Warning in RColorBrewer::brewer.pal(n, pal): n too large, allowed maximum for palette Set1 is 9
#&amp;gt; Returning the palette you asked for with that many colors
#&amp;gt; Warning: Ignoring unknown parameters: linewidth
#&amp;gt; Scale for &amp;#39;y&amp;#39; is already present. Adding another scale for &amp;#39;y&amp;#39;, which will
#&amp;gt; replace the existing scale.
#&amp;gt; Scale for &amp;#39;colour&amp;#39; is already present. Adding another scale for &amp;#39;colour&amp;#39;,
#&amp;gt; which will replace the existing scale.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/niqWOzx.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
# If you wanted or needed to make six levels (sextiles) instead 
# of ten, you could use the function sextiles_interaction_plot.

# Read in function from GitHub
source(&amp;#39;https://raw.githubusercontent.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/main/R_functions/sextiles_interaction_plot.R&amp;#39;)

sextiles_interaction_plot(
  model = fit, 
  x = &amp;#39;spin&amp;#39;,
  fill = &amp;#39;trait&amp;#39;,
  fill_nesting_factor = &amp;#39;ID&amp;#39;
)
#&amp;gt; Warning: Ignoring unknown parameters: linewidth
#&amp;gt; Scale for &amp;#39;y&amp;#39; is already present. Adding another scale for &amp;#39;y&amp;#39;, which will
#&amp;gt; replace the existing scale.
#&amp;gt; Scale for &amp;#39;colour&amp;#39; is already present. Adding another scale for &amp;#39;colour&amp;#39;,
#&amp;gt; which will replace the existing scale.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/w8Ydo4F.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;Created on 2023-06-24 with &lt;a href=&#34;https://reprex.tidyverse.org&#34;&gt;reprex v2.0.2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to map more informative values onto fill argument of sjPlot::plot_model</title>
      <link>https://pablobernabeu.github.io/2023/how-to-map-more-informative-values-onto-fill-argument-of-sjplot-plot-model/</link>
      <pubDate>Sat, 24 Jun 2023 16:51:11 +0200</pubDate>
      <guid>https://pablobernabeu.github.io/2023/how-to-map-more-informative-values-onto-fill-argument-of-sjplot-plot-model/</guid>
      <description>


&lt;p&gt;Whereas the direction of main effects can be interpreted from the sign of the estimate, the interpretation of interaction effects often requires plots. This task is facilitated by the R package &lt;a href=&#34;https://strengejacke.github.io/sjPlot&#34;&gt;&lt;code&gt;sjPlot&lt;/code&gt;&lt;/a&gt;. For instance, using the &lt;code&gt;plot_model&lt;/code&gt; function, I plotted the interaction between a continuous variable and a categorical variable. The categorical variable was passed to the &lt;code&gt;fill&lt;/code&gt; argument of plot_model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lme4)
#&amp;gt; Loading required package: Matrix
library(sjPlot)
#&amp;gt; Install package &amp;quot;strengejacke&amp;quot; from GitHub (`devtools::install_github(&amp;quot;strengejacke/strengejacke&amp;quot;)`) to load all sj-packages at once!
library(ggplot2)

theme_set(theme_sjplot())

cake$recipe_recoded = ifelse(cake$recipe == &amp;#39;A&amp;#39;, -0.5,
                             ifelse(cake$recipe == &amp;#39;B&amp;#39;, 0,
                                    ifelse(cake$recipe == &amp;#39;C&amp;#39;, 0.5,
                                           NA)))

fit = lmer(angle ~ recipe_recoded * temp + 
             (1|recipe_recoded:replicate), 
           cake, REML= FALSE)

plot_model(fit, type = &amp;#39;pred&amp;#39;, terms = c(&amp;#39;temp&amp;#39;, &amp;#39;recipe_recoded&amp;#39;))
#&amp;gt; Warning: Ignoring unknown parameters: linewidth&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/SiigAMp.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;Created on 2023-06-24 with &lt;a href=&#34;https://reprex.tidyverse.org&#34;&gt;reprex v2.0.2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;However, I needed an extra feature, as the categorical variable was not quite informative because it was a sum-coded transformation. Thus, I wanted the legend of the plot to show the values of the original variable (i.e., A, B and C), instead of those of the sum-coded variable that had been used in the model (i.e., -0.5, 0 and 0.5).&lt;/p&gt;
&lt;p&gt;Below is a solution using a custom function called &lt;a href=&#34;https://pablobernabeu.github.io/2022/plotting-two-way-interactions-from-mixed-effects-models-using-alias-variables&#34;&gt;&lt;code&gt;alias_interaction_plot&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lme4)
#&amp;gt; Loading required package: Matrix
library(sjPlot)
library(ggplot2)

theme_set(theme_sjplot())

cake$recipe_recoded = ifelse(cake$recipe == &amp;#39;A&amp;#39;, -0.5,
                             ifelse(cake$recipe == &amp;#39;B&amp;#39;, 0,
                                    ifelse(cake$recipe == &amp;#39;C&amp;#39;, 0.5,
                                           NA)))

fit = lmer(angle ~ recipe_recoded * temp + 
             (1|recipe_recoded:replicate), 
           cake, REML= FALSE)

# plot_model(fit, type = &amp;#39;pred&amp;#39;, terms = c(&amp;#39;temp&amp;#39;, &amp;#39;recipe_recoded&amp;#39;))

# Displaying the original variable instead

# Read in function from GitHub
source(&amp;#39;https://raw.githubusercontent.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/main/R_functions/alias_interaction_plot.R&amp;#39;)

alias_interaction_plot(
  model = fit, 
  dataset = cake,
  x = &amp;#39;temp&amp;#39;,
  fill = &amp;#39;recipe_recoded&amp;#39;,
  fill_alias = &amp;#39;recipe&amp;#39;,
  fill_title = &amp;#39;recipe&amp;#39;
)
#&amp;gt; Loading required package: rlang
#&amp;gt; Loading required package: dplyr
#&amp;gt; 
#&amp;gt; Attaching package: &amp;#39;dplyr&amp;#39;
#&amp;gt; The following objects are masked from &amp;#39;package:stats&amp;#39;:
#&amp;gt; 
#&amp;gt;     filter, lag
#&amp;gt; The following objects are masked from &amp;#39;package:base&amp;#39;:
#&amp;gt; 
#&amp;gt;     intersect, setdiff, setequal, union
#&amp;gt; Loading required package: RColorBrewer
#&amp;gt; Loading required package: ggtext
#&amp;gt; Loading required package: Cairo
#&amp;gt; Warning: Ignoring unknown parameters: linewidth
#&amp;gt; Scale for &amp;#39;y&amp;#39; is already present. Adding another scale for &amp;#39;y&amp;#39;, which will
#&amp;gt; replace the existing scale.
#&amp;gt; Scale for &amp;#39;colour&amp;#39; is already present. Adding another scale for &amp;#39;colour&amp;#39;,
#&amp;gt; which will replace the existing scale.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/SS03gK6.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;Created on 2023-06-24 with &lt;a href=&#34;https://reprex.tidyverse.org&#34;&gt;reprex v2.0.2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to visually assess the convergence of a mixed-effects model by plotting various optimizers</title>
      <link>https://pablobernabeu.github.io/2023/how-to-visually-assess-the-convergence-of-a-mixed-effects-model-by-plotting-various-optimizers/</link>
      <pubDate>Sat, 24 Jun 2023 16:42:34 +0200</pubDate>
      <guid>https://pablobernabeu.github.io/2023/how-to-visually-assess-the-convergence-of-a-mixed-effects-model-by-plotting-various-optimizers/</guid>
      <description>


&lt;p&gt;To assess whether convergence warnings render the results invalid, or on the contrary, the results can be deemed valid in spite of the warnings, &lt;a href=&#34;https://cran.r-project.org/web/packages/lme4/lme4.pdf&#34;&gt;Bates et al. (2023)&lt;/a&gt; suggest refitting models affected by convergence warnings with a variety of optimizers. The authors argue that, if the different optimizers produce practically-equivalent results, the results are valid. The &lt;code&gt;allFit&lt;/code&gt; function from the ‘lme4’ package allows the refitting of models using a number of optimizers. To use the seven optimizers listed above, two extra packages must be installed: ‘dfoptim’ and ‘optimx’ (see lme4 manual). The output from &lt;code&gt;allFit&lt;/code&gt; contains several statistics on the fixed and the random effects fitted by each optimizer.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lme4)
#&amp;gt; Loading required package: Matrix
library(dfoptim)
library(optimx)

# Create data using code by Ben Bolker from 
# https://stackoverflow.com/a/38296264/7050882

set.seed(101)
spin = runif(600, 1, 24)
reg = runif(600, 1, 15)
ID = rep(c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;3&amp;quot;,&amp;quot;4&amp;quot;,&amp;quot;5&amp;quot;, &amp;quot;6&amp;quot;, &amp;quot;7&amp;quot;, &amp;quot;8&amp;quot;, &amp;quot;9&amp;quot;, &amp;quot;10&amp;quot;))
day = rep(1:30, each = 10)
testdata &amp;lt;- data.frame(spin, reg, ID, day)
testdata$fatigue &amp;lt;- testdata$spin * testdata$reg/10 * rnorm(30, mean=3, sd=2)

# Model
fit = lmer(fatigue ~ spin * reg + (1|ID),
           data = testdata, REML = TRUE)

# Refit model using all available algorithms
multi_fit = allFit(fit)
#&amp;gt; bobyqa : [OK]
#&amp;gt; Nelder_Mead : [OK]
#&amp;gt; nlminbwrap : [OK]
#&amp;gt; nmkbw : [OK]
#&amp;gt; optimx.L-BFGS-B : [OK]
#&amp;gt; nloptwrap.NLOPT_LN_NELDERMEAD : [OK]
#&amp;gt; nloptwrap.NLOPT_LN_BOBYQA : [OK]

# Show results 
summary(multi_fit)$fixef
#&amp;gt;                               (Intercept)      spin       reg  spin:reg
#&amp;gt; bobyqa                          -2.975678 0.5926561 0.1437204 0.1834016
#&amp;gt; Nelder_Mead                     -2.975675 0.5926559 0.1437202 0.1834016
#&amp;gt; nlminbwrap                      -2.975677 0.5926560 0.1437203 0.1834016
#&amp;gt; nmkbw                           -2.975678 0.5926561 0.1437204 0.1834016
#&amp;gt; optimx.L-BFGS-B                 -2.975680 0.5926562 0.1437205 0.1834016
#&amp;gt; nloptwrap.NLOPT_LN_NELDERMEAD   -2.975666 0.5926552 0.1437196 0.1834017
#&amp;gt; nloptwrap.NLOPT_LN_BOBYQA       -2.975678 0.5926561 0.1437204 0.1834016

# Read in function from GitHub
source(&amp;#39;https://raw.githubusercontent.com/pablobernabeu/plot.fixef.allFit/main/plot.fixef.allFit.R&amp;#39;)

plot.fixef.allFit(multi_fit, 
                  
                  select_predictors = c(&amp;#39;spin&amp;#39;, &amp;#39;reg&amp;#39;, &amp;#39;spin:reg&amp;#39;), 
                  
                  # Increase padding at top and bottom of Y axis
                  multiply_y_axis_limits = 1.3,
                  
                  y_title = &amp;#39;Fixed effect (*b*)&amp;#39;)
#&amp;gt; Loading required package: dplyr
#&amp;gt; 
#&amp;gt; Attaching package: &amp;#39;dplyr&amp;#39;
#&amp;gt; The following objects are masked from &amp;#39;package:stats&amp;#39;:
#&amp;gt; 
#&amp;gt;     filter, lag
#&amp;gt; The following objects are masked from &amp;#39;package:base&amp;#39;:
#&amp;gt; 
#&amp;gt;     intersect, setdiff, setequal, union
#&amp;gt; Loading required package: reshape2
#&amp;gt; Loading required package: stringr
#&amp;gt; Loading required package: scales
#&amp;gt; Loading required package: ggplot2
#&amp;gt; Loading required package: ggtext
#&amp;gt; Loading required package: patchwork&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/XYQDug2.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
# Alternative using plot-specific Y axes and other modified settings

plot.fixef.allFit(multi_fit, 
                  
                  select_predictors = c(&amp;#39;spin&amp;#39;, &amp;#39;spin:reg&amp;#39;), 
                  
                  # Use plot-specific Y axis limits
                  shared_y_axis_limits = FALSE,
                  
                  decimal_places = 7, 
                  
                  # Move up Y axis title
                  y_title_hjust = 4.5,
                  
                  y_title = &amp;#39;Fixed effect (*b*)&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/BYXJYxM.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;Created on 2023-06-26 with &lt;a href=&#34;https://reprex.tidyverse.org&#34;&gt;reprex v2.0.2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A new function to plot convergence diagnostics from lme4::allFit()</title>
      <link>https://pablobernabeu.github.io/2023/a-new-function-to-plot-convergence-diagnostics-from-lme4-allfit/</link>
      <pubDate>Thu, 22 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/2023/a-new-function-to-plot-convergence-diagnostics-from-lme4-allfit/</guid>
      <description>
&lt;script src=&#34;https://pablobernabeu.github.io/2023/a-new-function-to-plot-convergence-diagnostics-from-lme4-allfit/index_files/clipboard/clipboard.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://pablobernabeu.github.io/2023/a-new-function-to-plot-convergence-diagnostics-from-lme4-allfit/index_files/xaringanExtra-clipboard/xaringanExtra-clipboard.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://pablobernabeu.github.io/2023/a-new-function-to-plot-convergence-diagnostics-from-lme4-allfit/index_files/xaringanExtra-clipboard/xaringanExtra-clipboard.js&#34;&gt;&lt;/script&gt;
&lt;script&gt;window.xaringanExtraClipboard(null, {&#34;button&#34;:&#34;Copy Code&#34;,&#34;success&#34;:&#34;Copied!&#34;,&#34;error&#34;:&#34;Press Ctrl+C to Copy&#34;})&lt;/script&gt;


&lt;p&gt;Linear mixed-effects models (LMM) offer a consistent way of performing regression and analysis of variance tests which allows accounting for non-independence in the data. Over the past decades, LMMs have subsumed most of the General Linear Model, with a steady increase in popularity (Meteyard &amp;amp; Davies, 2020). Since their conception, LMMs have presented the challenge of model &lt;em&gt;convergence&lt;/em&gt;. In essence, the issue of convergence boils down to the widespread tension between parsimony and completeness in data analysis. That is, on the one hand, a good model must allow an accurate, parsimonious analysis of each predictor, and thus, it must not be overfitted with too many parameters. Yet, on the other hand, the model must be complete enough to account for a sufficient amount of variation in the data. In LMMs, any predictors that entail non-independent observations (also known as repeated measures) will normally bring both fixed and random effects into the model. Where a few of these predictors coexist, models often struggle to find enough information in the data to account for every predictor—and especially, for every random effect. This difficulty translates into convergence warnings (Brauer &amp;amp; Curtin, 2018; Singmann &amp;amp; Kellen, 2019). In this article, I review the issue of convergence before presenting a new plotting function in R that facilitates the diagnosis of convergence by visualising the fixed effects fitted by different optimization algorithms (also dubbed optimizers).&lt;/p&gt;
&lt;div id=&#34;completeness-versus-parsimony&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Completeness versus parsimony&lt;/h2&gt;
&lt;p&gt;Both fixed and random effects comprise intercepts and slopes. The pressure exerted by each of those types of effects on the model is determined by the number of data points involved by each. First, slopes are more demanding than intercepts, as they involve a (far) larger number of data points. Second, random effects are more demanding than fixed effects, as random effects entail the number of estimates required for fixed effects &lt;em&gt;times&lt;/em&gt; the number of levels in the grouping factor. As a result, on the most lenient end of the scale lies the fixed intercept, and on the heaviest end lie the random slopes. Convergence warnings in LMMs are often due to the random slopes alone.&lt;/p&gt;
&lt;p&gt;Sounds easy, then! Not inviting the random slopes to the party should solve the problem. Indeed, since random slopes involve the highest number of estimates by far, removing them does often remove convergence warnings. This, however, leads to a different problem. Surrendering the information provided by random slopes can result in the violation of the assumption of independence of observations. For years, the removal of random slopes due to convergence warnings was standard practice. Currently, in contrast, proposals increasingly consider other options, such as removing random effects if they do not significantly improve the fit of the model (Matuschek et al., 2017), and keeping the random slopes in the model in spite of the convergence warnings to safeguard the assumption of independence (see Table 17 in Brauer &amp;amp; Curtin, 2018; Singmann &amp;amp; Kellen, 2019).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-multiple-optimizers-sanity-check-from-lme4allfit&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The multiple-optimizers sanity check from &lt;code&gt;lme4::allFit()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Framed within the drive to maintain random slopes wherever possible, the developers of the ‘lme4’ package propose a sanity check that uses a part of the ‘lme4’ &lt;em&gt;engine&lt;/em&gt; called ‘optimizer’. Every model has a default optimizer, unless a specific one is chosen through &lt;code&gt;control = lmerControl(optimizer = &#39;...&#39;)&lt;/code&gt; (in lmer models) or &lt;code&gt;control = glmerControl(optimizer = &#39;...&#39;)&lt;/code&gt; (in glmer models). The seven widely-available optimizers are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bobyqa&lt;/li&gt;
&lt;li&gt;Nelder_Mead&lt;/li&gt;
&lt;li&gt;nlminbwrap&lt;/li&gt;
&lt;li&gt;nmkbw&lt;/li&gt;
&lt;li&gt;optimx.L-BFGS-B&lt;/li&gt;
&lt;li&gt;nloptwrap.NLOPT_LN_NELDERMEAD&lt;/li&gt;
&lt;li&gt;nloptwrap.NLOPT_LN_BOBYQA&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To assess whether convergence warnings render the results invalid, or on the contrary, the results can be deemed valid in spite of the warnings, Bates et al. (2022) suggest refitting models affected by convergence warnings with a variety of optimizers. The authors argue that if the different optimizers produce practically-equivalent results, the results are valid. The &lt;code&gt;allFit&lt;/code&gt; function from the ‘lme4’ package allows the refitting of models using a number of optimizers. To use the seven optimizers listed above, two extra packages must be installed: ‘dfoptim’ and ‘optimx’ (see &lt;a href=&#34;https://cran.r-project.org/web/packages/lme4/lme4.pdf&#34;&gt;lme4 manual&lt;/a&gt;). The output from &lt;code&gt;allFit()&lt;/code&gt; contains several statistics on the fixed and the random effects fitted by each optimizer (see &lt;a href=&#34;https://github.com/lme4/lme4/issues/512#issue-425198940&#34;&gt;example&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-the-fixed-effects-from-allfit&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plotting the fixed effects from allFit()&lt;/h2&gt;
&lt;p&gt;Several R users have ventured into &lt;a href=&#34;https://www.google.com/search?q=%22ggplot%22+%22allfit%22+optimizers&#34;&gt;plotting the allFit() output&lt;/a&gt; but there is not a function in ‘lme4’ yet at the time of writing. I (Bernabeu, 2022) developed a &lt;a href=&#34;https://github.com/pablobernabeu/plot.fixef.allFit/blob/main/plot.fixef.allFit.R&#34;&gt;function&lt;/a&gt; that takes the output from &lt;code&gt;allFit()&lt;/code&gt;, tidies it, selects the fixed effects and plots them using ‘ggplot2’. The function is shown below, and can be copied through the &lt;code&gt;Copy Code&lt;/code&gt; button at the top right corner. It can be renamed by changing &lt;code&gt;plot.fixef.allFit&lt;/code&gt; to another valid name.&lt;/p&gt;
&lt;div style=&#34;height: 800px; border: 0.5px dotted grey; padding: 10px; resize: both; overflow: auto;&#34;&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Plot the results from the fixed effects produced by different optimizers. This function 
# takes the output from lme4::allFit(), tidies it, selects fixed effects and plots them.

plot.fixef.allFit = function(allFit_output, 
                             # Set the same Y axis limits in every plot
                             shared_y_axis_limits = TRUE,
                             # Multiply Y axis limits by a factor (only 
                             # available if shared_y_axis_limits = TRUE)
                             multiply_y_axis_limits = 1, 
                             # Number of decimal places
                             decimal_places = NULL,
                             # Select predictors
                             select_predictors = NULL, 
                             # Number of rows
                             nrow = NULL, 
                             # Y axis title
                             y_title = &amp;#39;Fixed effect&amp;#39;,
                             # Alignment of the Y axis title
                             y_title_hjust = NULL,
                             # Add number to the names of optimizers
                             number_optimizers = TRUE,
                             # Replace colon in interactions with x
                             interaction_symbol_x = TRUE) {
  
  require(lme4)
  require(dfoptim)
  require(optimx)
  require(dplyr)
  require(reshape2)
  require(stringr)
  require(scales)
  require(ggplot2)
  require(ggtext)
  require(patchwork)
  library(Cairo)
  
  # Tidy allFit output
  
  # Extract fixed effects from the allFit() output
  allFit_fixef = summary(allFit_output)$fixef %&amp;gt;%  # Select fixed effects in the allFit results
    reshape2::melt() %&amp;gt;%  # Structure the output as a data frame
    rename(&amp;#39;Optimizer&amp;#39; = &amp;#39;Var1&amp;#39;, &amp;#39;fixed_effect&amp;#39; = &amp;#39;Var2&amp;#39;)  # set informative names
  
  # If number_optimizers = TRUE, assign number to each optimizer and place it before its name
  if(number_optimizers == TRUE) {
    allFit_fixef$Optimizer = paste0(as.numeric(allFit_fixef$Optimizer), &amp;#39;. &amp;#39;, allFit_fixef$Optimizer)
  }
  
  # If select_predictors was supplied, select them along with the intercept (the latter required)
  if(!is.null(select_predictors)) {
    allFit_fixef = allFit_fixef %&amp;gt;% dplyr::filter(fixed_effect %in% c(&amp;#39;(Intercept)&amp;#39;, select_predictors))
  }
  
  # Order variables
  allFit_fixef = allFit_fixef[, c(&amp;#39;Optimizer&amp;#39;, &amp;#39;fixed_effect&amp;#39;, &amp;#39;value&amp;#39;)]
  
  # PLOT. The overall plot is formed of a first row containing the intercept and the legend 
  # (intercept_plot), and a second row containing the predictors (predictors_plot), 
  # which may in turn occupy several rows.
  
  # If multiply_y_axis_limits was supplied but shared_y_axis_limits = FALSE,
  # warn that shared_y_axis_limits is required.
  if(!multiply_y_axis_limits == 1 &amp;amp; shared_y_axis_limits == FALSE) {
    message(&amp;#39;The argument `multiply_y_axis_limits` has not been used because \n it requires `shared_y_axis_limits` set to TRUE.&amp;#39;)
  }
  
  # If extreme values were entered in y_title_hjust, show warning
  if(!is.null(y_title_hjust)) {
    if(y_title_hjust &amp;lt; 0.5 | y_title_hjust &amp;gt; 6) {
      message(&amp;#39;NOTE: For y_title_hjust, a working range of values is between 0.6 and 6.&amp;#39;)
    }
  }
  
  # If decimal_places was supplied, convert number to the format used in &amp;#39;scales&amp;#39; package
  if(!is.null(decimal_places)) {
    decimal_places = 
      ifelse(decimal_places == 1, 0.1, 
             ifelse(decimal_places == 2, 0.01, 
                    ifelse(decimal_places == 3, 0.001, 
                           ifelse(decimal_places == 4, 0.0001, 
                                  ifelse(decimal_places == 5, 0.00001, 
                                         ifelse(decimal_places == 6, 0.000001, 
                                                ifelse(decimal_places == 7, 0.0000001, 
                                                       ifelse(decimal_places == 8, 0.00000001, 
                                                              ifelse(decimal_places == 9, 0.000000001, 
                                                                     ifelse(decimal_places == 10, 0.0000000001,
                                                                            ifelse(decimal_places == 11, 0.00000000001,
                                                                                   ifelse(decimal_places == 12, 0.000000000001,
                                                                                          ifelse(decimal_places == 13, 0.0000000000001,
                                                                                                 ifelse(decimal_places == 14, 0.00000000000001,
                                                                                                        ifelse(decimal_places &amp;gt;= 15, 0.000000000000001, 
                                                                                                               0.001
                                                                                                        )))))))))))))))
  }
  
  # First row: intercept_plot
  
  # Select intercept data only
  intercept = allFit_fixef %&amp;gt;% dplyr::filter(fixed_effect == &amp;#39;(Intercept)&amp;#39;)
  
  intercept_plot = intercept %&amp;gt;%
    ggplot(., aes(fixed_effect, value, colour = Optimizer)) +
    geom_point(position = position_dodge(1)) +
    facet_wrap(~fixed_effect, scale = &amp;#39;free&amp;#39;) +
    guides(colour = guide_legend(title.position = &amp;#39;left&amp;#39;)) +
    theme_bw() + 
    theme(axis.title = element_blank(), axis.ticks.x = element_blank(),
          axis.text.x = element_blank(), 
          strip.text = element_text(size = 10, margin = margin(t = 4, b = 6)),
          strip.background = element_rect(fill = &amp;#39;grey96&amp;#39;),
          legend.margin = margin(0.3, 0, 0.8, 1, &amp;#39;cm&amp;#39;), 
          legend.title = element_text(size = unit(15, &amp;#39;pt&amp;#39;), angle = 90, hjust = 0.5))
  
  # Second row: predictors_plot
  
  # Select all predictors except intercept
  predictors = allFit_fixef %&amp;gt;% dplyr::filter(!fixed_effect == &amp;#39;(Intercept)&amp;#39;)
  
  # If interaction_symbol_x = TRUE (default), replace colon with times symbol x between spaces
  if(interaction_symbol_x == TRUE) {
    # Replace colon in interactions with \u00D7, i.e., x; then set factor class
    predictors$fixed_effect = predictors$fixed_effect %&amp;gt;% 
      str_replace_all(&amp;#39;:&amp;#39;, &amp;#39; \u00D7 &amp;#39;) %&amp;gt;% factor()
  }
  
  # Order predictors as in the original output from lme4::allFit()
  predictors$fixed_effect = factor(predictors$fixed_effect, 
                                   levels = unique(predictors$fixed_effect))
  
  # Set number of rows for the predictors excluding the intercept.
  # First, if nrow argument supplied, use it
  if(!is.null(nrow)) {
    predictors_plot_nrow = nrow - 1  # Subtract 1 as intercept row not considered
    
    # Else, if nrow argument not supplied, calculate sensible number of rows: i.e., divide number of
    # predictors (exc. intercept) by 2 and round up the result. For instance, 7 predictors --&amp;gt; 3 rows
  } else predictors_plot_nrow = (length(unique(predictors$fixed_effect)) / 2) %&amp;gt;% ceiling()
  
  predictors_plot = ggplot(predictors, aes(fixed_effect, value, colour = Optimizer)) +
    geom_point(position = position_dodge(1)) +
    facet_wrap(~fixed_effect, scale = &amp;#39;free&amp;#39;,
               # Note that predictors_plot_nrow was defined a few lines above
               nrow = predictors_plot_nrow, 
               # Wrap names of predictors with more than 54 characters into new lines
               labeller = labeller(fixed_effect = label_wrap_gen(width = 55))) +
    labs(y = y_title) +
    theme_bw() + 
    theme(axis.title.x = element_blank(), axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          axis.title.y = ggtext::element_markdown(size = 14, margin = margin(0, 15, 0, 0)),
          strip.text = element_text(size = 10, margin = margin(t = 4, b = 6)),
          strip.background = element_rect(fill = &amp;#39;grey96&amp;#39;), legend.position = &amp;#39;none&amp;#39;)
  
  # Below, the function scale_y_continuous is applied conditionally to avoid overriding settings. First, 
  # if shared_y_axis_limits = TRUE and decimal_places was supplied, set the same Y axis limits in 
  # every plot and set decimal_places. By default, also expand limits by a seventh of its original 
  # limit, and allow further multiplication of limits through multiply_y_axis_limits.
  if(shared_y_axis_limits == TRUE &amp;amp; !is.null(decimal_places)) {
    
    intercept_plot = intercept_plot +
      scale_y_continuous(limits = c(min(allFit_fixef$value) - allFit_fixef$value %&amp;gt;% abs %&amp;gt;% 
                                      max / 7 * multiply_y_axis_limits,
                                    max(allFit_fixef$value) + allFit_fixef$value %&amp;gt;% abs %&amp;gt;% 
                                      max / 7 * multiply_y_axis_limits), 
                         # Set number of decimal places
                         labels = scales::label_number(accuracy = decimal_places))
    
    predictors_plot = predictors_plot + 
      scale_y_continuous(limits = c(min(allFit_fixef$value) - allFit_fixef$value %&amp;gt;% abs %&amp;gt;% 
                                      max / 7 * multiply_y_axis_limits,
                                    max(allFit_fixef$value) + allFit_fixef$value %&amp;gt;% abs %&amp;gt;% 
                                      max / 7 * multiply_y_axis_limits), 
                         # Set number of decimal places
                         labels = scales::label_number(accuracy = decimal_places))
    
    # Else, if shared_y_axis_limits = TRUE but decimal_places were not supplied, do as above but without
    # setting decimal_places.
  } else if(shared_y_axis_limits == TRUE &amp;amp; is.null(decimal_places)) {
    
    intercept_plot = intercept_plot +
      scale_y_continuous(limits = c(min(allFit_fixef$value) - allFit_fixef$value %&amp;gt;% abs %&amp;gt;% 
                                      max / 7 * multiply_y_axis_limits,
                                    max(allFit_fixef$value) + allFit_fixef$value %&amp;gt;% abs %&amp;gt;% 
                                      max / 7 * multiply_y_axis_limits),
                         # Set number of decimal places
                         labels = scales::label_number(accuracy = decimal_places))
    
    predictors_plot = predictors_plot + 
      scale_y_continuous(limits = c(min(allFit_fixef$value) - allFit_fixef$value %&amp;gt;% abs %&amp;gt;% 
                                      max / 7 * multiply_y_axis_limits,
                                    max(allFit_fixef$value) + allFit_fixef$value %&amp;gt;% abs %&amp;gt;% 
                                      max / 7 * multiply_y_axis_limits),
                         # Set number of decimal places
                         labels = scales::label_number(accuracy = decimal_places))
    
    # Else, if shared_y_axis_limits = FALSE and decimal_places was supplied, set decimal_places. 
  } else if(shared_y_axis_limits == FALSE &amp;amp; !is.null(decimal_places)) {
    
    # Set number of decimal places in both plots
    intercept_plot = intercept_plot +
      scale_y_continuous(labels = scales::label_number(accuracy = decimal_places))
    
    predictors_plot = predictors_plot +
      scale_y_continuous(labels = scales::label_number(accuracy = decimal_places))
  }
  
  # Plot matrix: based on number of predictors_plot_nrow, adjust height of Y axis title
  # (unless supplied), and assign space to intercept_plot and predictors_plot
  if(predictors_plot_nrow == 1) {
    
    # If y_title_hjust supplied, use it
    if(!is.null(y_title_hjust)) {
      predictors_plot = predictors_plot + 
        theme(axis.title.y = ggtext::element_markdown(hjust = y_title_hjust))
      # Otherwise, set a sensible height
    } else predictors_plot = predictors_plot + 
        theme(axis.title.y = ggtext::element_markdown(hjust = 3.6))
    
    layout = c(
      patchwork::area(t = 1.5, r = 8.9, b = 6.8, l = 0),  # intercept row
      patchwork::area(t = 7.3, r = 9, b = 11, l = 0)      # predictors row(s)
    )
    
  } else if(predictors_plot_nrow == 2) {
    
    # If y_title_hjust supplied, use it
    if(!is.null(y_title_hjust)) {
      predictors_plot = predictors_plot + 
        theme(axis.title.y = ggtext::element_markdown(hjust = y_title_hjust))
      # Otherwise, set a sensible height
    } else predictors_plot = predictors_plot + 
        theme(axis.title.y = ggtext::element_markdown(hjust = 1.4))
    
    layout = c(
      patchwork::area(t = 1.5, r = 8.9, b = 6.8, l = 0),  # intercept row
      patchwork::area(t = 7.3, r = 9, b = 16, l = 0)      # predictors row(s)
    )
    
  } else if(predictors_plot_nrow == 3) {
    
    # If y_title_hjust supplied, use it
    if(!is.null(y_title_hjust)) {
      predictors_plot = predictors_plot + 
        theme(axis.title.y = ggtext::element_markdown(hjust = y_title_hjust))
      # Otherwise, set a sensible height
    } else predictors_plot = predictors_plot + 
        theme(axis.title.y = ggtext::element_markdown(hjust = 0.92))
    
    layout = c(
      patchwork::area(t = 1.5, r = 8.9, b = 6.8, l = 0),  # intercept row
      patchwork::area(t = 7.3, r = 9, b = 21, l = 0)      # predictors row(s)
    )
    
  } else if(predictors_plot_nrow == 4) {
    
    # If y_title_hjust supplied, use it
    if(!is.null(y_title_hjust)) {
      predictors_plot = predictors_plot + 
        theme(axis.title.y = ggtext::element_markdown(hjust = y_title_hjust))
      # Otherwise, set a sensible height
    } else predictors_plot = predictors_plot + 
        theme(axis.title.y = ggtext::element_markdown(hjust = 0.8))
    
    layout = c(
      patchwork::area(t = 1.5, r = 8.9, b = 6.8, l = 0),  # intercept row
      patchwork::area(t = 7.3, r = 9, b = 26, l = 0)      # predictors row(s)
    )
    
  } else if(predictors_plot_nrow == 5) {
    
    # If y_title_hjust supplied, use it
    if(!is.null(y_title_hjust)) {
      predictors_plot = predictors_plot + 
        theme(axis.title.y = ggtext::element_markdown(hjust = y_title_hjust))
      # Otherwise, set a sensible height
    } else predictors_plot = predictors_plot + 
        theme(axis.title.y = ggtext::element_markdown(hjust = 0.73))
    
    layout = c(
      patchwork::area(t = 1.5, r = 8.9, b = 6.8, l = 0),  # intercept row
      patchwork::area(t = 7.3, r = 9, b = 31, l = 0)      # predictors row(s)
    )
    
  } else if(predictors_plot_nrow &amp;gt; 5) {
    
    # If y_title_hjust supplied, use it
    if(!is.null(y_title_hjust)) {
      predictors_plot = predictors_plot + 
        theme(axis.title.y = ggtext::element_markdown(hjust = y_title_hjust))
      # Otherwise, set a sensible height
    } else predictors_plot = predictors_plot + 
        theme(axis.title.y = ggtext::element_markdown(hjust = 0.65))
    
    layout = c(
      patchwork::area(t = 1.5, r = 8.9, b = 6.8, l = 0),  # intercept row
      patchwork::area(t = 7.3, r = 9, b = 36, l = 0)      # predictors row(s)
    )
    
    # Also, advise user to consider distributing predictors into several plots
    message(&amp;#39;  Many rows! Consider distributing predictors into several plots \n  using argument `select_predictors`&amp;#39;)
  } 
  
  # Add margin
  predictors_plot = predictors_plot + theme(plot.margin = margin(15, 15, 15, 15))
  
  # Return matrix of plots
  wrap_plots(intercept_plot, predictors_plot, design = layout,
             # The 2 below corresponds to intercept_plot and predictors_plot
             nrow = 2)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;div id=&#34;optional-arguments&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Optional arguments&lt;/h3&gt;
&lt;p&gt;Below are the optional arguments allowed by the function, with their default values.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
# Set the same Y axis limits in every plot
shared_y_axis_limits = TRUE,

# Multiply Y axis limits by a factor (only 
# available if shared_y_axis_limits = TRUE)
multiply_y_axis_limits = 1, 

# Number of decimal places
decimal_places = NULL,

# Select predictors
select_predictors = NULL, 

# Number of rows
nrow = NULL, 

# Y axis title
y_title = &amp;#39;Fixed effect&amp;#39;,

# Alignment of the Y axis title
y_title_hjust = NULL,

# Add number to the names of optimizers
number_optimizers = TRUE,

# Replace colon in interactions with x
interaction_symbol_x = TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The argument &lt;code&gt;shared_y_axis_limits&lt;/code&gt; deserves a comment. It allows using the same Y axis limits (i.e., range) in all plots or, alternatively, using plot-specific limits. The parameter is &lt;code&gt;TRUE&lt;/code&gt; by default to prevent overinterpretations of small differences across optimizers (see the first figure below). In contrast, when &lt;code&gt;shared_y_axis_limits = FALSE&lt;/code&gt;, plot-specific limits are used, which results in a narrower range of values in the Y axis (see the second figure below). Since data points will span the entire Y axis in that case, any difference across optimizers—regardless of its relative importance—might be perceived as large, unless the specific range of values in each plot is noticed.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;use-case&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Use case&lt;/h2&gt;
&lt;p&gt;Let’s test the function with a minimal model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create data using code by Ben Bolker from 
# https://stackoverflow.com/a/38296264/7050882

set.seed(101)
spin = runif(600, 1, 24)
reg = runif(600, 1, 15)
ID = rep(c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;3&amp;quot;,&amp;quot;4&amp;quot;,&amp;quot;5&amp;quot;, &amp;quot;6&amp;quot;, &amp;quot;7&amp;quot;, &amp;quot;8&amp;quot;, &amp;quot;9&amp;quot;, &amp;quot;10&amp;quot;))
day = rep(1:30, each = 10)
testdata &amp;lt;- data.frame(spin, reg, ID, day)
testdata$fatigue &amp;lt;- testdata$spin * testdata$reg/10 * rnorm(30, mean=3, sd=2)

# Model

library(lme4)

fit = lmer(fatigue ~ spin * reg + (1|ID),
           data = testdata, REML = TRUE)

# Refit model using all available algorithms
multi_fit = allFit(fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## bobyqa : [OK]
## Nelder_Mead : [OK]
## nlminbwrap : [OK]
## nmkbw : [OK]
## optimx.L-BFGS-B : [OK]
## nloptwrap.NLOPT_LN_NELDERMEAD : [OK]
## nloptwrap.NLOPT_LN_BOBYQA : [OK]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(multi_fit)$fixef&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                               (Intercept)      spin       reg  spin:reg
## bobyqa                          -2.975678 0.5926561 0.1437204 0.1834016
## Nelder_Mead                     -2.975675 0.5926559 0.1437202 0.1834016
## nlminbwrap                      -2.975677 0.5926560 0.1437203 0.1834016
## nmkbw                           -2.975678 0.5926561 0.1437204 0.1834016
## optimx.L-BFGS-B                 -2.975680 0.5926562 0.1437205 0.1834016
## nloptwrap.NLOPT_LN_NELDERMEAD   -2.975666 0.5926552 0.1437196 0.1834017
## nloptwrap.NLOPT_LN_BOBYQA       -2.975678 0.5926561 0.1437204 0.1834016&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The effects to be visualised are selected below using the argument &lt;code&gt;select_predictors&lt;/code&gt;. Notice that the intercept is plotted by default on the first row, along with the legend that lists all the optimizers used.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Read in function from GitHub
source(&amp;#39;https://raw.githubusercontent.com/pablobernabeu/plot.fixef.allFit/main/plot.fixef.allFit.R&amp;#39;)

plot.fixef.allFit(multi_fit, 
                  
                  select_predictors = c(&amp;#39;spin&amp;#39;, &amp;#39;reg&amp;#39;, &amp;#39;spin:reg&amp;#39;), 
                  
                  # Increase padding at top and bottom of Y axis
                  multiply_y_axis_limits = 1.3,
                  
                  y_title = &amp;#39;Fixed effect (*b*)&amp;#39;,
                  
                  # Align y title
                  y_title_hjust = .9)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://pablobernabeu.github.io/2023/a-new-function-to-plot-convergence-diagnostics-from-lme4-allfit/index_files/figure-html/demo-plot.fixef.allFit-function-1-1.png&#34; width=&#34;864&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The plot produced by &lt;code&gt;plot.fixef.allFit()&lt;/code&gt; by default replaces the colons in interaction effects (e.g., &lt;code&gt;spin:reg&lt;/code&gt;) with ’ × ’ to facilitate the visibility (this can be overriden by setting &lt;code&gt;interaction_symbol_x = FALSE&lt;/code&gt;). Yet, it is important to note that any interactions passed to &lt;code&gt;select_predictors&lt;/code&gt; must have the colon, as that is the symbol present in the &lt;code&gt;lme4::allFit()&lt;/code&gt; output.&lt;/p&gt;
&lt;p&gt;The output of &lt;code&gt;plot.fixef.allFit()&lt;/code&gt; is a &lt;a href=&#34;https://ggplot2.tidyverse.org/&#34;&gt;ggplot2&lt;/a&gt; object that can be stored for further use, as in the example below, in which new parameters are used.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

plot_fit_convergence = 
  
  plot.fixef.allFit(multi_fit, 
                    
                    select_predictors = c(&amp;#39;spin&amp;#39;, &amp;#39;spin:reg&amp;#39;), 
                    
                    # Use plot-specific Y axis limits
                    shared_y_axis_limits = FALSE,
                    
                    decimal_places = 7, 
                    
                    # Move up Y axis title
                    y_title_hjust = -20,
                    
                    y_title = &amp;#39;Fixed effect (*b*)&amp;#39;)

# Print
plot_fit_convergence&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://pablobernabeu.github.io/2023/a-new-function-to-plot-convergence-diagnostics-from-lme4-allfit/index_files/figure-html/demo-plot.fixef.allFit-function-2-1.png&#34; width=&#34;864&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Plot can be saved to disk as pdf, png, etc. through `ggplot2::ggsave()`
# ggsave(&amp;#39;plot_fit_convergence.pdf&amp;#39;, plot_fit_convergence, 
#        device = cairo_pdf, width = 9, height = 9, dpi = 900)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div style=&#34;text-indent:-2em; margin-left:2em;&#34;&gt;
&lt;p&gt;Bates, D., Maechler, M., Bolker, B., Walker, S., Christensen, R. H. B., Singmann, H., Dai, B., Scheipl, F., Grothendieck, G., Green, P., Fox, J., Bauer, A., &amp;amp; Krivitsky, P. N. (2022). &lt;em&gt;Package ‘lme4’.&lt;/em&gt; CRAN. &lt;a href=&#34;https://cran.r-project.org/web/packages/lme4/lme4.pdf&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/lme4/lme4.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bernabeu, P. (2022). Language and sensorimotor simulation in conceptual processing: Multilevel analysis and statistical power. Lancaster University. &lt;a href=&#34;https://doi.org/10.17635/lancaster/thesis/1795&#34; class=&#34;uri&#34;&gt;https://doi.org/10.17635/lancaster/thesis/1795&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Brauer, M., &amp;amp; Curtin, J. J. (2018). Linear mixed-effects models and the analysis of nonindependent data: A unified framework to analyze categorical and continuous independent variables that vary within-subjects and/or within-items. &lt;em&gt;Psychological Methods, 23&lt;/em&gt;(3), 389–411. &lt;a href=&#34;https://doi.org/10.1037/met0000159&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1037/met0000159&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Matuschek, H., Kliegl, R., Vasishth, S., Baayen, H., &amp;amp; Bates, D. (2017). Balancing type 1 error and power in linear mixed models. &lt;em&gt;Journal of Memory and Language, 94&lt;/em&gt;, 305–315. &lt;a href=&#34;https://doi.org/10.1016/j.jml.2017.01.001&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1016/j.jml.2017.01.001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Meteyard, L., &amp;amp; Davies, R. A. (2020). Best practice guidance for linear mixed-effects models in psychological science. &lt;em&gt;Journal of Memory and Language, 112&lt;/em&gt;, 104092. &lt;a href=&#34;https://doi.org/10.1016/j.jml.2020.104092&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1016/j.jml.2020.104092&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Singmann, H., &amp;amp; Kellen, D. (2019). An introduction to mixed models for experimental psychology. In D. H. Spieler &amp;amp; E. Schumacher (Eds.), &lt;em&gt;New methods in cognitive psychology&lt;/em&gt; (pp. 4–31). Psychology Press.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Cannot open plots created with brms::mcmc_plot due to lack of `discrete_range` function</title>
      <link>https://pablobernabeu.github.io/2023/cannot-open-plots-created-with-brms-mcmc-plot-due-to-lack-of-discrete-range-function/</link>
      <pubDate>Tue, 11 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/2023/cannot-open-plots-created-with-brms-mcmc-plot-due-to-lack-of-discrete-range-function/</guid>
      <description>


</description>
    </item>
    
    <item>
      <title>Plotting two-way interactions from mixed-effects models using alias variables</title>
      <link>https://pablobernabeu.github.io/2022/plotting-two-way-interactions-from-mixed-effects-models-using-alias-variables/</link>
      <pubDate>Mon, 26 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/2022/plotting-two-way-interactions-from-mixed-effects-models-using-alias-variables/</guid>
      <description>


&lt;p&gt;Whereas the direction of main effects can be interpreted from the sign of the estimate, the interpretation of interaction effects often requires plots. This task is facilitated by the R package &lt;a href=&#34;https://cran.r-project.org/web/packages/sjPlot/sjPlot.pdf&#34;&gt;&lt;code&gt;sjPlot&lt;/code&gt;&lt;/a&gt; (Lüdecke, 2022). In Bernabeu (2022), the sjPlot function called &lt;code&gt;plot_model&lt;/code&gt; served as the basis for the creation of some &lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/tree/main/R_functions&#34;&gt;custom functions&lt;/a&gt;. One of these functions is &lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/R_functions/alias_interaction_plot.R&#34;&gt;&lt;code&gt;alias_interaction_plot&lt;/code&gt;&lt;/a&gt;, which allows the plotting of interactions between a continuous variable and a categorical variable. Importantly, the categorical variable is replaced with an alias variable. This feature allows the back-transformation of the categorical variable to facilitate the communication of the results, for instance, when the categorical variable was sum-coded, which has been recommended for mixed-effects models (Brauer &amp;amp; Curtin, 2018).&lt;/p&gt;
&lt;p&gt;Below, we’ll use the function with a model fitted using &lt;a href=&#34;https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf&#34;&gt;&lt;code&gt;lmerTest&lt;/code&gt;&lt;/a&gt; (Kuznetsova et al., 2022), although the function also works with several other models (see &lt;a href=&#34;https://cran.r-project.org/web/packages/sjPlot/sjPlot.pdf&#34;&gt;sjPlot manual&lt;/a&gt;). The plot can be reproduced using the materials at &lt;a href=&#34;https://osf.io/gt5uf&#34; class=&#34;uri&#34;&gt;https://osf.io/gt5uf&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;alias-interaction-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Alias interaction plot&lt;/h2&gt;
&lt;div id=&#34;the-function&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The function&lt;/h3&gt;
&lt;script src=&#34;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Flanguage-sensorimotor-simulation-PhD-thesis%2Fblob%2Fmain%2FR_functions%2Falias_interaction_plot.R&amp;style=default&amp;type=code&amp;showBorder=on&amp;showLineNumbers=on&amp;showFileMeta=on&amp;showFullPath=on&amp;showCopy=on&#34;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div id=&#34;the-function-in-use&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The function in use&lt;/h3&gt;
&lt;script src=&#34;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Flanguage-sensorimotor-simulation-PhD-thesis%2Fblob%2Fmain%2Fsemanticpriming%2Ffrequentist_analysis%2Fsemanticpriming-interactions-with-SOA.R&amp;style=default&amp;type=code&amp;showBorder=on&amp;showLineNumbers=on&amp;showFileMeta=on&amp;showFullPath=on&amp;showCopy=on&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/frequentist_analysis/plots/semanticpriming-interactions-with-SOA.pdf&#34;&gt;&lt;img src=&#34;Screenshot%202022-12-27%20234345.png&#34; width=&#34;550&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;Bernabeu, P. (2022). &lt;em&gt;Language and sensorimotor simulation in conceptual processing: Multilevel analysis and statistical power&lt;/em&gt;. Lancaster University. &lt;a href=&#34;https://doi.org/10.17635/lancaster/thesis/1795&#34; class=&#34;uri&#34;&gt;https://doi.org/10.17635/lancaster/thesis/1795&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Brauer, M., &amp;amp; Curtin, J. J. (2018). Linear mixed-effects models and the analysis of nonindependent data: A unified framework to analyze categorical and continuous independent variables that vary within-subjects and/or within-items. &lt;em&gt;Psychological Methods, 23&lt;/em&gt;(3), 389–411. &lt;a href=&#34;https://doi.org/10.1037/met0000159&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1037/met0000159&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kuznetsova, A., Brockhoff, P. B., &amp;amp; Christensen, R. H. B. (2022). &lt;em&gt;Package ’lmerTest’&lt;/em&gt;. CRAN. &lt;a href=&#34;https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lüdecke, D. (2022). &lt;em&gt;Package ’sjPlot’&lt;/em&gt;. CRAN. &lt;a href=&#34;https://cran.r-project.org/web/packages/sjPlot/sjPlot.pdf&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/sjPlot/sjPlot.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Plotting two-way interactions from mixed-effects models using ten or six bins</title>
      <link>https://pablobernabeu.github.io/2022/plotting-two-way-interactions-from-mixed-effects-models-using-ten-or-six-bins/</link>
      <pubDate>Mon, 26 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/2022/plotting-two-way-interactions-from-mixed-effects-models-using-ten-or-six-bins/</guid>
      <description>


&lt;p&gt;Whereas the direction of main effects can be interpreted from the sign of the estimate, the interpretation of interaction effects often requires plots. This task is facilitated by the R package &lt;a href=&#34;https://cran.r-project.org/web/packages/sjPlot/sjPlot.pdf&#34;&gt;&lt;code&gt;sjPlot&lt;/code&gt;&lt;/a&gt; (Lüdecke, 2022). In Bernabeu (2022), the sjPlot function called &lt;code&gt;plot_model&lt;/code&gt; served as the basis for the creation of some &lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/tree/main/R_functions&#34;&gt;custom functions&lt;/a&gt;. Two of these functions are &lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/R_functions/deciles_interaction_plot.R&#34;&gt;&lt;code&gt;deciles_interaction_plot&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/R_functions/sextiles_interaction_plot.R&#34;&gt;&lt;code&gt;sextiles_interaction_plot&lt;/code&gt;&lt;/a&gt;. These functions allow the plotting of interactions between two continuous variables. In the case of &lt;code&gt;deciles_interaction_plot&lt;/code&gt;, one of the variables is divided into ten bins, known as deciles, and the other variable is unchanged. In the case of &lt;code&gt;sextiles_interaction_plot&lt;/code&gt;, one of the variables is divided into six bins, or sextiles, and the other variable is unchanged.&lt;/p&gt;
&lt;p&gt;Below, we’ll use these functions with models fitted using &lt;a href=&#34;https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf&#34;&gt;&lt;code&gt;lmerTest&lt;/code&gt;&lt;/a&gt; (Kuznetsova et al., 2022), although the functions also work with several other models (see &lt;a href=&#34;https://cran.r-project.org/web/packages/sjPlot/sjPlot.pdf&#34;&gt;sjPlot manual&lt;/a&gt;). The plots can be reproduced using the materials at &lt;a href=&#34;https://osf.io/gt5uf&#34; class=&#34;uri&#34;&gt;https://osf.io/gt5uf&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;deciles-interaction-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Deciles interaction plot&lt;/h2&gt;
&lt;div id=&#34;the-function&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The function&lt;/h3&gt;
&lt;script src=&#34;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Flanguage-sensorimotor-simulation-PhD-thesis%2Fblob%2Fmain%2FR_functions%2Fdeciles_interaction_plot.R&amp;style=default&amp;type=code&amp;showBorder=on&amp;showLineNumbers=on&amp;showFileMeta=on&amp;showFullPath=on&amp;showCopy=on&#34;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div id=&#34;the-function-in-use&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The function in use&lt;/h3&gt;
&lt;script src=&#34;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Flanguage-sensorimotor-simulation-PhD-thesis%2Fblob%2Fmain%2Fsemanticpriming%2Ffrequentist_analysis%2Fsemanticpriming-interactions-with-vocabulary-size.R&amp;style=default&amp;type=code&amp;showBorder=on&amp;showLineNumbers=on&amp;showFileMeta=on&amp;showFullPath=on&amp;showCopy=on&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/frequentist_analysis/plots/semanticpriming-interactions-with-vocabulary-size.pdf&#34;&gt;&lt;img src=&#34;Screenshot%202022-12-27%20234321.png&#34; width=&#34;580&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;sextiles-interaction-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sextiles interaction plot&lt;/h2&gt;
&lt;div id=&#34;the-function-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The function&lt;/h3&gt;
&lt;script src=&#34;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Flanguage-sensorimotor-simulation-PhD-thesis%2Fblob%2Fmain%2FR_functions%2Fsextiles_interaction_plot.R&amp;style=default&amp;type=code&amp;showBorder=on&amp;showLineNumbers=on&amp;showFileMeta=on&amp;showFullPath=on&amp;showCopy=on&#34;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div id=&#34;the-function-in-use-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The function in use&lt;/h3&gt;
&lt;script src=&#34;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Flanguage-sensorimotor-simulation-PhD-thesis%2Fblob%2Fmain%2Flexicaldecision%2Ffrequentist_analysis%2Flexicaldecision-interactions-with-vocabulary-age.R&amp;style=default&amp;type=code&amp;showBorder=on&amp;showLineNumbers=on&amp;showFileMeta=on&amp;showFullPath=on&amp;showCopy=on&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/lexicaldecision/frequentist_analysis/plots/lexicaldecision-interactions-with-vocabulary-age.pdf&#34;&gt;&lt;img src=&#34;Screenshot%202022-12-27%20234252.png&#34; width=&#34;650&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;Bernabeu, P. (2022). &lt;em&gt;Language and sensorimotor simulation in conceptual processing: Multilevel analysis and statistical power&lt;/em&gt;. Lancaster University. &lt;a href=&#34;https://doi.org/10.17635/lancaster/thesis/1795&#34; class=&#34;uri&#34;&gt;https://doi.org/10.17635/lancaster/thesis/1795&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kuznetsova, A., Brockhoff, P. B., &amp;amp; Christensen, R. H. B. (2022). &lt;em&gt;Package ’lmerTest’&lt;/em&gt;. CRAN. &lt;a href=&#34;https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lüdecke, D. (2022). &lt;em&gt;Package ’sjPlot’&lt;/em&gt;. CRAN. &lt;a href=&#34;https://cran.r-project.org/web/packages/sjPlot/sjPlot.pdf&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/sjPlot/sjPlot.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Why can&#39;t we be friends? Plotting frequentist (lmerTest) and Bayesian (brms) mixed-effects models</title>
      <link>https://pablobernabeu.github.io/2022/why-can-t-we-be-friends-plotting-frequentist-lmertest-and-bayesian-brms-mixed-effects-models/</link>
      <pubDate>Fri, 23 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/2022/why-can-t-we-be-friends-plotting-frequentist-lmertest-and-bayesian-brms-mixed-effects-models/</guid>
      <description>
&lt;script src=&#34;https://pablobernabeu.github.io/2022/why-can-t-we-be-friends-plotting-frequentist-lmertest-and-bayesian-brms-mixed-effects-models/index.en_files/clipboard/clipboard.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://pablobernabeu.github.io/2022/why-can-t-we-be-friends-plotting-frequentist-lmertest-and-bayesian-brms-mixed-effects-models/index.en_files/xaringanExtra-clipboard/xaringanExtra-clipboard.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://pablobernabeu.github.io/2022/why-can-t-we-be-friends-plotting-frequentist-lmertest-and-bayesian-brms-mixed-effects-models/index.en_files/xaringanExtra-clipboard/xaringanExtra-clipboard.js&#34;&gt;&lt;/script&gt;
&lt;script&gt;window.xaringanExtraClipboard(null, {&#34;button&#34;:&#34;Copy Code&#34;,&#34;success&#34;:&#34;Copied!&#34;,&#34;error&#34;:&#34;Press Ctrl+C to Copy&#34;})&lt;/script&gt;


&lt;p&gt;Frequentist and Bayesian statistics are sometimes regarded as fundamentally different philosophies. Indeed, can both methods qualify as philosophies, or is one of them just a pointless ritual? Is frequentist statistics about &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; values only? Are frequentist estimates diametrically opposed to Bayesian posterior distributions? Are confidence intervals and credible intervals irreconcilable? Will R crash if &lt;a href=&#34;https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf&#34;&gt;&lt;code&gt;lmerTest&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/brms.pdf&#34;&gt;&lt;code&gt;brms&lt;/code&gt;&lt;/a&gt; are simultaneously loaded? If only we could fit frequentist and Bayesian models to the same data and plot the results together, we might get a glimpse into these puzzles.&lt;/p&gt;
&lt;p&gt;All the analyses shown below can be reproduced using the materials at &lt;a href=&#34;https://osf.io/gt5uf&#34; class=&#34;uri&#34;&gt;https://osf.io/gt5uf&lt;/a&gt;. The combination of the frequentist and the Bayesian estimates in the same plot is achieved using the following custom function from &lt;a href=&#34;https://pablobernabeu.github.io/publication/pablo-bernabeu-2022-phd-thesis&#34;&gt;Bernabeu (2022)&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;visualising-frequentist-and-bayesian-estimates-in-one-plot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Visualising frequentist and Bayesian estimates in one plot&lt;/h3&gt;
&lt;p&gt;Both frequentist and Bayesian statistics offer the options of hypothesis testing and parameter estimation (Cumming, 2014; Kruschke &amp;amp; Liddell, 2018; Rouder et al., 2018; Schmalz et al., 2022; Tendeiro &amp;amp; Kiers, 2019, 2022; van Ravenzwaaij &amp;amp; Wagenmakers, 2022). In the statistical analyses conducted by Bernabeu (2022), hypothesis testing was performed within the frequentist framework, whereas parameter estimation was performed within both the frequentist and the Bayesian frameworks (for other examples of the &lt;em&gt;estimation&lt;/em&gt; approach, see Milek et al., 2018; Pregla et al., 2021; Rodríguez-Ferreiro et al., 2020).&lt;/p&gt;
&lt;script src=&#34;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Flanguage-sensorimotor-simulation-PhD-thesis%2Fblob%2Fmain%2FR_functions%2Ffrequentist_bayesian_plot.R&amp;style=default&amp;type=code&amp;showBorder=on&amp;showLineNumbers=on&amp;showFileMeta=on&amp;showFullPath=on&amp;showCopy=on&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Let’s load the function from GitHub and put it to the test.&lt;/p&gt;
&lt;div style=&#34;height: 800px; border: 0.5px dotted grey; padding: 10px; resize: both; overflow: auto;&#34;&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Presenting the frequentist and the Bayesian estimates in the same plot. 
# For this purpose, the frequentist results are merged into a plot from 
# brms::mcmc_plot()

source(&amp;#39;https://raw.githubusercontent.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/main/R_functions/frequentist_bayesian_plot.R&amp;#39;)

# install.packages(&amp;#39;devtools&amp;#39;)
# library(devtools)
# install_version(&amp;#39;tidyverse&amp;#39;, &amp;#39;1.3.1&amp;#39;)  # Due to breaking changes, Version 1.3.1 is required.
# install_version(&amp;#39;ggplot2&amp;#39;, &amp;#39;5.3.5&amp;#39;)  # Due to breaking changes, Version 5.3.5 is required.
library(tidyverse)
library(ggplot2)
library(Cairo)

# Load frequentist coefficients (estimates and confidence intervals)

KR_summary_semanticpriming_lmerTest =
  readRDS(gzcon(url(&amp;#39;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/frequentist_analysis/results/KR_summary_semanticpriming_lmerTest.rds?raw=true&amp;#39;)))

confint_semanticpriming_lmerTest =
  readRDS(gzcon(url(&amp;#39;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/frequentist_analysis/results/confint_semanticpriming_lmerTest.rds?raw=true&amp;#39;)))

# Below are the default names of the effects
# rownames(KR_summary_semanticpriming_lmerTest$coefficients)
# rownames(confint_semanticpriming_lmerTest)

# Load Bayesian posterior distributions

semanticpriming_posteriordistributions_weaklyinformativepriors_exgaussian = 
  readRDS(gzcon(url(&amp;#39;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/bayesian_analysis/results/semanticpriming_posteriordistributions_weaklyinformativepriors_exgaussian.rds?raw=true&amp;#39;)))

# Below are the default names of the effects
# levels(semanticpriming_posteriordistributions_weaklyinformativepriors_exgaussian$data$parameter)


# Reorder the components of interactions in the frequentist results to match 
# with the order present in the Bayesian results.

rownames(KR_summary_semanticpriming_lmerTest$coefficients) =
  rownames(KR_summary_semanticpriming_lmerTest$coefficients) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_recoded_interstimulus_interval:z_cosine_similarity&amp;#39;, 
              replacement = &amp;#39;z_cosine_similarity:z_recoded_interstimulus_interval&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_recoded_interstimulus_interval:z_visual_rating_diff&amp;#39;, 
              replacement = &amp;#39;z_visual_rating_diff:z_recoded_interstimulus_interval&amp;#39;)

rownames(confint_semanticpriming_lmerTest)  = 
  rownames(confint_semanticpriming_lmerTest) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_recoded_interstimulus_interval:z_cosine_similarity&amp;#39;, 
              replacement = &amp;#39;z_cosine_similarity:z_recoded_interstimulus_interval&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_recoded_interstimulus_interval:z_visual_rating_diff&amp;#39;, 
              replacement = &amp;#39;z_visual_rating_diff:z_recoded_interstimulus_interval&amp;#39;)


# Create a vector containing the names of the effects. This vector will be passed 
# to the plotting function.

new_labels = 
  
  semanticpriming_posteriordistributions_weaklyinformativepriors_exgaussian$data$parameter %&amp;gt;% 
  unique %&amp;gt;%
  
  # Remove the default &amp;#39;b_&amp;#39; from the beginning of each effect
  str_remove(&amp;#39;^b_&amp;#39;) %&amp;gt;%
  
  # Put Intercept in parentheses
  str_replace(pattern = &amp;#39;Intercept&amp;#39;, replacement = &amp;#39;(Intercept)&amp;#39;) %&amp;gt;%
  
  # First, adjust names of variables (both in main effects and in interactions)
  str_replace(pattern = &amp;#39;z_target_word_frequency&amp;#39;,
              replacement = &amp;#39;Target-word frequency&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_target_number_syllables&amp;#39;,
              replacement = &amp;#39;Number of target-word syllables&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_word_concreteness_diff&amp;#39;,
              replacement = &amp;#39;Word-concreteness difference&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_cosine_similarity&amp;#39;,
              replacement = &amp;#39;Language-based similarity&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_visual_rating_diff&amp;#39;,
              replacement = &amp;#39;Visual-strength difference&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_attentional_control&amp;#39;,
              replacement = &amp;#39;Attentional control&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_vocabulary_size&amp;#39;,
              replacement = &amp;#39;Vocabulary size&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_recoded_participant_gender&amp;#39;,
              replacement = &amp;#39;Gender&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_recoded_interstimulus_interval&amp;#39;,
              replacement = &amp;#39;SOA&amp;#39;) %&amp;gt;%
  # Show acronym in main effect of SOA
  str_replace(pattern = &amp;#39;^SOA$&amp;#39;,
              replacement = &amp;#39;Stimulus onset asynchrony (SOA)&amp;#39;) %&amp;gt;%
  
  # Second, adjust order of effects in interactions. In the output from the model, 
  # the word-level variables of interest (i.e., &amp;#39;z_cosine_similarity&amp;#39; and 
  # &amp;#39;z_visual_rating_diff&amp;#39;) sometimes appeared second in their interactions. For 
  # better consistency, the code below moves those word-level variables (with 
  # their new names) to the first position in their interactions. Note that the 
  # order does not affect the results in any way.
  sub(&amp;#39;(\\w+.*):(Language-based similarity|Visual-strength difference)&amp;#39;, 
      &amp;#39;\\2:\\1&amp;#39;, 
      .) %&amp;gt;%
  
  # Replace colons denoting interactions with times symbols
  str_replace(pattern = &amp;#39;:&amp;#39;, replacement = &amp;#39; &amp;amp;times; &amp;#39;)


# Create plot
plot_semanticpriming_frequentist_bayesian_plot_weaklyinformativepriors_exgaussian =
  frequentist_bayesian_plot(KR_summary_semanticpriming_lmerTest,
                            confint_semanticpriming_lmerTest,
                            semanticpriming_posteriordistributions_weaklyinformativepriors_exgaussian,
                            labels = new_labels, interaction_symbol_x = TRUE,
                            vertical_line_at_x = 0, x_title = &amp;#39;Effect size (&amp;amp;beta;)&amp;#39;,
                            legend_ncol = 1) + 
  theme(legend.position = &amp;#39;bottom&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_semanticpriming_frequentist_bayesian_plot_weaklyinformativepriors_exgaussian&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://pablobernabeu.github.io/2022/why-can-t-we-be-friends-plotting-frequentist-lmertest-and-bayesian-brms-mixed-effects-models/index.en_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Frequentist and Bayesian estimates are not so polar opposites, are they? What is more, the larger differences between some estimates are the result of the priors that were set on the corresponding effects. With uninformative priors, the frequentist and the Bayesian estimates are virtually identical.&lt;/p&gt;
&lt;script src=&#39;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Flanguage-sensorimotor-simulation-PhD-thesis%2Fblob%2Fmain%2Fsemanticpriming%2Fbayesian_analysis%2Fsemanticpriming_brms_weaklyinformativepriors_exgaussian.R%23L16-L35&amp;style=default&amp;type=code&amp;showBorder=on&amp;showLineNumbers=on&amp;showFileMeta=on&amp;showFullPath=on&amp;showCopy=on&#39;&gt;&lt;/script&gt;
&lt;p&gt;Now it’s time to consider in earnest:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Is frequentist statistics about &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; values only? Are frequentist estimates diametrically opposed to Bayesian posterior distributions? Are confidence intervals and credible intervals irreconcilable? Will R crash if &lt;a href=&#34;https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf&#34;&gt;&lt;code&gt;lmerTest&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/brms.pdf&#34;&gt;&lt;code&gt;brms&lt;/code&gt;&lt;/a&gt; are simultaneously loaded?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Session info&lt;/h3&gt;
&lt;p&gt;If you encounter any blockers while reproducing the above analyses using the materials at &lt;a href=&#34;https://osf.io/gt5uf&#34; class=&#34;uri&#34;&gt;https://osf.io/gt5uf&lt;/a&gt;, my current session info may be useful. For instance, the legend of the plot may not show if the latest versions of the &lt;code&gt;ggplot2&lt;/code&gt; and the &lt;code&gt;tidyverse&lt;/code&gt; packages are used. Instead, &lt;code&gt;ggplot2 3.3.5&lt;/code&gt; and &lt;code&gt;tidyverse 1.3.1&lt;/code&gt; should be installed using &lt;code&gt;install_version(&#39;ggplot2&#39;, &#39;3.3.5&#39;)&lt;/code&gt; and &lt;code&gt;install_version(&#39;tidyverse&#39;, &#39;1.3.1&#39;)&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.2.3 (2023-03-15 ucrt)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 22621)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.utf8 
## [2] LC_CTYPE=English_United States.utf8   
## [3] LC_MONETARY=English_United States.utf8
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.utf8    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] ggtext_0.1.2        Cairo_1.6-0         forcats_1.0.0      
##  [4] stringr_1.5.0       dplyr_1.1.1         purrr_1.0.1        
##  [7] readr_2.1.4         tidyr_1.3.0         tibble_3.2.1       
## [10] ggplot2_3.3.5       tidyverse_1.3.1     knitr_1.42         
## [13] xaringanExtra_0.7.0
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.10      lubridate_1.9.2  digest_0.6.31    utf8_1.2.3      
##  [5] plyr_1.8.8       R6_2.5.1         cellranger_1.1.0 ggridges_0.5.4  
##  [9] backports_1.4.1  reprex_2.0.2     evaluate_0.21    highr_0.10      
## [13] httr_1.4.6       blogdown_1.16    pillar_1.9.0     rlang_1.1.0     
## [17] uuid_1.1-0       readxl_1.4.2     rstudioapi_0.14  jquerylib_0.1.4 
## [21] rmarkdown_2.21   labeling_0.4.2   munsell_0.5.0    gridtext_0.1.5  
## [25] broom_1.0.4      compiler_4.2.3   modelr_0.1.11    xfun_0.38       
## [29] pkgconfig_2.0.3  htmltools_0.5.5  tidyselect_1.2.0 bookdown_0.33.3 
## [33] fansi_1.0.4      crayon_1.5.2     tzdb_0.4.0       dbplyr_2.3.2    
## [37] withr_2.5.0      commonmark_1.9.0 grid_4.2.3       jsonlite_1.8.4  
## [41] gtable_0.3.3     lifecycle_1.0.3  DBI_1.1.3        magrittr_2.0.3  
## [45] scales_1.2.1     cli_3.4.1        stringi_1.7.12   cachem_1.0.7    
## [49] farver_2.1.1     fs_1.6.1         xml2_1.3.3       bslib_0.4.2     
## [53] generics_0.1.3   vctrs_0.6.1      tools_4.2.3      glue_1.6.2      
## [57] markdown_1.5     hms_1.1.3        fastmap_1.1.1    yaml_2.3.7      
## [61] timechange_0.2.0 colorspace_2.1-0 rvest_1.0.3      haven_2.5.2     
## [65] sass_0.4.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;div style=&#34;text-indent:-2em; margin-left:2em;&#34;&gt;
&lt;p&gt;Bernabeu, P. (2022). &lt;em&gt;Language and sensorimotor simulation in conceptual processing: Multilevel analysis and statistical power&lt;/em&gt;. Lancaster University. &lt;a href=&#34;https://doi.org/10.17635/lancaster/thesis/1795&#34; class=&#34;uri&#34;&gt;https://doi.org/10.17635/lancaster/thesis/1795&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Cumming, G. (2014). The new statistics: Why and how. &lt;em&gt;Psychological Science, 25&lt;/em&gt;(1), 7–29. &lt;a href=&#34;https://doi.org/10.1177/0956797613504966&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1177/0956797613504966&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kruschke, J. K., &amp;amp; Liddell, T. M. (2018). The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review, 25&lt;/em&gt;(1), 178–206.&lt;/p&gt;
&lt;p&gt;Milek, A., Butler, E. A., Tackman, A. M., Kaplan, D. M., Raison, C. L., Sbarra, D. A., Vazire, S., &amp;amp; Mehl, M. R. (2018). “Eavesdropping on happiness” revisited: A pooled, multisample replication of the association between life satisfaction and observed daily conversation quantity and quality. &lt;em&gt;Psychological Science, 29&lt;/em&gt;(9), 1451–1462. &lt;a href=&#34;https://doi.org/10.1177/0956797618774252&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1177/0956797618774252&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pregla, D., Lissón, P., Vasishth, S., Burchert, F., &amp;amp; Stadie, N. (2021). Variability in sentence comprehension in aphasia in German. &lt;em&gt;Brain and Language, 222&lt;/em&gt;, 105008. &lt;a href=&#34;https://doi.org/10.1016/j.bandl.2021.105008&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1016/j.bandl.2021.105008&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Rodríguez-Ferreiro, J., Aguilera, M., &amp;amp; Davies, R. (2020). Semantic priming and schizotypal personality: Reassessing the link between thought disorder and enhanced spreading of semantic activation. &lt;em&gt;PeerJ, 8&lt;/em&gt;, e9511. &lt;a href=&#34;https://doi.org/10.7717/peerj.9511&#34; class=&#34;uri&#34;&gt;https://doi.org/10.7717/peerj.9511&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Rouder, J. N., Haaf, J. M., &amp;amp; Vandekerckhove, J. (2018). Bayesian inference for psychology, part IV: Parameter estimation and Bayes factors. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review, 25&lt;/em&gt;(1), 102–113. &lt;a href=&#34;https://doi.org/10.3758/s13423-017-1420-7&#34; class=&#34;uri&#34;&gt;https://doi.org/10.3758/s13423-017-1420-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Schmalz, X., Biurrun Manresa, J., &amp;amp; Zhang, L. (2021). What is a Bayes factor? &lt;em&gt;Psychological Methods&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.1037/met0000421&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1037/met0000421&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tendeiro, J. N., &amp;amp; Kiers, H. A. L. (2019). A review of issues about null hypothesis Bayesian testing. &lt;em&gt;Psychological Methods, 24&lt;/em&gt;(6), 774–795. &lt;a href=&#34;https://doi.org/10.1037/met0000221&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1037/met0000221&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tendeiro, J. N., &amp;amp; Kiers, H. A. L. (2022). On the white, the black, and the many shades of gray in between: Our reply to van Ravenzwaaij and Wagenmakers (2021). &lt;em&gt;Psychological Methods, 27&lt;/em&gt;(3), 466–475. &lt;a href=&#34;https://doi.org/10.1037/met0000505&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1037/met0000505&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;van Ravenzwaaij, D., &amp;amp; Wagenmakers, E.-J. (2022). Advantages masquerading as “issues” in Bayesian hypothesis testing: A commentary on Tendeiro and Kiers (2019). &lt;em&gt;Psychological Methods, 27&lt;/em&gt;(3), 451–465. &lt;a href=&#34;https://doi.org/10.1037/met0000415&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1037/met0000415&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian workflow: Prior determination, predictive checks and sensitivity analyses</title>
      <link>https://pablobernabeu.github.io/2022/bayesian-workflow-prior-determination-predictive-checks-and-sensitivity-analyses/</link>
      <pubDate>Thu, 22 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/2022/bayesian-workflow-prior-determination-predictive-checks-and-sensitivity-analyses/</guid>
      <description>
&lt;script src=&#34;https://pablobernabeu.github.io/2022/bayesian-workflow-prior-determination-predictive-checks-and-sensitivity-analyses/index.en_files/clipboard/clipboard.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://pablobernabeu.github.io/2022/bayesian-workflow-prior-determination-predictive-checks-and-sensitivity-analyses/index.en_files/xaringanExtra-clipboard/xaringanExtra-clipboard.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://pablobernabeu.github.io/2022/bayesian-workflow-prior-determination-predictive-checks-and-sensitivity-analyses/index.en_files/xaringanExtra-clipboard/xaringanExtra-clipboard.js&#34;&gt;&lt;/script&gt;
&lt;script&gt;window.xaringanExtraClipboard(null, {&#34;button&#34;:&#34;Copy Code&#34;,&#34;success&#34;:&#34;Copied!&#34;,&#34;error&#34;:&#34;Press Ctrl+C to Copy&#34;})&lt;/script&gt;


&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(ggplot2)
library(ggridges)
library(ggtext)
library(patchwork)
library(papaja)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This post presents a code-through of a Bayesian workflow in R, which can be reproduced using the materials at &lt;a href=&#34;https://osf.io/gt5uf&#34; class=&#34;uri&#34;&gt;https://osf.io/gt5uf&lt;/a&gt;. The content is &lt;em&gt;closely&lt;/em&gt; based on &lt;span class=&#34;citation&#34;&gt;Bernabeu (&lt;a href=&#34;#ref-bernabeu2022a&#34; role=&#34;doc-biblioref&#34;&gt;2022&lt;/a&gt;)&lt;/span&gt;, which was in turn based on lots of other references. In addition to those, you may wish to consider &lt;span class=&#34;citation&#34;&gt;Nicenboim et al. (&lt;a href=&#34;#ref-nicenboimInprep&#34; role=&#34;doc-biblioref&#34;&gt;n.d.&lt;/a&gt;)&lt;/span&gt;, a book in preparation that is already available online (&lt;a href=&#34;https://vasishth.github.io/bayescogsci/book&#34; class=&#34;uri&#34;&gt;https://vasishth.github.io/bayescogsci/book&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;In &lt;span class=&#34;citation&#34;&gt;Bernabeu (&lt;a href=&#34;#ref-bernabeu2022a&#34; role=&#34;doc-biblioref&#34;&gt;2022&lt;/a&gt;)&lt;/span&gt;, a Bayesian analysis was performed to complement the estimates that had been obtained in the frequentist analysis. Whereas the goal of the frequentist analysis had been hypothesis testing, for which &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; values were used, the goal of the Bayesian analysis was parameter estimation. Accordingly, we estimated the posterior distribution of every effect, without calculating Bayes factors &lt;span class=&#34;citation&#34;&gt;(for other examples of the same &lt;em&gt;estimation approach&lt;/em&gt;, see &lt;a href=&#34;#ref-milekEavesdroppingHappinessRevisited2018&#34; role=&#34;doc-biblioref&#34;&gt;Milek et al., 2018&lt;/a&gt;; &lt;a href=&#34;#ref-preglaVariabilitySentenceComprehension2021&#34; role=&#34;doc-biblioref&#34;&gt;Pregla et al., 2021&lt;/a&gt;; &lt;a href=&#34;#ref-rodriguez-ferreiroSemanticPrimingSchizotypal2020&#34; role=&#34;doc-biblioref&#34;&gt;Rodríguez-Ferreiro et al., 2020&lt;/a&gt;; for comparisons between estimation and hypothesis testing, see &lt;a href=&#34;#ref-cummingNewStatisticsWhy2014&#34; role=&#34;doc-biblioref&#34;&gt;Cumming, 2014&lt;/a&gt;; &lt;a href=&#34;#ref-kruschkeBayesianNewStatistics2018&#34; role=&#34;doc-biblioref&#34;&gt;Kruschke &amp;amp; Liddell, 2018&lt;/a&gt;; &lt;a href=&#34;#ref-rouderBayesianInferencePsychology2018&#34; role=&#34;doc-biblioref&#34;&gt;Rouder et al., 2018&lt;/a&gt;; &lt;a href=&#34;#ref-schmalzWhatBayesFactor2021&#34; role=&#34;doc-biblioref&#34;&gt;Schmalz et al., 2021&lt;/a&gt;; &lt;a href=&#34;#ref-tendeiroReviewIssuesNull2019&#34; role=&#34;doc-biblioref&#34;&gt;Tendeiro &amp;amp; Kiers, 2019&lt;/a&gt;, &lt;a href=&#34;#ref-tendeiroOnTheWhite2022&#34; role=&#34;doc-biblioref&#34;&gt;in press&lt;/a&gt;; &lt;a href=&#34;#ref-vanravenzwaaijAdvantagesMasqueradingIssues2021&#34; role=&#34;doc-biblioref&#34;&gt;van Ravenzwaaij &amp;amp; Wagenmakers, 2021&lt;/a&gt;)&lt;/span&gt;. In the estimation approach, the estimates are interpreted by considering the position of their credible intervals in relation to the expected effect size. That is, the closer an interval is to an effect size of 0, the smaller the effect of that predictor. For instance, an interval that is symmetrically centred on 0 indicates a very small effect, whereas—in comparison—an interval that does not include 0 at all indicates a far larger effect.&lt;/p&gt;
&lt;p&gt;This analysis served two purposes: first, to ascertain the interpretation of the smaller effects—which were identified as unreliable in the power analyses—, and second, to complement the estimates obtained in the frequentist analysis. The latter purpose was pertinent because the frequentist models presented convergence warnings—even though it must be noted that a previous study found that frequentist and Bayesian estimates were similar despite convergence warnings appearing in the frequentist analysis &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-rodriguez-ferreiroSemanticPrimingSchizotypal2020&#34; role=&#34;doc-biblioref&#34;&gt;Rodríguez-Ferreiro et al., 2020&lt;/a&gt;)&lt;/span&gt;. Furthermore, the complementary analysis was pertinent because the frequentist models presented residual errors that deviated from normality—even though mixed-effects models are fairly robust to such a deviation &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kniefViolatingNormalityAssumption2021&#34; role=&#34;doc-biblioref&#34;&gt;Knief &amp;amp; Forstmeier, 2021&lt;/a&gt;; &lt;a href=&#34;#ref-schielzethRobustnessLinearMixed2020&#34; role=&#34;doc-biblioref&#34;&gt;Schielzeth et al., 2020&lt;/a&gt;)&lt;/span&gt;. Owing to these precedents, we expected to find broadly similar estimates in the frequentist analyses and in the Bayesian ones. Across studies, each frequentist model has a Bayesian counterpart, with the exception of the secondary analysis performed in Study 2.1 (semantic priming) that included &lt;code&gt;vision-based similarity&lt;/code&gt; as a predictor. The R package ‘brms’, Version 2.17.0, was used for the Bayesian analysis &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-burknerAdvancedBayesianMultilevel2018&#34; role=&#34;doc-biblioref&#34;&gt;Bürkner, 2018&lt;/a&gt;; &lt;a href=&#34;#ref-burknerPackageBrms2022&#34; role=&#34;doc-biblioref&#34;&gt;Bürkner et al., 2022&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;priors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Priors&lt;/h2&gt;
&lt;p&gt;Priors are one of the hardest nuts to crack in Bayesian statistics. First, it can be useful to inspect what priors can be set in the model. Second, it is important to visualise a reasonable set of priors based on the available literature or any other available sources. Third, just before fitting the model, the adequacy of a range of priors should be assessed using prior predictive checks. Fourth, posterior predictive checks were performed to assess the consistency between the observed data and new data predicted by the posterior distributions. Fifth, the influence of the priors on the results should be assessed through a prior sensitivity analysis &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-leeBayesianCognitiveModeling2014&#34; role=&#34;doc-biblioref&#34;&gt;Lee &amp;amp; Wagenmakers, 2014&lt;/a&gt;; &lt;a href=&#34;#ref-schootBayesianStatisticsModelling2021&#34; role=&#34;doc-biblioref&#34;&gt;Van de Schoot et al., 2021&lt;/a&gt;; also see &lt;a href=&#34;#ref-bernabeu2022a&#34; role=&#34;doc-biblioref&#34;&gt;Bernabeu, 2022&lt;/a&gt;; &lt;a href=&#34;#ref-preglaVariabilitySentenceComprehension2021&#34; role=&#34;doc-biblioref&#34;&gt;Pregla et al., 2021&lt;/a&gt;; &lt;a href=&#34;#ref-rodriguez-ferreiroSemanticPrimingSchizotypal2020&#34; role=&#34;doc-biblioref&#34;&gt;Rodríguez-Ferreiro et al., 2020&lt;/a&gt;; &lt;a href=&#34;#ref-stoneInteractionGrammaticallyDistinct2021&#34; role=&#34;doc-biblioref&#34;&gt;Stone et al., 2021&lt;/a&gt;; &lt;a href=&#34;#ref-stoneEffectDecayLexical2020&#34; role=&#34;doc-biblioref&#34;&gt;Stone et al., 2020&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;checking-what-priors-can-be-set&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1. Checking what priors can be set&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;brms::get_prior&lt;/code&gt; function can be used to check what effects in the model can be assigned a prior. The output (see &lt;a href=&#34;http://paul-buerkner.github.io/brms/reference/get_prior.html&#34;&gt;example&lt;/a&gt;) will include the current (perhaps default) prior on each effect.&lt;/p&gt;
&lt;script src=&#34;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Flanguage-sensorimotor-simulation-PhD-thesis%2Fblob%2Fmain%2Fsemanticpriming%2Fbayesian_analysis%2Fprior_predictive_checks%2Fsemanticpriming_priorpredictivecheck_informativepriors.R%23L28-L100&amp;style=default&amp;type=code&amp;showBorder=on&amp;showLineNumbers=on&amp;showFileMeta=on&amp;showFullPath=on&amp;showCopy=on&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;determining-the-priors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2. Determining the priors&lt;/h2&gt;
&lt;p&gt;The priors were established by inspecting the effect sizes obtained in previous studies as well as the effect sizes obtained in our frequentist analyses of the present data (reported in Studies 2.1, 2.2 and 2.3 below). In the first regard, the previous studies that were considered were selected because the experimental paradigms, variables and analytical procedures they had used were similar to those used in our current studies. Specifically, regarding paradigms, we sought studies that implemented: (I) semantic priming with a lexical decision task—as in Study 2.1—, (II) semantic decision—as in Study 2.2—, or (III) lexical decision—as in Study 2.3. Regarding analytical procedures, we sought studies in which both the dependent and the independent variables were &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;-scored. We found two studies that broadly matched these criteria: &lt;span class=&#34;citation&#34;&gt;Lim et al. (&lt;a href=&#34;#ref-lim2020a&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; (see Table 5 therein) and &lt;span class=&#34;citation&#34;&gt;Pexman &amp;amp; Yap (&lt;a href=&#34;#ref-pexman2018a&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt; (see Tables 6 and 7 therein). Out of these studies, &lt;span class=&#34;citation&#34;&gt;Pexman &amp;amp; Yap (&lt;a href=&#34;#ref-pexman2018a&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt; contained the variables that were most similar to ours, which included vocabulary size (labelled ‘NAART’) and word frequency.&lt;/p&gt;
&lt;p&gt;Based on both these studies and on the frequentist analyses reported below, a range of effect sizes was identified that spanned between β = -0.30 and β = 0.30. This range was centred around 0 as the variables were &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;-scored. The bounds of this range were determined by the largest effects, which appeared in &lt;span class=&#34;citation&#34;&gt;Pexman &amp;amp; Yap (&lt;a href=&#34;#ref-pexman2018a&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt;. Pexman et al. conducted a semantic decision study, and split the data set into abstract and concrete words. The two largest effects they found were—first—a word concreteness effect in the concrete-words analysis of β = -0.41, and—second—a word concreteness effect in the abstract-words analysis of β = 0.20. Unlike Pexman et al., we did not split the data set into abstract and concrete words, but analysed these sets together. Therefore, we averaged between the aforementioned values, obtaining a range between β = -0.30 and β = 0.30.&lt;/p&gt;
&lt;p&gt;In the results of &lt;span class=&#34;citation&#34;&gt;Lim et al. (&lt;a href=&#34;#ref-lim2020a&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;Pexman &amp;amp; Yap (&lt;a href=&#34;#ref-pexman2018a&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt;, and in our frequentist results, some effects consistently presented a negative polarity (i.e., leading to shorter response times), whereas some other effects were consistently positive. We incorporated the direction of effects into the priors only in cases of large effects that had presented a consistent direction (either positive or negative) in previous studies and in our frequentist analyses in the present studies. These criteria were matched by the following variables: word frequency—with a negative direction, as higher word frequency leads to shorter RTs &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-brysbaertWordFrequencyEffect2018a&#34; role=&#34;doc-biblioref&#34;&gt;Brysbaert et al., 2018&lt;/a&gt;; &lt;a href=&#34;#ref-brysbaertImpactWordPrevalence2016&#34; role=&#34;doc-biblioref&#34;&gt;Brysbaert et al., 2016&lt;/a&gt;; &lt;a href=&#34;#ref-lim2020a&#34; role=&#34;doc-biblioref&#34;&gt;Lim et al., 2020&lt;/a&gt;; &lt;a href=&#34;#ref-mendesPervasiveEffectWord2021&#34; role=&#34;doc-biblioref&#34;&gt;Mendes &amp;amp; Undorf, 2021&lt;/a&gt;; &lt;a href=&#34;#ref-pexman2018a&#34; role=&#34;doc-biblioref&#34;&gt;Pexman &amp;amp; Yap, 2018&lt;/a&gt;)&lt;/span&gt;—, number of letters and number of syllables—both with positive directions &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-bartonWordlengthEffectReading2014&#34; role=&#34;doc-biblioref&#34;&gt;Barton et al., 2014&lt;/a&gt;; &lt;a href=&#34;#ref-beyersmannEvidenceEmbeddedWord2020&#34; role=&#34;doc-biblioref&#34;&gt;Beyersmann et al., 2020&lt;/a&gt;; &lt;a href=&#34;#ref-pexman2018a&#34; role=&#34;doc-biblioref&#34;&gt;Pexman &amp;amp; Yap, 2018&lt;/a&gt;)&lt;/span&gt;—, and orthographic Levenshtein distance—with a positive direction &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-cerniMotorExpertiseTyping2016&#34; role=&#34;doc-biblioref&#34;&gt;Cerni et al., 2016&lt;/a&gt;; &lt;a href=&#34;#ref-dijkstraMultilinkComputationalModel2019&#34; role=&#34;doc-biblioref&#34;&gt;Dijkstra et al., 2019&lt;/a&gt;; &lt;a href=&#34;#ref-kimEffectsLexicalFeatures2018&#34; role=&#34;doc-biblioref&#34;&gt;Kim et al., 2018&lt;/a&gt;; &lt;a href=&#34;#ref-yarkoniMovingColtheartNew2008&#34; role=&#34;doc-biblioref&#34;&gt;Yarkoni et al., 2008&lt;/a&gt;)&lt;/span&gt;. We did not incorporate information about the direction of the word concreteness effect, as this effect can follow different directions in abstract and concrete words &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-brysbaert2014a&#34; role=&#34;doc-biblioref&#34;&gt;Brysbaert et al., 2014&lt;/a&gt;; &lt;a href=&#34;#ref-pexman2018a&#34; role=&#34;doc-biblioref&#34;&gt;Pexman &amp;amp; Yap, 2018&lt;/a&gt;)&lt;/span&gt;, and we analysed both sets of words together. In conclusion, the four predictors that had directional priors were covariates. All the other predictors had priors centred on 0. Last, as a methodological matter, it is noteworthy that most of the psycholinguistic studies applying Bayesian analysis have not incorporated any directional information in priors &lt;span class=&#34;citation&#34;&gt;(e.g., &lt;a href=&#34;#ref-preglaVariabilitySentenceComprehension2021&#34; role=&#34;doc-biblioref&#34;&gt;Pregla et al., 2021&lt;/a&gt;; &lt;a href=&#34;#ref-rodriguez-ferreiroSemanticPrimingSchizotypal2020&#34; role=&#34;doc-biblioref&#34;&gt;Rodríguez-Ferreiro et al., 2020&lt;/a&gt;; &lt;a href=&#34;#ref-stoneEffectDecayLexical2020&#34; role=&#34;doc-biblioref&#34;&gt;Stone et al., 2020&lt;/a&gt;; cf. &lt;a href=&#34;#ref-stoneInteractionGrammaticallyDistinct2021&#34; role=&#34;doc-biblioref&#34;&gt;Stone et al., 2021&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;prior-distributions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Prior distributions&lt;/h3&gt;
&lt;p&gt;The choice of priors can influence the results in consequential ways. To assess the extent of this influence, &lt;em&gt;prior sensitivity analyses&lt;/em&gt; have been recommended. These analyses are performed by comparing the effect of more and less strict priors—or, in other words, priors varying in their degree of informativeness. The degree of variation is adjusted through the standard deviation, and the means are not varied &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-leeBayesianCognitiveModeling2014&#34; role=&#34;doc-biblioref&#34;&gt;Lee &amp;amp; Wagenmakers, 2014&lt;/a&gt;; &lt;a href=&#34;#ref-stoneEffectDecayLexical2020&#34; role=&#34;doc-biblioref&#34;&gt;Stone et al., 2020&lt;/a&gt;; &lt;a href=&#34;#ref-schootBayesianStatisticsModelling2021&#34; role=&#34;doc-biblioref&#34;&gt;Van de Schoot et al., 2021&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In this way, we compared the results obtained using ‘informative’ priors (&lt;span class=&#34;math inline&#34;&gt;\(SD\)&lt;/span&gt; = 0.1), ‘weakly-informative’ priors (&lt;span class=&#34;math inline&#34;&gt;\(SD\)&lt;/span&gt; = 0.2) and ‘diffuse’ priors (&lt;span class=&#34;math inline&#34;&gt;\(SD\)&lt;/span&gt; = 0.3). These standard deviations were chosen so that around 95% of values in the informative priors would fall within our initial range of effect sizes that spanned from -0.30 to 0.30. All priors are illustrated in the figure below. These priors resembled others from previous psycholinguistic studies &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-preglaVariabilitySentenceComprehension2021&#34; role=&#34;doc-biblioref&#34;&gt;Pregla et al., 2021&lt;/a&gt;; &lt;a href=&#34;#ref-stoneInteractionGrammaticallyDistinct2021&#34; role=&#34;doc-biblioref&#34;&gt;Stone et al., 2021&lt;/a&gt;; &lt;a href=&#34;#ref-stoneEffectDecayLexical2020&#34; role=&#34;doc-biblioref&#34;&gt;Stone et al., 2020&lt;/a&gt;)&lt;/span&gt;. For instance, &lt;span class=&#34;citation&#34;&gt;Stone et al. (&lt;a href=&#34;#ref-stoneEffectDecayLexical2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; used the following priors: &lt;span class=&#34;math inline&#34;&gt;\(Normal\)&lt;/span&gt;(0, 0.1), &lt;span class=&#34;math inline&#34;&gt;\(Normal\)&lt;/span&gt;(0, 0.3) and &lt;span class=&#34;math inline&#34;&gt;\(Normal\)&lt;/span&gt;(0, 1). The range of standard deviations we used—i.e., 0.1, 0.2 and 0.3—was narrower than those of previous studies because our dependent variable and our predictors were &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;-scored, resulting in small estimates and small &lt;span class=&#34;math inline&#34;&gt;\(SD\)&lt;/span&gt;s &lt;span class=&#34;citation&#34;&gt;(see &lt;a href=&#34;#ref-lim2020a&#34; role=&#34;doc-biblioref&#34;&gt;Lim et al., 2020&lt;/a&gt;; &lt;a href=&#34;#ref-pexman2018a&#34; role=&#34;doc-biblioref&#34;&gt;Pexman &amp;amp; Yap, 2018&lt;/a&gt;)&lt;/span&gt;. These priors were used on the fixed effects and on the standard deviation parameters of the fixed effects. For the correlations among the random effects, an &lt;span class=&#34;math inline&#34;&gt;\(LKJ\)&lt;/span&gt;(2) prior was used &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-lewandowskiGeneratingRandomCorrelation2009&#34; role=&#34;doc-biblioref&#34;&gt;Lewandowski et al., 2009&lt;/a&gt;)&lt;/span&gt;. This is a ‘regularising’ prior, as it assumes that high correlations among random effects are rare &lt;span class=&#34;citation&#34;&gt;(also used in &lt;a href=&#34;#ref-rodriguez-ferreiroSemanticPrimingSchizotypal2020&#34; role=&#34;doc-biblioref&#34;&gt;Rodríguez-Ferreiro et al., 2020&lt;/a&gt;; &lt;a href=&#34;#ref-stoneInteractionGrammaticallyDistinct2021&#34; role=&#34;doc-biblioref&#34;&gt;Stone et al., 2021&lt;/a&gt;; &lt;a href=&#34;#ref-stoneEffectDecayLexical2020&#34; role=&#34;doc-biblioref&#34;&gt;Stone et al., 2020&lt;/a&gt;; &lt;a href=&#34;#ref-vasishthBayesianDataAnalysis2018&#34; role=&#34;doc-biblioref&#34;&gt;Vasishth et al., 2018&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Set seed number to ensure exact reproducibility 
# of the random distributions
set.seed(123)

# The code below plots all our types of priors. Each distribution 
# contains 10,000 simulations, resulting in 90,000 rows.

# The green vertical rectangle shows the range of plausible effect 
# sizes based on previous studies that applied a similar analysis 
# (Lim et al., 2020, https://doi.org/10.1177/1747021820906566; 
# Pexman &amp;amp; Yap, 2018, https://doi.org/10.1037/xlm0000499) as 
# well as on the frequentist analyses of the current data.

priors = data.frame(
  
  informativeness = 
    as.factor(c(rep(&amp;#39;Informative priors (*SD* = 0.1)&amp;#39;, 30000),
                rep(&amp;#39;Weakly-informative priors (*SD* = 0.2)&amp;#39;, 30000),
                rep(&amp;#39;Diffuse priors (*SD* = 0.3)&amp;#39;, 30000))), 
  
  direction = as.factor(c(rep(&amp;#39;negative&amp;#39;, 10000), 
                          rep(&amp;#39;neutral&amp;#39;, 10000),
                          rep(&amp;#39;positive&amp;#39;, 10000),
                          rep(&amp;#39;negative&amp;#39;, 10000), 
                          rep(&amp;#39;neutral&amp;#39;, 10000),
                          rep(&amp;#39;positive&amp;#39;, 10000),
                          rep(&amp;#39;negative&amp;#39;, 10000), 
                          rep(&amp;#39;neutral&amp;#39;, 10000),
                          rep(&amp;#39;positive&amp;#39;, 10000))),
  
  direction_and_distribution = 
    as.factor(c(rep(&amp;#39;Negative (*M* = -0.1)&amp;lt;br&amp;gt;*Normal*(-0.1, 0.1)&amp;#39;, 10000), 
                rep(&amp;#39;Neutral (*M* = 0)&amp;lt;br&amp;gt;*Normal*(0, 0.1)&amp;#39;, 10000),
                rep(&amp;#39;Positive (*M* = 0.1)&amp;lt;br&amp;gt;*Normal*(0.1, 0.1)&amp;#39;, 10000),
                rep(&amp;#39;Negative (*M* = -0.1)&amp;lt;br&amp;gt;*Normal*(-0.1, 0.2)&amp;#39;, 10000),
                rep(&amp;#39;Neutral (*M* = 0)&amp;lt;br&amp;gt;*Normal*(0, 0.2)&amp;#39;, 10000),
                rep(&amp;#39;Positive (*M* = 0.1)&amp;lt;br&amp;gt;*Normal*(0.1, 0.2)&amp;#39;, 10000),
                rep(&amp;#39;Negative (*M* = -0.1)&amp;lt;br&amp;gt;*Normal*(-0.1, 0.3)&amp;#39;, 10000), 
                rep(&amp;#39;Neutral (*M* = 0)&amp;lt;br&amp;gt;*Normal*(0, 0.3)&amp;#39;, 10000),
                rep(&amp;#39;Positive (*M* = 0.1)&amp;lt;br&amp;gt;*Normal*(0.1, 0.3)&amp;#39;, 10000))),
  
  estimate = c(rnorm(10000, m = -0.1, sd = 0.1),
               rnorm(10000, m = 0, sd = 0.1),
               rnorm(10000, m = 0.1, sd = 0.1),
               rnorm(10000, m = -0.1, sd = 0.2),
               rnorm(10000, m = 0, sd = 0.2),
               rnorm(10000, m = 0.1, sd = 0.2),
               rnorm(10000, m = -0.1, sd = 0.3),
               rnorm(10000, m = 0, sd = 0.3),
               rnorm(10000, m = 0.1, sd = 0.3))
)

# Order factor levels

priors$informativeness = 
  ordered(priors$informativeness, 
          levels = c(&amp;#39;Informative priors (*SD* = 0.1)&amp;#39;, 
                     &amp;#39;Weakly-informative priors (*SD* = 0.2)&amp;#39;, 
                     &amp;#39;Diffuse priors (*SD* = 0.3)&amp;#39;))

priors$direction = 
  ordered(priors$direction, 
          levels = c(&amp;#39;negative&amp;#39;, &amp;#39;neutral&amp;#39;, &amp;#39;positive&amp;#39;))

priors$direction_and_distribution =
  ordered(priors$direction_and_distribution,
          levels = c(&amp;#39;Negative (*M* = -0.1)&amp;lt;br&amp;gt;*Normal*(-0.1, 0.1)&amp;#39;, 
                     &amp;#39;Neutral (*M* = 0)&amp;lt;br&amp;gt;*Normal*(0, 0.1)&amp;#39;,
                     &amp;#39;Positive (*M* = 0.1)&amp;lt;br&amp;gt;*Normal*(0.1, 0.1)&amp;#39;,
                     &amp;#39;Negative (*M* = -0.1)&amp;lt;br&amp;gt;*Normal*(-0.1, 0.2)&amp;#39;, 
                     &amp;#39;Neutral (*M* = 0)&amp;lt;br&amp;gt;*Normal*(0, 0.2)&amp;#39;,
                     &amp;#39;Positive (*M* = 0.1)&amp;lt;br&amp;gt;*Normal*(0.1, 0.2)&amp;#39;,
                     &amp;#39;Negative (*M* = -0.1)&amp;lt;br&amp;gt;*Normal*(-0.1, 0.3)&amp;#39;, 
                     &amp;#39;Neutral (*M* = 0)&amp;lt;br&amp;gt;*Normal*(0, 0.3)&amp;#39;,
                     &amp;#39;Positive (*M* = 0.1)&amp;lt;br&amp;gt;*Normal*(0.1, 0.3)&amp;#39;))


# PLOT zone

colours = c(&amp;#39;#7276A2&amp;#39;, &amp;#39;black&amp;#39;, &amp;#39;#A27272&amp;#39;)
fill_colours = c(&amp;#39;#CCCBE7&amp;#39;, &amp;#39;#D7D7D7&amp;#39;, &amp;#39;#E7CBCB&amp;#39;)

# Initialise plot (`aes` specified separately to allow 
# use of `geom_rect` at the end)
ggplot() +
  
  # Turn to the distributions
  stat_density_ridges(data = priors, 
                      aes(x = estimate, y = direction_and_distribution, 
                          color = direction, fill = direction),
                      geom = &amp;#39;density_ridges_gradient&amp;#39;, alpha = 0.7, 
                      jittered_points = TRUE, quantile_lines = TRUE, 
                      quantiles = c(0.025, 0.975), show.legend = F) +
  scale_color_manual(values = colours) + 
  scale_fill_manual(values = fill_colours) + 
  # Adjust X axis to the random distributions obtained
  scale_x_continuous(limits = c(min(priors$estimate), 
                                max(priors$estimate)), 
                     n.breaks = 6, expand = c(0.04, 0.04)) +
  scale_y_discrete(expand = expansion(add = c(0.18, 1.9))) +
  # Facets containing the three models varying in informativeness
  facet_wrap(vars(informativeness), scales = &amp;#39;free&amp;#39;, dir = &amp;#39;v&amp;#39;) +
  # Vertical line at x = 0
  geom_vline(xintercept = 0, linetype = &amp;#39;dashed&amp;#39;, color = &amp;#39;grey50&amp;#39;) +
  xlab(&amp;#39;Effect size (&amp;amp;beta;)&amp;#39;) + 
  ylab(&amp;#39;Direction of the prior and corresponding distribution&amp;#39;) +
  theme_minimal() +
  theme(axis.title.x = ggtext::element_markdown(size = 12, margin = margin(t = 9)),
        axis.text.x = ggtext::element_markdown(size = 11, margin = margin(t = 4)),
        axis.title.y = ggtext::element_markdown(size = 12, margin = margin(r = 9)),
        axis.text.y = ggtext::element_markdown(lineheight = 1.6, colour = colours),
        strip.background = element_rect(fill = &amp;#39;grey98&amp;#39;, colour = &amp;#39;grey90&amp;#39;,
                                        linetype = &amp;#39;solid&amp;#39;),
        strip.text = element_markdown(size = 11, margin = margin(t = 7, b = 7)),
        panel.spacing.y = unit(9, &amp;#39;pt&amp;#39;), panel.grid.minor = element_blank(), 
        plot.margin = margin(8, 8, 9, 8)
  ) +
  
  # Shaded rectangle containing range of previous effects
  geom_rect(data = data.frame(x = 1), xmin = -0.3, xmax = 0.3, 
            ymin = -Inf, ymax = Inf, fill = &amp;#39;darkgreen&amp;#39;, alpha = .3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://pablobernabeu.github.io/2022/bayesian-workflow-prior-determination-predictive-checks-and-sensitivity-analyses/index.en_files/figure-html/bayesian-priors-1.png&#34; width=&#34;480&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Priors used in the three studies. The green vertical rectangle shows the range of plausible effect sizes based on previous studies and on our frequentist analyses. In the informative priors, around 95% of the values fall within the range.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;prior-predictive-checks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3. Prior predictive checks&lt;/h2&gt;
&lt;p&gt;The adequacy of each of these priors was assessed by performing prior predictive checks, in which we compared the observed data to the predictions of the model &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-schootBayesianStatisticsModelling2021&#34; role=&#34;doc-biblioref&#34;&gt;Van de Schoot et al., 2021&lt;/a&gt;)&lt;/span&gt;. Furthermore, in these checks we also tested the adequacy of two model-wide distributions: the traditional Gaussian distribution (default in most analyses) and an exponentially modified Gaussian—dubbed ‘ex-Gaussian’—distribution &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-matzkePsychologicalInterpretationExGaussian2009&#34; role=&#34;doc-biblioref&#34;&gt;Matzke &amp;amp; Wagenmakers, 2009&lt;/a&gt;)&lt;/span&gt;. The ex-Gaussian distribution was considered because the residual errors of the frequentist models were not normally distributed &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-loTransformNotTransform2015&#34; role=&#34;doc-biblioref&#34;&gt;Lo &amp;amp; Andrews, 2015&lt;/a&gt;)&lt;/span&gt;, and because this distribution was found to be more appropriate than the Gaussian one in a previous, related study &lt;span class=&#34;citation&#34;&gt;(see supplementary materials of &lt;a href=&#34;#ref-rodriguez-ferreiroSemanticPrimingSchizotypal2020&#34; role=&#34;doc-biblioref&#34;&gt;Rodríguez-Ferreiro et al., 2020&lt;/a&gt;)&lt;/span&gt;. The ex-Gaussian distribution had an identity link function, which preserves the interpretability of the coefficients, as opposed to a transformation applied directly to the dependent variable &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-loTransformNotTransform2015&#34; role=&#34;doc-biblioref&#34;&gt;Lo &amp;amp; Andrews, 2015&lt;/a&gt;)&lt;/span&gt;. The results of these prior predictive checks revealed that the priors were adequate, and that the ex-Gaussian distribution was more appropriate than the Gaussian one, converging with &lt;span class=&#34;citation&#34;&gt;Rodríguez-Ferreiro et al. (&lt;a href=&#34;#ref-rodriguez-ferreiroSemanticPrimingSchizotypal2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt;. Therefore, the ex-Gaussian distribution was used in the final models.&lt;/p&gt;
&lt;script src=&#34;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Flanguage-sensorimotor-simulation-PhD-thesis%2Fblob%2Fmain%2Fsemanticpriming%2Fbayesian_analysis%2Fprior_predictive_checks%2Fsemanticpriming_priorpredictivecheck_informativepriors.R%23L105-L235&amp;style=default&amp;type=code&amp;showBorder=on&amp;showLineNumbers=on&amp;showFileMeta=on&amp;showFullPath=on&amp;showCopy=on&#34;&gt;&lt;/script&gt;
&lt;div id=&#34;models-with-a-gaussian-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Models with a Gaussian distribution&lt;/h3&gt;
&lt;p&gt;The figures below show the prior predictive checks for the Gaussian models. These plots show the maximum, mean and minimum values of the observed data (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) and those of the predicted distribution (&lt;span class=&#34;math inline&#34;&gt;\(y_{rep}\)&lt;/span&gt;, which stands for &lt;em&gt;rep&lt;/em&gt;lications of the outcome). The way of interpreting these plots is by comparing the observed data to the predicted distribution. The specifics of this comparison vary across the three plots. First, in the upper plot, which shows the maximum values, the ideal scenario would show the observed maximum value (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) overlapping with the maximum value of the predicted distribution (&lt;span class=&#34;math inline&#34;&gt;\(y_{rep}\)&lt;/span&gt;). Second, in the middle plot, showing the mean values, the ideal scenario would show the observed mean value (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) overlapping with the mean value of the predicted distribution (&lt;span class=&#34;math inline&#34;&gt;\(y_{rep}\)&lt;/span&gt;). Last, in the lower plot, which shows the minimum values, the ideal scenario would have the observed minimum value (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) overlapping with the minimum value of the predicted distribution (&lt;span class=&#34;math inline&#34;&gt;\(y_{rep}\)&lt;/span&gt;). While the overlap need not be absolute, the closer the observed and the predicted values are on the X axis, the better. As such, the three predictive checks below—corresponding to models that used the default Gaussian distribution—show that the priors fitted the data acceptably but not very well.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/bayesian_analysis/prior_predictive_checks/plots/semanticpriming_priorpredictivecheck_informativepriors.pdf&#34;&gt;See plot on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Prior predictive checks for the Gaussian, informative prior model from the semantic priming study. &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; = observed data; &lt;span class=&#34;math inline&#34;&gt;\(y_{rep}\)&lt;/span&gt; = predicted data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/bayesian_analysis/prior_predictive_checks/plots/semanticpriming_priorpredictivecheck_weaklyinformativepriors.pdf&#34;&gt;See plot on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Prior predictive checks for the Gaussian, weakly-informative prior model from the semantic priming study. &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; = observed data; &lt;span class=&#34;math inline&#34;&gt;\(y_{rep}\)&lt;/span&gt; = predicted data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/bayesian_analysis/prior_predictive_checks/plots/semanticpriming_priorpredictivecheck_diffusepriors.pdf&#34;&gt;See plot on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Prior predictive checks for the Gaussian, diffuse prior model from the semantic priming study. &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; = observed data; &lt;span class=&#34;math inline&#34;&gt;\(y_{rep}\)&lt;/span&gt; = predicted data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;models-with-an-exponentially-modified-gaussian-i.e.-ex-gaussian-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Models with an exponentially-modified Gaussian (i.e., ex-Gaussian) distribution&lt;/h3&gt;
&lt;p&gt;In contrast to the above results, the figures below demonstrate that, when an ex-Gaussian distribution was used, the priors fitted the data far better, which converged with the results of a similar comparison performed by Rodríguez-Ferreiro et al. (2020; see supplementary materials of the latter study).&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/bayesian_analysis/prior_predictive_checks/plots/semanticpriming_priorpredictivecheck_informativepriors_exgaussian.pdf&#34;&gt;See plot on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Prior predictive checks for the ex-Gaussian, informative prior model from the semantic priming study. &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; = observed data; &lt;span class=&#34;math inline&#34;&gt;\(y_{rep}\)&lt;/span&gt; = predicted data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/bayesian_analysis/prior_predictive_checks/plots/semanticpriming_priorpredictivecheck_weaklyinformativepriors_exgaussian.pdf&#34;&gt;See plot on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Prior predictive checks for the ex-Gaussian, weakly-informative prior model from the semantic priming study. &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; = observed data; &lt;span class=&#34;math inline&#34;&gt;\(y_{rep}\)&lt;/span&gt; = predicted data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/bayesian_analysis/prior_predictive_checks/plots/semanticpriming_priorpredictivecheck_diffusepriors_exgaussian.pdf&#34;&gt;See plot on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Prior predictive checks for the ex-Gaussian, diffuse prior model from the semantic priming study. &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; = observed data; &lt;span class=&#34;math inline&#34;&gt;\(y_{rep}\)&lt;/span&gt; = predicted data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;posterior-predictive-checks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;4. Posterior predictive checks&lt;/h2&gt;
&lt;p&gt;Based on the results from the prior predictive checks, the ex-Gaussian distribution was used in the final models. Next, posterior predictive checks were performed to assess the consistency between the observed data and new data predicted by the posterior distributions &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-schootBayesianStatisticsModelling2021&#34; role=&#34;doc-biblioref&#34;&gt;Van de Schoot et al., 2021&lt;/a&gt;)&lt;/span&gt;. The figure below presents the posterior predictive checks for the latter models. The interpretation of these plots is simple: the distributions of the observed (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) and the predicted data (&lt;span class=&#34;math inline&#34;&gt;\(y_{rep}\)&lt;/span&gt;) should be as similar as possible. As such, the plots below suggest that the results are trustworthy.&lt;/p&gt;
&lt;script src=&#34;https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpablobernabeu%2Flanguage-sensorimotor-simulation-PhD-thesis%2Fblob%2Fmain%2Fsemanticpriming%2Fbayesian_analysis%2Fposterior_predictive_checks%2Fsemanticpriming_posteriorpredictivechecks.R&amp;style=default&amp;type=code&amp;showBorder=on&amp;showLineNumbers=on&amp;showFileMeta=on&amp;showFullPath=on&amp;showCopy=on&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/bayesian_analysis/posterior_predictive_checks/plots/semanticpriming_posteriorpredictivechecks_allpriors_exgaussian.pdf&#34;&gt;See plot on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Posterior predictive checks for the (ex-Gaussian) models from the semantic priming study. The observed data (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) and the predicted data (&lt;span class=&#34;math inline&#34;&gt;\(y_{rep}\)&lt;/span&gt;) almost entirely overlap with each other, demonstrating a very good fit.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;prior-sensitivity-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;5. Prior sensitivity analysis&lt;/h2&gt;
&lt;p&gt;In the main analysis, the informative, weakly-informative and diffuse priors were used in separate models. In other words, in each model, all priors had the same degree of informativeness &lt;span class=&#34;citation&#34;&gt;(as done in &lt;a href=&#34;#ref-preglaVariabilitySentenceComprehension2021&#34; role=&#34;doc-biblioref&#34;&gt;Pregla et al., 2021&lt;/a&gt;; &lt;a href=&#34;#ref-rodriguez-ferreiroSemanticPrimingSchizotypal2020&#34; role=&#34;doc-biblioref&#34;&gt;Rodríguez-Ferreiro et al., 2020&lt;/a&gt;; &lt;a href=&#34;#ref-stoneInteractionGrammaticallyDistinct2021&#34; role=&#34;doc-biblioref&#34;&gt;Stone et al., 2021&lt;/a&gt;; &lt;a href=&#34;#ref-stoneEffectDecayLexical2020&#34; role=&#34;doc-biblioref&#34;&gt;Stone et al., 2020&lt;/a&gt;)&lt;/span&gt;. In this way, a prior sensitivity analysis was performed to acknowledge the likely influence of the priors on the posterior distributions—that is, on the results &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-leeBayesianCognitiveModeling2014&#34; role=&#34;doc-biblioref&#34;&gt;Lee &amp;amp; Wagenmakers, 2014&lt;/a&gt;; &lt;a href=&#34;#ref-stoneEffectDecayLexical2020&#34; role=&#34;doc-biblioref&#34;&gt;Stone et al., 2020&lt;/a&gt;; &lt;a href=&#34;#ref-schootBayesianStatisticsModelling2021&#34; role=&#34;doc-biblioref&#34;&gt;Van de Schoot et al., 2021&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We’ll first load a &lt;a href=&#34;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/R_functions/frequentist_bayesian_plot.R&#34;&gt;custom function (&lt;code&gt;frequentist_bayesian_plot&lt;/code&gt;)&lt;/a&gt; from GitHub.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;source(&amp;#39;https://raw.githubusercontent.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/main/R_functions/frequentist_bayesian_plot.R&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;height: 800px; border: 0.5px dotted grey; padding: 10px; resize: both; overflow: auto;&#34;&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Presenting the frequentist and the Bayesian estimates in the same plot. 
# For this purpose, the frequentist results are merged into a plot from 
# brms::mcmc_plot()

# install.packages(&amp;#39;devtools&amp;#39;)
# library(devtools)
# install_version(&amp;#39;tidyverse&amp;#39;, &amp;#39;1.3.1&amp;#39;)  # Due to breaking changes, Version 1.3.1 is required.
# install_version(&amp;#39;ggplot2&amp;#39;, &amp;#39;5.3.5&amp;#39;)  # Due to breaking changes, Version 5.3.5 is required.
library(tidyverse)
library(ggplot2)
library(Cairo)

# Load frequentist coefficients (estimates and confidence intervals)

KR_summary_semanticpriming_lmerTest =
  readRDS(gzcon(url(&amp;#39;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/frequentist_analysis/results/KR_summary_semanticpriming_lmerTest.rds?raw=true&amp;#39;)))

confint_semanticpriming_lmerTest =
  readRDS(gzcon(url(&amp;#39;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/frequentist_analysis/results/confint_semanticpriming_lmerTest.rds?raw=true&amp;#39;)))

# Below are the default names of the effects
# rownames(KR_summary_semanticpriming_lmerTest$coefficients)
# rownames(confint_semanticpriming_lmerTest)

# Load Bayesian posterior distributions

semanticpriming_posteriordistributions_informativepriors_exgaussian = 
  readRDS(gzcon(url(&amp;#39;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/bayesian_analysis/results/semanticpriming_posteriordistributions_informativepriors_exgaussian.rds?raw=true&amp;#39;)))

semanticpriming_posteriordistributions_weaklyinformativepriors_exgaussian =
  readRDS(gzcon(url(&amp;#39;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/bayesian_analysis/results/semanticpriming_posteriordistributions_weaklyinformativepriors_exgaussian.rds?raw=true&amp;#39;)))

semanticpriming_posteriordistributions_diffusepriors_exgaussian = 
  readRDS(gzcon(url(&amp;#39;https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/bayesian_analysis/results/semanticpriming_posteriordistributions_diffusepriors_exgaussian.rds?raw=true&amp;#39;)))

# Below are the default names of the effects
# levels(semanticpriming_posteriordistributions_weaklyinformativepriors_exgaussian$data$parameter)


# Reorder the components of interactions in the frequentist results to match 
# with the order present in the Bayesian results.

rownames(KR_summary_semanticpriming_lmerTest$coefficients) =
  rownames(KR_summary_semanticpriming_lmerTest$coefficients) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_recoded_interstimulus_interval:z_cosine_similarity&amp;#39;, 
              replacement = &amp;#39;z_cosine_similarity:z_recoded_interstimulus_interval&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_recoded_interstimulus_interval:z_visual_rating_diff&amp;#39;, 
              replacement = &amp;#39;z_visual_rating_diff:z_recoded_interstimulus_interval&amp;#39;)

rownames(confint_semanticpriming_lmerTest)  = 
  rownames(confint_semanticpriming_lmerTest) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_recoded_interstimulus_interval:z_cosine_similarity&amp;#39;, 
              replacement = &amp;#39;z_cosine_similarity:z_recoded_interstimulus_interval&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_recoded_interstimulus_interval:z_visual_rating_diff&amp;#39;, 
              replacement = &amp;#39;z_visual_rating_diff:z_recoded_interstimulus_interval&amp;#39;)


# Create a vector containing the names of the effects. This vector will be passed 
# to the plotting function.

new_labels = 
  
  semanticpriming_posteriordistributions_weaklyinformativepriors_exgaussian$data$parameter %&amp;gt;% 
  unique %&amp;gt;%
  
  # Remove the default &amp;#39;b_&amp;#39; from the beginning of each effect
  str_remove(&amp;#39;^b_&amp;#39;) %&amp;gt;%
  
  # Put Intercept in parentheses
  str_replace(pattern = &amp;#39;Intercept&amp;#39;, replacement = &amp;#39;(Intercept)&amp;#39;) %&amp;gt;%
  
  # First, adjust names of variables (both in main effects and in interactions)
  str_replace(pattern = &amp;#39;z_target_word_frequency&amp;#39;,
              replacement = &amp;#39;Target-word frequency&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_target_number_syllables&amp;#39;,
              replacement = &amp;#39;Number of target-word syllables&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_word_concreteness_diff&amp;#39;,
              replacement = &amp;#39;Word-concreteness difference&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_cosine_similarity&amp;#39;,
              replacement = &amp;#39;Language-based similarity&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_visual_rating_diff&amp;#39;, 
              replacement = &amp;#39;Visual-strength difference&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_attentional_control&amp;#39;,
              replacement = &amp;#39;Attentional control&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_vocabulary_size&amp;#39;,
              replacement = &amp;#39;Vocabulary size&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_recoded_participant_gender&amp;#39;,
              replacement = &amp;#39;Gender&amp;#39;) %&amp;gt;%
  str_replace(pattern = &amp;#39;z_recoded_interstimulus_interval&amp;#39;,
              replacement = &amp;#39;SOA&amp;#39;) %&amp;gt;%
  # Show acronym in main effect of SOA
  str_replace(pattern = &amp;#39;^SOA$&amp;#39;,
              replacement = &amp;#39;Stimulus onset asynchrony (SOA)&amp;#39;) %&amp;gt;%
  
  # Second, adjust order of effects in interactions. In the output from the model, 
  # the word-level variables of interest (i.e., &amp;#39;z_cosine_similarity&amp;#39; and 
  # &amp;#39;z_visual_rating_diff&amp;#39;) sometimes appeared second in their interactions. For 
  # better consistency, the code below moves those word-level variables (with 
  # their new names) to the first position in their interactions. Note that the 
  # order does not affect the results in any way.
  sub(&amp;#39;(\\w+.*):(Language-based similarity|Visual-strength difference)&amp;#39;, 
      &amp;#39;\\2:\\1&amp;#39;, 
      .) %&amp;gt;%
  
  # Replace colons denoting interactions with times symbols
  str_replace(pattern = &amp;#39;:&amp;#39;, replacement = &amp;#39; &amp;amp;times; &amp;#39;) 


# Create plots, beginning with the informative-prior model

plot_semanticpriming_frequentist_bayesian_plot_informativepriors_exgaussian =
  frequentist_bayesian_plot(KR_summary_semanticpriming_lmerTest,
                            confint_semanticpriming_lmerTest,
                            semanticpriming_posteriordistributions_informativepriors_exgaussian,
                            labels = new_labels, interaction_symbol_x = TRUE,
                            vertical_line_at_x = 0, x_title = &amp;#39;Effect size (&amp;amp;beta;)&amp;#39;, 
                            x_axis_labels = 3, note_frequentist_no_prior = TRUE) +
  ggtitle(&amp;#39;Prior *SD* = 0.1&amp;#39;)

#####

plot_semanticpriming_frequentist_bayesian_plot_weaklyinformativepriors_exgaussian =
  frequentist_bayesian_plot(KR_summary_semanticpriming_lmerTest,
                            confint_semanticpriming_lmerTest,
                            semanticpriming_posteriordistributions_weaklyinformativepriors_exgaussian,
                            labels = new_labels, interaction_symbol_x = TRUE,
                            vertical_line_at_x = 0, x_title = &amp;#39;Effect size (&amp;amp;beta;)&amp;#39;,
                            x_axis_labels = 3, note_frequentist_no_prior = TRUE) +
  ggtitle(&amp;#39;Prior *SD* = 0.2&amp;#39;) +
  theme(axis.text.y = element_blank())

#####

plot_semanticpriming_frequentist_bayesian_plot_diffusepriors_exgaussian =
  frequentist_bayesian_plot(KR_summary_semanticpriming_lmerTest,
                            confint_semanticpriming_lmerTest,
                            semanticpriming_posteriordistributions_diffusepriors_exgaussian,
                            labels = new_labels, interaction_symbol_x = TRUE,
                            vertical_line_at_x = 0, x_title = &amp;#39;Effect size (&amp;amp;beta;)&amp;#39;, 
                            x_axis_labels = 3, note_frequentist_no_prior = TRUE) +
  ggtitle(&amp;#39;Prior *SD* = 0.3&amp;#39;) + 
  theme(axis.text.y = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;The figure below presents the posterior distribution of each effect in each model. The frequentist estimates are also shown to facilitate the comparison.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_semanticpriming_frequentist_bayesian_plot_informativepriors_exgaussian +
    plot_semanticpriming_frequentist_bayesian_plot_weaklyinformativepriors_exgaussian +
    plot_semanticpriming_frequentist_bayesian_plot_diffusepriors_exgaussian +
    
    plot_layout(ncol = 3, guides = &amp;#39;collect&amp;#39;) &amp;amp; theme(legend.position = &amp;#39;bottom&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://pablobernabeu.github.io/2022/bayesian-workflow-prior-determination-predictive-checks-and-sensitivity-analyses/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;768&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Estimates from the frequentist analysis (in red) and from the Bayesian analysis (in blue) for the semantic priming study, in each model. The frequentist means (represented by points) are flanked by 95% confidence intervals. The Bayesian means (represented by vertical lines) are flanked by 95% credible intervals in light blue (in some cases, the interval is occluded by the bar of the mean)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;A blog post on the &lt;a href=&#34;https://pablobernabeu.github.io/2022/why-can-t-we-be-friends-plotting-frequentist-lme4-and-bayesian-brms-mixed-effects-models&#34;&gt;frequentist-Bayesian plots is also available&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Session info&lt;/h3&gt;
&lt;p&gt;If you encounter any blockers while reproduce the above analyses using the materials at &lt;a href=&#34;https://osf.io/gt5uf&#34; class=&#34;uri&#34;&gt;https://osf.io/gt5uf&lt;/a&gt;, my current session info may be useful. For instance, the legend of the last plot may not show if the latest versions of the &lt;code&gt;ggplot2&lt;/code&gt; and the &lt;code&gt;tidyverse&lt;/code&gt; packages are used. Instead, &lt;code&gt;ggplot2 3.3.5&lt;/code&gt; and &lt;code&gt;tidyverse 1.3.1&lt;/code&gt; should be installed using &lt;code&gt;install_version(&#39;ggplot2&#39;, &#39;3.3.5&#39;)&lt;/code&gt; and &lt;code&gt;install_version(&#39;tidyverse&#39;, &#39;1.3.1&#39;)&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.2.3 (2023-03-15 ucrt)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 22621)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.utf8 
## [2] LC_CTYPE=English_United States.utf8   
## [3] LC_MONETARY=English_United States.utf8
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.utf8    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] Cairo_1.6-0         forcats_1.0.0       stringr_1.5.0      
##  [4] purrr_1.0.1         readr_2.1.4         tidyr_1.3.0        
##  [7] tibble_3.2.1        tidyverse_1.3.1     papaja_0.1.1       
## [10] tinylabels_0.2.3    patchwork_1.1.2     ggtext_0.1.2       
## [13] ggridges_0.5.4      ggplot2_3.3.5       dplyr_1.1.1        
## [16] knitr_1.42          xaringanExtra_0.7.0
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.10      lubridate_1.9.2  digest_0.6.31    utf8_1.2.3      
##  [5] plyr_1.8.8       cellranger_1.1.0 R6_2.5.1         backports_1.4.1 
##  [9] reprex_2.0.2     evaluate_0.21    httr_1.4.6       highr_0.10      
## [13] blogdown_1.16    pillar_1.9.0     rlang_1.1.0      readxl_1.4.2    
## [17] uuid_1.1-0       rstudioapi_0.14  jquerylib_0.1.4  rmarkdown_2.21  
## [21] labeling_0.4.2   munsell_0.5.0    gridtext_0.1.5   broom_1.0.4     
## [25] compiler_4.2.3   modelr_0.1.11    xfun_0.38        pkgconfig_2.0.3 
## [29] htmltools_0.5.5  tidyselect_1.2.0 bookdown_0.33.3  fansi_1.0.4     
## [33] crayon_1.5.2     tzdb_0.4.0       dbplyr_2.3.2     withr_2.5.0     
## [37] commonmark_1.9.0 grid_4.2.3       jsonlite_1.8.4   gtable_0.3.3    
## [41] lifecycle_1.0.3  DBI_1.1.3        magrittr_2.0.3   scales_1.2.1    
## [45] cli_3.4.1        stringi_1.7.12   cachem_1.0.7     farver_2.1.1    
## [49] fs_1.6.1         xml2_1.3.3       bslib_0.4.2      generics_0.1.3  
## [53] vctrs_0.6.1      tools_4.2.3      glue_1.6.2       markdown_1.5    
## [57] hms_1.1.3        fastmap_1.1.1    yaml_2.3.7       timechange_0.2.0
## [61] colorspace_2.1-0 rvest_1.0.3      haven_2.5.2      sass_0.4.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;div style=&#34;text-indent:-2em; margin-left:2em;&#34;&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-bartonWordlengthEffectReading2014&#34; class=&#34;csl-entry&#34;&gt;
Barton, J. J. S., Hanif, H. M., Eklinder Björnström, L., &amp;amp; Hills, C. (2014). The word-length effect in reading: &lt;span&gt;A&lt;/span&gt; review. &lt;em&gt;Cognitive Neuropsychology&lt;/em&gt;, &lt;em&gt;31&lt;/em&gt;(5-6), 378–412. &lt;a href=&#34;https://doi.org/10.1080/02643294.2014.895314&#34;&gt;https://doi.org/10.1080/02643294.2014.895314&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-bernabeu2022a&#34; class=&#34;csl-entry&#34;&gt;
Bernabeu, P. (2022). &lt;em&gt;Language and sensorimotor simulation in conceptual processing: &lt;span&gt;Multilevel&lt;/span&gt; analysis and statistical power&lt;/em&gt;. &lt;span&gt;Lancaster University&lt;/span&gt;. &lt;a href=&#34;https://doi.org/10.17635/lancaster/thesis/1795&#34;&gt;https://doi.org/10.17635/lancaster/thesis/1795&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-beyersmannEvidenceEmbeddedWord2020&#34; class=&#34;csl-entry&#34;&gt;
Beyersmann, E., Grainger, J., &amp;amp; Taft, M. (2020). Evidence for embedded word length effects in complex nonwords. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;35&lt;/em&gt;(2), 235–245. &lt;a href=&#34;https://doi.org/10.1080/23273798.2019.1659989&#34;&gt;https://doi.org/10.1080/23273798.2019.1659989&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-brysbaertWordFrequencyEffect2018a&#34; class=&#34;csl-entry&#34;&gt;
Brysbaert, M., Mandera, P., &amp;amp; Keuleers, E. (2018). The word frequency effect in word processing: &lt;span&gt;An&lt;/span&gt; updated review. &lt;em&gt;Current Directions in Psychological Science&lt;/em&gt;, &lt;em&gt;27&lt;/em&gt;(1), 45–50. &lt;a href=&#34;https://doi.org/10.1177/0963721417727521&#34;&gt;https://doi.org/10.1177/0963721417727521&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-brysbaertImpactWordPrevalence2016&#34; class=&#34;csl-entry&#34;&gt;
Brysbaert, M., Stevens, M., Mandera, P., &amp;amp; Keuleers, E. (2016). The impact of word prevalence on lexical decision times: &lt;span&gt;Evidence&lt;/span&gt; from the &lt;span&gt;Dutch Lexicon Project&lt;/span&gt; 2. &lt;em&gt;Journal of Experimental Psychology: Human Perception and Performance&lt;/em&gt;, &lt;em&gt;42&lt;/em&gt;(3), 441–458. &lt;a href=&#34;https://doi.org/10.1037/xhp0000159&#34;&gt;https://doi.org/10.1037/xhp0000159&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-brysbaert2014a&#34; class=&#34;csl-entry&#34;&gt;
Brysbaert, M., Warriner, A. B., &amp;amp; Kuperman, V. (2014). Concreteness ratings for 40 thousand generally known &lt;span&gt;English&lt;/span&gt; word lemmas. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;46&lt;/em&gt;, 904–911. &lt;a href=&#34;https://doi.org/10.3758/s13428-013-0403-5&#34;&gt;https://doi.org/10.3758/s13428-013-0403-5&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-burknerAdvancedBayesianMultilevel2018&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2018). Advanced &lt;span&gt;Bayesian&lt;/span&gt; multilevel modeling with the &lt;span&gt;R&lt;/span&gt; package &lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;. &lt;em&gt;The R Journal&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(1), 395–411. &lt;a href=&#34;https://journal.r-project.org/archive/2018/RJ-2018-017/index.html&#34;&gt;https://journal.r-project.org/archive/2018/RJ-2018-017/index.html&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-burknerPackageBrms2022&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C., Gabry, J., Weber, S., Johnson, A., Modrak, M., Badr, H. S., Weber, F., Ben-Shachar, M. S., &amp;amp; Rabel, H. (2022). &lt;em&gt;Package ’&lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;’&lt;/em&gt;. &lt;span&gt;CRAN&lt;/span&gt;. &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/brms.pdf&#34;&gt;https://cran.r-project.org/web/packages/brms/brms.pdf&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-cerniMotorExpertiseTyping2016&#34; class=&#34;csl-entry&#34;&gt;
Cerni, T., Velay, J.-L., Alario, F.-X., Vaugoyeau, M., &amp;amp; Longcamp, M. (2016). Motor expertise for typing impacts lexical decision performance. &lt;em&gt;Trends in Neuroscience and Education&lt;/em&gt;, &lt;em&gt;5&lt;/em&gt;(3), 130–138. &lt;a href=&#34;https://doi.org/10.1016/j.tine.2016.07.007&#34;&gt;https://doi.org/10.1016/j.tine.2016.07.007&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-cummingNewStatisticsWhy2014&#34; class=&#34;csl-entry&#34;&gt;
Cumming, G. (2014). The new statistics: &lt;span&gt;Why&lt;/span&gt; and how. &lt;em&gt;Psychological Science&lt;/em&gt;, &lt;em&gt;25&lt;/em&gt;(1), 7–29. &lt;a href=&#34;https://doi.org/10.1177/0956797613504966&#34;&gt;https://doi.org/10.1177/0956797613504966&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-dijkstraMultilinkComputationalModel2019&#34; class=&#34;csl-entry&#34;&gt;
Dijkstra, T., Wahl, A., Buytenhuijs, F., Halem, N. V., Al-Jibouri, Z., Korte, M. D., &amp;amp; Rekké, S. (2019). Multilink: &lt;span&gt;A&lt;/span&gt; computational model for bilingual word recognition and word translation. &lt;em&gt;Bilingualism: Language and Cognition&lt;/em&gt;, &lt;em&gt;22&lt;/em&gt;(4), 657–679. &lt;a href=&#34;https://doi.org/10.1017/S1366728918000287&#34;&gt;https://doi.org/10.1017/S1366728918000287&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kimEffectsLexicalFeatures2018&#34; class=&#34;csl-entry&#34;&gt;
Kim, M., Crossley, S. A., &amp;amp; Skalicky, S. (2018). Effects of lexical features, textual properties, and individual differences on word processing times during second language reading comprehension. &lt;em&gt;Reading and Writing&lt;/em&gt;, &lt;em&gt;31&lt;/em&gt;(5), 1155–1180. &lt;a href=&#34;https://doi.org/10.1007/s11145-018-9833-x&#34;&gt;https://doi.org/10.1007/s11145-018-9833-x&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kniefViolatingNormalityAssumption2021&#34; class=&#34;csl-entry&#34;&gt;
Knief, U., &amp;amp; Forstmeier, W. (2021). Violating the normality assumption may be the lesser of two evils. &lt;em&gt;Behavior Research Methods&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.3758/s13428-021-01587-5&#34;&gt;https://doi.org/10.3758/s13428-021-01587-5&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kruschkeBayesianNewStatistics2018&#34; class=&#34;csl-entry&#34;&gt;
Kruschke, J. K., &amp;amp; Liddell, T. M. (2018). The &lt;span&gt;Bayesian New Statistics&lt;/span&gt;: &lt;span&gt;Hypothesis&lt;/span&gt; testing, estimation, meta-analysis, and power analysis from a &lt;span&gt;Bayesian&lt;/span&gt; perspective. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;25&lt;/em&gt;(1), 178–206. &lt;a href=&#34;https://doi.org/10.3758/s13423-016-1221-4&#34;&gt;https://doi.org/10.3758/s13423-016-1221-4&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-leeBayesianCognitiveModeling2014&#34; class=&#34;csl-entry&#34;&gt;
Lee, M. D., &amp;amp; Wagenmakers, E.-J. (2014). &lt;em&gt;Bayesian cognitive modeling: &lt;span&gt;A&lt;/span&gt; practical course&lt;/em&gt;. &lt;span&gt;Cambridge University Press&lt;/span&gt;. &lt;a href=&#34;https://doi.org/10.1017/CBO9781139087759&#34;&gt;https://doi.org/10.1017/CBO9781139087759&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-lewandowskiGeneratingRandomCorrelation2009&#34; class=&#34;csl-entry&#34;&gt;
Lewandowski, D., Kurowicka, D., &amp;amp; Joe, H. (2009). Generating random correlation matrices based on vines and extended onion method. &lt;em&gt;Journal of Multivariate Analysis&lt;/em&gt;, &lt;em&gt;100&lt;/em&gt;(9), 1989–2001. &lt;a href=&#34;https://doi.org/10.1016/j.jmva.2009.04.008&#34;&gt;https://doi.org/10.1016/j.jmva.2009.04.008&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-lim2020a&#34; class=&#34;csl-entry&#34;&gt;
Lim, R. Y., Yap, M. J., &amp;amp; Tse, C.-S. (2020). Individual differences in &lt;span&gt;Cantonese Chinese&lt;/span&gt; word recognition: &lt;span&gt;Insights&lt;/span&gt; from the &lt;span&gt;Chinese Lexicon Project&lt;/span&gt;. &lt;em&gt;Quarterly Journal of Experimental Psychology&lt;/em&gt;, &lt;em&gt;73&lt;/em&gt;(4), 504–518. &lt;a href=&#34;https://doi.org/10.1177/1747021820906566&#34;&gt;https://doi.org/10.1177/1747021820906566&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-loTransformNotTransform2015&#34; class=&#34;csl-entry&#34;&gt;
Lo, S., &amp;amp; Andrews, S. (2015). To transform or not to transform: Using generalized linear mixed models to analyse reaction time data. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;6&lt;/em&gt;, 1171. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2015.01171&#34;&gt;https://doi.org/10.3389/fpsyg.2015.01171&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-matzkePsychologicalInterpretationExGaussian2009&#34; class=&#34;csl-entry&#34;&gt;
Matzke, D., &amp;amp; Wagenmakers, E.-J. (2009). Psychological interpretation of the ex-&lt;span&gt;Gaussian&lt;/span&gt; and shifted &lt;span&gt;Wald&lt;/span&gt; parameters: &lt;span&gt;A&lt;/span&gt; diffusion model analysis. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;(5), 798–817. &lt;a href=&#34;https://doi.org/10.3758/PBR.16.5.798&#34;&gt;https://doi.org/10.3758/PBR.16.5.798&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mendesPervasiveEffectWord2021&#34; class=&#34;csl-entry&#34;&gt;
Mendes, P. S., &amp;amp; Undorf, M. (2021). On the pervasive effect of word frequency in metamemory. &lt;em&gt;Quarterly Journal of Experimental Psychology&lt;/em&gt;, 17470218211053329. &lt;a href=&#34;https://doi.org/10.1177/17470218211053329&#34;&gt;https://doi.org/10.1177/17470218211053329&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-milekEavesdroppingHappinessRevisited2018&#34; class=&#34;csl-entry&#34;&gt;
Milek, A., Butler, E. A., Tackman, A. M., Kaplan, D. M., Raison, C. L., Sbarra, D. A., Vazire, S., &amp;amp; Mehl, M. R. (2018). &lt;span&gt;“&lt;span&gt;Eavesdropping&lt;/span&gt; on happiness”&lt;/span&gt; revisited: &lt;span&gt;A&lt;/span&gt; pooled, multisample replication of the association between life satisfaction and observed daily conversation quantity and quality. &lt;em&gt;Psychological Science&lt;/em&gt;, &lt;em&gt;29&lt;/em&gt;(9), 1451–1462. &lt;a href=&#34;https://doi.org/10.1177/0956797618774252&#34;&gt;https://doi.org/10.1177/0956797618774252&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-nicenboimInprep&#34; class=&#34;csl-entry&#34;&gt;
Nicenboim, B., Schad, D., &amp;amp; Vasishth, S. (n.d.). &lt;em&gt;An introduction to &lt;span&gt;Bayesian&lt;/span&gt; data analysis for cognitive science&lt;/em&gt;. &lt;span&gt;Chapman and Hall/CRC Statistics in the Social and Behavioral Sciences Series&lt;/span&gt;.
&lt;/div&gt;
&lt;div id=&#34;ref-pexman2018a&#34; class=&#34;csl-entry&#34;&gt;
Pexman, P. M., &amp;amp; Yap, M. J. (2018). Individual differences in semantic processing: &lt;span&gt;Insights&lt;/span&gt; from the &lt;span&gt;Calgary&lt;/span&gt; semantic decision project. &lt;em&gt;Journal of Experimental Psychology: Learning, Memory, and Cognition&lt;/em&gt;, &lt;em&gt;44&lt;/em&gt;(7), 1091–1112. &lt;a href=&#34;https://doi.org/10.1037/xlm0000499&#34;&gt;https://doi.org/10.1037/xlm0000499&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-preglaVariabilitySentenceComprehension2021&#34; class=&#34;csl-entry&#34;&gt;
Pregla, D., Lissón, P., Vasishth, S., Burchert, F., &amp;amp; Stadie, N. (2021). Variability in sentence comprehension in aphasia in &lt;span&gt;German&lt;/span&gt;. &lt;em&gt;Brain and Language&lt;/em&gt;, &lt;em&gt;222&lt;/em&gt;, 105008. &lt;a href=&#34;https://doi.org/10.1016/j.bandl.2021.105008&#34;&gt;https://doi.org/10.1016/j.bandl.2021.105008&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rodriguez-ferreiroSemanticPrimingSchizotypal2020&#34; class=&#34;csl-entry&#34;&gt;
Rodríguez-Ferreiro, J., Aguilera, M., &amp;amp; Davies, R. (2020). Semantic priming and schizotypal personality: Reassessing the link between thought disorder and enhanced spreading of semantic activation. &lt;em&gt;PeerJ&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;, e9511. &lt;a href=&#34;https://doi.org/10.7717/peerj.9511&#34;&gt;https://doi.org/10.7717/peerj.9511&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rouderBayesianInferencePsychology2018&#34; class=&#34;csl-entry&#34;&gt;
Rouder, J. N., Haaf, J. M., &amp;amp; Vandekerckhove, J. (2018). Bayesian inference for psychology, part &lt;span&gt;IV&lt;/span&gt;: &lt;span&gt;Parameter&lt;/span&gt; estimation and &lt;span&gt;Bayes&lt;/span&gt; factors. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;25&lt;/em&gt;(1), 102–113. &lt;a href=&#34;https://doi.org/10.3758/s13423-017-1420-7&#34;&gt;https://doi.org/10.3758/s13423-017-1420-7&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-schielzethRobustnessLinearMixed2020&#34; class=&#34;csl-entry&#34;&gt;
Schielzeth, H., Dingemanse, N. J., Nakagawa, S., Westneat, D. F., Allegue, H., Teplitsky, C., Réale, D., Dochtermann, N. A., Garamszegi, L. Z., &amp;amp; Araya‐Ajoy, Y. G. (2020). Robustness of linear mixed‐effects models to violations of distributional assumptions. &lt;em&gt;Methods in Ecology and Evolution&lt;/em&gt;, &lt;em&gt;11&lt;/em&gt;(9), 1141–1152. &lt;a href=&#34;https://doi.org/10.1111/2041-210X.13434&#34;&gt;https://doi.org/10.1111/2041-210X.13434&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-schmalzWhatBayesFactor2021&#34; class=&#34;csl-entry&#34;&gt;
Schmalz, X., Biurrun Manresa, J., &amp;amp; Zhang, L. (2021). What is a &lt;span&gt;Bayes&lt;/span&gt; factor? &lt;em&gt;Psychological Methods&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.1037/met0000421&#34;&gt;https://doi.org/10.1037/met0000421&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-stoneEffectDecayLexical2020&#34; class=&#34;csl-entry&#34;&gt;
Stone, K., Malsburg, T. von der, &amp;amp; Vasishth, S. (2020). The effect of decay and lexical uncertainty on processing long-distance dependencies in reading. &lt;em&gt;PeerJ&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;, e10438. &lt;a href=&#34;https://doi.org/10.7717/peerj.10438&#34;&gt;https://doi.org/10.7717/peerj.10438&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-stoneInteractionGrammaticallyDistinct2021&#34; class=&#34;csl-entry&#34;&gt;
Stone, K., Veríssimo, J., Schad, D. J., Oltrogge, E., Vasishth, S., &amp;amp; Lago, S. (2021). The interaction of grammatically distinct agreement dependencies in predictive processing. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;36&lt;/em&gt;(9), 1159–1179. &lt;a href=&#34;https://doi.org/10.1080/23273798.2021.1921816&#34;&gt;https://doi.org/10.1080/23273798.2021.1921816&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-tendeiroReviewIssuesNull2019&#34; class=&#34;csl-entry&#34;&gt;
Tendeiro, J. N., &amp;amp; Kiers, H. A. L. (2019). A review of issues about null hypothesis &lt;span&gt;Bayesian&lt;/span&gt; testing. &lt;em&gt;Psychological Methods&lt;/em&gt;, &lt;em&gt;24&lt;/em&gt;(6), 774–795. &lt;a href=&#34;https://doi.org/10.1037/met0000221&#34;&gt;https://doi.org/10.1037/met0000221&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-tendeiroOnTheWhite2022&#34; class=&#34;csl-entry&#34;&gt;
Tendeiro, J. N., &amp;amp; Kiers, H. A. L. (in press). On the white, the black, and the many shades of gray in between: &lt;span&gt;Our&lt;/span&gt; reply to van &lt;span&gt;Ravenzwaaij&lt;/span&gt; and &lt;span&gt;Wagenmakers&lt;/span&gt; (2021). &lt;em&gt;Psychological Methods&lt;/em&gt;.
&lt;/div&gt;
&lt;div id=&#34;ref-schootBayesianStatisticsModelling2021&#34; class=&#34;csl-entry&#34;&gt;
Van de Schoot, R., Depaoli, S., Gelman, A., King, R., Kramer, B., Märtens, K., Tadesse, M. G., Vannucci, M., Willemsen, J., &amp;amp; Yau, C. (2021). Bayesian statistics and modelling. &lt;em&gt;Nature Reviews Methods Primers&lt;/em&gt;, &lt;em&gt;1&lt;/em&gt;, 3. &lt;a href=&#34;https://doi.org/10.1038/s43586-020-00003-0&#34;&gt;https://doi.org/10.1038/s43586-020-00003-0&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vanravenzwaaijAdvantagesMasqueradingIssues2021&#34; class=&#34;csl-entry&#34;&gt;
van Ravenzwaaij, D., &amp;amp; Wagenmakers, E.-J. (2021). Advantages masquerading as &lt;span&gt;“issues”&lt;/span&gt; in &lt;span&gt;Bayesian&lt;/span&gt; hypothesis testing: &lt;span&gt;A&lt;/span&gt; commentary on &lt;span&gt;Tendeiro&lt;/span&gt; and &lt;span&gt;Kiers&lt;/span&gt; (2019). &lt;em&gt;Psychological Methods&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.1037/met0000415&#34;&gt;https://doi.org/10.1037/met0000415&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vasishthBayesianDataAnalysis2018&#34; class=&#34;csl-entry&#34;&gt;
Vasishth, S., Nicenboim, B., Beckman, M. E., Li, F., &amp;amp; Kong, E. J. (2018). Bayesian data analysis in the phonetic sciences: &lt;span&gt;A&lt;/span&gt; tutorial introduction. &lt;em&gt;Journal of Phonetics&lt;/em&gt;, &lt;em&gt;71&lt;/em&gt;, 147–161. &lt;a href=&#34;https://doi.org/10.1016/j.wocn.2018.07.008&#34;&gt;https://doi.org/10.1016/j.wocn.2018.07.008&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-yarkoniMovingColtheartNew2008&#34; class=&#34;csl-entry&#34;&gt;
Yarkoni, T., Balota, D., &amp;amp; Yap, M. J. (2008). Moving beyond &lt;span&gt;Coltheart&lt;/span&gt;’s &lt;span&gt;N&lt;/span&gt;: &lt;span&gt;A&lt;/span&gt; new measure of orthographic similarity. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;15&lt;/em&gt;(5), 971–979. &lt;a href=&#34;https://doi.org/10.3758/PBR.15.5.971&#34;&gt;https://doi.org/10.3758/PBR.15.5.971&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Language and vision in conceptual processing: Multilevel analysis and statistical power</title>
      <link>https://pablobernabeu.github.io/publication/language-vision-conceptual-processing/</link>
      <pubDate>Sat, 15 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/publication/language-vision-conceptual-processing/</guid>
      <description>


&lt;div id=&#34;reference&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Reference&lt;/h3&gt;
&lt;div style=&#34;text-indent:-2em; margin-left:2em;&#34;&gt;
&lt;p&gt;Bernabeu, P., Lynott, D., &amp;amp; Connell, L. (2022). &lt;em&gt;Language and vision in conceptual processing: Multilevel analysis and statistical power&lt;/em&gt;. OSF. &lt;a href=&#34;https://osf.io/dnskh&#34; class=&#34;uri&#34;&gt;https://osf.io/dnskh&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Language and sensorimotor simulation in conceptual processing: Multilevel analysis and statistical power</title>
      <link>https://pablobernabeu.github.io/publication/pablo-bernabeu-2022-phd-thesis/</link>
      <pubDate>Fri, 14 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/publication/pablo-bernabeu-2022-phd-thesis/</guid>
      <description>&lt;br&gt;
&lt;a href=&#39;https://pablobernabeu.github.io/thesis&#39;&gt;
&lt;button style = &#34;background-color: white; color: black; border: 2px solid #DF2E2E; border-radius: 12px;&#34;&gt;
&lt;h3 style = &#34;margin-top: 7px !important; margin-left: 9px !important; margin-right: 9px !important;&#34;&gt;
&lt;span style=&#34;color:#DBE6DA;&#34;&gt;&lt;i class=&#34;fas fa-mouse-pointer&#34;&gt;&lt;/i&gt;&lt;/span&gt;&amp;nbsp; Online book &lt;/h3&gt;&lt;/button&gt;
&lt;/a&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;div style = &#34;text-indent:-2em; margin-left:2em;&#34;&gt;
&lt;p&gt;Bernabeu, P. (2022). &lt;em&gt;Language and sensorimotor simulation in conceptual processing: Multilevel analysis and statistical power&lt;/em&gt;. Lancaster University. &lt;a href=&#34;https://doi.org/10.17635/lancaster/thesis/1795&#34;&gt;https://doi.org/10.17635/lancaster/thesis/1795&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;br&gt; 
</description>
    </item>
    
    <item>
      <title>Preregistration: The interplay between linguistic and embodied systems in conceptual processing</title>
      <link>https://pablobernabeu.github.io/publication/the-interplay-between-linguistic-and-embodied-systems-in-conceptual-processing/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/publication/the-interplay-between-linguistic-and-embodied-systems-in-conceptual-processing/</guid>
      <description>


&lt;div id=&#34;reference&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Reference&lt;/h3&gt;
&lt;div style=&#34;text-indent:-2em; margin-left:2em;&#34;&gt;
&lt;p&gt;Bernabeu, P., Lynott, D., &amp;amp; Connell, L. (2021). &lt;em&gt;Preregistration: The interplay between linguistic and embodied systems in conceptual processing&lt;/em&gt;. OSF. &lt;a href=&#34;https://osf.io/ftydw&#34; class=&#34;uri&#34;&gt;https://osf.io/ftydw&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Mixed-effects models in R, and a new tool for data simulation</title>
      <link>https://pablobernabeu.github.io/talk/2020-11-26-mixed-effects-models-in-r-and-a-new-tool-for-data-simulation/</link>
      <pubDate>Thu, 26 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/talk/2020-11-26-mixed-effects-models-in-r-and-a-new-tool-for-data-simulation/</guid>
      <description>


&lt;div id=&#34;slides&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Slides   &lt;a href=&#34;https://hackmd.io/@pablobernabeu/SkRyLbaqw&#34;&gt;&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;iframe width=&#34;100%&#34; height=&#34;500&#34; src=&#34;https://hackmd.io/@pablobernabeu/SkRyLbaqw&#34; frameborder=&#34;0&#34; style=&#34;padding-top:5px&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;div id=&#34;abstract&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Abstract&lt;/h3&gt;
&lt;p&gt;Linear mixed-effects models (LMEMs) are used to account for variation within factors with multiple observations, such as participants, trials, items, channels, etc (for an earlier approach, see Clark, 1973). This variation is modelled in terms of random intercepts (e.g., overall variation per participant) as well as random slopes for the fixed effects (e.g., treatment effect per participant). These measures help reduce false positives and false negatives (Barr et al., 2013), and the resulting models tend to be robust to violations of assumptions (Schielzeth et al., 2020). The use of LMEMs has grown over the past decade, under various implementation forms (Meteyard &amp;amp; Davies, 2020). In this talk, I will look over the rationale for LMEMs, and demonstrate how to fit them in R (Brauer &amp;amp; Curtin, 2018; Luke, 2017). Challenges will also be covered. For instance, when using the widely-accepted ‘maximal’ approach, based on fitting all possible random effects for each fixed effect, models sometimes fail to find a solution, or ‘convergence’. Advice for the problem of nonconvergence will be demonstrated, based on the progressive lightening of the random effects structure (Singman &amp;amp; Kellen, 2017; for an alternative approach, especially with small samples, see Matuschek et al., 2017). At the end, on a different note, I will present a web application that facilitates data simulation for research and teaching (Bernabeu &amp;amp; Lynott, 2020).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;div style=&#34;text-indent:-2em; margin-left:2em;&#34;&gt;
&lt;p&gt;Barr, D. J., Levy, R., Scheepers, C., &amp;amp; Tily, H. J. (2013). Random effects structure for confirmatory hypothesis testing: Keep it maximal. &lt;em&gt;Journal of Memory and Language, 68&lt;/em&gt;, 255–278. &lt;a href=&#34;http://dx.doi.org/10.1016/j.jml.2012.11.001&#34; class=&#34;uri&#34;&gt;http://dx.doi.org/10.1016/j.jml.2012.11.001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bernabeu, P., &amp;amp; Lynott, D. (2020). &lt;em&gt;Web application for the simulation of experimental data&lt;/em&gt; (Version 1.2). &lt;a href=&#34;https://github.com/pablobernabeu/Experimental-data-simulation/&#34; class=&#34;uri&#34;&gt;https://github.com/pablobernabeu/Experimental-data-simulation/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Brauer, M., &amp;amp; Curtin, J. J. (2018). Linear mixed-effects models and the analysis of nonindependent data: A unified framework to analyze categorical and continuous independent variables that vary within-subjects and/or within-items. &lt;em&gt;Psychological Methods, 23&lt;/em&gt;(3), 389–411. &lt;a href=&#34;https://psych.wisc.edu/Brauer/BrauerLab/wp-content/uploads/2014/04/Brauer-Curtin-2018-on-LMEMs.pdf&#34; class=&#34;uri&#34;&gt;https://psych.wisc.edu/Brauer/BrauerLab/wp-content/uploads/2014/04/Brauer-Curtin-2018-on-LMEMs.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Clark, H. H. (1973). The language-as-fixed-effect fallacy: A critique of language statistics in psychological research. &lt;em&gt;Journal of Verbal Learning and Verbal Behavior, 12&lt;/em&gt;(4), 335-359. &lt;a href=&#34;https://doi.org/10.1016/S0022-5371(73)80014-3&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1016/S0022-5371(73)80014-3&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Luke, S. G. (2017). Evaluating significance in linear mixed-effects models in R. &lt;em&gt;Behavior Research Methods, 49&lt;/em&gt;(4), 1494–1502. &lt;a href=&#34;https://doi.org/10.3758/s13428-016-0809-y&#34; class=&#34;uri&#34;&gt;https://doi.org/10.3758/s13428-016-0809-y&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Matuschek, H., Kliegl, R., Vasishth, S., Baayen, H., &amp;amp; Bates, D. (2017). Balancing type 1 error and power in linear mixed models. &lt;em&gt;Journal of Memory and Language, 94&lt;/em&gt;, 305–315. &lt;a href=&#34;https://doi.org/10.1016/j.jml.2017.01.001&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1016/j.jml.2017.01.001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Meteyard, L., &amp;amp; Davies, R. A. (2020). Best practice guidance for linear mixed-effects models in psychological science. &lt;em&gt;Journal of Memory and Language, 112&lt;/em&gt;, 104092. &lt;a href=&#34;https://doi.org/10.1016/j.jml.2020.104092&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1016/j.jml.2020.104092&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Schielzeth, H., Dingemanse, N. J., Nakagawa, S., Westneat, D. F., Allegue, H, Teplitsky, C., Reale, D., Dochtermann, N. A., Garamszegi, L. Z., &amp;amp; Araya-Ajoy, Y. G. (2020). Robustness of linear mixed-effects models to violations of distributional assumptions. &lt;em&gt;Methods in Ecology and Evolution, 00&lt;/em&gt;, 1– 12. &lt;a href=&#34;https://doi.org/10.1111/2041-210X.13434&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1111/2041-210X.13434&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Singmann, H., &amp;amp; Kellen, D. (2019). An Introduction to Mixed Models for Experimental Psychology. In D. H. Spieler &amp;amp; E. Schumacher (Eds.), &lt;em&gt;New Methods in Cognitive Psychology&lt;/em&gt; (pp. 4–31). Hove, UK: Psychology Press. &lt;a href=&#34;http://singmann.org/download/publications/singmann_kellen-introduction-mixed-models.pdf&#34; class=&#34;uri&#34;&gt;http://singmann.org/download/publications/singmann_kellen-introduction-mixed-models.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Event-related potentials: Why and how I used them</title>
      <link>https://pablobernabeu.github.io/2020/event-related-potentials-why-and-how-i-used-them/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/2020/event-related-potentials-why-and-how-i-used-them/</guid>
      <description>&lt;p&gt;Event-related potentials (ERPs) offer a unique insight in the study of human cognition. Let&#39;s look at their reason-to-be for the purposes of research, and how they are defined and processed. Most of this content is based on my master&#39;s thesis, which I could fortunately conduct at the Max Planck Institute for Psycholinguistics (see &lt;a href=&#39;https://psyarxiv.com/5gjvk/&#39;&gt;thesis&lt;/a&gt; or &lt;a href=&#39;https://psyarxiv.com/a5pcz/&#39;&gt;conference paper&lt;/a&gt;).&lt;/p&gt;
&lt;h2 id=&#34;electroencephalography&#34;&gt;Electroencephalography&lt;/h2&gt;
&lt;p&gt;The brain produces electrical activity all the time, which can be measured via electrodes on the scalp—a method known as electroencephalography (EEG). These pulses are produced for every one of our states and actions, in a voltage at a micro (µ) scale, typically between 10 µV (0.000010) and 100 µV (0.000100; Aurlien et al., 2004). The overlapping pulses happen at extremely high frequencies; indeed, the signal can be measured once per millisecond. The high frequency of this signal is very interesting for the study of some cognitive processes in particular, for which the time course is (or may be) critical. One such example is conceptual processing, namely, the process of understanding the meaning of words.&lt;/p&gt;
&lt;p&gt;Research has revealed the relation between certain EEG patterns and cognitive states and functions. Brain activity includes dozens of types, but broadly, it can be divided into neural oscillations and event-related potentials. Specific oscillations (also known as brain waves) are associated with &lt;em&gt;states&lt;/em&gt; such as wakefulness, sleep, arousal, relaxation, etc. (Roohi-Azizi et al., 2017). Event-related potentials instead represent more finite &lt;em&gt;events&lt;/em&gt;, such as the presentation of as a stimulus. In cognitive neuroscience, both oscillations and ERPs are studied, whereas in cognitive psychology, ERPs are much more common than oscillations. Let&#39;s dive into ERPs below.&lt;/p&gt;
&lt;h3 id=&#34;event-related-potentials&#34;&gt;Event-related potentials&lt;/h3&gt;
&lt;p&gt;In the lab, ERPs are elicited using controlled designs. In each trial, a series of stimuli are presented. At a fixed point therein, an EEG measurement begins and spans for a certain period. In turn, in the analysis, this measurement period is divided into &lt;em&gt;time windows&lt;/em&gt;, which often correspond to specific ERP components (e.g., N400 window).&lt;/p&gt;
&lt;p&gt;In psycholinguistics, for instance, a typical scenario is the presentation of words, and ERPs are systematically &lt;em&gt;time-locked&lt;/em&gt; to the same position in consecutive trials, often the onset of a word. By this means, the experimental manipulation is collected, and the non-experimental variation—&amp;lsquo;noise&amp;rsquo;—is largely cancelled out by the aggregation of multiple trials that share the experimental manipulation.&lt;/p&gt;
&lt;p&gt;The chief reason to employ the ERP method is the measurement of cognitive processes online, that is, precisely as they unfold. This is fitting in the context of language comprehension, where some important processes last for less than a second.&lt;/p&gt;
&lt;h2 id=&#34;time-course-of-word-processing&#34;&gt;Time course of word processing&lt;/h2&gt;
&lt;p&gt;Processing a word takes around 800 milliseconds (ms). Within that time, earlier processes (compared to later ones) have been ascribed greater relevance to the core process of understanding a word (Mahon &amp;amp; Caramazza, 2008). This assumes that broader processes start only after more immediate ones have started (but see Lebois, Wilson‐Mendenhall &amp;amp; Barsalou, 2014). The most immediate process is the recognition of a string of letters, which seems to start within 90 ms post word onset in early auditory cortex and the Visual Word Form Area (Willems et al., 2016). Then ensue further, fundamental stages known as &lt;em&gt;lexical&lt;/em&gt; and &lt;em&gt;semantic&lt;/em&gt; processes. Lexical processing is the identification of a string of letters as a known word, and it happens within around 160 ms post word onset. Next, at around 200 ms, we may see the beginning of semantic processing, which denotes a further step in the cognitive analysis of the word that is akin to &lt;em&gt;meaning&lt;/em&gt; (Hauk, 2016). These processes may overlap, as indeed suggested by the sensitivity of the N400 ERP (see also next section) to both lexical and semantic tasks (Kutas &amp;amp; Federmeier, 2011). Both processes also likely extend further in the processing timeline (Hauk, 2016). In spite of this overlap, however, lexical and semantic processing have often been linked to different cognitive phenomena. For instance, tasks promoting semantic processing (e.g., semantic decision, whereby participants describe words as concrete or abstract) have been found to engage sensorimotor simulation of the word&#39;s meaning (known as &lt;em&gt;embodiment&lt;/em&gt;) more strongly than lexical tasks do (Connell &amp;amp; Lynott, 2013; Pexman et al., 2019; Sato et al., 2008).&lt;/p&gt;
&lt;p&gt;Once the lexical and semantic stages have emerged, post-lexical, post-semantic processes follow (Mahon &amp;amp; Caramazza, 2008). These are mental imagery and episodic memory processes—both with an approximate emergence around 270 ms after word onset. The gradual progression from the identification of a word up to accessing its broadest meaning is an important anchoring point in the current research on the alleged embodiment of meaning comprehension, even if we might hope to count on more definitive threshold points (Hauk, 2016).&lt;/p&gt;
&lt;p&gt;Word processing data are mainly based on written word processing, but spoken words are processed quite similarly, if slightly faster (Leonard et al., 2016; Pulvermüller et al., 2005; Shtyrov et al., 2004).&lt;/p&gt;
&lt;p&gt;The bigger take-home messages would be: (1) the processing of meaning might only start at around 160 ms post word onset, and (2) processes outside of meaning comprehension might only start at around 270 ms. These working references must be taken with some caution because particular semantic effects have been found at different stages (e.g., the conceptual modality switch, as in Hald et al., 2011; Collins, Pecher et al., 2011). Indeed, in an influential critique of blooming findings on embodiment, Mahon and Caramazza (2008) argued that even early effects might possibly be explained in terms of non-embodied processing. They contended that working memory processes that were ancillary rather than semantic could be quickly engaged with the function of ‘colouring’ a concept, not building it up. To further complicate the matter, we do not have absolute certainty on the later section of the time course. Thus, as Hauk (2016) reviews, the different stages likely overlap at certain points, with different degrees of relevance. For instance, lexical processing may continue even once semantic processing has started, but would naturally become less relevant. Indeed, the relation among these processes is likely more of a continuum than a set of clear-cut modules. In a nutshell, the time course is important with some experimental effects in word processing, and, to that extent, we depend on our knowledge of the basic time course of word processing.&lt;/p&gt;
&lt;h2 id=&#34;the-conceptual-modality-switch-paradigm-and-its-time-course&#34;&gt;The conceptual modality switch paradigm and its time course&lt;/h2&gt;
&lt;p&gt;In demonstrating the relevance of embodied cognition, a sizeable series of studies have shown that reading about different conceptual modalities (e.g., auditory ‘loud bell’ followed by visual ‘pink background’) incurs processing costs (Pecher et al., 2003). Importantly, this manipulation does not concern the presentation mode of the stimulus, maintained constant, but the intrinsic semantic modality of the stimulus concepts. The conceptual modality switch effect has often been replicated (Pecher et al., 2004; Solomon &amp;amp; Barsalou, 2004; Marques, 2006; Vermeulen et al., 2007; van Dantzig et al., 2008; Lynott &amp;amp; Connell, 2009; Ambrosi et al., 2011; Collins et al., 2011; Hald et al., 2011; Hald et al., 2013; Scerrati et al., 2015).&lt;/p&gt;
&lt;p&gt;Bernabeu, Willems and Louwerse (2017) addressed a caveat with the time course of the conceptual modality switch paradigm. In previous experiments, trials presented a concept word followed by a property word. ERPs were time-locked to the latter property word. This design may have left uncontrolled a switch produced already at the concept. Indeed, the property word was already supposed to be in the particular modality of the trial. That pitfall could have had two consequences: loss of power and loss of certainty on the time course of the effect. Thus, Bernabeu et al. created a design in which ERPs were time-locked to the first word in target trials (see some &lt;a href=&#34;https://www.researchgate.net/post/Conceptual_modality_switch_effect_measured_at_first_word&#34;&gt;early input from researchers online&lt;/a&gt;). The purpose of this relocation was not to completely annul the possibility of post-core sensory processes, but to increase the time accuracy by measuring the modality switch from the point at which it is elicited.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;designoverview.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Implementing this design had an ancillary effect on the measurement of response times. A psycholinguistic experiment like this one requires controlling fundamental variables such as word frequency and length, by matching the means of these variables across experimental conditions. This must be controlled in the target words at least. As it is often the case, this control was only possible in the target words—the first one in target trials—, but it was not possible in the second word, which is the crucial one for response times. Response times could still be measured, but comparisons across conditions were not fully warranted. In sum, this was an ERP design.&lt;/p&gt;
&lt;h2 id=&#34;erp-components&#34;&gt;ERP components&lt;/h2&gt;
&lt;p&gt;When the ERP signal is plotted, it displays multiple wave shapes, or &lt;em&gt;waveforms&lt;/em&gt;, each with a peak flanked by falling tails. Each of these waves often corresponds to an ERP component, which is what cognitive scientists are often interested in.&lt;/p&gt;
&lt;p&gt;Multiple components are known, each having been found to consistently peak around specific points in time during a cognitive process. The peak is one of several features characterising each component. A sketch list is shown below (van Hell &amp;amp; Kroll, 2013).&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Polarity:&lt;/strong&gt; The component either peaks in the positive or the negative pole of the signal. This polarity is relative to the &lt;em&gt;baseline&lt;/em&gt; point that is created in the preprocessing stage (see below);&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Latency:&lt;/strong&gt; the time course of the component, encompassing an onset, a peak and an overall duration. Time windows are normally set to match relevant components (e.g., the N400 window, etc.);&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Amplitude:&lt;/strong&gt; the voltage reached at a given time (e.g., the peak) or for a certain period (e.g., a time window);&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Scalp distribution, or topography:&lt;/strong&gt; the areas on the scalp (the scalp being a reasonable proxy for the brain) in which the component appears;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Functional role:&lt;/strong&gt; the cognitive functions that have been consistently associated with the component.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Examples of components in language processing include the N400, consistently linked to semantic processing, that is, seeking the meaning of words or sentences. The N400 is characterised by a large, negative amplitude peaking at around 400 ms post word onset, primarily found in central and posterior sites. N400 &lt;em&gt;effects&lt;/em&gt;, which are comparisons of the N400 component in different experimental conditions, have consistently appeared under violations of semantic expectations, i.e., related to meaning and events (Kutas &amp;amp; Federmeier, 2011; Swaab et al., 2012). Another well-known component in language is the P600, linked to syntactic processing, which allows the comprehension of sentences (Swaab et al., 2012). Other examples of components include lateralized readiness potentials, signalling motor preparation (Mordkoff &amp;amp; Gianaros, 2000), and the P3b component, which appears in the context of responses (van Vliet et al., 2014). Both of the latter components are relevant to researchers across domains, who often need to ward off &lt;em&gt;contamination&lt;/em&gt; from these components in their experiments. In Bernabeu et al.&amp;lsquo;s experiment, for instance, part of the reason why ERPs were time-locked to the first word in target trials was to prevent contamination from these components.&lt;/p&gt;
&lt;p&gt;ERP data sets are large, being the product of the number of electrodes (also called &amp;lsquo;channels&amp;rsquo;) times the number of time points, times the number of experimental conditions, and times the number of participants. In recent studies, the number of trials often adds to that product, whereas in previous experiments, the trials tended to be aggregated in each condition.&lt;/p&gt;
&lt;h2 id=&#34;eeg-montage&#34;&gt;EEG montage&lt;/h2&gt;
&lt;p&gt;The EEG montage is an important factor. The options are broadly characterised by three parameters of the electrodes:&lt;/p&gt;
&lt;p style=&#34;margin-left: 30px; line-height: 1.2; padding-bottom: 12px; padding-left: 15px; float: right; display: block;&#34;&gt;&lt;img src=&#34;EEG MPI open day photo.jpg&#34; alt=&#34;Pablo Bernabeu, 2015&#34; width=&#34;170px&#34; style=&#39;padding-bottom: 15px; margin-bottom: 0px;&#39; /&gt;&lt;span style=&#34;font-size: small; padding-left: 5px; padding-top: 0px; margin-top: 0px;&#34;&gt;Brainwaves exposed at an open day.&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Active / passive:&lt;/strong&gt; Active electrodes amplify the EEG signal directly at the scalp, whereas passive electrodes require the raw signal to be sent through a lead (i.e., a wire) and up to an amplifier. In the latter case, the lead acts as an antenna, picking up ambient electrical noise. This noise can hinder the subtle measurement of interest. This problem is solved by active electrodes (Laszlo et al., 2014).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Number:&lt;/strong&gt; Traditionally, montages with 32, 64 or 128 electrodes have been used. The more electrodes, the &amp;lsquo;denser&amp;rsquo; the montage, and the higher the spatial resolution.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Wet / dry:&lt;/strong&gt; In some montages, the electrical conductance on the electrodes&amp;rsquo; contact point must be increased using some fluid solutions, such as a specific gel (often commercialised by the companies that also make EEG apparatuses). Conversely, other electrodes function in a dry way. Ensuring the proper conductance on wet electrodes has traditionally been very time-consuming for experimenters, often taking over half an hour of wiggling a blunt syringe distributing the saline solution around the tip. Traditionally, wet electrodes produced more reliable data than dry ones, but &lt;em&gt;the times they are a&#39;changing&lt;/em&gt; (di Flumeri, 2019).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An EEG/ERP experiment is time-consuming. The preparation (especially conductance-prompting with wet montages) and post-experiment procedures (especially washing the EEG cap) often take four or five times as long as the experiment proper. These procedures are especially long for higher-density, wet montages.&lt;/p&gt;
&lt;h2 id=&#34;preprocessing-erps&#34;&gt;Preprocessing ERPs&lt;/h2&gt;
&lt;p&gt;ERPs are not the first signal collected in experiments. They are obtained after considerable, systematic preprocessing of the EEG signal.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#39;https://www.researchgate.net/post/EEG_error_datasets_missing_channels_Its_strange_because_they_were_recorded_well_and_faulty_files_are_quite_as_heavy_as_the_good_ones_Any_ideas&#39;&gt;&lt;img src=&#34;https://www.researchgate.net/profile/Nikolay_Novitskiy/post/EEG_error_datasets_missing_channels_Its_strange_because_they_were_recorded_well_and_faulty_files_are_quite_as_heavy_as_the_good_ones_Any_ideas/attachment/59d6391b79197b8077996520/AS%3A400433085468672%401472482095219/image/41_64ch.png&#34; alt=&#34;Brain Vision waveforms&#34; width=&#39;70%&#39;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For the Bernabeu et al. study, I used Brain Vision software, and followed the &lt;a href=&#34;https://erpinfo.org/resources&#34;&gt;tutorials from the well-known ERP Boot Camp&lt;/a&gt; of Steve Luck and Emily Kappenman. I applied the following pipeline separately for each participant:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;labeling channels (64 electrodes);&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;creating channel groups (anterior and posterior);&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;re-referencing the signal offline to the right mastoid (RM), having referenced online to the left mastoid (Ref);&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#39;EEG montage.png&#39;&gt;&lt;/img&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;
&lt;p&gt;separating my three experimental conditions;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ocular correction for blinks and significant, vertical or horizontal movements of the eyes (seminal method by Gratton et al., 1983, which is the default in Brain Vision);&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;baseline correction, which is a standardisation based on a certain period immediately before the onset of the target manipulation;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;further correction of artifacts such as motor action potentials (or lateralised readiness potentials) resulting from even the subtlest muscle activity.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This pipeline is reflected in the &lt;a href=&#34;https://osf.io/98fs6/&#34;&gt;scripts exported from Brain Vision&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  &amp;lt;Nodes&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions/rerefRM&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions/rerefRM/TotalMatch&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions/rerefRM/TotalMatch/OcularCorrection&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions/rerefRM/TotalMatch/OcularCorrection/baselinecorr&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions/rerefRM/TotalMatch/OcularCorrection/baselinecorr/baselinecorr_artif&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions/rerefRM/TotalMatch/OcularCorrection/baselinecorr/baselinecorr_artif/minave_TotalMatch&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions/rerefRM/EmbodiedMismatch&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions/rerefRM/EmbodiedMismatch/OcularCorrection&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions/rerefRM/EmbodiedMismatch/OcularCorrection/baselinecorr&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions/rerefRM/EmbodiedMismatch/OcularCorrection/baselinecorr/baselinecorr_artif&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions/rerefRM/EmbodiedMismatch/OcularCorrection/baselinecorr/baselinecorr_artif/minave_EmbodiedMismatch&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions/rerefRM/TotalMismatch&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions/rerefRM/TotalMismatch/OcularCorrection&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions/rerefRM/TotalMismatch/OcularCorrection/baselinecorr&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions/rerefRM/TotalMismatch/OcularCorrection/baselinecorr/baselinecorr_artif&amp;lt;/string&amp;gt;
    &amp;lt;string&amp;gt;1/Raw Data/labels/positions/rerefRM/TotalMismatch/OcularCorrection/baselinecorr/baselinecorr_artif/minave_TotalMismatch&amp;lt;/string&amp;gt;
  &amp;lt;/Nodes
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;p&gt;Word reading ERPs can look somewhat like this after the preprocessing (&lt;a href=&#39;https://osf.io/bz7ae/&#39;&gt;plots made in R&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#39;Four main waveform plots stacked.png&#39;&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;To visualise these waveforms throughout the different sections of the data, a &lt;a href=&#34;https://pablobernabeu.shinyapps.io/ERP-waveform-visualization_CMS-experiment&#34;&gt;dashboard is available&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;statistical-analysis&#34;&gt;Statistical analysis&lt;/h2&gt;
&lt;p&gt;With the myriad repeated measures involved in EEG, linear mixed-effects models are a good option, allowing the registration of electrodes and time points in the error term per participant (and trial, too, if these are not aggregated). The analysis I performed, in R, is &lt;a href=&#34;https://osf.io/sx3nw/&#34;&gt;available&lt;/a&gt; (plots visible by downloading the file from the aforementioned link).&lt;/p&gt;
&lt;style&gt;.embed-responsive{position:relative;height:100%;}.embed-responsive iframe{position:absolute;height:100%;}&lt;/style&gt;&lt;script&gt;window.jQuery || document.write(&#39;&lt;script src=&#34;//code.jquery.com/jquery-1.11.2.min.js&#34;&gt;\x3C/script&gt;&#39;) &lt;/script&gt;&lt;link href=&#34;https://mfr.osf.io/static/css/mfr.css&#34; media=&#34;all&#34; rel=&#34;stylesheet&#34;&gt;&lt;div id=&#34;mfrIframe&#34; class=&#34;mfr mfr-file&#34;&gt;&lt;/div&gt;&lt;script src=&#34;https://mfr.osf.io/static/js/mfr.js&#34;&gt;&lt;/script&gt; &lt;script&gt;var mfrRender = new mfr.Render(&#34;mfrIframe&#34;, &#34;https://mfr.osf.io/render?url=https://osf.io/sx3nw/?direct%26mode=render%26action=download%26mode=render&#34;);&lt;/script&gt;
&lt;br&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Event-related potentials fulfil an important role in cognitive neuroscience and psychology, only surpassed by magnetic electroencephalography (MEG), which unites high temporal and spatial resolution. Learning how to use ERPs is demanding but even more rewarding. It certainly does not make for fast science, but allows the measurement of experimental effects online, that is, as they unfold.&lt;/p&gt;
&lt;p&gt;You can learn about and overcome multiple challenges. One of the issues I faced once regarded some channels (electrodes) that appeared to be missing from the data. I posted a &lt;a href=&#34;https://www.researchgate.net/post/EEG_error_datasets_missing_channels_Its_strange_because_they_were_recorded_well_and_faulty_files_are_quite_as_heavy_as_the_good_ones_Any_ideas&#34;&gt;question on ResearchGate&lt;/a&gt;, and emailed Brain Products, the maker of Brain Vision Recorder, which I was using.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hi everyone,&lt;/p&gt;
&lt;p&gt;If you could please give me a hand with this error, I would be very grateful. I have EEG from a psychological experiment, recorded with BrainVision Recorder, and being analyzed with BrainVision Analyzer 2. Most of the recordings are perfectly fine, but a few present a big error. Out of 64 original electrodes, only two appear. These are the right mastoid (RM) and the left eye sensor (LEOG). Both are bipolar electrodes. RM is to be re-referenced to the online reference electrode, while LEOG is to be re-referenced to the right eye electrode.&lt;/p&gt;
&lt;p&gt;I just can&#39;t fathom the error because all electrodes worked fine during the recording. Also, the data sets with the error are quite as heavy in terms of bytes as those without the error. Further, why should the RM and LEOG channels remain perfectly well as they do?&lt;/p&gt;
&lt;p&gt;This issue might seem like a simple zoom I&#39;ve bypassed, or similar&amp;hellip; But unfortunately the channels are just not there. I&#39;ve confirmed it as I tried to copy the pipeline from the good data sets onto the faulty ones, where I got the error &amp;lsquo;No channels enabled.&amp;rsquo; In case you had access to the BVA analysis software, please find the raw files for one of the faulty data sets here.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;p&gt;Thanks to invaluable help from a &lt;a href=&#34;https://www.researchgate.net/post/EEG_error_datasets_missing_channels_Its_strange_because_they_were_recorded_well_and_faulty_files_are_quite_as_heavy_as_the_good_ones_Any_ideas&#34;&gt;ResearchGate contributor&lt;/a&gt; and the Brain Products team, I could put the pieces back together.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Update: Problem solved.&lt;/p&gt;
&lt;p&gt;As Nikolay said, the error originated in Recorder (I had used the workspace from the previous experimenter), and the problem was solved by setting the label and position of each channel.&lt;/p&gt;
&lt;p&gt;I tried editing the .vhdr file in raw (it seemed nice and quick to directly assign the channel names as labels) but i didn&#39;t quite find the way. Therefore, with a tip from the Brain Products team, I went about it within the program.&lt;/p&gt;
&lt;p&gt;First, I used the transform function &amp;lsquo;Edit channels&amp;rsquo; to rename all labels and set each within their coordinates. I did that for just one subject (it doesn&#39;t take as long as it sounds). Afterwards, I created a &amp;lsquo;History template&amp;rsquo; out of that process, and copied it to all other nodes.
At any rate, never getting out of the comfort workspace again&amp;hellip; :D&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;div style = &#34;text-indent:-2em; margin-left:2em;&#34;&gt;
&lt;p&gt;Ambrosi, S., Kalenine, S., Blaye, A., &amp;amp; Bonthoux, F. (2011). Modality switching cost during property verification by 7 years of age. &lt;em&gt;International Journal of Behavioral Development, 35&lt;/em&gt;, 1, 78-83.&lt;/p&gt;
&lt;p&gt;Aurlien, H., Gjerde, I., Aarseth, J., Eldøen, G., Karlsen, B., Skeidsvoll, H., &amp;amp; Gilhus, N. (2003).
EEG background activity described by a large computerized database. &lt;em&gt;Clinical Neurophysiology, 115&lt;/em&gt;, 665–673.&lt;/p&gt;
&lt;p&gt;Bernabeu, P., Willems, R. M., &amp;amp; Louwerse, M. M. (2017). Modality switch effects emerge early and increase throughout conceptual processing: evidence from ERPs. In G. Gunzelmann, A. Howes, T. Tenbrink, &amp;amp; E. J. Davelaar (Eds.), &lt;em&gt;Proceedings of the 39th Annual Conference of the Cognitive Science Society&lt;/em&gt; (pp. 1629-1634). Austin, TX: Cognitive Science Society.&lt;/p&gt;
&lt;p&gt;Collins, J., Pecher, D., Zeelenberg, R., &amp;amp; Coulson, S. (2011). Modality switching in a property verification task: an ERP study of what happens when candles flicker after high heels click. &lt;em&gt;Frontiers in Psychology, 2&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Connell, L., &amp;amp; Lynott, D. (2013). Flexible and fast: Linguistic shortcut affects both shallow and deep conceptual processing. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review, 20&lt;/em&gt;, 542-550.&lt;/p&gt;
&lt;p&gt;Di Flumeri, G., Aricò, P., Borghini, G., Sciaraffa, N., Di Florio, A., &amp;amp; Babiloni, F. (2019). The Dry Revolution: Evaluation of Three Different EEG Dry Electrode Types in Terms of Signal Spectral Features, Mental States Classification and Usability. &lt;em&gt;Sensors (Basel, Switzerland), 19&lt;/em&gt;(6), 1365.&lt;/p&gt;
&lt;p&gt;Gratton, G., Coles, M. G., &amp;amp; Donchin, E. (1983). A new method for offline removal of ocular artefact. &lt;em&gt;Electroencephalography and Clinical Neurophysiology, 55&lt;/em&gt;, 4, 468-484.&lt;/p&gt;
&lt;p&gt;Hald, L. A., Hocking, I., Vernon, D., Marshall, J.-A., &amp;amp; Garnham, A. (2013). Exploring modality switching effects in negated sentences: further evidence for grounded representations. &lt;em&gt;Frontiers in Psychology, 4&lt;/em&gt;, 93.&lt;/p&gt;
&lt;p&gt;Hald, L. A., Marshall, J.-A., Janssen, D. P., &amp;amp; Garnham, A. (2011). Switching modalities in a sentence verification task: ERP evidence for embodied language processing. &lt;em&gt;Frontiers in Psychology, 2&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Hauk, O. (2016). Only time will tell—Why temporal information is essential for our neuroscientific understanding of semantics. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review, 23&lt;/em&gt;, 4, 1072-1079.&lt;/p&gt;
&lt;p&gt;Kutas, M., &amp;amp; Federmeier, K. D. (2011). Thirty years and counting: finding meaning in the N400 component of the event-related brain potential (ERP). &lt;em&gt;Annual Review of Psychology, 62&lt;/em&gt;, 621–647.&lt;/p&gt;
&lt;p&gt;Laszlo, S., Ruiz-Blondet, M., Khalifian, N., Chu, F., &amp;amp; Jin, Z. (2014). A direct comparison of active and passive amplification electrodes in the same amplifier system. &lt;em&gt;Journal of Neuroscience Methods, 235&lt;/em&gt;, 298-307.&lt;/p&gt;
&lt;p&gt;Lebois, L. A. M., Wilson-Mendenhall, C. D., &amp;amp; Barsalou, L. W. (2014). Are automatic conceptual cores the gold standard of semantic processing? The context-dependence of spatial meaning in grounded congruency effects. &lt;em&gt;Cognitive Science, 39&lt;/em&gt;, 8, 1764-801.&lt;/p&gt;
&lt;p&gt;Leonard, M. K., Baud, M. O., Sjerps, M. J., &amp;amp; Chang, E. F. (2016). Perceptual restoration of masked speech in human cortex. &lt;em&gt;Nature Communications, 7&lt;/em&gt;, 13619.&lt;/p&gt;
&lt;p&gt;Luck, S. J. &amp;amp; Kappenman, E.S. (Eds.), &lt;em&gt;Oxford Handbook of Event-Related Potential Components&lt;/em&gt;. New York: Oxford University Press&lt;/p&gt;
&lt;p&gt;Mahon, B.Z., &amp;amp; Caramazza, A. (2008). A critical look at the Embodied Cognition Hypothesis and a new proposal for grounding conceptual content. &lt;em&gt;Journal of Physiology - Paris, 102&lt;/em&gt;, 59-70.&lt;/p&gt;
&lt;p&gt;Marques, J. F. (2006). Specialization and semantic organization: Evidence for multiple semantics linked to sensory modalities. *&lt;em&gt;Memory &amp;amp; Cognition, 34&lt;/em&gt;, 1, 60-67.&lt;/p&gt;
&lt;p&gt;Mordkoff, J. T., &amp;amp; Gianaros, P. J. (2000). Detecting the onset of the lateralized readiness potential: A comparison of available methods and procedures. &lt;em&gt;Psychophysiology, 37&lt;/em&gt;(3), 347–360.&lt;/p&gt;
&lt;p&gt;Pecher, D., Zeelenberg, R., &amp;amp; Barsalou, L. W. (2003). Verifying different-modality properties for concepts produces switching costs. &lt;em&gt;Psychological Science, 14&lt;/em&gt;, 2, 119-24.&lt;/p&gt;
&lt;p&gt;____ (2004). Sensorimotor simulations underlie conceptual representations: Modality-specific effects of prior activation. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review, 11&lt;/em&gt;, 1, 164-167.&lt;/p&gt;
&lt;p&gt;Pexman, P. M., Muraki, E. J., Sidhu, D. M., Siakaluk, P. D., &amp;amp; Yap, M. J. (2019). Quantifying sensorimotor experience: Body-object interaction ratings for more than 9,000 English words. &lt;em&gt;Behavior Research Methods, 51&lt;/em&gt;, 453-466.&lt;/p&gt;
&lt;p&gt;Pulvermüller, F., Shtyrov, Y., &amp;amp; Hauk, O. (2009). Understanding in an instant: Neurophysiological evidence for mechanistic language circuits in the brain. &lt;em&gt;Brain and Language, 110&lt;/em&gt;, 2, 81–94.&lt;/p&gt;
&lt;p&gt;Roohi-Azizi, M., Azimi, L., Heysieattalab, S., &amp;amp; Aamidfar, M. (2017). Changes of the brain&#39;s bioelectrical activity in cognition, consciousness, and some mental disorders. &lt;em&gt;Medical journal of the Islamic Republic of Iran, 31&lt;/em&gt;, 53.&lt;/p&gt;
&lt;p&gt;Sato, M., Mengarelli, M., Riggio, L., Gallese, V., &amp;amp; Buccino, G. (2008). Task related modulation of the motor system during language processing. &lt;em&gt;Brain and Language, 105&lt;/em&gt;, 83–90.&lt;/p&gt;
&lt;p&gt;Scerrati, E., Baroni, G., Borghi, A. M., Galatolo, R., Lugli, L., &amp;amp; Nicoletti, R. (2015). The modality-switch effect: visually and aurally presented prime sentences activate our senses. &lt;em&gt;Frontiers in Psychology, 6&lt;/em&gt;, 1668.&lt;/p&gt;
&lt;p&gt;Shtyrov, Y., Hauk, O., &amp;amp; Pulvermüller, F. (2004). Distributed neuronal networks for encoding category-specific semantic information: the mismatch negativity to action words. &lt;em&gt;European Journal of Neuroscience, 1&lt;/em&gt;, 4, 1083–1092.&lt;/p&gt;
&lt;p&gt;Solomon, K. O., &amp;amp; Barsalou, L. W. (2004). Perceptual simulation in property verification. &lt;em&gt;Memory &amp;amp; Cognition, 32&lt;/em&gt;, 244-259.&lt;/p&gt;
&lt;p&gt;Swaab, T.Y., Ledoux, K., Camblin, C.C., &amp;amp; Boudewyn, M.A. (2012) Language related ERP components. (Book Chapter). In Luck, S. J. &amp;amp; Kappenman, E.S. (Eds.), &lt;em&gt;Oxford Handbook of Event-Related Potential Components&lt;/em&gt; (pp. 397-440). New York: Oxford University Press&lt;/p&gt;
&lt;p&gt;Van Dantzig, S., Pecher, D., Zeelenberg, R., &amp;amp; Barsalou, L. W. (2008). Perceptual processing affects conceptual processing. &lt;em&gt;Cognitive Science, 32&lt;/em&gt;, 579–590.&lt;/p&gt;
&lt;p&gt;Van Hell, J. G., &amp;amp; Kroll, J. F. (2013). Using electrophysiological measures to track the mapping of words to concepts in the bilingual brain: a focus on translation. In J. Altarriba &amp;amp; L. Isurin (Eds.), &lt;em&gt;Memory, Language, and Bilingualism: Theoretical and Applied Approaches&lt;/em&gt; (pp. 126-160). New York: Cambridge University Press.&lt;/p&gt;
&lt;p&gt;Van Vliet, M., Manyakov, N., Storms, G., Fias, W., Wiersema, J., &amp;amp; Van Hulle, M. (2014). Response-Related Potentials during semantic priming: the effect of a speeded button response task on ERPs. &lt;em&gt;PLoS One, 9&lt;/em&gt;, 2, e87650.&lt;/p&gt;
&lt;p&gt;Vermeulen, N., Niedenthal, P. M., &amp;amp; Luminet, O. (2007). Switching between sensory and affective systems incurs processing costs. &lt;em&gt;Cognitive Science, 31&lt;/em&gt;, 1, 183-192.&lt;/p&gt;
&lt;p&gt;Willems, R. M., Frank, S. L., Nijhoff, A. D., Hagoort, P., &amp;amp; Van den Bosch, A. (2016). Prediction during natural language comprehension. &lt;em&gt;Cerebral Cortex, 26&lt;/em&gt;, 6, 2506-2516.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Modality switch effects emerge early and increase throughout conceptual processing: Evidence from ERPs</title>
      <link>https://pablobernabeu.github.io/publication/bernabeu-etal-2017/</link>
      <pubDate>Sat, 01 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/publication/bernabeu-etal-2017/</guid>
      <description>&lt;h3 id=&#34;bonus-a-conference-poster-with-further-analyses-nbspa-hrefhttpsmfrosfiorenderurlhttpsosfiodj52ndirect26moderender26actiondownload26moderenderi-classfas-fa-external-link-altia&#34;&gt;Bonus: a conference poster with further analyses  &lt;a href=&#39;https://mfr.osf.io/render?url=https://osf.io/dj52n/?direct%26mode=render%26action=download%26mode=render&#39;&gt;&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;style&gt;.embed-responsive{position:relative;height:100%;}.embed-responsive iframe{position:absolute;height:100%;}&lt;/style&gt;&lt;script&gt;window.jQuery || document.write(&#39;&lt;script src=&#34;//code.jquery.com/jquery-1.11.2.min.js&#34;&gt;\x3C/script&gt;&#39;) &lt;/script&gt;&lt;link href=&#34;https://mfr.osf.io/static/css/mfr.css&#34; media=&#34;all&#34; rel=&#34;stylesheet&#34;&gt;&lt;div id=&#34;mfrIframe&#34; class=&#34;mfr mfr-file&#34;&gt;&lt;/div&gt;&lt;script src=&#34;https://mfr.osf.io/static/js/mfr.js&#34;&gt;&lt;/script&gt; &lt;script&gt;var mfrRender = new mfr.Render(&#34;mfrIframe&#34;, &#34;https://mfr.osf.io/render?url=https://osf.io/dj52n/?direct%26mode=render%26action=download%26mode=render&#34;);&lt;/script&gt;
&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;div style = &#34;text-indent: -2em; margin-left: 2em;&#34;&gt;
&lt;p&gt;Bernabeu, P., Willems, R. M., &amp;amp; Louwerse, M. M. (2017). Modality switch effects emerge early and increase throughout conceptual processing: Evidence from ERPs. In G. Gunzelmann, A. Howes, T. Tenbrink, &amp;amp; E. J. Davelaar (Eds.), &lt;em&gt;Proceedings of the 39th Annual Conference of the Cognitive Science Society&lt;/em&gt; (pp. 1629-1634). Austin, TX: Cognitive Science Society. &lt;a href=&#34;https://doi.org/10.31234/osf.io/a5pcz&#34;&gt;https://doi.org/10.31234/osf.io/a5pcz&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;h3 id=&#34;related-references&#34;&gt;Related references&lt;/h3&gt;
&lt;div style = &#34;text-indent: -2em; margin-left: 2em; color: darkgrey;&#34;&gt;
&lt;p&gt;Ali Qurbi, E. (2022). Ambiguous Word Processing among Second Language Learners. &lt;em&gt;The Canadian Modern Language Review&lt;/em&gt;, &lt;em&gt;78&lt;/em&gt;(2), 151&amp;ndash;173. &lt;a href=&#34;https://doi.org/10.3138/cmlr-2020-0115&#34;&gt;https://doi.org/10.3138/cmlr-2020-0115&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Amenta, S., Crepaldi, D., &amp;amp; Marelli, M. (2020). Consistency measures individuate dissociating semantic modulations in priming paradigms: A new look on semantics in the processing of (complex) words. &lt;em&gt;Quarterly Journal of Experimental Psychology&lt;/em&gt;, &lt;em&gt;73&lt;/em&gt;(10), 1546&amp;ndash;1563. &lt;a href=&#34;https://doi.org/10.1177/1747021820927663&#34;&gt;https://doi.org/10.1177/1747021820927663&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Amsel, B. D., Kutas, M., &amp;amp; Coulson, S. (2017). Projectors, associators, visual imagery, and the time course of visual processing in grapheme-color synesthesia. &lt;em&gt;Cognitive Neuroscience&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;(4), 206&amp;ndash;223. &lt;a href=&#34;https://doi.org/10.1080/17588928.2017.1353492&#34;&gt;https://doi.org/10.1080/17588928.2017.1353492&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Argiris, G., Rumiati, R. I., &amp;amp; Crepaldi, D. (2021). No fruits without color: Cross-modal priming and EEG reveal different roles for different features across semantic categories. &lt;em&gt;PLOS ONE&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;(4), e0234219. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0234219&#34;&gt;https://doi.org/10.1371/journal.pone.0234219&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Avramova, Y. R., De Pelsmacker, P., &amp;amp; Dens, N. (2017). Brand placement in text: The short- and long-term effects of placement modality and need for cognition. &lt;em&gt;International Journal of Advertising&lt;/em&gt;, &lt;em&gt;36&lt;/em&gt;(5), 682&amp;ndash;704. &lt;a href=&#34;https://doi.org/10.1080/02650487.2017.1335041&#34;&gt;https://doi.org/10.1080/02650487.2017.1335041&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bagli, M. (2023). How to Point with Language: English Source-Based Language to Describe Taste Qualities. &lt;em&gt;Lublin Studies in Modern Languages and Literature&lt;/em&gt;, &lt;em&gt;42&lt;/em&gt;(2), 31&amp;ndash;46. &lt;a href=&#34;https://doi.org/10.17951/lsmll.2023.47.2.31-46&#34;&gt;https://doi.org/10.17951/lsmll.2023.47.2.31-46&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Banks, B., Wingfield, C., &amp;amp; Connell, L. (2021). Linguistic Distributional Knowledge and Sensorimotor Grounding both Contribute to Semantic Category Production. &lt;em&gt;Cognitive Science&lt;/em&gt;, &lt;em&gt;45&lt;/em&gt;(10), e13055. &lt;a href=&#34;https://doi.org/10.1111/cogs.13055&#34;&gt;https://doi.org/10.1111/cogs.13055&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Barros García, B. (2017). In Other Words: Reformulation Strategies in Dostoevskii&#39;s Literary Works. &lt;em&gt;Russian Literature&lt;/em&gt;, &lt;em&gt;91&lt;/em&gt;, 1&amp;ndash;25. &lt;a href=&#34;https://doi.org/10.1016/j.ruslit.2017.09.001&#34;&gt;https://doi.org/10.1016/j.ruslit.2017.09.001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Barsalou, L. W. (2017a). Cognitively Plausible Theories of Concept Composition. In J. A. Hampton &amp;amp; Y. Winter (Eds.), &lt;em&gt;Compositionality and Concepts in Linguistics and Psychology&lt;/em&gt; (Vol. 3, pp. 9&amp;ndash;30). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-319-45977-6_2&#34;&gt;https://doi.org/10.1007/978-3-319-45977-6_2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Barsalou, L. W. (2017b). What does semantic tiling of the cortex tell us about semantics? &lt;em&gt;Neuropsychologia&lt;/em&gt;, &lt;em&gt;105&lt;/em&gt;, 18&amp;ndash;38. &lt;a href=&#34;https://doi.org/10.1016/j.neuropsychologia.2017.04.011&#34;&gt;https://doi.org/10.1016/j.neuropsychologia.2017.04.011&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Barsalou, L. W. (2020). Challenges and Opportunities for Grounding Cognition. &lt;em&gt;Journal of Cognition&lt;/em&gt;, &lt;em&gt;3&lt;/em&gt;(1), 31. &lt;a href=&#34;https://doi.org/10.5334/joc.116&#34;&gt;https://doi.org/10.5334/joc.116&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bartl, S., &amp;amp; Lahey, E. (2023). &amp;lsquo;As the title implies&amp;rsquo;: How readers talk about titles in Amazon book reviews. &lt;em&gt;Language and Literature: International Journal of Stylistics&lt;/em&gt;, &lt;em&gt;32&lt;/em&gt;(2), 209&amp;ndash;230. &lt;a href=&#34;https://doi.org/10.1177/09639470221147788&#34;&gt;https://doi.org/10.1177/09639470221147788&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Baumann, A., Hofmann, K., Marakasova, A., Neidhardt, J., &amp;amp; Wissik, T. (2023). Semantic micro-dynamics as a reflex of occurrence frequency: A semantic networks approach. &lt;em&gt;Cognitive Linguistics&lt;/em&gt;, &lt;em&gt;34&lt;/em&gt;(3&amp;ndash;4), 533&amp;ndash;568. &lt;a href=&#34;https://doi.org/10.1515/cog-2022-0008&#34;&gt;https://doi.org/10.1515/cog-2022-0008&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bechtold, L., Bellebaum, C., Egan, S., Tettamanti, M., &amp;amp; Ghio, M. (2019). The role of experience for abstract concepts: Expertise modulates the electrophysiological correlates of mathematical word processing. &lt;em&gt;Brain and Language&lt;/em&gt;, &lt;em&gt;188&lt;/em&gt;, 1&amp;ndash;10. &lt;a href=&#34;https://doi.org/10.1016/j.bandl.2018.10.002&#34;&gt;https://doi.org/10.1016/j.bandl.2018.10.002&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bechtold, L., Bellebaum, C., &amp;amp; Ghio, M. (2023). When a Sunny Day Gives You Butterflies: An Electrophysiological Investigation of Concreteness and Context Effects in Semantic Word Processing. &lt;em&gt;Journal of Cognitive Neuroscience&lt;/em&gt;, &lt;em&gt;35&lt;/em&gt;(2), 241&amp;ndash;258. &lt;a href=&#34;https://doi.org/10.1162/jocn_a_01942&#34;&gt;https://doi.org/10.1162/jocn_a_01942&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bechtold, L., Bellebaum, C., Hoffman, P., &amp;amp; Ghio, M. (2021). Corroborating behavioral evidence for the interplay of representational richness and semantic control in semantic word processing. &lt;em&gt;Scientific Reports&lt;/em&gt;, &lt;em&gt;11&lt;/em&gt;(1), 6184. &lt;a href=&#34;https://doi.org/10.1038/s41598-021-85711-7&#34;&gt;https://doi.org/10.1038/s41598-021-85711-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bidet-Ildei, C., Gimenes, M., Toussaint, L., Almecija, Y., &amp;amp; Badets, A. (2017). Sentence plausibility influences the link between action words and the perception of biological human movements. &lt;em&gt;Psychological Research&lt;/em&gt;, &lt;em&gt;81&lt;/em&gt;(4), 806&amp;ndash;813. &lt;a href=&#34;https://doi.org/10.1007/s00426-016-0776-z&#34;&gt;https://doi.org/10.1007/s00426-016-0776-z&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bidet-Ildei, C., Gimenes, M., Toussaint, L., Beauprez, S.-A., &amp;amp; Badets, A. (2017). Painful semantic context modulates the relationship between action words and biological movement perception. &lt;em&gt;Journal of Cognitive Psychology&lt;/em&gt;, &lt;em&gt;29&lt;/em&gt;(7), 821&amp;ndash;831. &lt;a href=&#34;https://doi.org/10.1080/20445911.2017.1322093&#34;&gt;https://doi.org/10.1080/20445911.2017.1322093&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bolognesi, M., &amp;amp; Strik Lievers, F. (2020). How language and image construct synaesthetic metaphors in print advertising. &lt;em&gt;Visual Communication&lt;/em&gt;, &lt;em&gt;19&lt;/em&gt;(4), 431&amp;ndash;457. &lt;a href=&#34;https://doi.org/10.1177/1470357218782001&#34;&gt;https://doi.org/10.1177/1470357218782001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Borghesani, V., &amp;amp; Piazza, M. (2017). The neuro-cognitive representations of symbols: The case of concrete words. &lt;em&gt;Neuropsychologia&lt;/em&gt;, &lt;em&gt;105&lt;/em&gt;, 4&amp;ndash;17. &lt;a href=&#34;https://doi.org/10.1016/j.neuropsychologia.2017.06.026&#34;&gt;https://doi.org/10.1016/j.neuropsychologia.2017.06.026&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Borghi, A. M., &amp;amp; Barsalou, L. (2021). Perspective in the conceptualization of categories. &lt;em&gt;Psychological Research&lt;/em&gt;, &lt;em&gt;85&lt;/em&gt;(2), 697&amp;ndash;719. &lt;a href=&#34;https://doi.org/10.1007/s00426-019-01269-0&#34;&gt;https://doi.org/10.1007/s00426-019-01269-0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Borghi, A. M., Binkofski, F., Castelfranchi, C., Cimatti, F., Scorolli, C., &amp;amp; Tummolini, L. (2017). The challenge of abstract concepts. &lt;em&gt;Psychological Bulletin&lt;/em&gt;, &lt;em&gt;143&lt;/em&gt;(3), 263&amp;ndash;292. &lt;a href=&#34;https://doi.org/10.1037/bul0000089&#34;&gt;https://doi.org/10.1037/bul0000089&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Borghi, A. M., Mazzuca, C., Gervasi, A. M., Mannella, F., &amp;amp; Tummolini, L. (2023). Grounded cognition can be multimodal all the way down. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, 1&amp;ndash;5. &lt;a href=&#34;https://doi.org/10.1080/23273798.2023.2210238&#34;&gt;https://doi.org/10.1080/23273798.2023.2210238&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bottini, R., Ferraro, S., Nigri, A., Cuccarini, V., Bruzzone, M. G., &amp;amp; Collignon, O. (2020). Brain Regions Involved in Conceptual Retrieval in Sighted and Blind People. &lt;em&gt;Journal of Cognitive Neuroscience&lt;/em&gt;, &lt;em&gt;32&lt;/em&gt;(6), 1009&amp;ndash;1025. &lt;a href=&#34;https://doi.org/10.1162/jocn_a_01538&#34;&gt;https://doi.org/10.1162/jocn_a_01538&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bruffaerts, R., De Deyne, S., Meersmans, K., Liuzzi, A. G., Storms, G., &amp;amp; Vandenberghe, R. (2019). Redefining the resolution of semantic knowledge in the brain: Advances made by the introduction of models of semantics in neuroimaging. &lt;em&gt;Neuroscience &amp;amp; Biobehavioral Reviews&lt;/em&gt;, &lt;em&gt;103&lt;/em&gt;, 3&amp;ndash;13. &lt;a href=&#34;https://doi.org/10.1016/j.neubiorev.2019.05.015&#34;&gt;https://doi.org/10.1016/j.neubiorev.2019.05.015&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Caballero, R., &amp;amp; Paradis, C. (2020). Soundscapes in English and Spanish: A corpus investigation of verb constructions. &lt;em&gt;Language and Cognition&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(4), 705&amp;ndash;728. &lt;a href=&#34;https://doi.org/10.1017/langcog.2020.19&#34;&gt;https://doi.org/10.1017/langcog.2020.19&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Caballero, R., &amp;amp; Paradis, C. (2023). Sharing Perceptual Experiences through Language. &lt;em&gt;Journal of Intelligence&lt;/em&gt;, &lt;em&gt;11&lt;/em&gt;(7), 129. &lt;a href=&#34;https://doi.org/10.3390/jintelligence11070129&#34;&gt;https://doi.org/10.3390/jintelligence11070129&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Cantarero, K., Parzuchowski, M., &amp;amp; Dukala, K. (2017). White Lies in Hand: Are Other-Oriented Lies Modified by Hand Gestures? Possibly Not. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;, 814. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2017.00814&#34;&gt;https://doi.org/10.3389/fpsyg.2017.00814&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Carney, J. (2020). Thinking avant la lettre: A Review of 4E Cognition. &lt;em&gt;Evolutionary Studies in Imaginative Culture&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(1), 77&amp;ndash;90. &lt;a href=&#34;https://doi.org/10.26613/esic.4.1.172&#34;&gt;https://doi.org/10.26613/esic.4.1.172&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Caterina Villani &amp;amp; Luisa Lugli. (2020). L&#39;effetto Simon e il suo decorso temporale con stimoli linguistici non spaziali. &lt;em&gt;Giornale italiano di psicologia&lt;/em&gt;, &lt;em&gt;1&lt;/em&gt;, 305&amp;ndash;314. &lt;a href=&#34;https://doi.org/10.1421/96612&#34;&gt;https://doi.org/10.1421/96612&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chan, S. (2022). Dynamics of nominal classification systems in language processing. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(6), 671&amp;ndash;685. &lt;a href=&#34;https://doi.org/10.1080/23273798.2021.2011331&#34;&gt;https://doi.org/10.1080/23273798.2021.2011331&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Charmhun Jo, Sun-A Kim, &amp;amp; Chu-Ren Huang. (2022). Linguistic synesthesia in Korean: A compound word-based study of cross-modal directionality. &lt;em&gt;Linguistic Research&lt;/em&gt;, &lt;em&gt;39&lt;/em&gt;(2), 275&amp;ndash;296. &lt;a href=&#34;https://doi.org/10.17250/KHISLI.39.2.202206.002&#34;&gt;https://doi.org/10.17250/KHISLI.39.2.202206.002&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chedid, G., Brambati, S. M., Bedetti, C., Rey, A. E., Wilson, M. A., &amp;amp; Vallet, G. T. (2019). Visual and auditory perceptual strength norms for 3,596 French nouns and their relationship with other psycholinguistic variables. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;51&lt;/em&gt;(5), 2094&amp;ndash;2105. &lt;a href=&#34;https://doi.org/10.3758/s13428-019-01254-w&#34;&gt;https://doi.org/10.3758/s13428-019-01254-w&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chen, I.-H., Zhao, Q., Long, Y., Lu, Q., &amp;amp; Huang, C.-R. (2019). Mandarin Chinese modality exclusivity norms. &lt;em&gt;PLOS ONE&lt;/em&gt;, &lt;em&gt;14&lt;/em&gt;(2), e0211336. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0211336&#34;&gt;https://doi.org/10.1371/journal.pone.0211336&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Choi, U., Sung, Y., &amp;amp; Ogawa, S. (2020). Measurement of ultra‐fast signal progression related to face processing by 7T fMRI. &lt;em&gt;Human Brain Mapping&lt;/em&gt;, &lt;em&gt;41&lt;/em&gt;(7), 1754&amp;ndash;1764. &lt;a href=&#34;https://doi.org/10.1002/hbm.24907&#34;&gt;https://doi.org/10.1002/hbm.24907&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chwilla, D. J. (2022). Context effects in language comprehension: The role of emotional state and attention on semantic and syntactic processing. &lt;em&gt;Frontiers in Human Neuroscience&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;, 1014547. &lt;a href=&#34;https://doi.org/10.3389/fnhum.2022.1014547&#34;&gt;https://doi.org/10.3389/fnhum.2022.1014547&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Cirillo, G., Strijkers, K., Runnqvist, E., &amp;amp; Baus, C. (2023). Effects of Shared Attention on joint language production across processing stages. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, 1&amp;ndash;12. &lt;a href=&#34;https://doi.org/10.1080/23273798.2023.2260021&#34;&gt;https://doi.org/10.1080/23273798.2023.2260021&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Cochrane, B. A., &amp;amp; Milliken, B. (2019). Imagined event files: An interplay between imagined and perceived objects. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;26&lt;/em&gt;(2), 538&amp;ndash;544. &lt;a href=&#34;https://doi.org/10.3758/s13423-019-01572-2&#34;&gt;https://doi.org/10.3758/s13423-019-01572-2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Connell, L. (2019). What have labels ever done for us? The linguistic shortcut in conceptual processing. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;34&lt;/em&gt;(10), 1308&amp;ndash;1318. &lt;a href=&#34;https://doi.org/10.1080/23273798.2018.1471512&#34;&gt;https://doi.org/10.1080/23273798.2018.1471512&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Connell, L., Lynott, D., &amp;amp; Banks, B. (2018). Interoception: The forgotten modality in perceptual grounding of abstract and concrete concepts. &lt;em&gt;Philosophical Transactions of the Royal Society B: Biological Sciences&lt;/em&gt;, &lt;em&gt;373&lt;/em&gt;(1752), 20170143. &lt;a href=&#34;https://doi.org/10.1098/rstb.2017.0143&#34;&gt;https://doi.org/10.1098/rstb.2017.0143&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Corciulo, S., Bioglio, L., Basile, V., Patti, V., &amp;amp; Damiano, R. (2023). The DEEP Sensorium: A multidimensional approach to sensory domain labelling. &lt;em&gt;Companion Proceedings of the ACM Web Conference 2023&lt;/em&gt;, 661&amp;ndash;668. &lt;a href=&#34;https://doi.org/10.1145/3543873.3587631&#34;&gt;https://doi.org/10.1145/3543873.3587631&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Courson, M., Macoir, J., &amp;amp; Tremblay, P. (2018). A facilitating role for the primary motor cortex in action sentence processing. &lt;em&gt;Behavioural Brain Research&lt;/em&gt;, &lt;em&gt;336&lt;/em&gt;, 244&amp;ndash;249. &lt;a href=&#34;https://doi.org/10.1016/j.bbr.2017.09.019&#34;&gt;https://doi.org/10.1016/j.bbr.2017.09.019&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Davis, C. P., Joergensen, G. H., Boddy, P., Dowling, C., &amp;amp; Yee, E. (2020). Making It Harder to &amp;ldquo;See&amp;rdquo; Meaning: The More You See Something, the More Its Conceptual Representation Is Susceptible to Visual Interference. &lt;em&gt;Psychological Science&lt;/em&gt;, &lt;em&gt;31&lt;/em&gt;(5), 505&amp;ndash;517. &lt;a href=&#34;https://doi.org/10.1177/0956797620910748&#34;&gt;https://doi.org/10.1177/0956797620910748&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Davis, C. P., &amp;amp; Yee, E. (2021). Building semantic memory from embodied and distributional language experience. &lt;em&gt;WIREs Cognitive Science&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(5), e1555. &lt;a href=&#34;https://doi.org/10.1002/wcs.1555&#34;&gt;https://doi.org/10.1002/wcs.1555&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Davis, J. D., Coulson, S., Arnold, A. J., &amp;amp; Winkielman, P. (2021). Dynamic Grounding of Concepts: Implications for Emotion and Social Cognition. In M. D. Robinson &amp;amp; L. E. Thomas (Eds.), &lt;em&gt;Handbook of Embodied Psychology&lt;/em&gt; (pp. 23&amp;ndash;42). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-78471-3_2&#34;&gt;https://doi.org/10.1007/978-3-030-78471-3_2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;De Deyne, S., Brysbaert, M., &amp;amp; Elgort, I. (2023). Chapter 7. Cross-language influences in L2 semantic and conceptual representation and processing. In I. Elgort, A. Siyanova-Chanturia, &amp;amp; M. Brysbaert (Eds.), &lt;em&gt;Bilingual Processing and Acquisition&lt;/em&gt; (Vol. 16, pp. 152&amp;ndash;186). John Benjamins Publishing Company. &lt;a href=&#34;https://doi.org/10.1075/bpa.16.07ded&#34;&gt;https://doi.org/10.1075/bpa.16.07ded&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dellantonio, S., &amp;amp; Pastore, L. (2017). The &amp;lsquo;Proprioceptive&amp;rsquo; Component of Abstract Concepts. In S. Dellantonio &amp;amp; L. Pastore, &lt;em&gt;Internal Perception&lt;/em&gt; (Vol. 40, pp. 297&amp;ndash;357). Springer Berlin Heidelberg. &lt;a href=&#34;https://doi.org/10.1007/978-3-662-55763-1_6&#34;&gt;https://doi.org/10.1007/978-3-662-55763-1_6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Díez-Álamo, A. M., Díez, E., Alonso, M. Á., Vargas, C. A., &amp;amp; Fernandez, A. (2018). Normative ratings for perceptual and motor attributes of 750 object concepts in Spanish. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;50&lt;/em&gt;(4), 1632&amp;ndash;1644. &lt;a href=&#34;https://doi.org/10.3758/s13428-017-0970-y&#34;&gt;https://doi.org/10.3758/s13428-017-0970-y&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dove, G. (2018). Language as a disruptive technology: Abstract concepts, embodiment and the flexible mind. &lt;em&gt;Philosophical Transactions of the Royal Society B: Biological Sciences&lt;/em&gt;, &lt;em&gt;373&lt;/em&gt;(1752), 20170135. &lt;a href=&#34;https://doi.org/10.1098/rstb.2017.0135&#34;&gt;https://doi.org/10.1098/rstb.2017.0135&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dove, G. (2021). The Challenges of Abstract Concepts. In M. D. Robinson &amp;amp; L. E. Thomas (Eds.), &lt;em&gt;Handbook of Embodied Psychology&lt;/em&gt; (pp. 171&amp;ndash;195). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-78471-3_8&#34;&gt;https://doi.org/10.1007/978-3-030-78471-3_8&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dove, G., Barca, L., Tummolini, L., &amp;amp; Borghi, A. M. (2022). Words have a weight: Language as a source of inner grounding and flexibility in abstract concepts. &lt;em&gt;Psychological Research&lt;/em&gt;, &lt;em&gt;86&lt;/em&gt;(8), 2451&amp;ndash;2467. &lt;a href=&#34;https://doi.org/10.1007/s00426-020-01438-6&#34;&gt;https://doi.org/10.1007/s00426-020-01438-6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dupont, W., Papaxanthis, C., Lebon, F., &amp;amp; Madden-Lombardi, C. (2022). Does the Motor Cortex Want the Full Story? The Influence of Sentence Context on Corticospinal Excitability in Action Language Processing. &lt;em&gt;Neuroscience&lt;/em&gt;, &lt;em&gt;506&lt;/em&gt;, 58&amp;ndash;67. &lt;a href=&#34;https://doi.org/10.1016/j.neuroscience.2022.10.022&#34;&gt;https://doi.org/10.1016/j.neuroscience.2022.10.022&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dutriaux, L., Dahiez, X., &amp;amp; Gyselinck, V. (2019). How to change your memory of an object with a posture and a verb. &lt;em&gt;Quarterly Journal of Experimental Psychology&lt;/em&gt;, &lt;em&gt;72&lt;/em&gt;(5), 1112&amp;ndash;1118. &lt;a href=&#34;https://doi.org/10.1177/1747021818785096&#34;&gt;https://doi.org/10.1177/1747021818785096&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dymarska, A., Connell, L., &amp;amp; Banks, B. (2022). Linguistic Bootstrapping Allows More Real-world Object Concepts to Be Held in Mind. &lt;em&gt;Collabra: Psychology&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;(1), 40171. &lt;a href=&#34;https://doi.org/10.1525/collabra.40171&#34;&gt;https://doi.org/10.1525/collabra.40171&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dymarska, A., Connell, L., &amp;amp; Banks, B. (2023). More is not necessarily better: How different aspects of sensorimotor experience affect recognition memory for words. &lt;em&gt;Journal of Experimental Psychology: Learning, Memory, and Cognition&lt;/em&gt;, &lt;em&gt;49&lt;/em&gt;(10), 1572&amp;ndash;1587. &lt;a href=&#34;https://doi.org/10.1037/xlm0001265&#34;&gt;https://doi.org/10.1037/xlm0001265&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Edmiston, P., &amp;amp; Lupyan, G. (2017). Visual interference disrupts visual knowledge. &lt;em&gt;Journal of Memory and Language&lt;/em&gt;, &lt;em&gt;92&lt;/em&gt;, 281&amp;ndash;292. &lt;a href=&#34;https://doi.org/10.1016/j.jml.2016.07.002&#34;&gt;https://doi.org/10.1016/j.jml.2016.07.002&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Elisa Scerrati, Cristina Iani, Luisa Lugli, &amp;amp; Sandro Rubichi. (2019). C&#39;è un effetto di potenziamento dell&#39;azione con oggetti bimanuali? &lt;em&gt;Giornale italiano di psicologia&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;, 987&amp;ndash;996. &lt;a href=&#34;https://doi.org/10.1421/95573&#34;&gt;https://doi.org/10.1421/95573&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Elpidorou, A., &amp;amp; Dove, G. (2018). &lt;em&gt;Consciousness and Physicalism: A Defense of a Research Program&lt;/em&gt; (1st ed.). Routledge. &lt;a href=&#34;https://doi.org/10.4324/9781315682075&#34;&gt;https://doi.org/10.4324/9781315682075&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Espino, O., &amp;amp; Byrne, R. M. J. (2018). Thinking About the Opposite of What Is Said: Counterfactual Conditionals and Symbolic or Alternate Simulations of Negation. &lt;em&gt;Cognitive Science&lt;/em&gt;, &lt;em&gt;42&lt;/em&gt;(8), 2459&amp;ndash;2501. &lt;a href=&#34;https://doi.org/10.1111/cogs.12677&#34;&gt;https://doi.org/10.1111/cogs.12677&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Fabrizio Calzavarini. (2023). Comprensione e cervello. &lt;em&gt;Sistemi intelligenti&lt;/em&gt;, &lt;em&gt;2&lt;/em&gt;, 251&amp;ndash;276. &lt;a href=&#34;https://doi.org/10.1422/107149&#34;&gt;https://doi.org/10.1422/107149&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Fischer, J., &amp;amp; Mahon, B. Z. (2021). What tool representation, intuitive physics, and action have in common: The brain&#39;s first-person physics engine. &lt;em&gt;Cognitive Neuropsychology&lt;/em&gt;, &lt;em&gt;38&lt;/em&gt;(7&amp;ndash;8), 455&amp;ndash;467. &lt;a href=&#34;https://doi.org/10.1080/02643294.2022.2106126&#34;&gt;https://doi.org/10.1080/02643294.2022.2106126&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Galetzka, C. (2017). The Story So Far: How Embodied Cognition Advances Our Understanding of Meaning-Making. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;, 1315. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2017.01315&#34;&gt;https://doi.org/10.3389/fpsyg.2017.01315&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gálvez-García, G., Aldunate, N., Bascour-Sandoval, C., Martínez-Molina, A., Peña, J., &amp;amp; Barramuño, M. (2020). Muscle activation in semantic processing: An electromyography approach. &lt;em&gt;Biological Psychology&lt;/em&gt;, &lt;em&gt;152&lt;/em&gt;, 107881. &lt;a href=&#34;https://doi.org/10.1016/j.biopsycho.2020.107881&#34;&gt;https://doi.org/10.1016/j.biopsycho.2020.107881&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gao, C., Baucom, L. B., Kim, J., Wang, J., Wedell, D. H., &amp;amp; Shinkareva, S. V. (2019). Distinguishing abstract from concrete concepts in supramodal brain regions. &lt;em&gt;Neuropsychologia&lt;/em&gt;, &lt;em&gt;131&lt;/em&gt;, 102&amp;ndash;110. &lt;a href=&#34;https://doi.org/10.1016/j.neuropsychologia.2019.05.032&#34;&gt;https://doi.org/10.1016/j.neuropsychologia.2019.05.032&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gatti, D., Marelli, M., Vecchi, T., &amp;amp; Rinaldi, L. (2022). Spatial Representations Without Spatial Computations. &lt;em&gt;Psychological Science&lt;/em&gt;, &lt;em&gt;33&lt;/em&gt;(11), 1947&amp;ndash;1958. &lt;a href=&#34;https://doi.org/10.1177/09567976221094863&#34;&gt;https://doi.org/10.1177/09567976221094863&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gijssels, T., &amp;amp; Casasanto, D. (2020). Hand-use norms for Dutch and English manual action verbs: Implicit measures from a pantomime task. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;52&lt;/em&gt;(4), 1744&amp;ndash;1767. &lt;a href=&#34;https://doi.org/10.3758/s13428-020-01347-x&#34;&gt;https://doi.org/10.3758/s13428-020-01347-x&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Grand, G., Blank, I. A., Pereira, F., &amp;amp; Fedorenko, E. (2022). Semantic projection recovers rich human knowledge of multiple object features from word embeddings. &lt;em&gt;Nature Human Behaviour&lt;/em&gt;, &lt;em&gt;6&lt;/em&gt;(7), 975&amp;ndash;987. &lt;a href=&#34;https://doi.org/10.1038/s41562-022-01316-8&#34;&gt;https://doi.org/10.1038/s41562-022-01316-8&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Grant, L. D., &amp;amp; Weissman, D. H. (2023). The binary structure of event files generalizes to abstract features: A nonhierarchical explanation of task set boundaries for the congruency sequence effect. &lt;em&gt;Journal of Experimental Psychology: Learning, Memory, and Cognition&lt;/em&gt;, &lt;em&gt;49&lt;/em&gt;(7), 1033&amp;ndash;1050. &lt;a href=&#34;https://doi.org/10.1037/xlm0001148&#34;&gt;https://doi.org/10.1037/xlm0001148&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Greco, A. (2021). Spatial and Motor Aspects in the &amp;ldquo;Action-Sentence Compatibility Effect.&amp;rdquo; &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;, 647899. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2021.647899&#34;&gt;https://doi.org/10.3389/fpsyg.2021.647899&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Guerra, E., &amp;amp; Knoeferle, P. (2018). Semantic Interference and Facilitation: Understanding the Integration of Spatial Distance and Conceptual Similarity During Sentence Reading. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;, 718. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2018.00718&#34;&gt;https://doi.org/10.3389/fpsyg.2018.00718&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Günther, F., Petilli, M. A., Vergallito, A., &amp;amp; Marelli, M. (2022). Images of the unseen: Extrapolating visual representations for abstract and concrete words in a data-driven computational model. &lt;em&gt;Psychological Research&lt;/em&gt;, &lt;em&gt;86&lt;/em&gt;(8), 2512&amp;ndash;2532. &lt;a href=&#34;https://doi.org/10.1007/s00426-020-01429-7&#34;&gt;https://doi.org/10.1007/s00426-020-01429-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Günther, F., Rinaldi, L., &amp;amp; Marelli, M. (2019). Vector-Space Models of Semantic Representation From a Cognitive Perspective: A Discussion of Common Misconceptions. &lt;em&gt;Perspectives on Psychological Science&lt;/em&gt;, &lt;em&gt;14&lt;/em&gt;(6), 1006&amp;ndash;1033. &lt;a href=&#34;https://doi.org/10.1177/1745691619861372&#34;&gt;https://doi.org/10.1177/1745691619861372&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hafri, A., Trueswell, J. C., &amp;amp; Strickland, B. (2018). Encoding of event roles from visual scenes is rapid, spontaneous, and interacts with higher-level visual processing. &lt;em&gt;Cognition&lt;/em&gt;, &lt;em&gt;175&lt;/em&gt;, 36&amp;ndash;52. &lt;a href=&#34;https://doi.org/10.1016/j.cognition.2018.02.011&#34;&gt;https://doi.org/10.1016/j.cognition.2018.02.011&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hardy, B. W. (2021). Embodied Cognition in Communication Science. &lt;em&gt;Communication Theory&lt;/em&gt;, &lt;em&gt;31&lt;/em&gt;(4), 633&amp;ndash;653. &lt;a href=&#34;https://doi.org/10.1093/ct/qtaa003&#34;&gt;https://doi.org/10.1093/ct/qtaa003&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Harpaintner, M., Sim, E.-J., Trumpp, N. M., Ulrich, M., &amp;amp; Kiefer, M. (2020). The grounding of abstract concepts in the motor and visual system: An fMRI study. &lt;em&gt;Cortex&lt;/em&gt;, &lt;em&gt;124&lt;/em&gt;, 1&amp;ndash;22. &lt;a href=&#34;https://doi.org/10.1016/j.cortex.2019.10.014&#34;&gt;https://doi.org/10.1016/j.cortex.2019.10.014&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Harpaintner, M., Trumpp, N. M., &amp;amp; Kiefer, M. (2018). The Semantic Content of Abstract Concepts: A Property Listing Study of 296 Abstract Words. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;, 1748. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2018.01748&#34;&gt;https://doi.org/10.3389/fpsyg.2018.01748&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Harpaintner, M., Trumpp, N. M., &amp;amp; Kiefer, M. (2022). Time course of brain activity during the processing of motor- and vision-related abstract concepts: Flexibility and task dependency. &lt;em&gt;Psychological Research&lt;/em&gt;, &lt;em&gt;86&lt;/em&gt;(8), 2560&amp;ndash;2582. &lt;a href=&#34;https://doi.org/10.1007/s00426-020-01374-5&#34;&gt;https://doi.org/10.1007/s00426-020-01374-5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hartman, J., &amp;amp; Paradis, C. (2023). The language of sound: Events and meaning multitasking of words. &lt;em&gt;Cognitive Linguistics&lt;/em&gt;, &lt;em&gt;34&lt;/em&gt;(3&amp;ndash;4), 445&amp;ndash;477. &lt;a href=&#34;https://doi.org/10.1515/cog-2022-0006&#34;&gt;https://doi.org/10.1515/cog-2022-0006&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hauk, O., Giraud, A.-L., &amp;amp; Clarke, A. (2017). Brain oscillations in language comprehension. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;32&lt;/em&gt;(5), 533&amp;ndash;535. &lt;a href=&#34;https://doi.org/10.1080/23273798.2017.1297842&#34;&gt;https://doi.org/10.1080/23273798.2017.1297842&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hauk, O., Jackson, R. L., &amp;amp; Rahimi, S. (2023). Transforming the neuroscience of language: Estimating pattern-to-pattern transformations of brain activity. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, 1&amp;ndash;16. &lt;a href=&#34;https://doi.org/10.1080/23273798.2023.2226268&#34;&gt;https://doi.org/10.1080/23273798.2023.2226268&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hauk, O., Magnabosco, F., &amp;amp; Law, R. (2023). Can we separate semantic representations from computations? A commentary on Calzavarini (2023). &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, 1&amp;ndash;4. &lt;a href=&#34;https://doi.org/10.1080/23273798.2023.2226269&#34;&gt;https://doi.org/10.1080/23273798.2023.2226269&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Heim, E. M. (2017a). &lt;em&gt;Adoption in Galatians and Romans: Contemporary Metaphor Theories and the Pauline Huiothesia Metaphors&lt;/em&gt;. BRILL. &lt;a href=&#34;https://doi.org/10.1163/9789004339873&#34;&gt;https://doi.org/10.1163/9789004339873&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Heim, E. M. (2017b). &lt;em&gt;Adoption in Galatians and Romans: Contemporary Metaphor Theories and the Pauline Huiothesia Metaphors&lt;/em&gt;. BRILL. &lt;a href=&#34;https://doi.org/10.1163/9789004339873&#34;&gt;https://doi.org/10.1163/9789004339873&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hoeben Mannaert, L. N., Dijkstra, K., &amp;amp; Zwaan, R. A. (2020). Object combination in mental simulations. &lt;em&gt;Quarterly Journal of Experimental Psychology&lt;/em&gt;, &lt;em&gt;73&lt;/em&gt;(11), 1796&amp;ndash;1806. &lt;a href=&#34;https://doi.org/10.1177/1747021820933214&#34;&gt;https://doi.org/10.1177/1747021820933214&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hoffman, P., McClelland, J. L., &amp;amp; Lambon Ralph, M. A. (2018). Concepts, control, and context: A connectionist account of normal and disordered semantic cognition. &lt;em&gt;Psychological Review&lt;/em&gt;, &lt;em&gt;125&lt;/em&gt;(3), 293&amp;ndash;328. &lt;a href=&#34;https://doi.org/10.1037/rev0000094&#34;&gt;https://doi.org/10.1037/rev0000094&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hohol, M. (2019). &lt;em&gt;Foundations of Geometric Cognition&lt;/em&gt; (1st ed.). Routledge. &lt;a href=&#34;https://doi.org/10.4324/9780429056291&#34;&gt;https://doi.org/10.4324/9780429056291&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Holman, A., &amp;amp; Gîrbă, A. (2019). The match in orientation between verbal context and object accelerates change detection. &lt;em&gt;Psihologija&lt;/em&gt;, &lt;em&gt;52&lt;/em&gt;(1), 93&amp;ndash;105. &lt;a href=&#34;https://doi.org/10.2298/PSI180412033H&#34;&gt;https://doi.org/10.2298/PSI180412033H&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hörberg, T., Larsson, M., &amp;amp; Olofsson, J. K. (2022). The Semantic Organization of the English Odor Vocabulary. &lt;em&gt;Cognitive Science&lt;/em&gt;, &lt;em&gt;46&lt;/em&gt;(11), e13205. &lt;a href=&#34;https://doi.org/10.1111/cogs.13205&#34;&gt;https://doi.org/10.1111/cogs.13205&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Huang, C.-R., &amp;amp; Xiong, J. (2019). Linguistic synaesthesia in Chinese. In C.-R. Huang, Z. Jing-Schmidt, &amp;amp; B. Meisterernst (Eds.), &lt;em&gt;The Routledge Handbook of Chinese Applied Linguistics&lt;/em&gt; (1st ed., pp. 294&amp;ndash;312). Routledge. &lt;a href=&#34;https://doi.org/10.4324/9781315625157-20&#34;&gt;https://doi.org/10.4324/9781315625157-20&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Iatropoulos, G., Herman, P., Lansner, A., Karlgren, J., Larsson, M., &amp;amp; Olofsson, J. K. (2018). The language of smell: Connecting linguistic and psychophysical properties of odor descriptors. &lt;em&gt;Cognition&lt;/em&gt;, &lt;em&gt;178&lt;/em&gt;, 37&amp;ndash;49. &lt;a href=&#34;https://doi.org/10.1016/j.cognition.2018.05.007&#34;&gt;https://doi.org/10.1016/j.cognition.2018.05.007&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Iriguchi, M., Fujimura, R., Koda, H., &amp;amp; Masataka, N. (2019). Traffic symbol recognition modulates bodily actions. &lt;em&gt;PLOS ONE&lt;/em&gt;, &lt;em&gt;14&lt;/em&gt;(3), e0214281. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0214281&#34;&gt;https://doi.org/10.1371/journal.pone.0214281&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Jo, C. (2022). Linguistic Synesthesia in Korean: Universality and Variation. &lt;em&gt;SAGE Open&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(3), 215824402211178. &lt;a href=&#34;https://doi.org/10.1177/21582440221117804&#34;&gt;https://doi.org/10.1177/21582440221117804&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Johns, B. T. (2022). Accounting for item-level variance in recognition memory: Comparing word frequency and contextual diversity. &lt;em&gt;Memory &amp;amp; Cognition&lt;/em&gt;, &lt;em&gt;50&lt;/em&gt;(5), 1013&amp;ndash;1032. &lt;a href=&#34;https://doi.org/10.3758/s13421-021-01249-z&#34;&gt;https://doi.org/10.3758/s13421-021-01249-z&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Jones, L. L., Wurm, L. H., Calcaterra, R. D., &amp;amp; Ofen, N. (2017). Integrative Priming of Compositional and Locative Relations. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2017.00359&#34;&gt;https://doi.org/10.3389/fpsyg.2017.00359&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Julich-Warpakowski, N., &amp;amp; Pérez Sobrino, P. (2023). Introduction: Current challenges in metaphor research. &lt;em&gt;Metaphor and the Social World&lt;/em&gt;, &lt;em&gt;13&lt;/em&gt;(1), 1&amp;ndash;15. &lt;a href=&#34;https://doi.org/10.1075/msw.00026.jul&#34;&gt;https://doi.org/10.1075/msw.00026.jul&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kabbach, A., &amp;amp; Herbelot, A. (2021). Avoiding Conflict: When Speaker Coordination Does Not Require Conceptual Agreement. &lt;em&gt;Frontiers in Artificial Intelligence&lt;/em&gt;, &lt;em&gt;3&lt;/em&gt;, 523920. &lt;a href=&#34;https://doi.org/10.3389/frai.2020.523920&#34;&gt;https://doi.org/10.3389/frai.2020.523920&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kaiser, E. (2021). Consequences of Sensory Modality for Perspective-Taking: Comparing Visual, Olfactory and Gustatory Perception. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;, 701486. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2021.701486&#34;&gt;https://doi.org/10.3389/fpsyg.2021.701486&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kaup, B., Ulrich, R., Bausenhart, K. M., Bryce, D., Butz, M. V., Dignath, D., Dudschig, C., Franz, V. H., Friedrich, C., Gawrilow, C., Heller, J., Huff, M., Hütter, M., Janczyk, M., Leuthold, H., Mallot, H., Nürk, H.-C., Ramscar, M., Said, N., &amp;hellip; Wong, H. Y. (2023). Modal and amodal cognition: An overarching principle in various domains of psychology. &lt;em&gt;Psychological Research&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.1007/s00426-023-01878-w&#34;&gt;https://doi.org/10.1007/s00426-023-01878-w&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Keogh, R., &amp;amp; Pearson, J. (2017). The perceptual and phenomenal capacity of mental imagery. &lt;em&gt;Cognition&lt;/em&gt;, &lt;em&gt;162&lt;/em&gt;, 124&amp;ndash;132. &lt;a href=&#34;https://doi.org/10.1016/j.cognition.2017.02.004&#34;&gt;https://doi.org/10.1016/j.cognition.2017.02.004&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kernot, D., Bossomaier, T., &amp;amp; Bradbury, R. (2017). Novel Text Analysis for Investigating Personality: Identifying the Dark Lady in Shakespeare&#39;s Sonnets. &lt;em&gt;Journal of Quantitative Linguistics&lt;/em&gt;, &lt;em&gt;24&lt;/em&gt;(4), 255&amp;ndash;272. &lt;a href=&#34;https://doi.org/10.1080/09296174.2017.1304049&#34;&gt;https://doi.org/10.1080/09296174.2017.1304049&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kernot, D., Bossomaier, T., &amp;amp; Bradbury, R. (2018). Using Shakespeare&#39;s Sotto Voce to Determine True Identity From Text. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;, 289. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2018.00289&#34;&gt;https://doi.org/10.3389/fpsyg.2018.00289&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kernot, D., Bossomaier, T., &amp;amp; Bradbury, R. (2019). The Stylometric Impacts of Ageing and Life Events on Identity. &lt;em&gt;Journal of Quantitative Linguistics&lt;/em&gt;, &lt;em&gt;26&lt;/em&gt;(1), 1&amp;ndash;21. &lt;a href=&#34;https://doi.org/10.1080/09296174.2017.1405719&#34;&gt;https://doi.org/10.1080/09296174.2017.1405719&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Keus, K., &amp;amp; Harde, R. (2022). &amp;ldquo;She Wished Someone Would Help Them&amp;rdquo;: PTSD and Empathy in the Six of Crows Duology. &lt;em&gt;Children&#39;s Literature in Education&lt;/em&gt;, &lt;em&gt;53&lt;/em&gt;(1), 130&amp;ndash;146. &lt;a href=&#34;https://doi.org/10.1007/s10583-021-09441-0&#34;&gt;https://doi.org/10.1007/s10583-021-09441-0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Khatin-Zadeh, O., Hu, J., Banaruee, H., &amp;amp; Marmolejo-Ramos, F. (2023). How emotions are metaphorically embodied: Measuring hand and head action strengths of typical emotional states. &lt;em&gt;Cognition and Emotion&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(3), 486&amp;ndash;498. &lt;a href=&#34;https://doi.org/10.1080/02699931.2023.2181314&#34;&gt;https://doi.org/10.1080/02699931.2023.2181314&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kim, M.-K., Müller, H. M., &amp;amp; Weiss, S. (2021). What you &amp;ldquo;mean&amp;rdquo; is not what I &amp;ldquo;mean&amp;rdquo;: Categorization of verbs by Germans and Koreans using the semantic differential. &lt;em&gt;Lingua&lt;/em&gt;, &lt;em&gt;252&lt;/em&gt;, 103012. &lt;a href=&#34;https://doi.org/10.1016/j.lingua.2020.103012&#34;&gt;https://doi.org/10.1016/j.lingua.2020.103012&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Klomberg, B., Schilhab, T., &amp;amp; Burke, M. (2022). &lt;em&gt;Picturing Fiction through Embodied Cognition: Drawn Representations and Viewpoint in Literary Texts&lt;/em&gt; (1st ed.). Routledge. &lt;a href=&#34;https://doi.org/10.4324/9781003225300&#34;&gt;https://doi.org/10.4324/9781003225300&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Knoeferle, P. (2019). Predicting (variability of) context effects in language comprehension. &lt;em&gt;Journal of Cultural Cognitive Science&lt;/em&gt;, &lt;em&gt;3&lt;/em&gt;(2), 141&amp;ndash;158. &lt;a href=&#34;https://doi.org/10.1007/s41809-019-00025-5&#34;&gt;https://doi.org/10.1007/s41809-019-00025-5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Koblet, O., &amp;amp; Purves, R. S. (2020). From online texts to Landscape Character Assessment: Collecting and analysing first-person landscape perception computationally. &lt;em&gt;Landscape and Urban Planning&lt;/em&gt;, &lt;em&gt;197&lt;/em&gt;, 103757. &lt;a href=&#34;https://doi.org/10.1016/j.landurbplan.2020.103757&#34;&gt;https://doi.org/10.1016/j.landurbplan.2020.103757&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kompa, N. A. (2021). Language and embodiment&amp;mdash;Or the cognitive benefits of abstract representations. &lt;em&gt;Mind &amp;amp; Language&lt;/em&gt;, &lt;em&gt;36&lt;/em&gt;(1), 27&amp;ndash;47. &lt;a href=&#34;https://doi.org/10.1111/mila.12266&#34;&gt;https://doi.org/10.1111/mila.12266&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kompa, N. A., &amp;amp; Mueller, J. L. (2022). Inner speech as a cognitive tool&amp;mdash;Or what is the point of talking to oneself? &lt;em&gt;Philosophical Psychology&lt;/em&gt;, 1&amp;ndash;24. &lt;a href=&#34;https://doi.org/10.1080/09515089.2022.2112164&#34;&gt;https://doi.org/10.1080/09515089.2022.2112164&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Körner, A., Castillo, M., Drijvers, L., Fischer, M. H., Günther, F., Marelli, M., Platonova, O., Rinaldi, L., Shaki, S., Trujillo, J. P., Tsaregorodtseva, O., &amp;amp; Glenberg, A. M. (2023). Embodied Processing at Six Linguistic Granularity Levels: A Consensus Paper. &lt;em&gt;Journal of Cognition&lt;/em&gt;, &lt;em&gt;6&lt;/em&gt;(1), 60. &lt;a href=&#34;https://doi.org/10.5334/joc.231&#34;&gt;https://doi.org/10.5334/joc.231&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Krishna, P. P., Arulmozi, S., &amp;amp; Mishra, R. K. (2022). &amp;ldquo;Do You See and Hear More? A Study on Telugu Perception Verbs.&amp;rdquo; &lt;em&gt;Journal of Psycholinguistic Research&lt;/em&gt;, &lt;em&gt;51&lt;/em&gt;(3), 473&amp;ndash;484. &lt;a href=&#34;https://doi.org/10.1007/s10936-021-09827-7&#34;&gt;https://doi.org/10.1007/s10936-021-09827-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kuhnke, P., Beaupain, M. C., Arola, J., Kiefer, M., &amp;amp; Hartwigsen, G. (2023). Meta-analytic evidence for a novel hierarchical model of conceptual processing. &lt;em&gt;Neuroscience &amp;amp; Biobehavioral Reviews&lt;/em&gt;, &lt;em&gt;144&lt;/em&gt;, 104994. &lt;a href=&#34;https://doi.org/10.1016/j.neubiorev.2022.104994&#34;&gt;https://doi.org/10.1016/j.neubiorev.2022.104994&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kuhnke, P., Kiefer, M., &amp;amp; Hartwigsen, G. (2021). Task-Dependent Functional and Effective Connectivity during Conceptual Processing. &lt;em&gt;Cerebral Cortex&lt;/em&gt;, &lt;em&gt;31&lt;/em&gt;(7), 3475&amp;ndash;3493. &lt;a href=&#34;https://doi.org/10.1093/cercor/bhab026&#34;&gt;https://doi.org/10.1093/cercor/bhab026&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kumcu, A. (2021). Linguistic Synesthesia in Turkish: A Corpus-based Study of Crossmodal Directionality. &lt;em&gt;Metaphor and Symbol&lt;/em&gt;, &lt;em&gt;36&lt;/em&gt;(4), 241&amp;ndash;255. &lt;a href=&#34;https://doi.org/10.1080/10926488.2021.1921557&#34;&gt;https://doi.org/10.1080/10926488.2021.1921557&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lai, V. T., Hubbard, R., Ku, L.-C., &amp;amp; Pfeifer, V. (2023). Electrophysiology of Non-Literal Language. In M. Grimaldi, E. Brattico, &amp;amp; Y. Shtyrov (Eds.), &lt;em&gt;Language Electrified&lt;/em&gt; (Vol. 202, pp. 613&amp;ndash;646). Springer US. &lt;a href=&#34;https://doi.org/10.1007/978-1-0716-3263-5_19&#34;&gt;https://doi.org/10.1007/978-1-0716-3263-5_19&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Landrigan, J.-F., &amp;amp; Mirman, D. (2018). The cost of switching between taxonomic and thematic semantics. &lt;em&gt;Memory &amp;amp; Cognition&lt;/em&gt;, &lt;em&gt;46&lt;/em&gt;(2), 191&amp;ndash;203. &lt;a href=&#34;https://doi.org/10.3758/s13421-017-0757-5&#34;&gt;https://doi.org/10.3758/s13421-017-0757-5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Large, A.-C., Bach, C., &amp;amp; Calvet, G. (2018). CONTACT: A Human Centered Approach of Multimodal Flight Deck Design and Evaluation. In D. Harris (Ed.), &lt;em&gt;Engineering Psychology and Cognitive Ergonomics&lt;/em&gt; (Vol. 10906, pp. 593&amp;ndash;604). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-319-91122-9_48&#34;&gt;https://doi.org/10.1007/978-3-319-91122-9_48&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lee, J., &amp;amp; Shin, J.-A. (2023). The cross-linguistic comparison of perceptual strength norms for Korean, English and L2 English. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;14&lt;/em&gt;, 1188909. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2023.1188909&#34;&gt;https://doi.org/10.3389/fpsyg.2023.1188909&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Li, M., Lu, Q., Long, Y., &amp;amp; Gui, L. (2017). Inferring Affective Meanings of Words from Word Embedding. &lt;em&gt;IEEE Transactions on Affective Computing&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;(4), 443&amp;ndash;456. &lt;a href=&#34;https://doi.org/10.1109/TAFFC.2017.2723012&#34;&gt;https://doi.org/10.1109/TAFFC.2017.2723012&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lin, K., &amp;amp; Chan, S. (2019). When senses meet functions: An amodal stage in conceptual processing. &lt;em&gt;Journal of Cognitive Psychology&lt;/em&gt;, &lt;em&gt;31&lt;/em&gt;(1), 64&amp;ndash;75. &lt;a href=&#34;https://doi.org/10.1080/20445911.2018.1560299&#34;&gt;https://doi.org/10.1080/20445911.2018.1560299&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Littlemore, J. (2019). &lt;em&gt;Metaphors in the Mind: Sources of Variation in Embodied Metaphor&lt;/em&gt; (1st ed.). Cambridge University Press. &lt;a href=&#34;https://doi.org/10.1017/9781108241441&#34;&gt;https://doi.org/10.1017/9781108241441&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Liu, S., Zhou, M., &amp;amp; Li, Y. (2019). Internet use experience influence individuals&amp;rsquo; lexical decision performance by changing their body representation. &lt;em&gt;Computers in Human Behavior&lt;/em&gt;, &lt;em&gt;91&lt;/em&gt;, 157&amp;ndash;166. &lt;a href=&#34;https://doi.org/10.1016/j.chb.2018.09.021&#34;&gt;https://doi.org/10.1016/j.chb.2018.09.021&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Liu, W., Bansal, D., Daruna, A., &amp;amp; Chernova, S. (2023). Learning instance-level N-ary semantic knowledge at scale for robots operating in everyday environments. &lt;em&gt;Autonomous Robots&lt;/em&gt;, &lt;em&gt;47&lt;/em&gt;(5), 529&amp;ndash;547. &lt;a href=&#34;https://doi.org/10.1007/s10514-023-10099-4&#34;&gt;https://doi.org/10.1007/s10514-023-10099-4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Liu, W., Bansal, D., Daruna, A., &amp;amp; Chernova, S. (2021, July 12). Learning Instance-Level N-Ary Semantic Knowledge At Scale For Robots Operating in Everyday Environments. &lt;em&gt;Robotics: Science and Systems XVII&lt;/em&gt;. Robotics: Science and Systems 2021. &lt;a href=&#34;https://doi.org/10.15607/RSS.2021.XVII.035&#34;&gt;https://doi.org/10.15607/RSS.2021.XVII.035&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Long, Y., Xiang, R., Lu, Q., Huang, C.-R., &amp;amp; Li, M. (2021). Improving Attention Model Based on Cognition Grounded Data for Sentiment Analysis. &lt;em&gt;IEEE Transactions on Affective Computing&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(4), 900&amp;ndash;912. &lt;a href=&#34;https://doi.org/10.1109/TAFFC.2019.2903056&#34;&gt;https://doi.org/10.1109/TAFFC.2019.2903056&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Louwerse, M. M. (2018). Knowing the Meaning of a Word by the Linguistic and Perceptual Company It Keeps. &lt;em&gt;Topics in Cognitive Science&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(3), 573&amp;ndash;589. &lt;a href=&#34;https://doi.org/10.1111/tops.12349&#34;&gt;https://doi.org/10.1111/tops.12349&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lupyan, G., &amp;amp; Winter, B. (2018). Language is more abstract than you think, or, why aren&#39;t languages more iconic? &lt;em&gt;Philosophical Transactions of the Royal Society B: Biological Sciences&lt;/em&gt;, &lt;em&gt;373&lt;/em&gt;(1752), 20170137. &lt;a href=&#34;https://doi.org/10.1098/rstb.2017.0137&#34;&gt;https://doi.org/10.1098/rstb.2017.0137&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lynott, D., Connell, L., Brysbaert, M., Brand, J., &amp;amp; Carney, J. (2020). The Lancaster Sensorimotor Norms: Multidimensional measures of perceptual and action strength for 40,000 English words. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;52&lt;/em&gt;(3), 1271&amp;ndash;1291. &lt;a href=&#34;https://doi.org/10.3758/s13428-019-01316-z&#34;&gt;https://doi.org/10.3758/s13428-019-01316-z&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lynott, D., Walsh, M., McEnery, T., Connell, L., Cross, L., &amp;amp; O&#39;Brien, K. (2019). Are You What You Read? Predicting Implicit Attitudes to Immigration Based on Linguistic Distributional Cues From Newspaper Readership; A Pre-registered Study. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;, 842. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2019.00842&#34;&gt;https://doi.org/10.3389/fpsyg.2019.00842&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Malhi, S. K., &amp;amp; Buchanan, L. (2018). A test of the symbol interdependency hypothesis with both concrete and abstract stimuli. &lt;em&gt;PLOS ONE&lt;/em&gt;, &lt;em&gt;13&lt;/em&gt;(3), e0192719. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0192719&#34;&gt;https://doi.org/10.1371/journal.pone.0192719&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Mangels, J. A., Rodriguez, S., Ochakovskaya, Y., &amp;amp; Guerra-Carrillo, B. (2017). Achievement Goal Task Framing and Fit With Personal Goals Modulate the Neurocognitive Response to Corrective Feedback. &lt;em&gt;AERA Open&lt;/em&gt;, &lt;em&gt;3&lt;/em&gt;(3), 233285841772087. &lt;a href=&#34;https://doi.org/10.1177/2332858417720875&#34;&gt;https://doi.org/10.1177/2332858417720875&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Marchetti, R., Vaugoyeau, M., Colé, P., &amp;amp; Assaiante, C. (2022). A sensorimotor representation impairment in dyslexic adults: A specific profile of comorbidity. &lt;em&gt;Neuropsychologia&lt;/em&gt;, &lt;em&gt;165&lt;/em&gt;, 108134. &lt;a href=&#34;https://doi.org/10.1016/j.neuropsychologia.2021.108134&#34;&gt;https://doi.org/10.1016/j.neuropsychologia.2021.108134&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Marmeleira, J., &amp;amp; Duarte Santos, G. (2019). Do Not Neglect the Body and Action: The Emergence of Embodiment Approaches to Understanding Human Development. &lt;em&gt;Perceptual and Motor Skills&lt;/em&gt;, &lt;em&gt;126&lt;/em&gt;(3), 410&amp;ndash;445. &lt;a href=&#34;https://doi.org/10.1177/0031512519834389&#34;&gt;https://doi.org/10.1177/0031512519834389&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Marson, F., Paoletti, P., Naor-Ziv, R., Carducci, F., &amp;amp; Ben-Soussan, T. D. (2023). Embodied empathy and abstract concepts&amp;rsquo; concreteness: Evidence from contemplative practices. In &lt;em&gt;Progress in Brain Research&lt;/em&gt; (Vol. 277, pp. 181&amp;ndash;209). Elsevier. &lt;a href=&#34;https://doi.org/10.1016/bs.pbr.2022.12.005&#34;&gt;https://doi.org/10.1016/bs.pbr.2022.12.005&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Márton, Z. C., Türker, S., Rink, C., Brucker, M., Kriegel, S., Bodenmüller, T., &amp;amp; Riedel, S. (2018). Improving object orientation estimates by considering multiple viewpoints: Orientation histograms of symmetries and measurement models for view selection. &lt;em&gt;Autonomous Robots&lt;/em&gt;, &lt;em&gt;42&lt;/em&gt;(2), 423&amp;ndash;442. &lt;a href=&#34;https://doi.org/10.1007/s10514-017-9633-1&#34;&gt;https://doi.org/10.1007/s10514-017-9633-1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;McRae, K., Nedjadrasul, D., Pau, R., Lo, B. P., &amp;amp; King, L. (2018). Abstract Concepts and Pictures of Real‐World Situations Activate One Another. &lt;em&gt;Topics in Cognitive Science&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(3), 518&amp;ndash;532. &lt;a href=&#34;https://doi.org/10.1111/tops.12328&#34;&gt;https://doi.org/10.1111/tops.12328&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Meng, X., Sun, C., Du, B., Liu, L., Zhang, Y., Dong, Q., Georgiou, G. K., &amp;amp; Nan, Y. (2022). The development of brain rhythms at rest and its impact on vocabulary acquisition. &lt;em&gt;Developmental Science&lt;/em&gt;, &lt;em&gt;25&lt;/em&gt;(2), e13157. &lt;a href=&#34;https://doi.org/10.1111/desc.13157&#34;&gt;https://doi.org/10.1111/desc.13157&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Miceli, A., Wauthia, E., Kandana Arachchige, K., Lefebvre, L., Ris, L., &amp;amp; Simoes Loureiro, I. (2023). Perceptual strength influences lexical decision in Alzheimer&#39;s disease. &lt;em&gt;Journal of Neurolinguistics&lt;/em&gt;, &lt;em&gt;68&lt;/em&gt;, 101144. &lt;a href=&#34;https://doi.org/10.1016/j.jneuroling.2023.101144&#34;&gt;https://doi.org/10.1016/j.jneuroling.2023.101144&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Miceli, A., Wauthia, E., Lefebvre, L., Ris, L., &amp;amp; Simoes Loureiro, I. (2021). Perceptual and Interoceptive Strength Norms for 270 French Words. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;, 667271. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2021.667271&#34;&gt;https://doi.org/10.3389/fpsyg.2021.667271&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Miceli, A., Wauthia, E., Lefebvre, L., Vallet, G. T., Ris, L., &amp;amp; Loureiro, I. S. (2022). Differences related to aging in sensorimotor knowledge: Investigation of perceptual strength and body object interaction. &lt;em&gt;Archives of Gerontology and Geriatrics&lt;/em&gt;, &lt;em&gt;102&lt;/em&gt;, 104715. &lt;a href=&#34;https://doi.org/10.1016/j.archger.2022.104715&#34;&gt;https://doi.org/10.1016/j.archger.2022.104715&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Miklashevsky, A. (2018). Perceptual Experience Norms for 506 Russian Nouns: Modality Rating, Spatial Localization, Manipulability, Imageability and Other Variables. &lt;em&gt;Journal of Psycholinguistic Research&lt;/em&gt;, &lt;em&gt;47&lt;/em&gt;(3), 641&amp;ndash;661. &lt;a href=&#34;https://doi.org/10.1007/s10936-017-9548-1&#34;&gt;https://doi.org/10.1007/s10936-017-9548-1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Miller, J., Brookie, K., Wales, S., Wallace, S., &amp;amp; Kaup, B. (2018). Embodied cognition: Is activation of the motor cortex essential for understanding action verbs? &lt;em&gt;Journal of Experimental Psychology: Learning, Memory, and Cognition&lt;/em&gt;, &lt;em&gt;44&lt;/em&gt;(3), 335&amp;ndash;370. &lt;a href=&#34;https://doi.org/10.1037/xlm0000451&#34;&gt;https://doi.org/10.1037/xlm0000451&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Minervino, R. A., Martín, A., Tavernini, L. M., &amp;amp; Trench, M. (2018). The Understanding of Visual Metaphors by the Congenitally Blind. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;, 1242. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2018.01242&#34;&gt;https://doi.org/10.3389/fpsyg.2018.01242&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Moretti, S., &amp;amp; Greco, A. (2018). Truth is in the head. A nod and shake compatibility effect. &lt;em&gt;Acta Psychologica&lt;/em&gt;, &lt;em&gt;185&lt;/em&gt;, 203&amp;ndash;218. &lt;a href=&#34;https://doi.org/10.1016/j.actpsy.2018.02.010&#34;&gt;https://doi.org/10.1016/j.actpsy.2018.02.010&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Moretti, S., &amp;amp; Greco, A. (2020). Nodding and shaking of the head as simulated approach and avoidance responses. &lt;em&gt;Acta Psychologica&lt;/em&gt;, &lt;em&gt;203&lt;/em&gt;, 102988. &lt;a href=&#34;https://doi.org/10.1016/j.actpsy.2019.102988&#34;&gt;https://doi.org/10.1016/j.actpsy.2019.102988&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Morucci, P., Bottini, R., &amp;amp; Crepaldi, D. (2019). Augmented Modality Exclusivity Norms for Concrete and Abstract Italian Property Words. &lt;em&gt;Journal of Cognition&lt;/em&gt;, &lt;em&gt;2&lt;/em&gt;(1), 42. &lt;a href=&#34;https://doi.org/10.5334/joc.88&#34;&gt;https://doi.org/10.5334/joc.88&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Mueller, C. J., White, C. N., &amp;amp; Kuchinke, L. (2017). Electrophysiological correlates of the drift diffusion model in visual word recognition. &lt;em&gt;Human Brain Mapping&lt;/em&gt;, &lt;em&gt;38&lt;/em&gt;(11), 5616&amp;ndash;5627. &lt;a href=&#34;https://doi.org/10.1002/hbm.23753&#34;&gt;https://doi.org/10.1002/hbm.23753&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Muraki, E. J., Doyle, A., Protzner, A. B., &amp;amp; Pexman, P. M. (2023). Context matters: How do task demands modulate the recruitment of sensorimotor information during language processing? &lt;em&gt;Frontiers in Human Neuroscience&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;, 976954. &lt;a href=&#34;https://doi.org/10.3389/fnhum.2022.976954&#34;&gt;https://doi.org/10.3389/fnhum.2022.976954&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Muraki, E. J., Speed, L. J., &amp;amp; Pexman, P. M. (2023). Insights into embodied cognition and mental imagery from aphantasia. &lt;em&gt;Nature Reviews Psychology&lt;/em&gt;, &lt;em&gt;2&lt;/em&gt;(10), 591&amp;ndash;605. &lt;a href=&#34;https://doi.org/10.1038/s44159-023-00221-9&#34;&gt;https://doi.org/10.1038/s44159-023-00221-9&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Okuno, H. Y., &amp;amp; Guedes, G. (2020). Automatic XML creation for Multisensorial Books. &lt;em&gt;2020 XV Conferencia Latinoamericana de Tecnologias de Aprendizaje (LACLO)&lt;/em&gt;, 1&amp;ndash;6. &lt;a href=&#34;https://doi.org/10.1109/LACLO50806.2020.9381139&#34;&gt;https://doi.org/10.1109/LACLO50806.2020.9381139&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ostarek, M., &amp;amp; Vigliocco, G. (2017). Reading sky and seeing a cloud: On the relevance of events for perceptual simulation. &lt;em&gt;Journal of Experimental Psychology: Learning, Memory, and Cognition&lt;/em&gt;, &lt;em&gt;43&lt;/em&gt;(4), 579&amp;ndash;590. &lt;a href=&#34;https://doi.org/10.1037/xlm0000318&#34;&gt;https://doi.org/10.1037/xlm0000318&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pecher, D. (2018). Curb Your Embodiment. &lt;em&gt;Topics in Cognitive Science&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(3), 501&amp;ndash;517. &lt;a href=&#34;https://doi.org/10.1111/tops.12311&#34;&gt;https://doi.org/10.1111/tops.12311&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pérez-Gay Juárez, F., Labrecque, D., &amp;amp; Frak, V. (2019). Assessing language-induced motor activity through Event Related Potentials and the Grip Force Sensor, an exploratory study. &lt;em&gt;Brain and Cognition&lt;/em&gt;, &lt;em&gt;135&lt;/em&gt;, 103572. &lt;a href=&#34;https://doi.org/10.1016/j.bandc.2019.05.010&#34;&gt;https://doi.org/10.1016/j.bandc.2019.05.010&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pérez-Sánchez, M. Á., Stadthagen-Gonzalez, H., Guasch, M., Hinojosa, J. A., Fraga, I., Marín, J., &amp;amp; Ferré, P. (2021). EmoPro &amp;ndash; Emotional prototypicality for 1286 Spanish words: Relationships with affective and psycholinguistic variables. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;53&lt;/em&gt;(5), 1857&amp;ndash;1875. &lt;a href=&#34;https://doi.org/10.3758/s13428-020-01519-9&#34;&gt;https://doi.org/10.3758/s13428-020-01519-9&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Perfecto, H., Galak, J., Simmons, J. P., &amp;amp; Nelson, L. D. (2017). Rejecting a bad option feels like choosing a good one. &lt;em&gt;Journal of Personality and Social Psychology&lt;/em&gt;, &lt;em&gt;113&lt;/em&gt;(5), 659&amp;ndash;670. &lt;a href=&#34;https://doi.org/10.1037/pspa0000092&#34;&gt;https://doi.org/10.1037/pspa0000092&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Perlman, M., Little, H., Thompson, B., &amp;amp; Thompson, R. L. (2018). Iconicity in Signed and Spoken Vocabulary: A Comparison Between American Sign Language, British Sign Language, English, and Spanish. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;, 1433. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2018.01433&#34;&gt;https://doi.org/10.3389/fpsyg.2018.01433&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pexman, P. M. (2019). The role of embodiment in conceptual development. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;34&lt;/em&gt;(10), 1274&amp;ndash;1283. &lt;a href=&#34;https://doi.org/10.1080/23273798.2017.1303522&#34;&gt;https://doi.org/10.1080/23273798.2017.1303522&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pexman, P. M., Muraki, E., Sidhu, D. M., Siakaluk, P. D., &amp;amp; Yap, M. J. (2019). Quantifying sensorimotor experience: Body&amp;ndash;object interaction ratings for more than 9,000 English words. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;51&lt;/em&gt;(2), 453&amp;ndash;466. &lt;a href=&#34;https://doi.org/10.3758/s13428-018-1171-z&#34;&gt;https://doi.org/10.3758/s13428-018-1171-z&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Piai, V., &amp;amp; Zheng, X. (2019). Speaking waves: Neuronal oscillations in language production. In &lt;em&gt;Psychology of Learning and Motivation&lt;/em&gt; (Vol. 71, pp. 265&amp;ndash;302). Elsevier. &lt;a href=&#34;https://doi.org/10.1016/bs.plm.2019.07.002&#34;&gt;https://doi.org/10.1016/bs.plm.2019.07.002&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Plekhanov Russian University of Economics, Simonenko, M. A., Kazaryan, S. Y., &amp;amp; Plekhanov Russian University of Economics. (2023). Synaesthetic metaphor and its reproduction in Russian-to-English translation: A frame-based study. &lt;em&gt;RESEARCH RESULT Theoretical and Applied Linguistics&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;(3). &lt;a href=&#34;https://doi.org/10.18413/2313-8912-2023-9-3-0-2&#34;&gt;https://doi.org/10.18413/2313-8912-2023-9-3-0-2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Popović Stijačić, M., &amp;amp; Filipović Đurđević, D. (2022). Perceptual richness of words and its role in free and cued recall. &lt;em&gt;Primenjena Psihologija&lt;/em&gt;, &lt;em&gt;15&lt;/em&gt;(3), 355&amp;ndash;381. &lt;a href=&#34;https://doi.org/10.19090/pp.v15i3.2400&#34;&gt;https://doi.org/10.19090/pp.v15i3.2400&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pulvermüller, F. (2018a). Neural reuse of action perception circuits for language, concepts and communication. &lt;em&gt;Progress in Neurobiology&lt;/em&gt;, &lt;em&gt;160&lt;/em&gt;, 1&amp;ndash;44. &lt;a href=&#34;https://doi.org/10.1016/j.pneurobio.2017.07.001&#34;&gt;https://doi.org/10.1016/j.pneurobio.2017.07.001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pulvermüller, F. (2018b). Neurobiological Mechanisms for Semantic Feature Extraction and Conceptual Flexibility. &lt;em&gt;Topics in Cognitive Science&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(3), 590&amp;ndash;620. &lt;a href=&#34;https://doi.org/10.1111/tops.12367&#34;&gt;https://doi.org/10.1111/tops.12367&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Purves, R. S., Striedl, P., Kong, I., &amp;amp; Majid, A. (2023). Conceptualizing Landscapes Through Language: The Role of Native Language and Expertise in the Representation of Waterbody Related Terms. &lt;em&gt;Topics in Cognitive Science&lt;/em&gt;, &lt;em&gt;15&lt;/em&gt;(3), 560&amp;ndash;583. &lt;a href=&#34;https://doi.org/10.1111/tops.12652&#34;&gt;https://doi.org/10.1111/tops.12652&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Radvansky, G. A. (2017). &lt;em&gt;Human Memory&lt;/em&gt; (3rd ed.). Routledge. &lt;a href=&#34;https://doi.org/10.4324/9781315542768&#34;&gt;https://doi.org/10.4324/9781315542768&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Radvansky, G. A. (2021). &lt;em&gt;Human Memory&lt;/em&gt; (4th ed.). Routledge. &lt;a href=&#34;https://doi.org/10.4324/9780429287039&#34;&gt;https://doi.org/10.4324/9780429287039&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Rahimi, S., Farahibozorg, S.-R., Jackson, R., &amp;amp; Hauk, O. (2022). Task modulation of spatiotemporal dynamics in semantic brain networks: An EEG/MEG study. &lt;em&gt;NeuroImage&lt;/em&gt;, &lt;em&gt;246&lt;/em&gt;, 118768. &lt;a href=&#34;https://doi.org/10.1016/j.neuroimage.2021.118768&#34;&gt;https://doi.org/10.1016/j.neuroimage.2021.118768&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Raia, R. (2023). An analysis of conceptual ambiguities in the debate on the format of concepts. &lt;em&gt;Phenomenology and the Cognitive Sciences&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.1007/s11097-023-09938-7&#34;&gt;https://doi.org/10.1007/s11097-023-09938-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Raj, R., Hörberg, T., Lindroos, R., Larsson, M., Herman, P., Laukka, E. J., &amp;amp; Olofsson, J. K. (2023). Odor identification errors reveal cognitive aspects of age-associated smell loss. &lt;em&gt;Cognition&lt;/em&gt;, &lt;em&gt;236&lt;/em&gt;, 105445. &lt;a href=&#34;https://doi.org/10.1016/j.cognition.2023.105445&#34;&gt;https://doi.org/10.1016/j.cognition.2023.105445&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Reggin, L. D., Gómez Franco, L. E., Horchak, O. V., Labrecque, D., Lana, N., Rio, L., &amp;amp; Vigliocco, G. (2023). Consensus Paper: Situated and Embodied Language Acquisition. &lt;em&gt;Journal of Cognition&lt;/em&gt;, &lt;em&gt;6&lt;/em&gt;(1), 63. &lt;a href=&#34;https://doi.org/10.5334/joc.308&#34;&gt;https://doi.org/10.5334/joc.308&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Repetto, C., Rodella, C., Conca, F., Santi, G. C., &amp;amp; Catricalà, E. (2022). The Italian Sensorimotor Norms: Perception and action strength measures for 959 words. &lt;em&gt;Behavior Research Methods&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.3758/s13428-022-02004-1&#34;&gt;https://doi.org/10.3758/s13428-022-02004-1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Rey, A. E., Riou, B., Vallet, G. T., &amp;amp; Versace, R. (2017). The automatic visual simulation of words: A memory reactivated mask slows down conceptual access. &lt;em&gt;Canadian Journal of Experimental Psychology / Revue Canadienne de Psychologie Expérimentale&lt;/em&gt;, &lt;em&gt;71&lt;/em&gt;(1), 14&amp;ndash;22. &lt;a href=&#34;https://doi.org/10.1037/cep0000100&#34;&gt;https://doi.org/10.1037/cep0000100&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Reymore, L. (2022). Characterizing prototypical musical instrument timbres with timbre trait profiles. &lt;em&gt;Musicae Scientiae&lt;/em&gt;, &lt;em&gt;26&lt;/em&gt;(3), 648&amp;ndash;674. &lt;a href=&#34;https://doi.org/10.1177/10298649211001523&#34;&gt;https://doi.org/10.1177/10298649211001523&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Robinson, M. D., Fetterman, A. K., Meier, B. P., Persich, M. R., &amp;amp; Waters, M. R. (2021). Embodied Perspectives on Personality. In M. D. Robinson &amp;amp; L. E. Thomas (Eds.), &lt;em&gt;Handbook of Embodied Psychology&lt;/em&gt; (pp. 477&amp;ndash;498). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-78471-3_21&#34;&gt;https://doi.org/10.1007/978-3-030-78471-3_21&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Robinson, M. D., &amp;amp; Thomas, L. E. (2021). Introduction to Embodied Psychology: Thinking, Feeling, and Acting. In M. D. Robinson &amp;amp; L. E. Thomas (Eds.), &lt;em&gt;Handbook of Embodied Psychology&lt;/em&gt; (pp. 1&amp;ndash;19). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-78471-3_1&#34;&gt;https://doi.org/10.1007/978-3-030-78471-3_1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;San Roque, L., Kendrick, K. H., Norcliffe, E., &amp;amp; Majid, A. (2018). Universal meaning extensions of perception verbs are grounded in interaction. &lt;em&gt;Cognitive Linguistics&lt;/em&gt;, &lt;em&gt;29&lt;/em&gt;(3), 371&amp;ndash;406. &lt;a href=&#34;https://doi.org/10.1515/cog-2017-0034&#34;&gt;https://doi.org/10.1515/cog-2017-0034&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Scerrati, E., D&#39;Ascenzo, S., Nicoletti, R., Villani, C., &amp;amp; Lugli, L. (2022). Assessing Interpersonal Proximity Evaluation in the COVID-19 Era: Evidence From the Affective Priming Task. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;13&lt;/em&gt;, 901730. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2022.901730&#34;&gt;https://doi.org/10.3389/fpsyg.2022.901730&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Scerrati, E., Iani, C., Lugli, L., Nicoletti, R., &amp;amp; Rubichi, S. (2020). Do my hands prime your hands? The hand-to-response correspondence effect. &lt;em&gt;Acta Psychologica&lt;/em&gt;, &lt;em&gt;203&lt;/em&gt;, 103012. &lt;a href=&#34;https://doi.org/10.1016/j.actpsy.2020.103012&#34;&gt;https://doi.org/10.1016/j.actpsy.2020.103012&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Scerrati, E., Iani, C., &amp;amp; Rubichi, S. (2021). Does the Activation of Motor Information Affect Semantic Processing? In L. Bechberger, K.-U. Kühnberger, &amp;amp; M. Liu (Eds.), &lt;em&gt;Concepts in Action&lt;/em&gt; (Vol. 9, pp. 153&amp;ndash;166). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-69823-2_7&#34;&gt;https://doi.org/10.1007/978-3-030-69823-2_7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Scerrati, E., Lugli, L., Nicoletti, R., &amp;amp; Borghi, A. M. (2017). The Multilevel Modality-Switch Effect: What Happens When We See the Bees Buzzing and Hear the Diamonds Glistening. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;24&lt;/em&gt;(3), 798&amp;ndash;803. &lt;a href=&#34;https://doi.org/10.3758/s13423-016-1150-2&#34;&gt;https://doi.org/10.3758/s13423-016-1150-2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Scherer, D., &amp;amp; Wentura, D. (2018). Combining the Post-Cue Task and the Perceptual Identification Task to Assess Parallel Activation and Mutual Facilitation of Related Primes and Targets. &lt;em&gt;Experimental Psychology&lt;/em&gt;, &lt;em&gt;65&lt;/em&gt;(2), 84&amp;ndash;97. &lt;a href=&#34;https://doi.org/10.1027/1618-3169/a000396&#34;&gt;https://doi.org/10.1027/1618-3169/a000396&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Schilhab, T. (2017). &lt;em&gt;Derived Embodiment in Abstract Language&lt;/em&gt;. Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-319-56056-4&#34;&gt;https://doi.org/10.1007/978-3-319-56056-4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Schulte Im Walde, S., &amp;amp; Frassinelli, D. (2022). Distributional Measures of Semantic Abstraction. &lt;em&gt;Frontiers in Artificial Intelligence&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;, 796756. &lt;a href=&#34;https://doi.org/10.3389/frai.2021.796756&#34;&gt;https://doi.org/10.3389/frai.2021.796756&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Seghier, M. L. (2023). Multiple functions of the angular gyrus at high temporal resolution. &lt;em&gt;Brain Structure and Function&lt;/em&gt;, &lt;em&gt;228&lt;/em&gt;(1), 7&amp;ndash;46. &lt;a href=&#34;https://doi.org/10.1007/s00429-022-02512-y&#34;&gt;https://doi.org/10.1007/s00429-022-02512-y&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Šetić Beg, M. (2021). Uloga utjelovljenja u razumijevanju pojmova. &lt;em&gt;Psihologijske Teme&lt;/em&gt;, &lt;em&gt;30&lt;/em&gt;(2), 371&amp;ndash;395. &lt;a href=&#34;https://doi.org/10.31820/pt.30.2.12&#34;&gt;https://doi.org/10.31820/pt.30.2.12&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Shen, G., Wang, R., Yang, M., &amp;amp; Xie, J. (2022). Chinese Children with Congenital and Acquired Blindness Represent Concrete Concepts in Vertical Space through Tactile Perception. &lt;em&gt;International Journal of Environmental Research and Public Health&lt;/em&gt;, &lt;em&gt;19&lt;/em&gt;(17), 11055. &lt;a href=&#34;https://doi.org/10.3390/ijerph191711055&#34;&gt;https://doi.org/10.3390/ijerph191711055&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Sidhu, D. M., &amp;amp; Pexman, P. M. (2018). Lonely sensational icons: Semantic neighbourhood density, sensory experience and iconicity. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;33&lt;/em&gt;(1), 25&amp;ndash;31. &lt;a href=&#34;https://doi.org/10.1080/23273798.2017.1358379&#34;&gt;https://doi.org/10.1080/23273798.2017.1358379&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speed, L. J., &amp;amp; Brybaert, M. (2022). Dutch sensory modality norms. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;54&lt;/em&gt;(3), 1306&amp;ndash;1318. &lt;a href=&#34;https://doi.org/10.3758/s13428-021-01656-9&#34;&gt;https://doi.org/10.3758/s13428-021-01656-9&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speed, L. J., &amp;amp; Majid, A. (2017). Dutch modality exclusivity norms: Simulating perceptual modality in space. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;49&lt;/em&gt;(6), 2204&amp;ndash;2218. &lt;a href=&#34;https://doi.org/10.3758/s13428-017-0852-3&#34;&gt;https://doi.org/10.3758/s13428-017-0852-3&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speed, L. J., &amp;amp; Majid, A. (2018). An Exception to Mental Simulation: No Evidence for Embodied Odor Language. &lt;em&gt;Cognitive Science&lt;/em&gt;, &lt;em&gt;42&lt;/em&gt;(4), 1146&amp;ndash;1178. &lt;a href=&#34;https://doi.org/10.1111/cogs.12593&#34;&gt;https://doi.org/10.1111/cogs.12593&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speed, L. J., &amp;amp; Majid, A. (2020). Grounding language in the neglected senses of touch, taste, and smell. &lt;em&gt;Cognitive Neuropsychology&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(5&amp;ndash;6), 363&amp;ndash;392. &lt;a href=&#34;https://doi.org/10.1080/02643294.2019.1623188&#34;&gt;https://doi.org/10.1080/02643294.2019.1623188&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speed, L. J., Papies, E. K., &amp;amp; Majid, A. (2023). Mental simulation across sensory modalities predicts attractiveness of food concepts. &lt;em&gt;Journal of Experimental Psychology: Applied&lt;/em&gt;, &lt;em&gt;29&lt;/em&gt;(3), 557&amp;ndash;571. &lt;a href=&#34;https://doi.org/10.1037/xap0000461&#34;&gt;https://doi.org/10.1037/xap0000461&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Sri-Ganeshan, M. (2021). Modality Effect. In M. Raz &amp;amp; P. Pouryahya (Eds.), &lt;em&gt;Decision Making in Emergency Medicine&lt;/em&gt; (pp. 215&amp;ndash;220). Springer Singapore. &lt;a href=&#34;https://doi.org/10.1007/978-981-16-0143-9_34&#34;&gt;https://doi.org/10.1007/978-981-16-0143-9_34&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Strik Lievers, F., &amp;amp; Winter, B. (2018). Sensory language across lexical categories. &lt;em&gt;Lingua&lt;/em&gt;, &lt;em&gt;204&lt;/em&gt;, 45&amp;ndash;61. &lt;a href=&#34;https://doi.org/10.1016/j.lingua.2017.11.002&#34;&gt;https://doi.org/10.1016/j.lingua.2017.11.002&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Su, C., Wang, X., Wang, Z., &amp;amp; Chen, Y. (2019). A model of synesthetic metaphor interpretation based on cross-modality similarity. &lt;em&gt;Computer Speech &amp;amp; Language&lt;/em&gt;, &lt;em&gt;58&lt;/em&gt;, 1&amp;ndash;16. &lt;a href=&#34;https://doi.org/10.1016/j.csl.2019.03.003&#34;&gt;https://doi.org/10.1016/j.csl.2019.03.003&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Szychowska, M., &amp;amp; Wiens, S. (2021). Visual load effects on the auditory steady-state responses to 20-, 40-, and 80-Hz amplitude-modulated tones. &lt;em&gt;Physiology &amp;amp; Behavior&lt;/em&gt;, &lt;em&gt;228&lt;/em&gt;, 113240. &lt;a href=&#34;https://doi.org/10.1016/j.physbeh.2020.113240&#34;&gt;https://doi.org/10.1016/j.physbeh.2020.113240&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tarai, S., Bit, A., Kumar, R., &amp;amp; Savekar, A. (2021). Processing of party symbols and names predicts the results of 2019 Indian parliamentary election: Analysing psycholinguistic behavioural incongruency effects. &lt;em&gt;Psychology of Language and Communication&lt;/em&gt;, &lt;em&gt;25&lt;/em&gt;(1), 264&amp;ndash;295. &lt;a href=&#34;https://doi.org/10.2478/plc-2021-0012&#34;&gt;https://doi.org/10.2478/plc-2021-0012&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tatiya, G., Hosseini, R., Hughes, M. C., &amp;amp; Sinapov, J. (2019). Sensorimotor Cross-Behavior Knowledge Transfer for Grounded Category Recognition. &lt;em&gt;2019 Joint IEEE 9th International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob)&lt;/em&gt;, 1&amp;ndash;6. &lt;a href=&#34;https://doi.org/10.1109/DEVLRN.2019.8850715&#34;&gt;https://doi.org/10.1109/DEVLRN.2019.8850715&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tatiya, G., Hosseini, R., Hughes, M. C., &amp;amp; Sinapov, J. (2020). A Framework for Sensorimotor Cross-Perception and Cross-Behavior Knowledge Transfer for Object Categorization. &lt;em&gt;Frontiers in Robotics and AI&lt;/em&gt;, &lt;em&gt;7&lt;/em&gt;, 522141. &lt;a href=&#34;https://doi.org/10.3389/frobt.2020.522141&#34;&gt;https://doi.org/10.3389/frobt.2020.522141&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tatiya, G., &amp;amp; Sinapov, J. (2019). Deep Multi-Sensory Object Category Recognition Using Interactive Behavioral Exploration. &lt;em&gt;2019 International Conference on Robotics and Automation (ICRA)&lt;/em&gt;, 7872&amp;ndash;7878. &lt;a href=&#34;https://doi.org/10.1109/ICRA.2019.8794095&#34;&gt;https://doi.org/10.1109/ICRA.2019.8794095&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Teodorescu, H.-N., &amp;amp; Bolea, S. C. (2019). Text Sectioning based on Stylometric Distances. &lt;em&gt;2019 International Conference on Speech Technology and Human-Computer Dialogue (SpeD)&lt;/em&gt;, 1&amp;ndash;6. &lt;a href=&#34;https://doi.org/10.1109/SPED.2019.8906616&#34;&gt;https://doi.org/10.1109/SPED.2019.8906616&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thomason, J., Padmakumar, A., Sinapov, J., Walker, N., Jiang, Y., Yedidsion, H., Hart, J., Stone, P., &amp;amp; Mooney, R. (2020). Jointly Improving Parsing and Perception for Natural Language Commands through Human-Robot Dialog. &lt;em&gt;Journal of Artificial Intelligence Research&lt;/em&gt;, &lt;em&gt;67&lt;/em&gt;, 327&amp;ndash;374. &lt;a href=&#34;https://doi.org/10.1613/jair.1.11485&#34;&gt;https://doi.org/10.1613/jair.1.11485&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tillman, R., &amp;amp; Louwerse, M. (2018). Estimating Emotions Through Language Statistics and Embodied Cognition. &lt;em&gt;Journal of Psycholinguistic Research&lt;/em&gt;, &lt;em&gt;47&lt;/em&gt;(1), 159&amp;ndash;167. &lt;a href=&#34;https://doi.org/10.1007/s10936-017-9522-y&#34;&gt;https://doi.org/10.1007/s10936-017-9522-y&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tjuka, A., Forkel, R., &amp;amp; List, J.-M. (2021). Linking norms, ratings, and relations of words and concepts across multiple language varieties. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;54&lt;/em&gt;(2), 864&amp;ndash;884. &lt;a href=&#34;https://doi.org/10.3758/s13428-021-01650-1&#34;&gt;https://doi.org/10.3758/s13428-021-01650-1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tomsk State University, Vladimirova, V. E., Rezanova, Z. I., Tomsk State University, Korshunova, I. S., &amp;amp; Tomsk State University. (2022). Ethno-linguistic contact as reflected in language cognition: Does bilingualism affect subjective assessments of perceptual semantics?*. &lt;em&gt;Rusin&lt;/em&gt;, &lt;em&gt;70&lt;/em&gt;, 214&amp;ndash;231. &lt;a href=&#34;https://doi.org/10.17223/18572685/70/12&#34;&gt;https://doi.org/10.17223/18572685/70/12&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Utsumi, A. (2020). Exploring What Is Encoded in Distributional Word Vectors: A Neurobiologically Motivated Analysis. &lt;em&gt;Cognitive Science&lt;/em&gt;, &lt;em&gt;44&lt;/em&gt;(6), e12844. &lt;a href=&#34;https://doi.org/10.1111/cogs.12844&#34;&gt;https://doi.org/10.1111/cogs.12844&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Valenzuela, J. (2017). &lt;em&gt;Meaning in English: An Introduction&lt;/em&gt; (1st ed.). Cambridge University Press. &lt;a href=&#34;https://doi.org/10.1017/9781316156278&#34;&gt;https://doi.org/10.1017/9781316156278&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Van De Weijer, J., Bianchi, I., &amp;amp; Paradis, C. (2023). Sensory modality profiles of antonyms. &lt;em&gt;Language and Cognition&lt;/em&gt;, 1&amp;ndash;15. &lt;a href=&#34;https://doi.org/10.1017/langcog.2023.20&#34;&gt;https://doi.org/10.1017/langcog.2023.20&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Vergallito, A., Petilli, M. A., &amp;amp; Marelli, M. (2020). Perceptual modality norms for 1,121 Italian words: A comparison with concreteness and imageability scores and an analysis of their impact in word processing tasks. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;52&lt;/em&gt;(4), 1599&amp;ndash;1616. &lt;a href=&#34;https://doi.org/10.3758/s13428-019-01337-8&#34;&gt;https://doi.org/10.3758/s13428-019-01337-8&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Verheyen, S., De Deyne, S., Linsen, S., &amp;amp; Storms, G. (2020). Lexicosemantic, affective, and distributional norms for 1,000 Dutch adjectives. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;52&lt;/em&gt;(3), 1108&amp;ndash;1121. &lt;a href=&#34;https://doi.org/10.3758/s13428-019-01303-4&#34;&gt;https://doi.org/10.3758/s13428-019-01303-4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Vigliocco, G., Zhang, Y., Del Maschio, N., Todd, R., &amp;amp; Tuomainen, J. (2020). Electrophysiological signatures of English onomatopoeia. &lt;em&gt;Language and Cognition&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(1), 15&amp;ndash;35. &lt;a href=&#34;https://doi.org/10.1017/langcog.2019.38&#34;&gt;https://doi.org/10.1017/langcog.2019.38&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Volfart, A., Rice, G. E., Lambon Ralph, M. A., &amp;amp; Rossion, B. (2021). Implicit, automatic semantic word categorisation in the left occipito-temporal cortex as revealed by fast periodic visual stimulation. &lt;em&gt;NeuroImage&lt;/em&gt;, &lt;em&gt;238&lt;/em&gt;, 118228. &lt;a href=&#34;https://doi.org/10.1016/j.neuroimage.2021.118228&#34;&gt;https://doi.org/10.1016/j.neuroimage.2021.118228&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;W, D., C, P., C, M.-L., &amp;amp; F, L. (2023). Imagining and reading actions: Towards similar motor representations. &lt;em&gt;Heliyon&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;(2), e13426. &lt;a href=&#34;https://doi.org/10.1016/j.heliyon.2023.e13426&#34;&gt;https://doi.org/10.1016/j.heliyon.2023.e13426&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wajnerman Paz, A. (2018). A Defense of an Amodal Number System. &lt;em&gt;Philosophies&lt;/em&gt;, &lt;em&gt;3&lt;/em&gt;(2), 13. &lt;a href=&#34;https://doi.org/10.3390/philosophies3020013&#34;&gt;https://doi.org/10.3390/philosophies3020013&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wajnerman Paz, A. (2019). Using neural response properties to draw the distinction between modal and amodal representations. &lt;em&gt;Philosophical Psychology&lt;/em&gt;, &lt;em&gt;32&lt;/em&gt;(3), 301&amp;ndash;331. &lt;a href=&#34;https://doi.org/10.1080/09515089.2018.1563677&#34;&gt;https://doi.org/10.1080/09515089.2018.1563677&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wajnerman-Paz, A., &amp;amp; Rojas-Líbano, D. (2022). On the role of contextual factors in cognitive neuroscience experiments: A mechanistic approach. &lt;em&gt;Synthese&lt;/em&gt;, &lt;em&gt;200&lt;/em&gt;(5), 402. &lt;a href=&#34;https://doi.org/10.1007/s11229-022-03870-0&#34;&gt;https://doi.org/10.1007/s11229-022-03870-0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wan, M., Su, Q., Ahrens, K., &amp;amp; Huang, C.-R. (2023). Perceptional and actional enrichment for metaphor detection with sensorimotor norms. &lt;em&gt;Natural Language Engineering&lt;/em&gt;, 1&amp;ndash;29. &lt;a href=&#34;https://doi.org/10.1017/S135132492300044X&#34;&gt;https://doi.org/10.1017/S135132492300044X&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wang, L., Chen, Q., Chen, Y., &amp;amp; Zhong, R. (2019). The Effect of Sweet Taste on Romantic Semantic Processing: An ERP Study. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;, 1573. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2019.01573&#34;&gt;https://doi.org/10.3389/fpsyg.2019.01573&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wang, Y., &amp;amp; Zeng, Y. (2022a). Multisensory Concept Learning Framework Based on Spiking Neural Networks. &lt;em&gt;Frontiers in Systems Neuroscience&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;, 845177. &lt;a href=&#34;https://doi.org/10.3389/fnsys.2022.845177&#34;&gt;https://doi.org/10.3389/fnsys.2022.845177&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wang, Y., &amp;amp; Zeng, Y. (2022b). Statistical Analysis of Multisensory and Text-Derived Representations on Concept Learning. &lt;em&gt;Frontiers in Computational Neuroscience&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;, 861265. &lt;a href=&#34;https://doi.org/10.3389/fncom.2022.861265&#34;&gt;https://doi.org/10.3389/fncom.2022.861265&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wassenburg, S. I., De Koning, B. B., De Vries, M. H., Boonstra, A. M., &amp;amp; Van Der Schoot, M. (2017). Gender differences in mental simulation during sentence and word processing. &lt;em&gt;Journal of Research in Reading&lt;/em&gt;, &lt;em&gt;40&lt;/em&gt;(3), 274&amp;ndash;296. &lt;a href=&#34;https://doi.org/10.1111/1467-9817.12066&#34;&gt;https://doi.org/10.1111/1467-9817.12066&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wentura, D. (2019). Cognition and emotion: On paradigms and metaphors. &lt;em&gt;Cognition and Emotion&lt;/em&gt;, &lt;em&gt;33&lt;/em&gt;(1), 85&amp;ndash;93. &lt;a href=&#34;https://doi.org/10.1080/02699931.2019.1567464&#34;&gt;https://doi.org/10.1080/02699931.2019.1567464&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wingfield, C., &amp;amp; Connell, L. (2022a). Sensorimotor distance: A grounded measure of semantic similarity for 800 million concept pairs. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;55&lt;/em&gt;(7), 3416&amp;ndash;3432. &lt;a href=&#34;https://doi.org/10.3758/s13428-022-01965-7&#34;&gt;https://doi.org/10.3758/s13428-022-01965-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wingfield, C., &amp;amp; Connell, L. (2022b). Understanding the role of linguistic distributional knowledge in cognition. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(10), 1220&amp;ndash;1270. &lt;a href=&#34;https://doi.org/10.1080/23273798.2022.2069278&#34;&gt;https://doi.org/10.1080/23273798.2022.2069278&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, A., Dudschig, C., Miller, J., Ulrich, R., &amp;amp; Kaup, B. (2022). The action-sentence compatibility effect (ACE): Meta-analysis of a benchmark finding for embodiment. &lt;em&gt;Acta Psychologica&lt;/em&gt;, &lt;em&gt;230&lt;/em&gt;, 103712. &lt;a href=&#34;https://doi.org/10.1016/j.actpsy.2022.103712&#34;&gt;https://doi.org/10.1016/j.actpsy.2022.103712&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B. (2019). &lt;em&gt;Statistics for Linguists: An Introduction Using R&lt;/em&gt; (1st ed.). Routledge. &lt;a href=&#34;https://doi.org/10.4324/9781315165547&#34;&gt;https://doi.org/10.4324/9781315165547&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B. (2022). Mapping the landscape of exploratory and confirmatory data analysis in linguistics. In D. Tay &amp;amp; M. X. Pan (Eds.), &lt;em&gt;Data Analytics in Cognitive Linguistics&lt;/em&gt; (pp. 13&amp;ndash;48). De Gruyter. &lt;a href=&#34;https://doi.org/10.1515/9783110687279-002&#34;&gt;https://doi.org/10.1515/9783110687279-002&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B. (2023). Abstract concepts and emotion: Cross-linguistic evidence and arguments against affective embodiment. &lt;em&gt;Philosophical Transactions of the Royal Society B: Biological Sciences&lt;/em&gt;, &lt;em&gt;378&lt;/em&gt;(1870), 20210368. &lt;a href=&#34;https://doi.org/10.1098/rstb.2021.0368&#34;&gt;https://doi.org/10.1098/rstb.2021.0368&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B., Fischer, M. H., Scheepers, C., &amp;amp; Myachykov, A. (2023). More is Better: English Language Statistics are Biased Toward Addition. &lt;em&gt;Cognitive Science&lt;/em&gt;, &lt;em&gt;47&lt;/em&gt;(4), e13254. &lt;a href=&#34;https://doi.org/10.1111/cogs.13254&#34;&gt;https://doi.org/10.1111/cogs.13254&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B., Perlman, M., &amp;amp; Majid, A. (2018). Vision dominates in perceptual language: English sensory vocabulary is optimized for usage. &lt;em&gt;Cognition&lt;/em&gt;, &lt;em&gt;179&lt;/em&gt;, 213&amp;ndash;220. &lt;a href=&#34;https://doi.org/10.1016/j.cognition.2018.05.008&#34;&gt;https://doi.org/10.1016/j.cognition.2018.05.008&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B., Perlman, M., Perry, L. K., &amp;amp; Lupyan, G. (2017). Which words are most iconic?: Iconicity in English sensory words. &lt;em&gt;Interaction Studies. Social Behaviour and Communication in Biological and Artificial Systems&lt;/em&gt;, &lt;em&gt;18&lt;/em&gt;(3), 443&amp;ndash;464. &lt;a href=&#34;https://doi.org/10.1075/is.18.3.07win&#34;&gt;https://doi.org/10.1075/is.18.3.07win&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B., Sóskuthy, M., Perlman, M., &amp;amp; Dingemanse, M. (2022). Trilled /r/ is associated with roughness, linking sound and touch across spoken languages. &lt;em&gt;Scientific Reports&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(1), 1035. &lt;a href=&#34;https://doi.org/10.1038/s41598-021-04311-7&#34;&gt;https://doi.org/10.1038/s41598-021-04311-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B., &amp;amp; Strik-Lievers, F. (2023). Semantic distance predicts metaphoricity and creativity judgments in synesthetic metaphors. &lt;em&gt;Metaphor and the Social World&lt;/em&gt;, &lt;em&gt;13&lt;/em&gt;(1), 59&amp;ndash;80. &lt;a href=&#34;https://doi.org/10.1075/msw.00029.win&#34;&gt;https://doi.org/10.1075/msw.00029.win&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wu, C., &amp;amp; Mu, X. (2023). Sensory experience ratings (SERs) for 1,130 Chinese words: Relationships with other semantic and lexical psycholinguistic variables. &lt;em&gt;Linguistics Vanguard&lt;/em&gt;, &lt;em&gt;0&lt;/em&gt;(0). &lt;a href=&#34;https://doi.org/10.1515/lingvan-2022-0083&#34;&gt;https://doi.org/10.1515/lingvan-2022-0083&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Xiong, J., &amp;amp; Huang, C.-R. (2018). Somewhere in COLDNESS Lies Nibbāna: Lexical Manifestations of COLDNESS. In J.-F. Hong, Q. Su, &amp;amp; J.-S. Wu (Eds.), &lt;em&gt;Chinese Lexical Semantics&lt;/em&gt; (Vol. 11173, pp. 70&amp;ndash;81). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-04015-4_6&#34;&gt;https://doi.org/10.1007/978-3-030-04015-4_6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Xu, Y., Vignali, L., Sigismondi, F., Crepaldi, D., Bottini, R., &amp;amp; Collignon, O. (2023). Similar object shape representation encoded in the inferolateral occipitotemporal cortex of sighted and early blind people. &lt;em&gt;PLOS Biology&lt;/em&gt;, &lt;em&gt;21&lt;/em&gt;(7), e3001930. &lt;a href=&#34;https://doi.org/10.1371/journal.pbio.3001930&#34;&gt;https://doi.org/10.1371/journal.pbio.3001930&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Yan, J., Li, W., Zhang, T., Zhang, J., Jin, Z., &amp;amp; Li, L. (2023). Structural and functional neural substrates underlying the concreteness effect. &lt;em&gt;Brain Structure and Function&lt;/em&gt;, &lt;em&gt;228&lt;/em&gt;(6), 1493&amp;ndash;1510. &lt;a href=&#34;https://doi.org/10.1007/s00429-023-02668-1&#34;&gt;https://doi.org/10.1007/s00429-023-02668-1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Yasuda, M., Stins, J. F., &amp;amp; Higuchi, T. (2017). Effect of Constrained Arm Posture on the Processing of Action Verbs. &lt;em&gt;Frontiers in Neuroscience&lt;/em&gt;, &lt;em&gt;11&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.3389/fnins.2017.00057&#34;&gt;https://doi.org/10.3389/fnins.2017.00057&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Yin Zhong, &amp;amp; Chu-Ren Huang. (2020). Sweetness or Mouthfeel: A corpus-based study of the conceptualization of taste. &lt;em&gt;Linguistic Research&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(3), 359&amp;ndash;387. &lt;a href=&#34;https://doi.org/10.17250/KHISLI.37.3.202012.001&#34;&gt;https://doi.org/10.17250/KHISLI.37.3.202012.001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zappa, A., Mestre, D., Pergandi, J.-M., Bolger, D., &amp;amp; Frenck-Mestre, C. (2022). Cross-linguistic gender congruency effects during lexical access in novice L2 learners: Evidence from ERPs. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(9), 1073&amp;ndash;1098. &lt;a href=&#34;https://doi.org/10.1080/23273798.2022.2039726&#34;&gt;https://doi.org/10.1080/23273798.2022.2039726&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zeng, Y., Zhao, D., Zhao, F., Shen, G., Dong, Y., Lu, E., Zhang, Q., Sun, Y., Liang, Q., Zhao, Y., Zhao, Z., Fang, H., Wang, Y., Li, Y., Liu, X., Du, C., Kong, Q., Ruan, Z., &amp;amp; Bi, W. (2023). BrainCog: A spiking neural network based, brain-inspired cognitive intelligence engine for brain-inspired AI and brain simulation. &lt;em&gt;Patterns&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(8), 100789. &lt;a href=&#34;https://doi.org/10.1016/j.patter.2023.100789&#34;&gt;https://doi.org/10.1016/j.patter.2023.100789&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhang, M., Wu, X., &amp;amp; Wang, A. (2021). Crossmodal Nonspatial Repetition Inhibition Due to Modality Shift. &lt;em&gt;Perception&lt;/em&gt;, &lt;em&gt;50&lt;/em&gt;(2), 116&amp;ndash;128. &lt;a href=&#34;https://doi.org/10.1177/0301006620988209&#34;&gt;https://doi.org/10.1177/0301006620988209&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhang, X., Amiri, S., Sinapov, J., Thomason, J., Stone, P., &amp;amp; Zhang, S. (2023). Multimodal embodied attribute learning by robots for object-centric action policies. &lt;em&gt;Autonomous Robots&lt;/em&gt;, &lt;em&gt;47&lt;/em&gt;(5), 505&amp;ndash;528. &lt;a href=&#34;https://doi.org/10.1007/s10514-023-10098-5&#34;&gt;https://doi.org/10.1007/s10514-023-10098-5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhang, X., Sinapov, J., &amp;amp; Zhang, S. (2021, July 12). Planning Multimodal Exploratory Actions for Online Robot Attribute Learning. &lt;em&gt;Robotics: Science and Systems XVII&lt;/em&gt;. Robotics: Science and Systems 2021. &lt;a href=&#34;https://doi.org/10.15607/RSS.2021.XVII.005&#34;&gt;https://doi.org/10.15607/RSS.2021.XVII.005&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhang, Y., Mirman, D., &amp;amp; Hoffman, P. (2023). Taxonomic and thematic relations rely on different types of semantic features: Evidence from an fMRI meta-analysis and a semantic priming study. &lt;em&gt;Brain and Language&lt;/em&gt;, &lt;em&gt;242&lt;/em&gt;, 105287. &lt;a href=&#34;https://doi.org/10.1016/j.bandl.2023.105287&#34;&gt;https://doi.org/10.1016/j.bandl.2023.105287&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q. (2020a). From Linguistic Synaesthesia to Conceptual Metaphor Theory. In Q. Zhao, &lt;em&gt;Embodied Conceptualization or Neural Realization&lt;/em&gt; (Vol. 10, pp. 115&amp;ndash;128). Springer Singapore. &lt;a href=&#34;https://doi.org/10.1007/978-981-32-9315-1_7&#34;&gt;https://doi.org/10.1007/978-981-32-9315-1_7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q. (2020b). Methodology: A Corpus-Driven Approach. In Q. Zhao, &lt;em&gt;Embodied Conceptualization or Neural Realization&lt;/em&gt; (Vol. 10, pp. 19&amp;ndash;34). Springer Singapore. &lt;a href=&#34;https://doi.org/10.1007/978-981-32-9315-1_2&#34;&gt;https://doi.org/10.1007/978-981-32-9315-1_2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q., Ahrens, K., &amp;amp; Huang, C.-R. (2022). Linguistic synesthesia is metaphorical: A lexical-conceptual account. &lt;em&gt;Cognitive Linguistics&lt;/em&gt;, &lt;em&gt;33&lt;/em&gt;(3), 553&amp;ndash;583. &lt;a href=&#34;https://doi.org/10.1515/cog-2021-0098&#34;&gt;https://doi.org/10.1515/cog-2021-0098&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q., Huang, C.-R., &amp;amp; Ahrens, K. (2019). Directionality of linguistic synesthesia in Mandarin: A corpus-based study. &lt;em&gt;Lingua&lt;/em&gt;, &lt;em&gt;232&lt;/em&gt;, 102744. &lt;a href=&#34;https://doi.org/10.1016/j.lingua.2019.102744&#34;&gt;https://doi.org/10.1016/j.lingua.2019.102744&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q., &amp;amp; Long, Y. (2022). A Diachronic Study on Linguistic Synesthesia in Chinese. In M. Dong, Y. Gu, &amp;amp; J.-F. Hong (Eds.), &lt;em&gt;Chinese Lexical Semantics&lt;/em&gt; (Vol. 13250, pp. 84&amp;ndash;94). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-031-06547-7_6&#34;&gt;https://doi.org/10.1007/978-3-031-06547-7_6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q., Long, Y., &amp;amp; Huang, C.-R. (2020). Linguistic Synaesthesia of Mandarin Sensory Adjectives: Corpus-Based and Experimental Approaches. In J.-F. Hong, Y. Zhang, &amp;amp; P. Liu (Eds.), &lt;em&gt;Chinese Lexical Semantics&lt;/em&gt; (Vol. 11831, pp. 139&amp;ndash;146). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-38189-9_14&#34;&gt;https://doi.org/10.1007/978-3-030-38189-9_14&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, T., Huang, Y., Chen, D., Jiao, L., Marmolejo-Ramos, F., Wang, R., &amp;amp; Xie, J. (2020). The modality switching costs of Chinese&amp;ndash;English bilinguals in the processing of L1 and L2. &lt;em&gt;Quarterly Journal of Experimental Psychology&lt;/em&gt;, &lt;em&gt;73&lt;/em&gt;(3), 396&amp;ndash;412. &lt;a href=&#34;https://doi.org/10.1177/1747021819878089&#34;&gt;https://doi.org/10.1177/1747021819878089&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhong, J., Peniak, M., Tani, J., Ogata, T., &amp;amp; Cangelosi, A. (2019). Sensorimotor input as a language generalisation tool: A neurorobotics model for generation and generalisation of noun-verb combinations with sensorimotor inputs. &lt;em&gt;Autonomous Robots&lt;/em&gt;, &lt;em&gt;43&lt;/em&gt;(5), 1271&amp;ndash;1290. &lt;a href=&#34;https://doi.org/10.1007/s10514-018-9793-7&#34;&gt;https://doi.org/10.1007/s10514-018-9793-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhong, Y., Huang, C.-R., &amp;amp; Dong, S. (2022). Bodily sensation and embodiment: A corpus-based study of gustatory vocabulary in Mandarin Chinese. &lt;em&gt;Journal of Chinese Linguistics&lt;/em&gt;, &lt;em&gt;50&lt;/em&gt;(1), 196&amp;ndash;230. &lt;a href=&#34;https://doi.org/10.1353/jcl.2022.0008&#34;&gt;https://doi.org/10.1353/jcl.2022.0008&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhong, Y., Wan, M., Ahrens, K., &amp;amp; Huang, C.-R. (2022). Sensorimotor norms for Chinese nouns and their relationship with orthographic and semantic variables. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(8), 1000&amp;ndash;1022. &lt;a href=&#34;https://doi.org/10.1080/23273798.2022.2035416&#34;&gt;https://doi.org/10.1080/23273798.2022.2035416&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhu, S., Wang, X., &amp;amp; Liu, P. (2021). Who Killed Sanmao and Virginia Woolf? A Comparative Study of Writers with Suicidal Attempt Based on a Quantitative Linguistic Method. In M. Liu, C. Kit, &amp;amp; Q. Su (Eds.), &lt;em&gt;Chinese Lexical Semantics&lt;/em&gt; (Vol. 12278, pp. 408&amp;ndash;420). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-81197-6_34&#34;&gt;https://doi.org/10.1007/978-3-030-81197-6_34&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Гарах, Ж. В., Ребрейкина, А. Б., Стрелец, В. Б., Голикова, А. В., &amp;amp; Зайцева, Ю. С. (2019). НЕЙРОФИЗИОЛОГИЧЕСКИЕ МЕХАНИЗМЫ ЧТЕНИЯ. &lt;em&gt;Журнал высшей нервной деятельности им И П Павлова&lt;/em&gt;, &lt;em&gt;69&lt;/em&gt;(3), 294&amp;ndash;313. &lt;a href=&#34;https://doi.org/10.1134/S0044467719030055&#34;&gt;https://doi.org/10.1134/S0044467719030055&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Modality switches occur early and extend late in conceptual processing: Evidence from ERPs [Master&#39;s thesis]</title>
      <link>https://pablobernabeu.github.io/publication/bernabeu-2017-mphil-thesis/</link>
      <pubDate>Thu, 30 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/publication/bernabeu-2017-mphil-thesis/</guid>
      <description>&lt;br&gt;
&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;div style = &#34;text-indent:-2em; margin-left:2em;&#34;&gt;
&lt;p&gt;Bernabeu, P. (2017). &lt;em&gt;Modality switches occur early and extend late in conceptual processing: Evidence from ERPs&lt;/em&gt;. PsyArXiv. &lt;a href=&#34;https://doi.org/10.31234/osf.io/5gjvk&#34;&gt;https://doi.org/10.31234/osf.io/5gjvk&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;h3 id=&#34;related-references&#34;&gt;Related references&lt;/h3&gt;
&lt;div style = &#34;text-indent: -2em; margin-left: 2em; color: darkgrey;&#34;&gt;
&lt;p&gt;Ali Qurbi, E. (2022). Ambiguous Word Processing among Second Language Learners. &lt;em&gt;The Canadian Modern Language Review&lt;/em&gt;, &lt;em&gt;78&lt;/em&gt;(2), 151&amp;ndash;173. &lt;a href=&#34;https://doi.org/10.3138/cmlr-2020-0115&#34;&gt;https://doi.org/10.3138/cmlr-2020-0115&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Amenta, S., Crepaldi, D., &amp;amp; Marelli, M. (2020). Consistency measures individuate dissociating semantic modulations in priming paradigms: A new look on semantics in the processing of (complex) words. &lt;em&gt;Quarterly Journal of Experimental Psychology&lt;/em&gt;, &lt;em&gt;73&lt;/em&gt;(10), 1546&amp;ndash;1563. &lt;a href=&#34;https://doi.org/10.1177/1747021820927663&#34;&gt;https://doi.org/10.1177/1747021820927663&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Amsel, B. D., Kutas, M., &amp;amp; Coulson, S. (2017). Projectors, associators, visual imagery, and the time course of visual processing in grapheme-color synesthesia. &lt;em&gt;Cognitive Neuroscience&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;(4), 206&amp;ndash;223. &lt;a href=&#34;https://doi.org/10.1080/17588928.2017.1353492&#34;&gt;https://doi.org/10.1080/17588928.2017.1353492&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Argiris, G., Rumiati, R. I., &amp;amp; Crepaldi, D. (2021). No fruits without color: Cross-modal priming and EEG reveal different roles for different features across semantic categories. &lt;em&gt;PLOS ONE&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;(4), e0234219. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0234219&#34;&gt;https://doi.org/10.1371/journal.pone.0234219&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Avramova, Y. R., De Pelsmacker, P., &amp;amp; Dens, N. (2017). Brand placement in text: The short- and long-term effects of placement modality and need for cognition. &lt;em&gt;International Journal of Advertising&lt;/em&gt;, &lt;em&gt;36&lt;/em&gt;(5), 682&amp;ndash;704. &lt;a href=&#34;https://doi.org/10.1080/02650487.2017.1335041&#34;&gt;https://doi.org/10.1080/02650487.2017.1335041&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bagli, M. (2023). How to Point with Language: English Source-Based Language to Describe Taste Qualities. &lt;em&gt;Lublin Studies in Modern Languages and Literature&lt;/em&gt;, &lt;em&gt;42&lt;/em&gt;(2), 31&amp;ndash;46. &lt;a href=&#34;https://doi.org/10.17951/lsmll.2023.47.2.31-46&#34;&gt;https://doi.org/10.17951/lsmll.2023.47.2.31-46&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Banks, B., Wingfield, C., &amp;amp; Connell, L. (2021). Linguistic Distributional Knowledge and Sensorimotor Grounding both Contribute to Semantic Category Production. &lt;em&gt;Cognitive Science&lt;/em&gt;, &lt;em&gt;45&lt;/em&gt;(10), e13055. &lt;a href=&#34;https://doi.org/10.1111/cogs.13055&#34;&gt;https://doi.org/10.1111/cogs.13055&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Barros García, B. (2017). In Other Words: Reformulation Strategies in Dostoevskii&#39;s Literary Works. &lt;em&gt;Russian Literature&lt;/em&gt;, &lt;em&gt;91&lt;/em&gt;, 1&amp;ndash;25. &lt;a href=&#34;https://doi.org/10.1016/j.ruslit.2017.09.001&#34;&gt;https://doi.org/10.1016/j.ruslit.2017.09.001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Barsalou, L. W. (2017a). Cognitively Plausible Theories of Concept Composition. In J. A. Hampton &amp;amp; Y. Winter (Eds.), &lt;em&gt;Compositionality and Concepts in Linguistics and Psychology&lt;/em&gt; (Vol. 3, pp. 9&amp;ndash;30). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-319-45977-6_2&#34;&gt;https://doi.org/10.1007/978-3-319-45977-6_2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Barsalou, L. W. (2017b). What does semantic tiling of the cortex tell us about semantics? &lt;em&gt;Neuropsychologia&lt;/em&gt;, &lt;em&gt;105&lt;/em&gt;, 18&amp;ndash;38. &lt;a href=&#34;https://doi.org/10.1016/j.neuropsychologia.2017.04.011&#34;&gt;https://doi.org/10.1016/j.neuropsychologia.2017.04.011&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Barsalou, L. W. (2020). Challenges and Opportunities for Grounding Cognition. &lt;em&gt;Journal of Cognition&lt;/em&gt;, &lt;em&gt;3&lt;/em&gt;(1), 31. &lt;a href=&#34;https://doi.org/10.5334/joc.116&#34;&gt;https://doi.org/10.5334/joc.116&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bartl, S., &amp;amp; Lahey, E. (2023). &amp;lsquo;As the title implies&amp;rsquo;: How readers talk about titles in Amazon book reviews. &lt;em&gt;Language and Literature: International Journal of Stylistics&lt;/em&gt;, &lt;em&gt;32&lt;/em&gt;(2), 209&amp;ndash;230. &lt;a href=&#34;https://doi.org/10.1177/09639470221147788&#34;&gt;https://doi.org/10.1177/09639470221147788&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Baumann, A., Hofmann, K., Marakasova, A., Neidhardt, J., &amp;amp; Wissik, T. (2023). Semantic micro-dynamics as a reflex of occurrence frequency: A semantic networks approach. &lt;em&gt;Cognitive Linguistics&lt;/em&gt;, &lt;em&gt;34&lt;/em&gt;(3&amp;ndash;4), 533&amp;ndash;568. &lt;a href=&#34;https://doi.org/10.1515/cog-2022-0008&#34;&gt;https://doi.org/10.1515/cog-2022-0008&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bechtold, L., Bellebaum, C., Egan, S., Tettamanti, M., &amp;amp; Ghio, M. (2019). The role of experience for abstract concepts: Expertise modulates the electrophysiological correlates of mathematical word processing. &lt;em&gt;Brain and Language&lt;/em&gt;, &lt;em&gt;188&lt;/em&gt;, 1&amp;ndash;10. &lt;a href=&#34;https://doi.org/10.1016/j.bandl.2018.10.002&#34;&gt;https://doi.org/10.1016/j.bandl.2018.10.002&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bechtold, L., Bellebaum, C., &amp;amp; Ghio, M. (2023). When a Sunny Day Gives You Butterflies: An Electrophysiological Investigation of Concreteness and Context Effects in Semantic Word Processing. &lt;em&gt;Journal of Cognitive Neuroscience&lt;/em&gt;, &lt;em&gt;35&lt;/em&gt;(2), 241&amp;ndash;258. &lt;a href=&#34;https://doi.org/10.1162/jocn_a_01942&#34;&gt;https://doi.org/10.1162/jocn_a_01942&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bechtold, L., Bellebaum, C., Hoffman, P., &amp;amp; Ghio, M. (2021). Corroborating behavioral evidence for the interplay of representational richness and semantic control in semantic word processing. &lt;em&gt;Scientific Reports&lt;/em&gt;, &lt;em&gt;11&lt;/em&gt;(1), 6184. &lt;a href=&#34;https://doi.org/10.1038/s41598-021-85711-7&#34;&gt;https://doi.org/10.1038/s41598-021-85711-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bidet-Ildei, C., Gimenes, M., Toussaint, L., Almecija, Y., &amp;amp; Badets, A. (2017). Sentence plausibility influences the link between action words and the perception of biological human movements. &lt;em&gt;Psychological Research&lt;/em&gt;, &lt;em&gt;81&lt;/em&gt;(4), 806&amp;ndash;813. &lt;a href=&#34;https://doi.org/10.1007/s00426-016-0776-z&#34;&gt;https://doi.org/10.1007/s00426-016-0776-z&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bidet-Ildei, C., Gimenes, M., Toussaint, L., Beauprez, S.-A., &amp;amp; Badets, A. (2017). Painful semantic context modulates the relationship between action words and biological movement perception. &lt;em&gt;Journal of Cognitive Psychology&lt;/em&gt;, &lt;em&gt;29&lt;/em&gt;(7), 821&amp;ndash;831. &lt;a href=&#34;https://doi.org/10.1080/20445911.2017.1322093&#34;&gt;https://doi.org/10.1080/20445911.2017.1322093&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bolognesi, M., &amp;amp; Strik Lievers, F. (2020). How language and image construct synaesthetic metaphors in print advertising. &lt;em&gt;Visual Communication&lt;/em&gt;, &lt;em&gt;19&lt;/em&gt;(4), 431&amp;ndash;457. &lt;a href=&#34;https://doi.org/10.1177/1470357218782001&#34;&gt;https://doi.org/10.1177/1470357218782001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Borghesani, V., &amp;amp; Piazza, M. (2017). The neuro-cognitive representations of symbols: The case of concrete words. &lt;em&gt;Neuropsychologia&lt;/em&gt;, &lt;em&gt;105&lt;/em&gt;, 4&amp;ndash;17. &lt;a href=&#34;https://doi.org/10.1016/j.neuropsychologia.2017.06.026&#34;&gt;https://doi.org/10.1016/j.neuropsychologia.2017.06.026&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Borghi, A. M., &amp;amp; Barsalou, L. (2021). Perspective in the conceptualization of categories. &lt;em&gt;Psychological Research&lt;/em&gt;, &lt;em&gt;85&lt;/em&gt;(2), 697&amp;ndash;719. &lt;a href=&#34;https://doi.org/10.1007/s00426-019-01269-0&#34;&gt;https://doi.org/10.1007/s00426-019-01269-0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Borghi, A. M., Binkofski, F., Castelfranchi, C., Cimatti, F., Scorolli, C., &amp;amp; Tummolini, L. (2017). The challenge of abstract concepts. &lt;em&gt;Psychological Bulletin&lt;/em&gt;, &lt;em&gt;143&lt;/em&gt;(3), 263&amp;ndash;292. &lt;a href=&#34;https://doi.org/10.1037/bul0000089&#34;&gt;https://doi.org/10.1037/bul0000089&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Borghi, A. M., Mazzuca, C., Gervasi, A. M., Mannella, F., &amp;amp; Tummolini, L. (2023). Grounded cognition can be multimodal all the way down. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, 1&amp;ndash;5. &lt;a href=&#34;https://doi.org/10.1080/23273798.2023.2210238&#34;&gt;https://doi.org/10.1080/23273798.2023.2210238&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bottini, R., Ferraro, S., Nigri, A., Cuccarini, V., Bruzzone, M. G., &amp;amp; Collignon, O. (2020). Brain Regions Involved in Conceptual Retrieval in Sighted and Blind People. &lt;em&gt;Journal of Cognitive Neuroscience&lt;/em&gt;, &lt;em&gt;32&lt;/em&gt;(6), 1009&amp;ndash;1025. &lt;a href=&#34;https://doi.org/10.1162/jocn_a_01538&#34;&gt;https://doi.org/10.1162/jocn_a_01538&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bruffaerts, R., De Deyne, S., Meersmans, K., Liuzzi, A. G., Storms, G., &amp;amp; Vandenberghe, R. (2019). Redefining the resolution of semantic knowledge in the brain: Advances made by the introduction of models of semantics in neuroimaging. &lt;em&gt;Neuroscience &amp;amp; Biobehavioral Reviews&lt;/em&gt;, &lt;em&gt;103&lt;/em&gt;, 3&amp;ndash;13. &lt;a href=&#34;https://doi.org/10.1016/j.neubiorev.2019.05.015&#34;&gt;https://doi.org/10.1016/j.neubiorev.2019.05.015&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Caballero, R., &amp;amp; Paradis, C. (2020). Soundscapes in English and Spanish: A corpus investigation of verb constructions. &lt;em&gt;Language and Cognition&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(4), 705&amp;ndash;728. &lt;a href=&#34;https://doi.org/10.1017/langcog.2020.19&#34;&gt;https://doi.org/10.1017/langcog.2020.19&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Caballero, R., &amp;amp; Paradis, C. (2023). Sharing Perceptual Experiences through Language. &lt;em&gt;Journal of Intelligence&lt;/em&gt;, &lt;em&gt;11&lt;/em&gt;(7), 129. &lt;a href=&#34;https://doi.org/10.3390/jintelligence11070129&#34;&gt;https://doi.org/10.3390/jintelligence11070129&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Cantarero, K., Parzuchowski, M., &amp;amp; Dukala, K. (2017). White Lies in Hand: Are Other-Oriented Lies Modified by Hand Gestures? Possibly Not. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;, 814. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2017.00814&#34;&gt;https://doi.org/10.3389/fpsyg.2017.00814&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Carney, J. (2020). Thinking avant la lettre: A Review of 4E Cognition. &lt;em&gt;Evolutionary Studies in Imaginative Culture&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(1), 77&amp;ndash;90. &lt;a href=&#34;https://doi.org/10.26613/esic.4.1.172&#34;&gt;https://doi.org/10.26613/esic.4.1.172&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Caterina Villani &amp;amp; Luisa Lugli. (2020). L&#39;effetto Simon e il suo decorso temporale con stimoli linguistici non spaziali. &lt;em&gt;Giornale italiano di psicologia&lt;/em&gt;, &lt;em&gt;1&lt;/em&gt;, 305&amp;ndash;314. &lt;a href=&#34;https://doi.org/10.1421/96612&#34;&gt;https://doi.org/10.1421/96612&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chan, S. (2022). Dynamics of nominal classification systems in language processing. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(6), 671&amp;ndash;685. &lt;a href=&#34;https://doi.org/10.1080/23273798.2021.2011331&#34;&gt;https://doi.org/10.1080/23273798.2021.2011331&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Charmhun Jo, Sun-A Kim, &amp;amp; Chu-Ren Huang. (2022). Linguistic synesthesia in Korean: A compound word-based study of cross-modal directionality. &lt;em&gt;Linguistic Research&lt;/em&gt;, &lt;em&gt;39&lt;/em&gt;(2), 275&amp;ndash;296. &lt;a href=&#34;https://doi.org/10.17250/KHISLI.39.2.202206.002&#34;&gt;https://doi.org/10.17250/KHISLI.39.2.202206.002&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chedid, G., Brambati, S. M., Bedetti, C., Rey, A. E., Wilson, M. A., &amp;amp; Vallet, G. T. (2019). Visual and auditory perceptual strength norms for 3,596 French nouns and their relationship with other psycholinguistic variables. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;51&lt;/em&gt;(5), 2094&amp;ndash;2105. &lt;a href=&#34;https://doi.org/10.3758/s13428-019-01254-w&#34;&gt;https://doi.org/10.3758/s13428-019-01254-w&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chen, I.-H., Zhao, Q., Long, Y., Lu, Q., &amp;amp; Huang, C.-R. (2019). Mandarin Chinese modality exclusivity norms. &lt;em&gt;PLOS ONE&lt;/em&gt;, &lt;em&gt;14&lt;/em&gt;(2), e0211336. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0211336&#34;&gt;https://doi.org/10.1371/journal.pone.0211336&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Choi, U., Sung, Y., &amp;amp; Ogawa, S. (2020). Measurement of ultra‐fast signal progression related to face processing by 7T fMRI. &lt;em&gt;Human Brain Mapping&lt;/em&gt;, &lt;em&gt;41&lt;/em&gt;(7), 1754&amp;ndash;1764. &lt;a href=&#34;https://doi.org/10.1002/hbm.24907&#34;&gt;https://doi.org/10.1002/hbm.24907&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chwilla, D. J. (2022). Context effects in language comprehension: The role of emotional state and attention on semantic and syntactic processing. &lt;em&gt;Frontiers in Human Neuroscience&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;, 1014547. &lt;a href=&#34;https://doi.org/10.3389/fnhum.2022.1014547&#34;&gt;https://doi.org/10.3389/fnhum.2022.1014547&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Cirillo, G., Strijkers, K., Runnqvist, E., &amp;amp; Baus, C. (2023). Effects of Shared Attention on joint language production across processing stages. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, 1&amp;ndash;12. &lt;a href=&#34;https://doi.org/10.1080/23273798.2023.2260021&#34;&gt;https://doi.org/10.1080/23273798.2023.2260021&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Cochrane, B. A., &amp;amp; Milliken, B. (2019). Imagined event files: An interplay between imagined and perceived objects. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;26&lt;/em&gt;(2), 538&amp;ndash;544. &lt;a href=&#34;https://doi.org/10.3758/s13423-019-01572-2&#34;&gt;https://doi.org/10.3758/s13423-019-01572-2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Connell, L. (2019). What have labels ever done for us? The linguistic shortcut in conceptual processing. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;34&lt;/em&gt;(10), 1308&amp;ndash;1318. &lt;a href=&#34;https://doi.org/10.1080/23273798.2018.1471512&#34;&gt;https://doi.org/10.1080/23273798.2018.1471512&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Connell, L., Lynott, D., &amp;amp; Banks, B. (2018). Interoception: The forgotten modality in perceptual grounding of abstract and concrete concepts. &lt;em&gt;Philosophical Transactions of the Royal Society B: Biological Sciences&lt;/em&gt;, &lt;em&gt;373&lt;/em&gt;(1752), 20170143. &lt;a href=&#34;https://doi.org/10.1098/rstb.2017.0143&#34;&gt;https://doi.org/10.1098/rstb.2017.0143&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Corciulo, S., Bioglio, L., Basile, V., Patti, V., &amp;amp; Damiano, R. (2023). The DEEP Sensorium: A multidimensional approach to sensory domain labelling. &lt;em&gt;Companion Proceedings of the ACM Web Conference 2023&lt;/em&gt;, 661&amp;ndash;668. &lt;a href=&#34;https://doi.org/10.1145/3543873.3587631&#34;&gt;https://doi.org/10.1145/3543873.3587631&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Courson, M., Macoir, J., &amp;amp; Tremblay, P. (2018). A facilitating role for the primary motor cortex in action sentence processing. &lt;em&gt;Behavioural Brain Research&lt;/em&gt;, &lt;em&gt;336&lt;/em&gt;, 244&amp;ndash;249. &lt;a href=&#34;https://doi.org/10.1016/j.bbr.2017.09.019&#34;&gt;https://doi.org/10.1016/j.bbr.2017.09.019&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Davis, C. P., Joergensen, G. H., Boddy, P., Dowling, C., &amp;amp; Yee, E. (2020). Making It Harder to &amp;ldquo;See&amp;rdquo; Meaning: The More You See Something, the More Its Conceptual Representation Is Susceptible to Visual Interference. &lt;em&gt;Psychological Science&lt;/em&gt;, &lt;em&gt;31&lt;/em&gt;(5), 505&amp;ndash;517. &lt;a href=&#34;https://doi.org/10.1177/0956797620910748&#34;&gt;https://doi.org/10.1177/0956797620910748&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Davis, C. P., &amp;amp; Yee, E. (2021). Building semantic memory from embodied and distributional language experience. &lt;em&gt;WIREs Cognitive Science&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(5), e1555. &lt;a href=&#34;https://doi.org/10.1002/wcs.1555&#34;&gt;https://doi.org/10.1002/wcs.1555&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Davis, J. D., Coulson, S., Arnold, A. J., &amp;amp; Winkielman, P. (2021). Dynamic Grounding of Concepts: Implications for Emotion and Social Cognition. In M. D. Robinson &amp;amp; L. E. Thomas (Eds.), &lt;em&gt;Handbook of Embodied Psychology&lt;/em&gt; (pp. 23&amp;ndash;42). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-78471-3_2&#34;&gt;https://doi.org/10.1007/978-3-030-78471-3_2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;De Deyne, S., Brysbaert, M., &amp;amp; Elgort, I. (2023). Chapter 7. Cross-language influences in L2 semantic and conceptual representation and processing. In I. Elgort, A. Siyanova-Chanturia, &amp;amp; M. Brysbaert (Eds.), &lt;em&gt;Bilingual Processing and Acquisition&lt;/em&gt; (Vol. 16, pp. 152&amp;ndash;186). John Benjamins Publishing Company. &lt;a href=&#34;https://doi.org/10.1075/bpa.16.07ded&#34;&gt;https://doi.org/10.1075/bpa.16.07ded&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dellantonio, S., &amp;amp; Pastore, L. (2017). The &amp;lsquo;Proprioceptive&amp;rsquo; Component of Abstract Concepts. In S. Dellantonio &amp;amp; L. Pastore, &lt;em&gt;Internal Perception&lt;/em&gt; (Vol. 40, pp. 297&amp;ndash;357). Springer Berlin Heidelberg. &lt;a href=&#34;https://doi.org/10.1007/978-3-662-55763-1_6&#34;&gt;https://doi.org/10.1007/978-3-662-55763-1_6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Díez-Álamo, A. M., Díez, E., Alonso, M. Á., Vargas, C. A., &amp;amp; Fernandez, A. (2018). Normative ratings for perceptual and motor attributes of 750 object concepts in Spanish. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;50&lt;/em&gt;(4), 1632&amp;ndash;1644. &lt;a href=&#34;https://doi.org/10.3758/s13428-017-0970-y&#34;&gt;https://doi.org/10.3758/s13428-017-0970-y&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dove, G. (2018). Language as a disruptive technology: Abstract concepts, embodiment and the flexible mind. &lt;em&gt;Philosophical Transactions of the Royal Society B: Biological Sciences&lt;/em&gt;, &lt;em&gt;373&lt;/em&gt;(1752), 20170135. &lt;a href=&#34;https://doi.org/10.1098/rstb.2017.0135&#34;&gt;https://doi.org/10.1098/rstb.2017.0135&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dove, G. (2021). The Challenges of Abstract Concepts. In M. D. Robinson &amp;amp; L. E. Thomas (Eds.), &lt;em&gt;Handbook of Embodied Psychology&lt;/em&gt; (pp. 171&amp;ndash;195). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-78471-3_8&#34;&gt;https://doi.org/10.1007/978-3-030-78471-3_8&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dove, G., Barca, L., Tummolini, L., &amp;amp; Borghi, A. M. (2022). Words have a weight: Language as a source of inner grounding and flexibility in abstract concepts. &lt;em&gt;Psychological Research&lt;/em&gt;, &lt;em&gt;86&lt;/em&gt;(8), 2451&amp;ndash;2467. &lt;a href=&#34;https://doi.org/10.1007/s00426-020-01438-6&#34;&gt;https://doi.org/10.1007/s00426-020-01438-6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dupont, W., Papaxanthis, C., Lebon, F., &amp;amp; Madden-Lombardi, C. (2022). Does the Motor Cortex Want the Full Story? The Influence of Sentence Context on Corticospinal Excitability in Action Language Processing. &lt;em&gt;Neuroscience&lt;/em&gt;, &lt;em&gt;506&lt;/em&gt;, 58&amp;ndash;67. &lt;a href=&#34;https://doi.org/10.1016/j.neuroscience.2022.10.022&#34;&gt;https://doi.org/10.1016/j.neuroscience.2022.10.022&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dutriaux, L., Dahiez, X., &amp;amp; Gyselinck, V. (2019). How to change your memory of an object with a posture and a verb. &lt;em&gt;Quarterly Journal of Experimental Psychology&lt;/em&gt;, &lt;em&gt;72&lt;/em&gt;(5), 1112&amp;ndash;1118. &lt;a href=&#34;https://doi.org/10.1177/1747021818785096&#34;&gt;https://doi.org/10.1177/1747021818785096&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dymarska, A., Connell, L., &amp;amp; Banks, B. (2022). Linguistic Bootstrapping Allows More Real-world Object Concepts to Be Held in Mind. &lt;em&gt;Collabra: Psychology&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;(1), 40171. &lt;a href=&#34;https://doi.org/10.1525/collabra.40171&#34;&gt;https://doi.org/10.1525/collabra.40171&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dymarska, A., Connell, L., &amp;amp; Banks, B. (2023). More is not necessarily better: How different aspects of sensorimotor experience affect recognition memory for words. &lt;em&gt;Journal of Experimental Psychology: Learning, Memory, and Cognition&lt;/em&gt;, &lt;em&gt;49&lt;/em&gt;(10), 1572&amp;ndash;1587. &lt;a href=&#34;https://doi.org/10.1037/xlm0001265&#34;&gt;https://doi.org/10.1037/xlm0001265&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Edmiston, P., &amp;amp; Lupyan, G. (2017). Visual interference disrupts visual knowledge. &lt;em&gt;Journal of Memory and Language&lt;/em&gt;, &lt;em&gt;92&lt;/em&gt;, 281&amp;ndash;292. &lt;a href=&#34;https://doi.org/10.1016/j.jml.2016.07.002&#34;&gt;https://doi.org/10.1016/j.jml.2016.07.002&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Elisa Scerrati, Cristina Iani, Luisa Lugli, &amp;amp; Sandro Rubichi. (2019). C&#39;è un effetto di potenziamento dell&#39;azione con oggetti bimanuali? &lt;em&gt;Giornale italiano di psicologia&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;, 987&amp;ndash;996. &lt;a href=&#34;https://doi.org/10.1421/95573&#34;&gt;https://doi.org/10.1421/95573&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Elpidorou, A., &amp;amp; Dove, G. (2018). &lt;em&gt;Consciousness and Physicalism: A Defense of a Research Program&lt;/em&gt; (1st ed.). Routledge. &lt;a href=&#34;https://doi.org/10.4324/9781315682075&#34;&gt;https://doi.org/10.4324/9781315682075&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Espino, O., &amp;amp; Byrne, R. M. J. (2018). Thinking About the Opposite of What Is Said: Counterfactual Conditionals and Symbolic or Alternate Simulations of Negation. &lt;em&gt;Cognitive Science&lt;/em&gt;, &lt;em&gt;42&lt;/em&gt;(8), 2459&amp;ndash;2501. &lt;a href=&#34;https://doi.org/10.1111/cogs.12677&#34;&gt;https://doi.org/10.1111/cogs.12677&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Fabrizio Calzavarini. (2023). Comprensione e cervello. &lt;em&gt;Sistemi intelligenti&lt;/em&gt;, &lt;em&gt;2&lt;/em&gt;, 251&amp;ndash;276. &lt;a href=&#34;https://doi.org/10.1422/107149&#34;&gt;https://doi.org/10.1422/107149&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Fischer, J., &amp;amp; Mahon, B. Z. (2021). What tool representation, intuitive physics, and action have in common: The brain&#39;s first-person physics engine. &lt;em&gt;Cognitive Neuropsychology&lt;/em&gt;, &lt;em&gt;38&lt;/em&gt;(7&amp;ndash;8), 455&amp;ndash;467. &lt;a href=&#34;https://doi.org/10.1080/02643294.2022.2106126&#34;&gt;https://doi.org/10.1080/02643294.2022.2106126&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Galetzka, C. (2017). The Story So Far: How Embodied Cognition Advances Our Understanding of Meaning-Making. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;, 1315. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2017.01315&#34;&gt;https://doi.org/10.3389/fpsyg.2017.01315&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gálvez-García, G., Aldunate, N., Bascour-Sandoval, C., Martínez-Molina, A., Peña, J., &amp;amp; Barramuño, M. (2020). Muscle activation in semantic processing: An electromyography approach. &lt;em&gt;Biological Psychology&lt;/em&gt;, &lt;em&gt;152&lt;/em&gt;, 107881. &lt;a href=&#34;https://doi.org/10.1016/j.biopsycho.2020.107881&#34;&gt;https://doi.org/10.1016/j.biopsycho.2020.107881&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gao, C., Baucom, L. B., Kim, J., Wang, J., Wedell, D. H., &amp;amp; Shinkareva, S. V. (2019). Distinguishing abstract from concrete concepts in supramodal brain regions. &lt;em&gt;Neuropsychologia&lt;/em&gt;, &lt;em&gt;131&lt;/em&gt;, 102&amp;ndash;110. &lt;a href=&#34;https://doi.org/10.1016/j.neuropsychologia.2019.05.032&#34;&gt;https://doi.org/10.1016/j.neuropsychologia.2019.05.032&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gatti, D., Marelli, M., Vecchi, T., &amp;amp; Rinaldi, L. (2022). Spatial Representations Without Spatial Computations. &lt;em&gt;Psychological Science&lt;/em&gt;, &lt;em&gt;33&lt;/em&gt;(11), 1947&amp;ndash;1958. &lt;a href=&#34;https://doi.org/10.1177/09567976221094863&#34;&gt;https://doi.org/10.1177/09567976221094863&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gijssels, T., &amp;amp; Casasanto, D. (2020). Hand-use norms for Dutch and English manual action verbs: Implicit measures from a pantomime task. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;52&lt;/em&gt;(4), 1744&amp;ndash;1767. &lt;a href=&#34;https://doi.org/10.3758/s13428-020-01347-x&#34;&gt;https://doi.org/10.3758/s13428-020-01347-x&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Grand, G., Blank, I. A., Pereira, F., &amp;amp; Fedorenko, E. (2022). Semantic projection recovers rich human knowledge of multiple object features from word embeddings. &lt;em&gt;Nature Human Behaviour&lt;/em&gt;, &lt;em&gt;6&lt;/em&gt;(7), 975&amp;ndash;987. &lt;a href=&#34;https://doi.org/10.1038/s41562-022-01316-8&#34;&gt;https://doi.org/10.1038/s41562-022-01316-8&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Grant, L. D., &amp;amp; Weissman, D. H. (2023). The binary structure of event files generalizes to abstract features: A nonhierarchical explanation of task set boundaries for the congruency sequence effect. &lt;em&gt;Journal of Experimental Psychology: Learning, Memory, and Cognition&lt;/em&gt;, &lt;em&gt;49&lt;/em&gt;(7), 1033&amp;ndash;1050. &lt;a href=&#34;https://doi.org/10.1037/xlm0001148&#34;&gt;https://doi.org/10.1037/xlm0001148&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Greco, A. (2021). Spatial and Motor Aspects in the &amp;ldquo;Action-Sentence Compatibility Effect.&amp;rdquo; &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;, 647899. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2021.647899&#34;&gt;https://doi.org/10.3389/fpsyg.2021.647899&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Guerra, E., &amp;amp; Knoeferle, P. (2018). Semantic Interference and Facilitation: Understanding the Integration of Spatial Distance and Conceptual Similarity During Sentence Reading. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;, 718. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2018.00718&#34;&gt;https://doi.org/10.3389/fpsyg.2018.00718&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Günther, F., Petilli, M. A., Vergallito, A., &amp;amp; Marelli, M. (2022). Images of the unseen: Extrapolating visual representations for abstract and concrete words in a data-driven computational model. &lt;em&gt;Psychological Research&lt;/em&gt;, &lt;em&gt;86&lt;/em&gt;(8), 2512&amp;ndash;2532. &lt;a href=&#34;https://doi.org/10.1007/s00426-020-01429-7&#34;&gt;https://doi.org/10.1007/s00426-020-01429-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Günther, F., Rinaldi, L., &amp;amp; Marelli, M. (2019). Vector-Space Models of Semantic Representation From a Cognitive Perspective: A Discussion of Common Misconceptions. &lt;em&gt;Perspectives on Psychological Science&lt;/em&gt;, &lt;em&gt;14&lt;/em&gt;(6), 1006&amp;ndash;1033. &lt;a href=&#34;https://doi.org/10.1177/1745691619861372&#34;&gt;https://doi.org/10.1177/1745691619861372&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hafri, A., Trueswell, J. C., &amp;amp; Strickland, B. (2018). Encoding of event roles from visual scenes is rapid, spontaneous, and interacts with higher-level visual processing. &lt;em&gt;Cognition&lt;/em&gt;, &lt;em&gt;175&lt;/em&gt;, 36&amp;ndash;52. &lt;a href=&#34;https://doi.org/10.1016/j.cognition.2018.02.011&#34;&gt;https://doi.org/10.1016/j.cognition.2018.02.011&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hardy, B. W. (2021). Embodied Cognition in Communication Science. &lt;em&gt;Communication Theory&lt;/em&gt;, &lt;em&gt;31&lt;/em&gt;(4), 633&amp;ndash;653. &lt;a href=&#34;https://doi.org/10.1093/ct/qtaa003&#34;&gt;https://doi.org/10.1093/ct/qtaa003&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Harpaintner, M., Sim, E.-J., Trumpp, N. M., Ulrich, M., &amp;amp; Kiefer, M. (2020). The grounding of abstract concepts in the motor and visual system: An fMRI study. &lt;em&gt;Cortex&lt;/em&gt;, &lt;em&gt;124&lt;/em&gt;, 1&amp;ndash;22. &lt;a href=&#34;https://doi.org/10.1016/j.cortex.2019.10.014&#34;&gt;https://doi.org/10.1016/j.cortex.2019.10.014&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Harpaintner, M., Trumpp, N. M., &amp;amp; Kiefer, M. (2018). The Semantic Content of Abstract Concepts: A Property Listing Study of 296 Abstract Words. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;, 1748. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2018.01748&#34;&gt;https://doi.org/10.3389/fpsyg.2018.01748&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Harpaintner, M., Trumpp, N. M., &amp;amp; Kiefer, M. (2022). Time course of brain activity during the processing of motor- and vision-related abstract concepts: Flexibility and task dependency. &lt;em&gt;Psychological Research&lt;/em&gt;, &lt;em&gt;86&lt;/em&gt;(8), 2560&amp;ndash;2582. &lt;a href=&#34;https://doi.org/10.1007/s00426-020-01374-5&#34;&gt;https://doi.org/10.1007/s00426-020-01374-5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hartman, J., &amp;amp; Paradis, C. (2023). The language of sound: Events and meaning multitasking of words. &lt;em&gt;Cognitive Linguistics&lt;/em&gt;, &lt;em&gt;34&lt;/em&gt;(3&amp;ndash;4), 445&amp;ndash;477. &lt;a href=&#34;https://doi.org/10.1515/cog-2022-0006&#34;&gt;https://doi.org/10.1515/cog-2022-0006&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hauk, O., Giraud, A.-L., &amp;amp; Clarke, A. (2017). Brain oscillations in language comprehension. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;32&lt;/em&gt;(5), 533&amp;ndash;535. &lt;a href=&#34;https://doi.org/10.1080/23273798.2017.1297842&#34;&gt;https://doi.org/10.1080/23273798.2017.1297842&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hauk, O., Jackson, R. L., &amp;amp; Rahimi, S. (2023). Transforming the neuroscience of language: Estimating pattern-to-pattern transformations of brain activity. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, 1&amp;ndash;16. &lt;a href=&#34;https://doi.org/10.1080/23273798.2023.2226268&#34;&gt;https://doi.org/10.1080/23273798.2023.2226268&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hauk, O., Magnabosco, F., &amp;amp; Law, R. (2023). Can we separate semantic representations from computations? A commentary on Calzavarini (2023). &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, 1&amp;ndash;4. &lt;a href=&#34;https://doi.org/10.1080/23273798.2023.2226269&#34;&gt;https://doi.org/10.1080/23273798.2023.2226269&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Heim, E. M. (2017a). &lt;em&gt;Adoption in Galatians and Romans: Contemporary Metaphor Theories and the Pauline Huiothesia Metaphors&lt;/em&gt;. BRILL. &lt;a href=&#34;https://doi.org/10.1163/9789004339873&#34;&gt;https://doi.org/10.1163/9789004339873&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Heim, E. M. (2017b). &lt;em&gt;Adoption in Galatians and Romans: Contemporary Metaphor Theories and the Pauline Huiothesia Metaphors&lt;/em&gt;. BRILL. &lt;a href=&#34;https://doi.org/10.1163/9789004339873&#34;&gt;https://doi.org/10.1163/9789004339873&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hoeben Mannaert, L. N., Dijkstra, K., &amp;amp; Zwaan, R. A. (2020). Object combination in mental simulations. &lt;em&gt;Quarterly Journal of Experimental Psychology&lt;/em&gt;, &lt;em&gt;73&lt;/em&gt;(11), 1796&amp;ndash;1806. &lt;a href=&#34;https://doi.org/10.1177/1747021820933214&#34;&gt;https://doi.org/10.1177/1747021820933214&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hoffman, P., McClelland, J. L., &amp;amp; Lambon Ralph, M. A. (2018). Concepts, control, and context: A connectionist account of normal and disordered semantic cognition. &lt;em&gt;Psychological Review&lt;/em&gt;, &lt;em&gt;125&lt;/em&gt;(3), 293&amp;ndash;328. &lt;a href=&#34;https://doi.org/10.1037/rev0000094&#34;&gt;https://doi.org/10.1037/rev0000094&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hohol, M. (2019). &lt;em&gt;Foundations of Geometric Cognition&lt;/em&gt; (1st ed.). Routledge. &lt;a href=&#34;https://doi.org/10.4324/9780429056291&#34;&gt;https://doi.org/10.4324/9780429056291&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Holman, A., &amp;amp; Gîrbă, A. (2019). The match in orientation between verbal context and object accelerates change detection. &lt;em&gt;Psihologija&lt;/em&gt;, &lt;em&gt;52&lt;/em&gt;(1), 93&amp;ndash;105. &lt;a href=&#34;https://doi.org/10.2298/PSI180412033H&#34;&gt;https://doi.org/10.2298/PSI180412033H&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hörberg, T., Larsson, M., &amp;amp; Olofsson, J. K. (2022). The Semantic Organization of the English Odor Vocabulary. &lt;em&gt;Cognitive Science&lt;/em&gt;, &lt;em&gt;46&lt;/em&gt;(11), e13205. &lt;a href=&#34;https://doi.org/10.1111/cogs.13205&#34;&gt;https://doi.org/10.1111/cogs.13205&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Huang, C.-R., &amp;amp; Xiong, J. (2019). Linguistic synaesthesia in Chinese. In C.-R. Huang, Z. Jing-Schmidt, &amp;amp; B. Meisterernst (Eds.), &lt;em&gt;The Routledge Handbook of Chinese Applied Linguistics&lt;/em&gt; (1st ed., pp. 294&amp;ndash;312). Routledge. &lt;a href=&#34;https://doi.org/10.4324/9781315625157-20&#34;&gt;https://doi.org/10.4324/9781315625157-20&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Iatropoulos, G., Herman, P., Lansner, A., Karlgren, J., Larsson, M., &amp;amp; Olofsson, J. K. (2018). The language of smell: Connecting linguistic and psychophysical properties of odor descriptors. &lt;em&gt;Cognition&lt;/em&gt;, &lt;em&gt;178&lt;/em&gt;, 37&amp;ndash;49. &lt;a href=&#34;https://doi.org/10.1016/j.cognition.2018.05.007&#34;&gt;https://doi.org/10.1016/j.cognition.2018.05.007&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Iriguchi, M., Fujimura, R., Koda, H., &amp;amp; Masataka, N. (2019). Traffic symbol recognition modulates bodily actions. &lt;em&gt;PLOS ONE&lt;/em&gt;, &lt;em&gt;14&lt;/em&gt;(3), e0214281. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0214281&#34;&gt;https://doi.org/10.1371/journal.pone.0214281&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Jo, C. (2022). Linguistic Synesthesia in Korean: Universality and Variation. &lt;em&gt;SAGE Open&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(3), 215824402211178. &lt;a href=&#34;https://doi.org/10.1177/21582440221117804&#34;&gt;https://doi.org/10.1177/21582440221117804&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Johns, B. T. (2022). Accounting for item-level variance in recognition memory: Comparing word frequency and contextual diversity. &lt;em&gt;Memory &amp;amp; Cognition&lt;/em&gt;, &lt;em&gt;50&lt;/em&gt;(5), 1013&amp;ndash;1032. &lt;a href=&#34;https://doi.org/10.3758/s13421-021-01249-z&#34;&gt;https://doi.org/10.3758/s13421-021-01249-z&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Jones, L. L., Wurm, L. H., Calcaterra, R. D., &amp;amp; Ofen, N. (2017). Integrative Priming of Compositional and Locative Relations. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2017.00359&#34;&gt;https://doi.org/10.3389/fpsyg.2017.00359&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Julich-Warpakowski, N., &amp;amp; Pérez Sobrino, P. (2023). Introduction: Current challenges in metaphor research. &lt;em&gt;Metaphor and the Social World&lt;/em&gt;, &lt;em&gt;13&lt;/em&gt;(1), 1&amp;ndash;15. &lt;a href=&#34;https://doi.org/10.1075/msw.00026.jul&#34;&gt;https://doi.org/10.1075/msw.00026.jul&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kabbach, A., &amp;amp; Herbelot, A. (2021). Avoiding Conflict: When Speaker Coordination Does Not Require Conceptual Agreement. &lt;em&gt;Frontiers in Artificial Intelligence&lt;/em&gt;, &lt;em&gt;3&lt;/em&gt;, 523920. &lt;a href=&#34;https://doi.org/10.3389/frai.2020.523920&#34;&gt;https://doi.org/10.3389/frai.2020.523920&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kaiser, E. (2021). Consequences of Sensory Modality for Perspective-Taking: Comparing Visual, Olfactory and Gustatory Perception. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;, 701486. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2021.701486&#34;&gt;https://doi.org/10.3389/fpsyg.2021.701486&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kaup, B., Ulrich, R., Bausenhart, K. M., Bryce, D., Butz, M. V., Dignath, D., Dudschig, C., Franz, V. H., Friedrich, C., Gawrilow, C., Heller, J., Huff, M., Hütter, M., Janczyk, M., Leuthold, H., Mallot, H., Nürk, H.-C., Ramscar, M., Said, N., &amp;hellip; Wong, H. Y. (2023). Modal and amodal cognition: An overarching principle in various domains of psychology. &lt;em&gt;Psychological Research&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.1007/s00426-023-01878-w&#34;&gt;https://doi.org/10.1007/s00426-023-01878-w&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Keogh, R., &amp;amp; Pearson, J. (2017). The perceptual and phenomenal capacity of mental imagery. &lt;em&gt;Cognition&lt;/em&gt;, &lt;em&gt;162&lt;/em&gt;, 124&amp;ndash;132. &lt;a href=&#34;https://doi.org/10.1016/j.cognition.2017.02.004&#34;&gt;https://doi.org/10.1016/j.cognition.2017.02.004&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kernot, D., Bossomaier, T., &amp;amp; Bradbury, R. (2017). Novel Text Analysis for Investigating Personality: Identifying the Dark Lady in Shakespeare&#39;s Sonnets. &lt;em&gt;Journal of Quantitative Linguistics&lt;/em&gt;, &lt;em&gt;24&lt;/em&gt;(4), 255&amp;ndash;272. &lt;a href=&#34;https://doi.org/10.1080/09296174.2017.1304049&#34;&gt;https://doi.org/10.1080/09296174.2017.1304049&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kernot, D., Bossomaier, T., &amp;amp; Bradbury, R. (2018). Using Shakespeare&#39;s Sotto Voce to Determine True Identity From Text. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;, 289. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2018.00289&#34;&gt;https://doi.org/10.3389/fpsyg.2018.00289&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kernot, D., Bossomaier, T., &amp;amp; Bradbury, R. (2019). The Stylometric Impacts of Ageing and Life Events on Identity. &lt;em&gt;Journal of Quantitative Linguistics&lt;/em&gt;, &lt;em&gt;26&lt;/em&gt;(1), 1&amp;ndash;21. &lt;a href=&#34;https://doi.org/10.1080/09296174.2017.1405719&#34;&gt;https://doi.org/10.1080/09296174.2017.1405719&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Keus, K., &amp;amp; Harde, R. (2022). &amp;ldquo;She Wished Someone Would Help Them&amp;rdquo;: PTSD and Empathy in the Six of Crows Duology. &lt;em&gt;Children&#39;s Literature in Education&lt;/em&gt;, &lt;em&gt;53&lt;/em&gt;(1), 130&amp;ndash;146. &lt;a href=&#34;https://doi.org/10.1007/s10583-021-09441-0&#34;&gt;https://doi.org/10.1007/s10583-021-09441-0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Khatin-Zadeh, O., Hu, J., Banaruee, H., &amp;amp; Marmolejo-Ramos, F. (2023). How emotions are metaphorically embodied: Measuring hand and head action strengths of typical emotional states. &lt;em&gt;Cognition and Emotion&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(3), 486&amp;ndash;498. &lt;a href=&#34;https://doi.org/10.1080/02699931.2023.2181314&#34;&gt;https://doi.org/10.1080/02699931.2023.2181314&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kim, M.-K., Müller, H. M., &amp;amp; Weiss, S. (2021). What you &amp;ldquo;mean&amp;rdquo; is not what I &amp;ldquo;mean&amp;rdquo;: Categorization of verbs by Germans and Koreans using the semantic differential. &lt;em&gt;Lingua&lt;/em&gt;, &lt;em&gt;252&lt;/em&gt;, 103012. &lt;a href=&#34;https://doi.org/10.1016/j.lingua.2020.103012&#34;&gt;https://doi.org/10.1016/j.lingua.2020.103012&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Klomberg, B., Schilhab, T., &amp;amp; Burke, M. (2022). &lt;em&gt;Picturing Fiction through Embodied Cognition: Drawn Representations and Viewpoint in Literary Texts&lt;/em&gt; (1st ed.). Routledge. &lt;a href=&#34;https://doi.org/10.4324/9781003225300&#34;&gt;https://doi.org/10.4324/9781003225300&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Knoeferle, P. (2019). Predicting (variability of) context effects in language comprehension. &lt;em&gt;Journal of Cultural Cognitive Science&lt;/em&gt;, &lt;em&gt;3&lt;/em&gt;(2), 141&amp;ndash;158. &lt;a href=&#34;https://doi.org/10.1007/s41809-019-00025-5&#34;&gt;https://doi.org/10.1007/s41809-019-00025-5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Koblet, O., &amp;amp; Purves, R. S. (2020). From online texts to Landscape Character Assessment: Collecting and analysing first-person landscape perception computationally. &lt;em&gt;Landscape and Urban Planning&lt;/em&gt;, &lt;em&gt;197&lt;/em&gt;, 103757. &lt;a href=&#34;https://doi.org/10.1016/j.landurbplan.2020.103757&#34;&gt;https://doi.org/10.1016/j.landurbplan.2020.103757&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kompa, N. A. (2021). Language and embodiment&amp;mdash;Or the cognitive benefits of abstract representations. &lt;em&gt;Mind &amp;amp; Language&lt;/em&gt;, &lt;em&gt;36&lt;/em&gt;(1), 27&amp;ndash;47. &lt;a href=&#34;https://doi.org/10.1111/mila.12266&#34;&gt;https://doi.org/10.1111/mila.12266&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kompa, N. A., &amp;amp; Mueller, J. L. (2022). Inner speech as a cognitive tool&amp;mdash;Or what is the point of talking to oneself? &lt;em&gt;Philosophical Psychology&lt;/em&gt;, 1&amp;ndash;24. &lt;a href=&#34;https://doi.org/10.1080/09515089.2022.2112164&#34;&gt;https://doi.org/10.1080/09515089.2022.2112164&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Körner, A., Castillo, M., Drijvers, L., Fischer, M. H., Günther, F., Marelli, M., Platonova, O., Rinaldi, L., Shaki, S., Trujillo, J. P., Tsaregorodtseva, O., &amp;amp; Glenberg, A. M. (2023). Embodied Processing at Six Linguistic Granularity Levels: A Consensus Paper. &lt;em&gt;Journal of Cognition&lt;/em&gt;, &lt;em&gt;6&lt;/em&gt;(1), 60. &lt;a href=&#34;https://doi.org/10.5334/joc.231&#34;&gt;https://doi.org/10.5334/joc.231&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Krishna, P. P., Arulmozi, S., &amp;amp; Mishra, R. K. (2022). &amp;ldquo;Do You See and Hear More? A Study on Telugu Perception Verbs.&amp;rdquo; &lt;em&gt;Journal of Psycholinguistic Research&lt;/em&gt;, &lt;em&gt;51&lt;/em&gt;(3), 473&amp;ndash;484. &lt;a href=&#34;https://doi.org/10.1007/s10936-021-09827-7&#34;&gt;https://doi.org/10.1007/s10936-021-09827-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kuhnke, P., Beaupain, M. C., Arola, J., Kiefer, M., &amp;amp; Hartwigsen, G. (2023). Meta-analytic evidence for a novel hierarchical model of conceptual processing. &lt;em&gt;Neuroscience &amp;amp; Biobehavioral Reviews&lt;/em&gt;, &lt;em&gt;144&lt;/em&gt;, 104994. &lt;a href=&#34;https://doi.org/10.1016/j.neubiorev.2022.104994&#34;&gt;https://doi.org/10.1016/j.neubiorev.2022.104994&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kuhnke, P., Kiefer, M., &amp;amp; Hartwigsen, G. (2021). Task-Dependent Functional and Effective Connectivity during Conceptual Processing. &lt;em&gt;Cerebral Cortex&lt;/em&gt;, &lt;em&gt;31&lt;/em&gt;(7), 3475&amp;ndash;3493. &lt;a href=&#34;https://doi.org/10.1093/cercor/bhab026&#34;&gt;https://doi.org/10.1093/cercor/bhab026&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kumcu, A. (2021). Linguistic Synesthesia in Turkish: A Corpus-based Study of Crossmodal Directionality. &lt;em&gt;Metaphor and Symbol&lt;/em&gt;, &lt;em&gt;36&lt;/em&gt;(4), 241&amp;ndash;255. &lt;a href=&#34;https://doi.org/10.1080/10926488.2021.1921557&#34;&gt;https://doi.org/10.1080/10926488.2021.1921557&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lai, V. T., Hubbard, R., Ku, L.-C., &amp;amp; Pfeifer, V. (2023). Electrophysiology of Non-Literal Language. In M. Grimaldi, E. Brattico, &amp;amp; Y. Shtyrov (Eds.), &lt;em&gt;Language Electrified&lt;/em&gt; (Vol. 202, pp. 613&amp;ndash;646). Springer US. &lt;a href=&#34;https://doi.org/10.1007/978-1-0716-3263-5_19&#34;&gt;https://doi.org/10.1007/978-1-0716-3263-5_19&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Landrigan, J.-F., &amp;amp; Mirman, D. (2018). The cost of switching between taxonomic and thematic semantics. &lt;em&gt;Memory &amp;amp; Cognition&lt;/em&gt;, &lt;em&gt;46&lt;/em&gt;(2), 191&amp;ndash;203. &lt;a href=&#34;https://doi.org/10.3758/s13421-017-0757-5&#34;&gt;https://doi.org/10.3758/s13421-017-0757-5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Large, A.-C., Bach, C., &amp;amp; Calvet, G. (2018). CONTACT: A Human Centered Approach of Multimodal Flight Deck Design and Evaluation. In D. Harris (Ed.), &lt;em&gt;Engineering Psychology and Cognitive Ergonomics&lt;/em&gt; (Vol. 10906, pp. 593&amp;ndash;604). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-319-91122-9_48&#34;&gt;https://doi.org/10.1007/978-3-319-91122-9_48&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lee, J., &amp;amp; Shin, J.-A. (2023). The cross-linguistic comparison of perceptual strength norms for Korean, English and L2 English. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;14&lt;/em&gt;, 1188909. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2023.1188909&#34;&gt;https://doi.org/10.3389/fpsyg.2023.1188909&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Li, M., Lu, Q., Long, Y., &amp;amp; Gui, L. (2017). Inferring Affective Meanings of Words from Word Embedding. &lt;em&gt;IEEE Transactions on Affective Computing&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;(4), 443&amp;ndash;456. &lt;a href=&#34;https://doi.org/10.1109/TAFFC.2017.2723012&#34;&gt;https://doi.org/10.1109/TAFFC.2017.2723012&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lin, K., &amp;amp; Chan, S. (2019). When senses meet functions: An amodal stage in conceptual processing. &lt;em&gt;Journal of Cognitive Psychology&lt;/em&gt;, &lt;em&gt;31&lt;/em&gt;(1), 64&amp;ndash;75. &lt;a href=&#34;https://doi.org/10.1080/20445911.2018.1560299&#34;&gt;https://doi.org/10.1080/20445911.2018.1560299&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Littlemore, J. (2019). &lt;em&gt;Metaphors in the Mind: Sources of Variation in Embodied Metaphor&lt;/em&gt; (1st ed.). Cambridge University Press. &lt;a href=&#34;https://doi.org/10.1017/9781108241441&#34;&gt;https://doi.org/10.1017/9781108241441&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Liu, S., Zhou, M., &amp;amp; Li, Y. (2019). Internet use experience influence individuals&amp;rsquo; lexical decision performance by changing their body representation. &lt;em&gt;Computers in Human Behavior&lt;/em&gt;, &lt;em&gt;91&lt;/em&gt;, 157&amp;ndash;166. &lt;a href=&#34;https://doi.org/10.1016/j.chb.2018.09.021&#34;&gt;https://doi.org/10.1016/j.chb.2018.09.021&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Liu, W., Bansal, D., Daruna, A., &amp;amp; Chernova, S. (2023). Learning instance-level N-ary semantic knowledge at scale for robots operating in everyday environments. &lt;em&gt;Autonomous Robots&lt;/em&gt;, &lt;em&gt;47&lt;/em&gt;(5), 529&amp;ndash;547. &lt;a href=&#34;https://doi.org/10.1007/s10514-023-10099-4&#34;&gt;https://doi.org/10.1007/s10514-023-10099-4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Liu, W., Bansal, D., Daruna, A., &amp;amp; Chernova, S. (2021, July 12). Learning Instance-Level N-Ary Semantic Knowledge At Scale For Robots Operating in Everyday Environments. &lt;em&gt;Robotics: Science and Systems XVII&lt;/em&gt;. Robotics: Science and Systems 2021. &lt;a href=&#34;https://doi.org/10.15607/RSS.2021.XVII.035&#34;&gt;https://doi.org/10.15607/RSS.2021.XVII.035&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Long, Y., Xiang, R., Lu, Q., Huang, C.-R., &amp;amp; Li, M. (2021). Improving Attention Model Based on Cognition Grounded Data for Sentiment Analysis. &lt;em&gt;IEEE Transactions on Affective Computing&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(4), 900&amp;ndash;912. &lt;a href=&#34;https://doi.org/10.1109/TAFFC.2019.2903056&#34;&gt;https://doi.org/10.1109/TAFFC.2019.2903056&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Louwerse, M. M. (2018). Knowing the Meaning of a Word by the Linguistic and Perceptual Company It Keeps. &lt;em&gt;Topics in Cognitive Science&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(3), 573&amp;ndash;589. &lt;a href=&#34;https://doi.org/10.1111/tops.12349&#34;&gt;https://doi.org/10.1111/tops.12349&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lupyan, G., &amp;amp; Winter, B. (2018). Language is more abstract than you think, or, why aren&#39;t languages more iconic? &lt;em&gt;Philosophical Transactions of the Royal Society B: Biological Sciences&lt;/em&gt;, &lt;em&gt;373&lt;/em&gt;(1752), 20170137. &lt;a href=&#34;https://doi.org/10.1098/rstb.2017.0137&#34;&gt;https://doi.org/10.1098/rstb.2017.0137&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lynott, D., Connell, L., Brysbaert, M., Brand, J., &amp;amp; Carney, J. (2020). The Lancaster Sensorimotor Norms: Multidimensional measures of perceptual and action strength for 40,000 English words. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;52&lt;/em&gt;(3), 1271&amp;ndash;1291. &lt;a href=&#34;https://doi.org/10.3758/s13428-019-01316-z&#34;&gt;https://doi.org/10.3758/s13428-019-01316-z&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lynott, D., Walsh, M., McEnery, T., Connell, L., Cross, L., &amp;amp; O&#39;Brien, K. (2019). Are You What You Read? Predicting Implicit Attitudes to Immigration Based on Linguistic Distributional Cues From Newspaper Readership; A Pre-registered Study. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;, 842. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2019.00842&#34;&gt;https://doi.org/10.3389/fpsyg.2019.00842&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Malhi, S. K., &amp;amp; Buchanan, L. (2018). A test of the symbol interdependency hypothesis with both concrete and abstract stimuli. &lt;em&gt;PLOS ONE&lt;/em&gt;, &lt;em&gt;13&lt;/em&gt;(3), e0192719. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0192719&#34;&gt;https://doi.org/10.1371/journal.pone.0192719&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Mangels, J. A., Rodriguez, S., Ochakovskaya, Y., &amp;amp; Guerra-Carrillo, B. (2017). Achievement Goal Task Framing and Fit With Personal Goals Modulate the Neurocognitive Response to Corrective Feedback. &lt;em&gt;AERA Open&lt;/em&gt;, &lt;em&gt;3&lt;/em&gt;(3), 233285841772087. &lt;a href=&#34;https://doi.org/10.1177/2332858417720875&#34;&gt;https://doi.org/10.1177/2332858417720875&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Marchetti, R., Vaugoyeau, M., Colé, P., &amp;amp; Assaiante, C. (2022). A sensorimotor representation impairment in dyslexic adults: A specific profile of comorbidity. &lt;em&gt;Neuropsychologia&lt;/em&gt;, &lt;em&gt;165&lt;/em&gt;, 108134. &lt;a href=&#34;https://doi.org/10.1016/j.neuropsychologia.2021.108134&#34;&gt;https://doi.org/10.1016/j.neuropsychologia.2021.108134&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Marmeleira, J., &amp;amp; Duarte Santos, G. (2019). Do Not Neglect the Body and Action: The Emergence of Embodiment Approaches to Understanding Human Development. &lt;em&gt;Perceptual and Motor Skills&lt;/em&gt;, &lt;em&gt;126&lt;/em&gt;(3), 410&amp;ndash;445. &lt;a href=&#34;https://doi.org/10.1177/0031512519834389&#34;&gt;https://doi.org/10.1177/0031512519834389&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Marson, F., Paoletti, P., Naor-Ziv, R., Carducci, F., &amp;amp; Ben-Soussan, T. D. (2023). Embodied empathy and abstract concepts&amp;rsquo; concreteness: Evidence from contemplative practices. In &lt;em&gt;Progress in Brain Research&lt;/em&gt; (Vol. 277, pp. 181&amp;ndash;209). Elsevier. &lt;a href=&#34;https://doi.org/10.1016/bs.pbr.2022.12.005&#34;&gt;https://doi.org/10.1016/bs.pbr.2022.12.005&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Márton, Z. C., Türker, S., Rink, C., Brucker, M., Kriegel, S., Bodenmüller, T., &amp;amp; Riedel, S. (2018). Improving object orientation estimates by considering multiple viewpoints: Orientation histograms of symmetries and measurement models for view selection. &lt;em&gt;Autonomous Robots&lt;/em&gt;, &lt;em&gt;42&lt;/em&gt;(2), 423&amp;ndash;442. &lt;a href=&#34;https://doi.org/10.1007/s10514-017-9633-1&#34;&gt;https://doi.org/10.1007/s10514-017-9633-1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;McRae, K., Nedjadrasul, D., Pau, R., Lo, B. P., &amp;amp; King, L. (2018). Abstract Concepts and Pictures of Real‐World Situations Activate One Another. &lt;em&gt;Topics in Cognitive Science&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(3), 518&amp;ndash;532. &lt;a href=&#34;https://doi.org/10.1111/tops.12328&#34;&gt;https://doi.org/10.1111/tops.12328&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Meng, X., Sun, C., Du, B., Liu, L., Zhang, Y., Dong, Q., Georgiou, G. K., &amp;amp; Nan, Y. (2022). The development of brain rhythms at rest and its impact on vocabulary acquisition. &lt;em&gt;Developmental Science&lt;/em&gt;, &lt;em&gt;25&lt;/em&gt;(2), e13157. &lt;a href=&#34;https://doi.org/10.1111/desc.13157&#34;&gt;https://doi.org/10.1111/desc.13157&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Miceli, A., Wauthia, E., Kandana Arachchige, K., Lefebvre, L., Ris, L., &amp;amp; Simoes Loureiro, I. (2023). Perceptual strength influences lexical decision in Alzheimer&#39;s disease. &lt;em&gt;Journal of Neurolinguistics&lt;/em&gt;, &lt;em&gt;68&lt;/em&gt;, 101144. &lt;a href=&#34;https://doi.org/10.1016/j.jneuroling.2023.101144&#34;&gt;https://doi.org/10.1016/j.jneuroling.2023.101144&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Miceli, A., Wauthia, E., Lefebvre, L., Ris, L., &amp;amp; Simoes Loureiro, I. (2021). Perceptual and Interoceptive Strength Norms for 270 French Words. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;, 667271. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2021.667271&#34;&gt;https://doi.org/10.3389/fpsyg.2021.667271&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Miceli, A., Wauthia, E., Lefebvre, L., Vallet, G. T., Ris, L., &amp;amp; Loureiro, I. S. (2022). Differences related to aging in sensorimotor knowledge: Investigation of perceptual strength and body object interaction. &lt;em&gt;Archives of Gerontology and Geriatrics&lt;/em&gt;, &lt;em&gt;102&lt;/em&gt;, 104715. &lt;a href=&#34;https://doi.org/10.1016/j.archger.2022.104715&#34;&gt;https://doi.org/10.1016/j.archger.2022.104715&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Miklashevsky, A. (2018). Perceptual Experience Norms for 506 Russian Nouns: Modality Rating, Spatial Localization, Manipulability, Imageability and Other Variables. &lt;em&gt;Journal of Psycholinguistic Research&lt;/em&gt;, &lt;em&gt;47&lt;/em&gt;(3), 641&amp;ndash;661. &lt;a href=&#34;https://doi.org/10.1007/s10936-017-9548-1&#34;&gt;https://doi.org/10.1007/s10936-017-9548-1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Miller, J., Brookie, K., Wales, S., Wallace, S., &amp;amp; Kaup, B. (2018). Embodied cognition: Is activation of the motor cortex essential for understanding action verbs? &lt;em&gt;Journal of Experimental Psychology: Learning, Memory, and Cognition&lt;/em&gt;, &lt;em&gt;44&lt;/em&gt;(3), 335&amp;ndash;370. &lt;a href=&#34;https://doi.org/10.1037/xlm0000451&#34;&gt;https://doi.org/10.1037/xlm0000451&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Minervino, R. A., Martín, A., Tavernini, L. M., &amp;amp; Trench, M. (2018). The Understanding of Visual Metaphors by the Congenitally Blind. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;, 1242. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2018.01242&#34;&gt;https://doi.org/10.3389/fpsyg.2018.01242&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Moretti, S., &amp;amp; Greco, A. (2018). Truth is in the head. A nod and shake compatibility effect. &lt;em&gt;Acta Psychologica&lt;/em&gt;, &lt;em&gt;185&lt;/em&gt;, 203&amp;ndash;218. &lt;a href=&#34;https://doi.org/10.1016/j.actpsy.2018.02.010&#34;&gt;https://doi.org/10.1016/j.actpsy.2018.02.010&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Moretti, S., &amp;amp; Greco, A. (2020). Nodding and shaking of the head as simulated approach and avoidance responses. &lt;em&gt;Acta Psychologica&lt;/em&gt;, &lt;em&gt;203&lt;/em&gt;, 102988. &lt;a href=&#34;https://doi.org/10.1016/j.actpsy.2019.102988&#34;&gt;https://doi.org/10.1016/j.actpsy.2019.102988&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Morucci, P., Bottini, R., &amp;amp; Crepaldi, D. (2019). Augmented Modality Exclusivity Norms for Concrete and Abstract Italian Property Words. &lt;em&gt;Journal of Cognition&lt;/em&gt;, &lt;em&gt;2&lt;/em&gt;(1), 42. &lt;a href=&#34;https://doi.org/10.5334/joc.88&#34;&gt;https://doi.org/10.5334/joc.88&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Mueller, C. J., White, C. N., &amp;amp; Kuchinke, L. (2017). Electrophysiological correlates of the drift diffusion model in visual word recognition. &lt;em&gt;Human Brain Mapping&lt;/em&gt;, &lt;em&gt;38&lt;/em&gt;(11), 5616&amp;ndash;5627. &lt;a href=&#34;https://doi.org/10.1002/hbm.23753&#34;&gt;https://doi.org/10.1002/hbm.23753&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Muraki, E. J., Doyle, A., Protzner, A. B., &amp;amp; Pexman, P. M. (2023). Context matters: How do task demands modulate the recruitment of sensorimotor information during language processing? &lt;em&gt;Frontiers in Human Neuroscience&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;, 976954. &lt;a href=&#34;https://doi.org/10.3389/fnhum.2022.976954&#34;&gt;https://doi.org/10.3389/fnhum.2022.976954&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Muraki, E. J., Speed, L. J., &amp;amp; Pexman, P. M. (2023). Insights into embodied cognition and mental imagery from aphantasia. &lt;em&gt;Nature Reviews Psychology&lt;/em&gt;, &lt;em&gt;2&lt;/em&gt;(10), 591&amp;ndash;605. &lt;a href=&#34;https://doi.org/10.1038/s44159-023-00221-9&#34;&gt;https://doi.org/10.1038/s44159-023-00221-9&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Okuno, H. Y., &amp;amp; Guedes, G. (2020). Automatic XML creation for Multisensorial Books. &lt;em&gt;2020 XV Conferencia Latinoamericana de Tecnologias de Aprendizaje (LACLO)&lt;/em&gt;, 1&amp;ndash;6. &lt;a href=&#34;https://doi.org/10.1109/LACLO50806.2020.9381139&#34;&gt;https://doi.org/10.1109/LACLO50806.2020.9381139&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ostarek, M., &amp;amp; Vigliocco, G. (2017). Reading sky and seeing a cloud: On the relevance of events for perceptual simulation. &lt;em&gt;Journal of Experimental Psychology: Learning, Memory, and Cognition&lt;/em&gt;, &lt;em&gt;43&lt;/em&gt;(4), 579&amp;ndash;590. &lt;a href=&#34;https://doi.org/10.1037/xlm0000318&#34;&gt;https://doi.org/10.1037/xlm0000318&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pecher, D. (2018). Curb Your Embodiment. &lt;em&gt;Topics in Cognitive Science&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(3), 501&amp;ndash;517. &lt;a href=&#34;https://doi.org/10.1111/tops.12311&#34;&gt;https://doi.org/10.1111/tops.12311&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pérez-Gay Juárez, F., Labrecque, D., &amp;amp; Frak, V. (2019). Assessing language-induced motor activity through Event Related Potentials and the Grip Force Sensor, an exploratory study. &lt;em&gt;Brain and Cognition&lt;/em&gt;, &lt;em&gt;135&lt;/em&gt;, 103572. &lt;a href=&#34;https://doi.org/10.1016/j.bandc.2019.05.010&#34;&gt;https://doi.org/10.1016/j.bandc.2019.05.010&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pérez-Sánchez, M. Á., Stadthagen-Gonzalez, H., Guasch, M., Hinojosa, J. A., Fraga, I., Marín, J., &amp;amp; Ferré, P. (2021). EmoPro &amp;ndash; Emotional prototypicality for 1286 Spanish words: Relationships with affective and psycholinguistic variables. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;53&lt;/em&gt;(5), 1857&amp;ndash;1875. &lt;a href=&#34;https://doi.org/10.3758/s13428-020-01519-9&#34;&gt;https://doi.org/10.3758/s13428-020-01519-9&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Perfecto, H., Galak, J., Simmons, J. P., &amp;amp; Nelson, L. D. (2017). Rejecting a bad option feels like choosing a good one. &lt;em&gt;Journal of Personality and Social Psychology&lt;/em&gt;, &lt;em&gt;113&lt;/em&gt;(5), 659&amp;ndash;670. &lt;a href=&#34;https://doi.org/10.1037/pspa0000092&#34;&gt;https://doi.org/10.1037/pspa0000092&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Perlman, M., Little, H., Thompson, B., &amp;amp; Thompson, R. L. (2018). Iconicity in Signed and Spoken Vocabulary: A Comparison Between American Sign Language, British Sign Language, English, and Spanish. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;, 1433. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2018.01433&#34;&gt;https://doi.org/10.3389/fpsyg.2018.01433&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pexman, P. M. (2019). The role of embodiment in conceptual development. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;34&lt;/em&gt;(10), 1274&amp;ndash;1283. &lt;a href=&#34;https://doi.org/10.1080/23273798.2017.1303522&#34;&gt;https://doi.org/10.1080/23273798.2017.1303522&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pexman, P. M., Muraki, E., Sidhu, D. M., Siakaluk, P. D., &amp;amp; Yap, M. J. (2019). Quantifying sensorimotor experience: Body&amp;ndash;object interaction ratings for more than 9,000 English words. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;51&lt;/em&gt;(2), 453&amp;ndash;466. &lt;a href=&#34;https://doi.org/10.3758/s13428-018-1171-z&#34;&gt;https://doi.org/10.3758/s13428-018-1171-z&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Piai, V., &amp;amp; Zheng, X. (2019). Speaking waves: Neuronal oscillations in language production. In &lt;em&gt;Psychology of Learning and Motivation&lt;/em&gt; (Vol. 71, pp. 265&amp;ndash;302). Elsevier. &lt;a href=&#34;https://doi.org/10.1016/bs.plm.2019.07.002&#34;&gt;https://doi.org/10.1016/bs.plm.2019.07.002&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Plekhanov Russian University of Economics, Simonenko, M. A., Kazaryan, S. Y., &amp;amp; Plekhanov Russian University of Economics. (2023). Synaesthetic metaphor and its reproduction in Russian-to-English translation: A frame-based study. &lt;em&gt;RESEARCH RESULT Theoretical and Applied Linguistics&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;(3). &lt;a href=&#34;https://doi.org/10.18413/2313-8912-2023-9-3-0-2&#34;&gt;https://doi.org/10.18413/2313-8912-2023-9-3-0-2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Popović Stijačić, M., &amp;amp; Filipović Đurđević, D. (2022). Perceptual richness of words and its role in free and cued recall. &lt;em&gt;Primenjena Psihologija&lt;/em&gt;, &lt;em&gt;15&lt;/em&gt;(3), 355&amp;ndash;381. &lt;a href=&#34;https://doi.org/10.19090/pp.v15i3.2400&#34;&gt;https://doi.org/10.19090/pp.v15i3.2400&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pulvermüller, F. (2018a). Neural reuse of action perception circuits for language, concepts and communication. &lt;em&gt;Progress in Neurobiology&lt;/em&gt;, &lt;em&gt;160&lt;/em&gt;, 1&amp;ndash;44. &lt;a href=&#34;https://doi.org/10.1016/j.pneurobio.2017.07.001&#34;&gt;https://doi.org/10.1016/j.pneurobio.2017.07.001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pulvermüller, F. (2018b). Neurobiological Mechanisms for Semantic Feature Extraction and Conceptual Flexibility. &lt;em&gt;Topics in Cognitive Science&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(3), 590&amp;ndash;620. &lt;a href=&#34;https://doi.org/10.1111/tops.12367&#34;&gt;https://doi.org/10.1111/tops.12367&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Purves, R. S., Striedl, P., Kong, I., &amp;amp; Majid, A. (2023). Conceptualizing Landscapes Through Language: The Role of Native Language and Expertise in the Representation of Waterbody Related Terms. &lt;em&gt;Topics in Cognitive Science&lt;/em&gt;, &lt;em&gt;15&lt;/em&gt;(3), 560&amp;ndash;583. &lt;a href=&#34;https://doi.org/10.1111/tops.12652&#34;&gt;https://doi.org/10.1111/tops.12652&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Radvansky, G. A. (2017). &lt;em&gt;Human Memory&lt;/em&gt; (3rd ed.). Routledge. &lt;a href=&#34;https://doi.org/10.4324/9781315542768&#34;&gt;https://doi.org/10.4324/9781315542768&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Radvansky, G. A. (2021). &lt;em&gt;Human Memory&lt;/em&gt; (4th ed.). Routledge. &lt;a href=&#34;https://doi.org/10.4324/9780429287039&#34;&gt;https://doi.org/10.4324/9780429287039&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Rahimi, S., Farahibozorg, S.-R., Jackson, R., &amp;amp; Hauk, O. (2022). Task modulation of spatiotemporal dynamics in semantic brain networks: An EEG/MEG study. &lt;em&gt;NeuroImage&lt;/em&gt;, &lt;em&gt;246&lt;/em&gt;, 118768. &lt;a href=&#34;https://doi.org/10.1016/j.neuroimage.2021.118768&#34;&gt;https://doi.org/10.1016/j.neuroimage.2021.118768&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Raia, R. (2023). An analysis of conceptual ambiguities in the debate on the format of concepts. &lt;em&gt;Phenomenology and the Cognitive Sciences&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.1007/s11097-023-09938-7&#34;&gt;https://doi.org/10.1007/s11097-023-09938-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Raj, R., Hörberg, T., Lindroos, R., Larsson, M., Herman, P., Laukka, E. J., &amp;amp; Olofsson, J. K. (2023). Odor identification errors reveal cognitive aspects of age-associated smell loss. &lt;em&gt;Cognition&lt;/em&gt;, &lt;em&gt;236&lt;/em&gt;, 105445. &lt;a href=&#34;https://doi.org/10.1016/j.cognition.2023.105445&#34;&gt;https://doi.org/10.1016/j.cognition.2023.105445&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Reggin, L. D., Gómez Franco, L. E., Horchak, O. V., Labrecque, D., Lana, N., Rio, L., &amp;amp; Vigliocco, G. (2023). Consensus Paper: Situated and Embodied Language Acquisition. &lt;em&gt;Journal of Cognition&lt;/em&gt;, &lt;em&gt;6&lt;/em&gt;(1), 63. &lt;a href=&#34;https://doi.org/10.5334/joc.308&#34;&gt;https://doi.org/10.5334/joc.308&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Repetto, C., Rodella, C., Conca, F., Santi, G. C., &amp;amp; Catricalà, E. (2022). The Italian Sensorimotor Norms: Perception and action strength measures for 959 words. &lt;em&gt;Behavior Research Methods&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.3758/s13428-022-02004-1&#34;&gt;https://doi.org/10.3758/s13428-022-02004-1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Rey, A. E., Riou, B., Vallet, G. T., &amp;amp; Versace, R. (2017). The automatic visual simulation of words: A memory reactivated mask slows down conceptual access. &lt;em&gt;Canadian Journal of Experimental Psychology / Revue Canadienne de Psychologie Expérimentale&lt;/em&gt;, &lt;em&gt;71&lt;/em&gt;(1), 14&amp;ndash;22. &lt;a href=&#34;https://doi.org/10.1037/cep0000100&#34;&gt;https://doi.org/10.1037/cep0000100&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Reymore, L. (2022). Characterizing prototypical musical instrument timbres with timbre trait profiles. &lt;em&gt;Musicae Scientiae&lt;/em&gt;, &lt;em&gt;26&lt;/em&gt;(3), 648&amp;ndash;674. &lt;a href=&#34;https://doi.org/10.1177/10298649211001523&#34;&gt;https://doi.org/10.1177/10298649211001523&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Robinson, M. D., Fetterman, A. K., Meier, B. P., Persich, M. R., &amp;amp; Waters, M. R. (2021). Embodied Perspectives on Personality. In M. D. Robinson &amp;amp; L. E. Thomas (Eds.), &lt;em&gt;Handbook of Embodied Psychology&lt;/em&gt; (pp. 477&amp;ndash;498). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-78471-3_21&#34;&gt;https://doi.org/10.1007/978-3-030-78471-3_21&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Robinson, M. D., &amp;amp; Thomas, L. E. (2021). Introduction to Embodied Psychology: Thinking, Feeling, and Acting. In M. D. Robinson &amp;amp; L. E. Thomas (Eds.), &lt;em&gt;Handbook of Embodied Psychology&lt;/em&gt; (pp. 1&amp;ndash;19). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-78471-3_1&#34;&gt;https://doi.org/10.1007/978-3-030-78471-3_1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;San Roque, L., Kendrick, K. H., Norcliffe, E., &amp;amp; Majid, A. (2018). Universal meaning extensions of perception verbs are grounded in interaction. &lt;em&gt;Cognitive Linguistics&lt;/em&gt;, &lt;em&gt;29&lt;/em&gt;(3), 371&amp;ndash;406. &lt;a href=&#34;https://doi.org/10.1515/cog-2017-0034&#34;&gt;https://doi.org/10.1515/cog-2017-0034&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Scerrati, E., D&#39;Ascenzo, S., Nicoletti, R., Villani, C., &amp;amp; Lugli, L. (2022). Assessing Interpersonal Proximity Evaluation in the COVID-19 Era: Evidence From the Affective Priming Task. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;13&lt;/em&gt;, 901730. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2022.901730&#34;&gt;https://doi.org/10.3389/fpsyg.2022.901730&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Scerrati, E., Iani, C., Lugli, L., Nicoletti, R., &amp;amp; Rubichi, S. (2020). Do my hands prime your hands? The hand-to-response correspondence effect. &lt;em&gt;Acta Psychologica&lt;/em&gt;, &lt;em&gt;203&lt;/em&gt;, 103012. &lt;a href=&#34;https://doi.org/10.1016/j.actpsy.2020.103012&#34;&gt;https://doi.org/10.1016/j.actpsy.2020.103012&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Scerrati, E., Iani, C., &amp;amp; Rubichi, S. (2021). Does the Activation of Motor Information Affect Semantic Processing? In L. Bechberger, K.-U. Kühnberger, &amp;amp; M. Liu (Eds.), &lt;em&gt;Concepts in Action&lt;/em&gt; (Vol. 9, pp. 153&amp;ndash;166). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-69823-2_7&#34;&gt;https://doi.org/10.1007/978-3-030-69823-2_7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Scerrati, E., Lugli, L., Nicoletti, R., &amp;amp; Borghi, A. M. (2017). The Multilevel Modality-Switch Effect: What Happens When We See the Bees Buzzing and Hear the Diamonds Glistening. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;24&lt;/em&gt;(3), 798&amp;ndash;803. &lt;a href=&#34;https://doi.org/10.3758/s13423-016-1150-2&#34;&gt;https://doi.org/10.3758/s13423-016-1150-2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Scherer, D., &amp;amp; Wentura, D. (2018). Combining the Post-Cue Task and the Perceptual Identification Task to Assess Parallel Activation and Mutual Facilitation of Related Primes and Targets. &lt;em&gt;Experimental Psychology&lt;/em&gt;, &lt;em&gt;65&lt;/em&gt;(2), 84&amp;ndash;97. &lt;a href=&#34;https://doi.org/10.1027/1618-3169/a000396&#34;&gt;https://doi.org/10.1027/1618-3169/a000396&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Schilhab, T. (2017). &lt;em&gt;Derived Embodiment in Abstract Language&lt;/em&gt;. Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-319-56056-4&#34;&gt;https://doi.org/10.1007/978-3-319-56056-4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Schulte Im Walde, S., &amp;amp; Frassinelli, D. (2022). Distributional Measures of Semantic Abstraction. &lt;em&gt;Frontiers in Artificial Intelligence&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;, 796756. &lt;a href=&#34;https://doi.org/10.3389/frai.2021.796756&#34;&gt;https://doi.org/10.3389/frai.2021.796756&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Seghier, M. L. (2023). Multiple functions of the angular gyrus at high temporal resolution. &lt;em&gt;Brain Structure and Function&lt;/em&gt;, &lt;em&gt;228&lt;/em&gt;(1), 7&amp;ndash;46. &lt;a href=&#34;https://doi.org/10.1007/s00429-022-02512-y&#34;&gt;https://doi.org/10.1007/s00429-022-02512-y&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Šetić Beg, M. (2021). Uloga utjelovljenja u razumijevanju pojmova. &lt;em&gt;Psihologijske Teme&lt;/em&gt;, &lt;em&gt;30&lt;/em&gt;(2), 371&amp;ndash;395. &lt;a href=&#34;https://doi.org/10.31820/pt.30.2.12&#34;&gt;https://doi.org/10.31820/pt.30.2.12&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Shen, G., Wang, R., Yang, M., &amp;amp; Xie, J. (2022). Chinese Children with Congenital and Acquired Blindness Represent Concrete Concepts in Vertical Space through Tactile Perception. &lt;em&gt;International Journal of Environmental Research and Public Health&lt;/em&gt;, &lt;em&gt;19&lt;/em&gt;(17), 11055. &lt;a href=&#34;https://doi.org/10.3390/ijerph191711055&#34;&gt;https://doi.org/10.3390/ijerph191711055&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Sidhu, D. M., &amp;amp; Pexman, P. M. (2018). Lonely sensational icons: Semantic neighbourhood density, sensory experience and iconicity. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;33&lt;/em&gt;(1), 25&amp;ndash;31. &lt;a href=&#34;https://doi.org/10.1080/23273798.2017.1358379&#34;&gt;https://doi.org/10.1080/23273798.2017.1358379&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speed, L. J., &amp;amp; Brybaert, M. (2022). Dutch sensory modality norms. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;54&lt;/em&gt;(3), 1306&amp;ndash;1318. &lt;a href=&#34;https://doi.org/10.3758/s13428-021-01656-9&#34;&gt;https://doi.org/10.3758/s13428-021-01656-9&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speed, L. J., &amp;amp; Majid, A. (2017). Dutch modality exclusivity norms: Simulating perceptual modality in space. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;49&lt;/em&gt;(6), 2204&amp;ndash;2218. &lt;a href=&#34;https://doi.org/10.3758/s13428-017-0852-3&#34;&gt;https://doi.org/10.3758/s13428-017-0852-3&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speed, L. J., &amp;amp; Majid, A. (2018). An Exception to Mental Simulation: No Evidence for Embodied Odor Language. &lt;em&gt;Cognitive Science&lt;/em&gt;, &lt;em&gt;42&lt;/em&gt;(4), 1146&amp;ndash;1178. &lt;a href=&#34;https://doi.org/10.1111/cogs.12593&#34;&gt;https://doi.org/10.1111/cogs.12593&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speed, L. J., &amp;amp; Majid, A. (2020). Grounding language in the neglected senses of touch, taste, and smell. &lt;em&gt;Cognitive Neuropsychology&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(5&amp;ndash;6), 363&amp;ndash;392. &lt;a href=&#34;https://doi.org/10.1080/02643294.2019.1623188&#34;&gt;https://doi.org/10.1080/02643294.2019.1623188&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speed, L. J., Papies, E. K., &amp;amp; Majid, A. (2023). Mental simulation across sensory modalities predicts attractiveness of food concepts. &lt;em&gt;Journal of Experimental Psychology: Applied&lt;/em&gt;, &lt;em&gt;29&lt;/em&gt;(3), 557&amp;ndash;571. &lt;a href=&#34;https://doi.org/10.1037/xap0000461&#34;&gt;https://doi.org/10.1037/xap0000461&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Sri-Ganeshan, M. (2021). Modality Effect. In M. Raz &amp;amp; P. Pouryahya (Eds.), &lt;em&gt;Decision Making in Emergency Medicine&lt;/em&gt; (pp. 215&amp;ndash;220). Springer Singapore. &lt;a href=&#34;https://doi.org/10.1007/978-981-16-0143-9_34&#34;&gt;https://doi.org/10.1007/978-981-16-0143-9_34&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Strik Lievers, F., &amp;amp; Winter, B. (2018). Sensory language across lexical categories. &lt;em&gt;Lingua&lt;/em&gt;, &lt;em&gt;204&lt;/em&gt;, 45&amp;ndash;61. &lt;a href=&#34;https://doi.org/10.1016/j.lingua.2017.11.002&#34;&gt;https://doi.org/10.1016/j.lingua.2017.11.002&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Su, C., Wang, X., Wang, Z., &amp;amp; Chen, Y. (2019). A model of synesthetic metaphor interpretation based on cross-modality similarity. &lt;em&gt;Computer Speech &amp;amp; Language&lt;/em&gt;, &lt;em&gt;58&lt;/em&gt;, 1&amp;ndash;16. &lt;a href=&#34;https://doi.org/10.1016/j.csl.2019.03.003&#34;&gt;https://doi.org/10.1016/j.csl.2019.03.003&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Szychowska, M., &amp;amp; Wiens, S. (2021). Visual load effects on the auditory steady-state responses to 20-, 40-, and 80-Hz amplitude-modulated tones. &lt;em&gt;Physiology &amp;amp; Behavior&lt;/em&gt;, &lt;em&gt;228&lt;/em&gt;, 113240. &lt;a href=&#34;https://doi.org/10.1016/j.physbeh.2020.113240&#34;&gt;https://doi.org/10.1016/j.physbeh.2020.113240&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tarai, S., Bit, A., Kumar, R., &amp;amp; Savekar, A. (2021). Processing of party symbols and names predicts the results of 2019 Indian parliamentary election: Analysing psycholinguistic behavioural incongruency effects. &lt;em&gt;Psychology of Language and Communication&lt;/em&gt;, &lt;em&gt;25&lt;/em&gt;(1), 264&amp;ndash;295. &lt;a href=&#34;https://doi.org/10.2478/plc-2021-0012&#34;&gt;https://doi.org/10.2478/plc-2021-0012&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tatiya, G., Hosseini, R., Hughes, M. C., &amp;amp; Sinapov, J. (2019). Sensorimotor Cross-Behavior Knowledge Transfer for Grounded Category Recognition. &lt;em&gt;2019 Joint IEEE 9th International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob)&lt;/em&gt;, 1&amp;ndash;6. &lt;a href=&#34;https://doi.org/10.1109/DEVLRN.2019.8850715&#34;&gt;https://doi.org/10.1109/DEVLRN.2019.8850715&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tatiya, G., Hosseini, R., Hughes, M. C., &amp;amp; Sinapov, J. (2020). A Framework for Sensorimotor Cross-Perception and Cross-Behavior Knowledge Transfer for Object Categorization. &lt;em&gt;Frontiers in Robotics and AI&lt;/em&gt;, &lt;em&gt;7&lt;/em&gt;, 522141. &lt;a href=&#34;https://doi.org/10.3389/frobt.2020.522141&#34;&gt;https://doi.org/10.3389/frobt.2020.522141&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tatiya, G., &amp;amp; Sinapov, J. (2019). Deep Multi-Sensory Object Category Recognition Using Interactive Behavioral Exploration. &lt;em&gt;2019 International Conference on Robotics and Automation (ICRA)&lt;/em&gt;, 7872&amp;ndash;7878. &lt;a href=&#34;https://doi.org/10.1109/ICRA.2019.8794095&#34;&gt;https://doi.org/10.1109/ICRA.2019.8794095&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Teodorescu, H.-N., &amp;amp; Bolea, S. C. (2019). Text Sectioning based on Stylometric Distances. &lt;em&gt;2019 International Conference on Speech Technology and Human-Computer Dialogue (SpeD)&lt;/em&gt;, 1&amp;ndash;6. &lt;a href=&#34;https://doi.org/10.1109/SPED.2019.8906616&#34;&gt;https://doi.org/10.1109/SPED.2019.8906616&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thomason, J., Padmakumar, A., Sinapov, J., Walker, N., Jiang, Y., Yedidsion, H., Hart, J., Stone, P., &amp;amp; Mooney, R. (2020). Jointly Improving Parsing and Perception for Natural Language Commands through Human-Robot Dialog. &lt;em&gt;Journal of Artificial Intelligence Research&lt;/em&gt;, &lt;em&gt;67&lt;/em&gt;, 327&amp;ndash;374. &lt;a href=&#34;https://doi.org/10.1613/jair.1.11485&#34;&gt;https://doi.org/10.1613/jair.1.11485&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tillman, R., &amp;amp; Louwerse, M. (2018). Estimating Emotions Through Language Statistics and Embodied Cognition. &lt;em&gt;Journal of Psycholinguistic Research&lt;/em&gt;, &lt;em&gt;47&lt;/em&gt;(1), 159&amp;ndash;167. &lt;a href=&#34;https://doi.org/10.1007/s10936-017-9522-y&#34;&gt;https://doi.org/10.1007/s10936-017-9522-y&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tjuka, A., Forkel, R., &amp;amp; List, J.-M. (2021). Linking norms, ratings, and relations of words and concepts across multiple language varieties. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;54&lt;/em&gt;(2), 864&amp;ndash;884. &lt;a href=&#34;https://doi.org/10.3758/s13428-021-01650-1&#34;&gt;https://doi.org/10.3758/s13428-021-01650-1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tomsk State University, Vladimirova, V. E., Rezanova, Z. I., Tomsk State University, Korshunova, I. S., &amp;amp; Tomsk State University. (2022). Ethno-linguistic contact as reflected in language cognition: Does bilingualism affect subjective assessments of perceptual semantics?*. &lt;em&gt;Rusin&lt;/em&gt;, &lt;em&gt;70&lt;/em&gt;, 214&amp;ndash;231. &lt;a href=&#34;https://doi.org/10.17223/18572685/70/12&#34;&gt;https://doi.org/10.17223/18572685/70/12&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Utsumi, A. (2020). Exploring What Is Encoded in Distributional Word Vectors: A Neurobiologically Motivated Analysis. &lt;em&gt;Cognitive Science&lt;/em&gt;, &lt;em&gt;44&lt;/em&gt;(6), e12844. &lt;a href=&#34;https://doi.org/10.1111/cogs.12844&#34;&gt;https://doi.org/10.1111/cogs.12844&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Valenzuela, J. (2017). &lt;em&gt;Meaning in English: An Introduction&lt;/em&gt; (1st ed.). Cambridge University Press. &lt;a href=&#34;https://doi.org/10.1017/9781316156278&#34;&gt;https://doi.org/10.1017/9781316156278&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Van De Weijer, J., Bianchi, I., &amp;amp; Paradis, C. (2023). Sensory modality profiles of antonyms. &lt;em&gt;Language and Cognition&lt;/em&gt;, 1&amp;ndash;15. &lt;a href=&#34;https://doi.org/10.1017/langcog.2023.20&#34;&gt;https://doi.org/10.1017/langcog.2023.20&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Vergallito, A., Petilli, M. A., &amp;amp; Marelli, M. (2020). Perceptual modality norms for 1,121 Italian words: A comparison with concreteness and imageability scores and an analysis of their impact in word processing tasks. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;52&lt;/em&gt;(4), 1599&amp;ndash;1616. &lt;a href=&#34;https://doi.org/10.3758/s13428-019-01337-8&#34;&gt;https://doi.org/10.3758/s13428-019-01337-8&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Verheyen, S., De Deyne, S., Linsen, S., &amp;amp; Storms, G. (2020). Lexicosemantic, affective, and distributional norms for 1,000 Dutch adjectives. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;52&lt;/em&gt;(3), 1108&amp;ndash;1121. &lt;a href=&#34;https://doi.org/10.3758/s13428-019-01303-4&#34;&gt;https://doi.org/10.3758/s13428-019-01303-4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Vigliocco, G., Zhang, Y., Del Maschio, N., Todd, R., &amp;amp; Tuomainen, J. (2020). Electrophysiological signatures of English onomatopoeia. &lt;em&gt;Language and Cognition&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(1), 15&amp;ndash;35. &lt;a href=&#34;https://doi.org/10.1017/langcog.2019.38&#34;&gt;https://doi.org/10.1017/langcog.2019.38&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Volfart, A., Rice, G. E., Lambon Ralph, M. A., &amp;amp; Rossion, B. (2021). Implicit, automatic semantic word categorisation in the left occipito-temporal cortex as revealed by fast periodic visual stimulation. &lt;em&gt;NeuroImage&lt;/em&gt;, &lt;em&gt;238&lt;/em&gt;, 118228. &lt;a href=&#34;https://doi.org/10.1016/j.neuroimage.2021.118228&#34;&gt;https://doi.org/10.1016/j.neuroimage.2021.118228&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;W, D., C, P., C, M.-L., &amp;amp; F, L. (2023). Imagining and reading actions: Towards similar motor representations. &lt;em&gt;Heliyon&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;(2), e13426. &lt;a href=&#34;https://doi.org/10.1016/j.heliyon.2023.e13426&#34;&gt;https://doi.org/10.1016/j.heliyon.2023.e13426&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wajnerman Paz, A. (2018). A Defense of an Amodal Number System. &lt;em&gt;Philosophies&lt;/em&gt;, &lt;em&gt;3&lt;/em&gt;(2), 13. &lt;a href=&#34;https://doi.org/10.3390/philosophies3020013&#34;&gt;https://doi.org/10.3390/philosophies3020013&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wajnerman Paz, A. (2019). Using neural response properties to draw the distinction between modal and amodal representations. &lt;em&gt;Philosophical Psychology&lt;/em&gt;, &lt;em&gt;32&lt;/em&gt;(3), 301&amp;ndash;331. &lt;a href=&#34;https://doi.org/10.1080/09515089.2018.1563677&#34;&gt;https://doi.org/10.1080/09515089.2018.1563677&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wajnerman-Paz, A., &amp;amp; Rojas-Líbano, D. (2022). On the role of contextual factors in cognitive neuroscience experiments: A mechanistic approach. &lt;em&gt;Synthese&lt;/em&gt;, &lt;em&gt;200&lt;/em&gt;(5), 402. &lt;a href=&#34;https://doi.org/10.1007/s11229-022-03870-0&#34;&gt;https://doi.org/10.1007/s11229-022-03870-0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wan, M., Su, Q., Ahrens, K., &amp;amp; Huang, C.-R. (2023). Perceptional and actional enrichment for metaphor detection with sensorimotor norms. &lt;em&gt;Natural Language Engineering&lt;/em&gt;, 1&amp;ndash;29. &lt;a href=&#34;https://doi.org/10.1017/S135132492300044X&#34;&gt;https://doi.org/10.1017/S135132492300044X&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wang, L., Chen, Q., Chen, Y., &amp;amp; Zhong, R. (2019). The Effect of Sweet Taste on Romantic Semantic Processing: An ERP Study. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;, 1573. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2019.01573&#34;&gt;https://doi.org/10.3389/fpsyg.2019.01573&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wang, Y., &amp;amp; Zeng, Y. (2022a). Multisensory Concept Learning Framework Based on Spiking Neural Networks. &lt;em&gt;Frontiers in Systems Neuroscience&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;, 845177. &lt;a href=&#34;https://doi.org/10.3389/fnsys.2022.845177&#34;&gt;https://doi.org/10.3389/fnsys.2022.845177&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wang, Y., &amp;amp; Zeng, Y. (2022b). Statistical Analysis of Multisensory and Text-Derived Representations on Concept Learning. &lt;em&gt;Frontiers in Computational Neuroscience&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;, 861265. &lt;a href=&#34;https://doi.org/10.3389/fncom.2022.861265&#34;&gt;https://doi.org/10.3389/fncom.2022.861265&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wassenburg, S. I., De Koning, B. B., De Vries, M. H., Boonstra, A. M., &amp;amp; Van Der Schoot, M. (2017). Gender differences in mental simulation during sentence and word processing. &lt;em&gt;Journal of Research in Reading&lt;/em&gt;, &lt;em&gt;40&lt;/em&gt;(3), 274&amp;ndash;296. &lt;a href=&#34;https://doi.org/10.1111/1467-9817.12066&#34;&gt;https://doi.org/10.1111/1467-9817.12066&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wentura, D. (2019). Cognition and emotion: On paradigms and metaphors. &lt;em&gt;Cognition and Emotion&lt;/em&gt;, &lt;em&gt;33&lt;/em&gt;(1), 85&amp;ndash;93. &lt;a href=&#34;https://doi.org/10.1080/02699931.2019.1567464&#34;&gt;https://doi.org/10.1080/02699931.2019.1567464&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wingfield, C., &amp;amp; Connell, L. (2022a). Sensorimotor distance: A grounded measure of semantic similarity for 800 million concept pairs. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;55&lt;/em&gt;(7), 3416&amp;ndash;3432. &lt;a href=&#34;https://doi.org/10.3758/s13428-022-01965-7&#34;&gt;https://doi.org/10.3758/s13428-022-01965-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wingfield, C., &amp;amp; Connell, L. (2022b). Understanding the role of linguistic distributional knowledge in cognition. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(10), 1220&amp;ndash;1270. &lt;a href=&#34;https://doi.org/10.1080/23273798.2022.2069278&#34;&gt;https://doi.org/10.1080/23273798.2022.2069278&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, A., Dudschig, C., Miller, J., Ulrich, R., &amp;amp; Kaup, B. (2022). The action-sentence compatibility effect (ACE): Meta-analysis of a benchmark finding for embodiment. &lt;em&gt;Acta Psychologica&lt;/em&gt;, &lt;em&gt;230&lt;/em&gt;, 103712. &lt;a href=&#34;https://doi.org/10.1016/j.actpsy.2022.103712&#34;&gt;https://doi.org/10.1016/j.actpsy.2022.103712&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B. (2019). &lt;em&gt;Statistics for Linguists: An Introduction Using R&lt;/em&gt; (1st ed.). Routledge. &lt;a href=&#34;https://doi.org/10.4324/9781315165547&#34;&gt;https://doi.org/10.4324/9781315165547&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B. (2022). Mapping the landscape of exploratory and confirmatory data analysis in linguistics. In D. Tay &amp;amp; M. X. Pan (Eds.), &lt;em&gt;Data Analytics in Cognitive Linguistics&lt;/em&gt; (pp. 13&amp;ndash;48). De Gruyter. &lt;a href=&#34;https://doi.org/10.1515/9783110687279-002&#34;&gt;https://doi.org/10.1515/9783110687279-002&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B. (2023). Abstract concepts and emotion: Cross-linguistic evidence and arguments against affective embodiment. &lt;em&gt;Philosophical Transactions of the Royal Society B: Biological Sciences&lt;/em&gt;, &lt;em&gt;378&lt;/em&gt;(1870), 20210368. &lt;a href=&#34;https://doi.org/10.1098/rstb.2021.0368&#34;&gt;https://doi.org/10.1098/rstb.2021.0368&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B., Fischer, M. H., Scheepers, C., &amp;amp; Myachykov, A. (2023). More is Better: English Language Statistics are Biased Toward Addition. &lt;em&gt;Cognitive Science&lt;/em&gt;, &lt;em&gt;47&lt;/em&gt;(4), e13254. &lt;a href=&#34;https://doi.org/10.1111/cogs.13254&#34;&gt;https://doi.org/10.1111/cogs.13254&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B., Perlman, M., &amp;amp; Majid, A. (2018). Vision dominates in perceptual language: English sensory vocabulary is optimized for usage. &lt;em&gt;Cognition&lt;/em&gt;, &lt;em&gt;179&lt;/em&gt;, 213&amp;ndash;220. &lt;a href=&#34;https://doi.org/10.1016/j.cognition.2018.05.008&#34;&gt;https://doi.org/10.1016/j.cognition.2018.05.008&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B., Perlman, M., Perry, L. K., &amp;amp; Lupyan, G. (2017). Which words are most iconic?: Iconicity in English sensory words. &lt;em&gt;Interaction Studies. Social Behaviour and Communication in Biological and Artificial Systems&lt;/em&gt;, &lt;em&gt;18&lt;/em&gt;(3), 443&amp;ndash;464. &lt;a href=&#34;https://doi.org/10.1075/is.18.3.07win&#34;&gt;https://doi.org/10.1075/is.18.3.07win&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B., Sóskuthy, M., Perlman, M., &amp;amp; Dingemanse, M. (2022). Trilled /r/ is associated with roughness, linking sound and touch across spoken languages. &lt;em&gt;Scientific Reports&lt;/em&gt;, &lt;em&gt;12&lt;/em&gt;(1), 1035. &lt;a href=&#34;https://doi.org/10.1038/s41598-021-04311-7&#34;&gt;https://doi.org/10.1038/s41598-021-04311-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Winter, B., &amp;amp; Strik-Lievers, F. (2023). Semantic distance predicts metaphoricity and creativity judgments in synesthetic metaphors. &lt;em&gt;Metaphor and the Social World&lt;/em&gt;, &lt;em&gt;13&lt;/em&gt;(1), 59&amp;ndash;80. &lt;a href=&#34;https://doi.org/10.1075/msw.00029.win&#34;&gt;https://doi.org/10.1075/msw.00029.win&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wu, C., &amp;amp; Mu, X. (2023). Sensory experience ratings (SERs) for 1,130 Chinese words: Relationships with other semantic and lexical psycholinguistic variables. &lt;em&gt;Linguistics Vanguard&lt;/em&gt;, &lt;em&gt;0&lt;/em&gt;(0). &lt;a href=&#34;https://doi.org/10.1515/lingvan-2022-0083&#34;&gt;https://doi.org/10.1515/lingvan-2022-0083&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Xiong, J., &amp;amp; Huang, C.-R. (2018). Somewhere in COLDNESS Lies Nibbāna: Lexical Manifestations of COLDNESS. In J.-F. Hong, Q. Su, &amp;amp; J.-S. Wu (Eds.), &lt;em&gt;Chinese Lexical Semantics&lt;/em&gt; (Vol. 11173, pp. 70&amp;ndash;81). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-04015-4_6&#34;&gt;https://doi.org/10.1007/978-3-030-04015-4_6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Xu, Y., Vignali, L., Sigismondi, F., Crepaldi, D., Bottini, R., &amp;amp; Collignon, O. (2023). Similar object shape representation encoded in the inferolateral occipitotemporal cortex of sighted and early blind people. &lt;em&gt;PLOS Biology&lt;/em&gt;, &lt;em&gt;21&lt;/em&gt;(7), e3001930. &lt;a href=&#34;https://doi.org/10.1371/journal.pbio.3001930&#34;&gt;https://doi.org/10.1371/journal.pbio.3001930&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Yan, J., Li, W., Zhang, T., Zhang, J., Jin, Z., &amp;amp; Li, L. (2023). Structural and functional neural substrates underlying the concreteness effect. &lt;em&gt;Brain Structure and Function&lt;/em&gt;, &lt;em&gt;228&lt;/em&gt;(6), 1493&amp;ndash;1510. &lt;a href=&#34;https://doi.org/10.1007/s00429-023-02668-1&#34;&gt;https://doi.org/10.1007/s00429-023-02668-1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Yasuda, M., Stins, J. F., &amp;amp; Higuchi, T. (2017). Effect of Constrained Arm Posture on the Processing of Action Verbs. &lt;em&gt;Frontiers in Neuroscience&lt;/em&gt;, &lt;em&gt;11&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.3389/fnins.2017.00057&#34;&gt;https://doi.org/10.3389/fnins.2017.00057&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Yin Zhong, &amp;amp; Chu-Ren Huang. (2020). Sweetness or Mouthfeel: A corpus-based study of the conceptualization of taste. &lt;em&gt;Linguistic Research&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(3), 359&amp;ndash;387. &lt;a href=&#34;https://doi.org/10.17250/KHISLI.37.3.202012.001&#34;&gt;https://doi.org/10.17250/KHISLI.37.3.202012.001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zappa, A., Mestre, D., Pergandi, J.-M., Bolger, D., &amp;amp; Frenck-Mestre, C. (2022). Cross-linguistic gender congruency effects during lexical access in novice L2 learners: Evidence from ERPs. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(9), 1073&amp;ndash;1098. &lt;a href=&#34;https://doi.org/10.1080/23273798.2022.2039726&#34;&gt;https://doi.org/10.1080/23273798.2022.2039726&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zeng, Y., Zhao, D., Zhao, F., Shen, G., Dong, Y., Lu, E., Zhang, Q., Sun, Y., Liang, Q., Zhao, Y., Zhao, Z., Fang, H., Wang, Y., Li, Y., Liu, X., Du, C., Kong, Q., Ruan, Z., &amp;amp; Bi, W. (2023). BrainCog: A spiking neural network based, brain-inspired cognitive intelligence engine for brain-inspired AI and brain simulation. &lt;em&gt;Patterns&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(8), 100789. &lt;a href=&#34;https://doi.org/10.1016/j.patter.2023.100789&#34;&gt;https://doi.org/10.1016/j.patter.2023.100789&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhang, M., Wu, X., &amp;amp; Wang, A. (2021). Crossmodal Nonspatial Repetition Inhibition Due to Modality Shift. &lt;em&gt;Perception&lt;/em&gt;, &lt;em&gt;50&lt;/em&gt;(2), 116&amp;ndash;128. &lt;a href=&#34;https://doi.org/10.1177/0301006620988209&#34;&gt;https://doi.org/10.1177/0301006620988209&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhang, X., Amiri, S., Sinapov, J., Thomason, J., Stone, P., &amp;amp; Zhang, S. (2023). Multimodal embodied attribute learning by robots for object-centric action policies. &lt;em&gt;Autonomous Robots&lt;/em&gt;, &lt;em&gt;47&lt;/em&gt;(5), 505&amp;ndash;528. &lt;a href=&#34;https://doi.org/10.1007/s10514-023-10098-5&#34;&gt;https://doi.org/10.1007/s10514-023-10098-5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhang, X., Sinapov, J., &amp;amp; Zhang, S. (2021, July 12). Planning Multimodal Exploratory Actions for Online Robot Attribute Learning. &lt;em&gt;Robotics: Science and Systems XVII&lt;/em&gt;. Robotics: Science and Systems 2021. &lt;a href=&#34;https://doi.org/10.15607/RSS.2021.XVII.005&#34;&gt;https://doi.org/10.15607/RSS.2021.XVII.005&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhang, Y., Mirman, D., &amp;amp; Hoffman, P. (2023). Taxonomic and thematic relations rely on different types of semantic features: Evidence from an fMRI meta-analysis and a semantic priming study. &lt;em&gt;Brain and Language&lt;/em&gt;, &lt;em&gt;242&lt;/em&gt;, 105287. &lt;a href=&#34;https://doi.org/10.1016/j.bandl.2023.105287&#34;&gt;https://doi.org/10.1016/j.bandl.2023.105287&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q. (2020a). From Linguistic Synaesthesia to Conceptual Metaphor Theory. In Q. Zhao, &lt;em&gt;Embodied Conceptualization or Neural Realization&lt;/em&gt; (Vol. 10, pp. 115&amp;ndash;128). Springer Singapore. &lt;a href=&#34;https://doi.org/10.1007/978-981-32-9315-1_7&#34;&gt;https://doi.org/10.1007/978-981-32-9315-1_7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q. (2020b). Methodology: A Corpus-Driven Approach. In Q. Zhao, &lt;em&gt;Embodied Conceptualization or Neural Realization&lt;/em&gt; (Vol. 10, pp. 19&amp;ndash;34). Springer Singapore. &lt;a href=&#34;https://doi.org/10.1007/978-981-32-9315-1_2&#34;&gt;https://doi.org/10.1007/978-981-32-9315-1_2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q., Ahrens, K., &amp;amp; Huang, C.-R. (2022). Linguistic synesthesia is metaphorical: A lexical-conceptual account. &lt;em&gt;Cognitive Linguistics&lt;/em&gt;, &lt;em&gt;33&lt;/em&gt;(3), 553&amp;ndash;583. &lt;a href=&#34;https://doi.org/10.1515/cog-2021-0098&#34;&gt;https://doi.org/10.1515/cog-2021-0098&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q., Huang, C.-R., &amp;amp; Ahrens, K. (2019). Directionality of linguistic synesthesia in Mandarin: A corpus-based study. &lt;em&gt;Lingua&lt;/em&gt;, &lt;em&gt;232&lt;/em&gt;, 102744. &lt;a href=&#34;https://doi.org/10.1016/j.lingua.2019.102744&#34;&gt;https://doi.org/10.1016/j.lingua.2019.102744&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q., &amp;amp; Long, Y. (2022). A Diachronic Study on Linguistic Synesthesia in Chinese. In M. Dong, Y. Gu, &amp;amp; J.-F. Hong (Eds.), &lt;em&gt;Chinese Lexical Semantics&lt;/em&gt; (Vol. 13250, pp. 84&amp;ndash;94). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-031-06547-7_6&#34;&gt;https://doi.org/10.1007/978-3-031-06547-7_6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, Q., Long, Y., &amp;amp; Huang, C.-R. (2020). Linguistic Synaesthesia of Mandarin Sensory Adjectives: Corpus-Based and Experimental Approaches. In J.-F. Hong, Y. Zhang, &amp;amp; P. Liu (Eds.), &lt;em&gt;Chinese Lexical Semantics&lt;/em&gt; (Vol. 11831, pp. 139&amp;ndash;146). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-38189-9_14&#34;&gt;https://doi.org/10.1007/978-3-030-38189-9_14&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhao, T., Huang, Y., Chen, D., Jiao, L., Marmolejo-Ramos, F., Wang, R., &amp;amp; Xie, J. (2020). The modality switching costs of Chinese&amp;ndash;English bilinguals in the processing of L1 and L2. &lt;em&gt;Quarterly Journal of Experimental Psychology&lt;/em&gt;, &lt;em&gt;73&lt;/em&gt;(3), 396&amp;ndash;412. &lt;a href=&#34;https://doi.org/10.1177/1747021819878089&#34;&gt;https://doi.org/10.1177/1747021819878089&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhong, J., Peniak, M., Tani, J., Ogata, T., &amp;amp; Cangelosi, A. (2019). Sensorimotor input as a language generalisation tool: A neurorobotics model for generation and generalisation of noun-verb combinations with sensorimotor inputs. &lt;em&gt;Autonomous Robots&lt;/em&gt;, &lt;em&gt;43&lt;/em&gt;(5), 1271&amp;ndash;1290. &lt;a href=&#34;https://doi.org/10.1007/s10514-018-9793-7&#34;&gt;https://doi.org/10.1007/s10514-018-9793-7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhong, Y., Huang, C.-R., &amp;amp; Dong, S. (2022). Bodily sensation and embodiment: A corpus-based study of gustatory vocabulary in Mandarin Chinese. &lt;em&gt;Journal of Chinese Linguistics&lt;/em&gt;, &lt;em&gt;50&lt;/em&gt;(1), 196&amp;ndash;230. &lt;a href=&#34;https://doi.org/10.1353/jcl.2022.0008&#34;&gt;https://doi.org/10.1353/jcl.2022.0008&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhong, Y., Wan, M., Ahrens, K., &amp;amp; Huang, C.-R. (2022). Sensorimotor norms for Chinese nouns and their relationship with orthographic and semantic variables. &lt;em&gt;Language, Cognition and Neuroscience&lt;/em&gt;, &lt;em&gt;37&lt;/em&gt;(8), 1000&amp;ndash;1022. &lt;a href=&#34;https://doi.org/10.1080/23273798.2022.2035416&#34;&gt;https://doi.org/10.1080/23273798.2022.2035416&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhu, S., Wang, X., &amp;amp; Liu, P. (2021). Who Killed Sanmao and Virginia Woolf? A Comparative Study of Writers with Suicidal Attempt Based on a Quantitative Linguistic Method. In M. Liu, C. Kit, &amp;amp; Q. Su (Eds.), &lt;em&gt;Chinese Lexical Semantics&lt;/em&gt; (Vol. 12278, pp. 408&amp;ndash;420). Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-81197-6_34&#34;&gt;https://doi.org/10.1007/978-3-030-81197-6_34&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Гарах, Ж. В., Ребрейкина, А. Б., Стрелец, В. Б., Голикова, А. В., &amp;amp; Зайцева, Ю. С. (2019). НЕЙРОФИЗИОЛОГИЧЕСКИЕ МЕХАНИЗМЫ ЧТЕНИЯ. &lt;em&gt;Журнал высшей нервной деятельности им И П Павлова&lt;/em&gt;, &lt;em&gt;69&lt;/em&gt;(3), 294&amp;ndash;313. &lt;a href=&#34;https://doi.org/10.1134/S0044467719030055&#34;&gt;https://doi.org/10.1134/S0044467719030055&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Modality switch effects emerge early and increase throughout conceptual processing: Evidence from ERPs</title>
      <link>https://pablobernabeu.github.io/2017/modality-switch-effects-emerge-early-and-increase-throughout-conceptual-processing-evidence-from-erps/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://pablobernabeu.github.io/2017/modality-switch-effects-emerge-early-and-increase-throughout-conceptual-processing-evidence-from-erps/</guid>
      <description>&lt;p&gt;Research has extensively investigated whether conceptual processing is modality-specific—that is, whether meaning is processed to a large extent on the basis of perceptual and motor affordances (Barsalou, 2016). This possibility challenges long-established theories. It suggests a strong link between physical experience and language which is not borne out of the paradigmatic arbitrariness of words (see Lockwood, Dingemanse, &amp;amp; Hagoort, 2016). Modality-specificity also clashes with models of language that have no link to sensory and motor systems (Barsalou, 2016).&lt;/p&gt;
&lt;a href=&#39;https://pablobernabeu.github.io/publication/bernabeu-etal-2017/&#39;&gt;
      &lt;button style = &#34;background-color: white; color: black; border: 2px solid #4CAF50; border-radius: 12px;&#34;&gt;
      &lt;h3 style = &#34;margin-top: 7px !important; margin-left: 9px !important; margin-right: 9px !important;&#34;&gt; 
      &lt;span style=&#34;color:#DBE6DA;&#34;&gt;&lt;i class=&#34;fas fa-mouse-pointer&#34;&gt;&lt;/i&gt;&lt;/span&gt;&amp;nbsp; Conference paper &lt;/h3&gt;&lt;/button&gt;&lt;/a&gt; &amp;nbsp; 
&lt;a href=&#39;https://pablobernabeu.github.io/publication/bernabeu-2017-mphil-thesis/&#39;&gt;
      &lt;button style = &#34;background-color: white; color: black; border: 2px solid #196F27; border-radius: 12px;&#34;&gt;
      &lt;h3 style = &#34;margin-top: 7px !important; margin-left: 9px !important; margin-right: 9px !important;&#34;&gt; 
      &lt;span style=&#34;color:#DBE6DA;&#34;&gt;&lt;i class=&#34;fas fa-mouse-pointer&#34;&gt;&lt;/i&gt;&lt;/span&gt;&amp;nbsp; Master&#39;s thesis &lt;/h3&gt;&lt;/button&gt;&lt;/a&gt; &amp;nbsp; 
&lt;br&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.researchgate.net/post/Conceptual_modality_switch_effect_measured_at_first_word&#34;&gt;Early discussion on ResearchGate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://osf.io/97unm/&#34;&gt;Data and code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pablobernabeu.github.io/applications-and-dashboards/bernabeu-etal-2017-modalityswitch/&#34;&gt;Data dashboard&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the Conceptual Modality Switch (CMS) paradigm, participants perform a property verification task, deciding whether certain property words can reasonably describe concept words. Covertly, the conceptual modality of consecutive trials is manipulated in order to produce specific switches in conceptual modality. For instance, after the trial &lt;em&gt;Soundless Answer&lt;/em&gt;, which is primarily auditory, the following trial may match in modality—&lt;em&gt;Loud Welcome&lt;/em&gt;—or mismatch—&lt;em&gt;Fine Selection&lt;/em&gt; (visual).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;designoverview.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Modality switches incur processing costs, as reflected in brain signals linked to semantic violation, and in longer response times (RTs) (Scerrati, Lugli, Nicoletti, &amp;amp; Borghi, 2016). This effect suggests that perceptual features of concepts are accessed during conceptual processing. More recently, however, the CMS effect was reanalysed using a non-perceptual alternative. Louwerse and Connell (2011) found that language statistics (the co-occurrence of words in a language) were able to approximately predict visual/haptic, olfactory/gustatory, and auditory modalities, but not the subtler differences between visual and haptic and between olfactory and gustatory, which seemed to be reserved for perceptual simulations. Moreover, faster response times (RTs) were best explained by language statistics, whereas slower RTs were best explained by perceptual simulations.&lt;/p&gt;
&lt;p&gt;The time course of word processing is important. Research suggests that word processing spans one second, during which different processes—semantic and post-semantic—gradually accumulate (Hauk, 2016). The later an effect, the more reasons to question it. Yet, having an early emergence does not either make an effect lexicosemantic, as the meaning encoded could have gone through working memory before activating the actual system of interest, e.g., sensorimotor (Mahon &amp;amp; Caramazza, 2008). Research also suggests that modal systems may contribute to conceptual processing early on—within 200 ms (Vukovic, Feurra, Shpektor, Myachykov, &amp;amp; Shtyrov, 2017). Thus, measuring effects online may prove valuable.&lt;/p&gt;
&lt;h2 id=&#34;experiment&#34;&gt;Experiment&lt;/h2&gt;
&lt;p&gt;Bernabeu, Willems and Louwerse (2017) investigated whether CMS reflects a functionally relevant process of simulation or instead arises only after basic conceptual processing has been attained. We also examined whether different processing systems, amodal and modal, may compatibly operate.&lt;/p&gt;
&lt;p&gt;We measured CMS online by time-locking Event-Related brain Potentials (ERPs) to the onset of the first word in the target trials, in order to assess how strongly CMS may be influenced by post-semantic processes. Previous research would predict an increase in the CMS effect over time because earlier processing is relatively amodal (Louwerse &amp;amp; Hutchinson, 2012).&lt;/p&gt;
&lt;p&gt;We tested the compatibility of amodal and modal processing by drawing on Louwerse and Connell’s (2011) findings. In this conceptual replication, we split participants into a Quick and a Slow group based on RT. Maintaining CMS as a within-subjects factor, we predicted that the larger modality switches (e.g., auditory to visual) would be picked up equally by both groups, whereas the subtler switches (e.g., haptic to visual) would be picked up only—or more clearly—by the Slow group.&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;p&gt;The stimuli were normed (Bernabeu, Louwerse, &amp;amp; Willems, in prep.). Three CMS conditions were created—Auditory-to-visual, Haptic-to-visual, Visual-to-visual—, each with 36 target trials. The property verification task was pretested valid (&lt;em&gt;N&lt;/em&gt; = 19).&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;All participants but one responded correctly to over half of the trials, with an overall accuracy of 63%.&lt;/p&gt;
&lt;p&gt;ERPs showed a CMS effect from time window 1 on, larger after 350 ms. It appeared with both switch conditions, and was characterized by a more negative amplitude for the switch conditions compared to the no-switch condition. It was generally stronger in the posterior brain regions, and in the Slow group. The results are illustrated in the figure below, which includes 95% Confidence Intervals and time windows.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;stackERPs.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img style = &#34;float: right; margin-left: 30px;&#34; width = &#39;50%&#39; src=&#39;results.jpg&#39; /&gt;&lt;/p&gt;
&lt;p&gt;The analysis was done with Linear Mixed Effects models. Final models presented good fits, with R&lt;sup&gt;2&lt;/sup&gt; ranging from .748 to .862. First, the CMS effect in time window 1 was confirmed significant. Such an early emergence is unprecedented in the CMS literature, and it may have been enabled by the time-locking of ERPs to the first word in target trials. In this time window, the only process not lexicosemantic is possibly working memory (Hauk, 2016), and therefore this early emergence adds support to the possibility that CMS was directly caused by perceptual simulation.&lt;/p&gt;
&lt;p&gt;Whereas in time window 1, the effect was circumscribed to an interaction with Brain Area, by Time Window 2, a main effect of CMS emerged. In Windows 3 and 4, the only experimental effect was CMS.&lt;/p&gt;
&lt;p&gt;Bonferroni-corrected, planned ANOVA contrasts into CMS conditions revealed that the no-switch condition differed significantly from the switch conditions. By contrast, the switch conditions (Haptic-to-visual and Auditory-to-visual) hardly differed from each other, underscoring the CMS effect.&lt;/p&gt;
&lt;p&gt;Although the interaction of Group and CMS was only significant in Time Windows 1 and 2, Windows 2 to 4 presented a pattern fitting our predictions (Louwerse &amp;amp; Connell, 2011). While the Slow group picked up the switches across all modalities similarly, the Quick group picked up the Auditory-to-visual switch more clearly than the Haptic-to-visual switch.&lt;/p&gt;
&lt;h3 id=&#34;statistical-analysishttpsosfiosx3nw&#34;&gt;&lt;a href=&#34;https://osf.io/sx3nw/&#34;&gt;Statistical analysis&lt;/a&gt;&lt;/h3&gt;
&lt;style&gt;.embed-responsive{position:relative;height:100%;}.embed-responsive iframe{position:absolute;height:100%;}&lt;/style&gt;&lt;script&gt;window.jQuery || document.write(&#39;&lt;script src=&#34;//code.jquery.com/jquery-1.11.2.min.js&#34;&gt;\x3C/script&gt;&#39;) &lt;/script&gt;&lt;link href=&#34;https://mfr.osf.io/static/css/mfr.css&#34; media=&#34;all&#34; rel=&#34;stylesheet&#34;&gt;&lt;div id=&#34;mfrIframe&#34; class=&#34;mfr mfr-file&#34;&gt;&lt;/div&gt;&lt;script src=&#34;https://mfr.osf.io/static/js/mfr.js&#34;&gt;&lt;/script&gt; &lt;script&gt;var mfrRender = new mfr.Render(&#34;mfrIframe&#34;, &#34;https://mfr.osf.io/render?url=https://osf.io/sx3nw/?direct%26mode=render%26action=download%26mode=render&#34;);&lt;/script&gt;
&lt;h2 id=&#34;discussion&#34;&gt;Discussion&lt;/h2&gt;
&lt;p&gt;Results broadly suggest that cognition may operate on qualitatively different systems for the same task. In conceptual processing, one of these systems appears to be modality-independent, potentially based on linguistic co-occurrences, whereas another system is modality-specific, linked to physical experience.&lt;/p&gt;
&lt;p&gt;A conference poster with further analyses is &lt;a href=&#34;https://mfr.osf.io/render?url=https://osf.io/dj52n/?direct%26mode=render%26action=download%26mode=render&#34;&gt;also available&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;div style = &#34;text-indent:-2em; margin-left:2em;&#34;&gt;
&lt;p&gt;Barsalou, L. W. (2016). On staying grounded and avoiding quixotic dead ends. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review, 23&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Bernabeu, P., Louwerse, M. M., &amp;amp; Willems, R. M. (in prep.). Modality exclusivity norms for 747 properties and concepts in Dutch: a replication of English. Retrieved from &lt;a href=&#34;https://osf.io/brkjw/&#34;&gt;https://osf.io/brkjw/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bernabeu, P., Willems, R. M., &amp;amp; Louwerse, M. M. (2017). Modality switch effects emerge early and increase throughout conceptual processing: Evidence from ERPs. In G. Gunzelmann, A. Howes, T. Tenbrink, &amp;amp; E. J. Davelaar (Eds.), &lt;em&gt;Proceedings of the 39th Annual Conference of the Cognitive Science Society&lt;/em&gt; (pp. 1629-1634). Austin, TX: Cognitive Science Society. &lt;a href=&#34;https://doi.org/10.31234/osf.io/a5pcz&#34;&gt;https://doi.org/10.31234/osf.io/a5pcz&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hauk, O. (2016). Only time will tell—Why temporal information is essential for our neuroscientific understanding of semantics. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review, 23&lt;/em&gt;, 4, 1072-1079.&lt;/p&gt;
&lt;p&gt;Lockwood, G., Hagoort, P., &amp;amp; Dingemanse, M. (2016). How iconicity helps people learn new words: neural correlates and individual differences in sound-symbolic bootstrapping. &lt;em&gt;Collabra, 2&lt;/em&gt;, 1, 7.&lt;/p&gt;
&lt;p&gt;Louwerse, M., &amp;amp; Connell, L. (2011). A taste of words: linguistic context and perceptual simulation predict the modality of words. &lt;em&gt;Cognitive Science, 35&lt;/em&gt;, 2, 381-98.&lt;/p&gt;
&lt;p&gt;Louwerse, M., &amp;amp; Hutchinson, S. (2012). Neurological evidence linguistic processes precede perceptual simulation in conceptual processing. &lt;em&gt;Frontiers in Psychology, 3&lt;/em&gt;, 385.&lt;/p&gt;
&lt;p&gt;Mahon, B. Z., &amp;amp; Caramazza, A. (2008). A critical look at the Embodied Cognition Hypothesis and a new proposal for grounding conceptual content. &lt;em&gt;Journal of Physiology - Paris, 102&lt;/em&gt;, 59-70.&lt;/p&gt;
&lt;p&gt;Scerrati, E., Lugli, L., Nicoletti, R., &amp;amp; Borghi, A. M. (2016). The Multilevel Modality-Switch Effect: What Happens When We See the Bees Buzzing and Hear the Diamonds Glistening. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, doi:10.3758/s13423-016-1150-2.&lt;/p&gt;
&lt;p&gt;Vukovic, V., Feurra, M., Shpektor, A., Myachykov, A., &amp;amp; Shtyrov, Y. (2017). Primary motor cortex functionally contributes to language comprehension: An online rTMS study. &lt;em&gt;Neuropsychologia, 96&lt;/em&gt;, 222-229.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
